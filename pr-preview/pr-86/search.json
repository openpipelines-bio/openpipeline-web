[
  {
    "objectID": "fundamentals/concepts.html",
    "href": "fundamentals/concepts.html",
    "title": "Concepts",
    "section": "",
    "text": "Goals\nOpenPipelines strives to provide easy ways to interact with the pipeline and/or codebase for three types of users:\n\nPipeline executor: runs the pipeline from a GUI side\nPipeline editor: adapts pipelines with existing components for specific projects\nComponent developer: develops novel components and or pipelines\n\nThis means that openpipelines must be:\n\nUsable by non-experts\nEasy to deploy\nProvide reproducable results\nScalable\nEasy to maintain and adapt\n\n\n\nRequirements\nTo meet these demands, the following concepts have been implemented at the core of Openpipeline:\n\nüåç A language independent framework\nüíæ A versitile storage solution\nüî≥ Modularity\nüîÄ A best-practice pipeline layout\n‚åõ Versioning\n‚úÖ Automatic testing\nüí¨ Community input\nüì∫ A graphical interace\n\n\n\nA common file format: AnnData and MuData üíæ\nOne of the core principals of OpenPipelines is to use MuData as a common data format throughout the whole pipeline. This means that the input and output for most components and workflows will be a MuData file and converters from and to other common data formats are provided to improve compatibility with up-and downstream applications. Choosing a common data format greatly diminishes the development complexity because it facilitates interfacing between different tools in a pipeline without needing to convert multiple times.\nMuData is a format to store annotated multimodal data. It is derived from the AnnData format. If you are unfamiliar with AnnData or MuData, it is recommended to read up on AnnData first as it is the unimodal counterpart of MuData. MuData can be roughly described as collection of several AnnData objects (stored as a associative array in the .mod attribute). MuData provides a hierarchical way to store the data:\nMuData\n‚îú‚îÄ .mod\n‚îÇ  ‚îú‚îÄ modality_1 (AnnData Object)\n‚îÇ     ‚îú‚îÄ .X\n‚îÇ     ‚îú‚îÄ .layers\n‚îÇ         ‚îú‚îÄ layer_1 \n‚îÇ         ‚îú‚îÄ ...\n‚îÇ     ‚îú‚îÄ .var\n‚îÇ     ‚îú‚îÄ .obs\n‚îÇ     ‚îú‚îÄ .obsm\n‚îÇ     ‚îú‚îÄ .varm\n‚îÇ     ‚îú‚îÄ .uns\n‚îÇ  ‚îú‚îÄ modality_2 (AnnData Object)\n‚îú‚îÄ .var\n‚îú‚îÄ .obs\n‚îú‚îÄ .obms\n‚îú‚îÄ .varm\n‚îú‚îÄ .uns\n\n.mod: an associative array of AnnData objects. Used in OpenPipelines to store the different modalities (CITE-seq, RNA abundance, ‚Ä¶)\n.X and .layers: matrices storing the measurements with the columns being the variables measured and the rows being the observations (cells in most cases).\n.var: metadata for the variables (i.e.¬†annotation for the columns of .X or any matrix in .layers). The number of rows in the .var datafame (or the length of each entry in the dictionairy) is equal to the number of columns in the measurement matrices.\n.obs: metadata for the observations (i.e.¬†annotation for the rows of .X or any matrix in .layers). The number of rows in the .obs datafame (or the length of each entry in the dictionairy) is equal to the number of rows in the measurement matrices.\nvarm: the multi-dimensional variable annotation. A key-dataframe mapping where the number of rows in each dataframe is equal to the number of columns in the measurement matrices.\nobsm: the multi-dimensional observation annotation. A key-dataframe mapping where the number of rows in each dataframe is equal to the number of rows in the measurement matrices.\n.uns: A mapping where no restrictions are enforced on the dimensions of the data.\n\n\n\nModularity and a language independent framework üî≥\nTODO\n\n\nA graphical interface üì∫\nTODO"
  },
  {
    "objectID": "fundamentals/philosophy.html",
    "href": "fundamentals/philosophy.html",
    "title": "Philosophy",
    "section": "",
    "text": "Mission\nOpenPipelines are best-practice living workflows for single-cell uni- and multi-omics data. Building a best-practice pipeline requires knowledge and time that not one single person can provide, but rather requires input from a community. Additionally, a best-pratice pipeline needs constant maintenance to keep up to date with the latest standards, ideally sourcing input from a ‚Äòliving‚Äô benchmark. Continuous improvement necessitates a robust system for sourcing and applying community input both from a technical and organisational standpoint.\n\n\n\n\ngraph TB\n  ben[\"üå±üìà Living benchmarks\"]\n  pra[\"üå±üìñ Living best practices\"]\n  pip[\"üå±‚öôÔ∏è Living reproducible pipelines\"]\n  ben --&gt; pra --&gt; pip"
  },
  {
    "objectID": "fundamentals/roadmap.html",
    "href": "fundamentals/roadmap.html",
    "title": "Roadmap",
    "section": "",
    "text": "flowchart LR\n  classDef done fill:#a3f6cf,stroke:#000000;\n  classDef wip fill:#f4cb93,stroke:#000000;\n  classDef unprocessed fill:#afadff,stroke:#000000;\n\n  Raw1[Sample 1] --&gt; Split1[/Split\\nmodalities/]:::done --&gt; ProcGEX1 & ProcRNAV1 & ProcADT1 & ProcATAC1 & ProcVDJ1\n  ProcGEX1[/Process GEX\\nprofile/]:::done --&gt; ConcatGEX[/Concatenate\\nprofiles/]:::done --&gt; ProcGEX[/Process GEX\\nprofiles/]:::done\n  ProcRNAV1[/Process RNAV\\nprofile/]:::wip --&gt; ConcatRNAV[/Concatenate\\nprofiles/]:::done --&gt; ProcRNAV[/Process RNAV\\nprofiles/]:::wip\n  ProcADT1[/Process ADT\\nprofile/]:::done --&gt; ConcatADT[/Concatenate\\nprofiles/]:::done --&gt; ProcADT[/Process ADT\\nprofiles/]:::done\n  ProcATAC1[/Process ATAC\\nprofile/]:::unprocessed --&gt; ConcatATAC[/Concatenate\\nprofiles/]:::done --&gt; ProcATAC[/Process ATAC\\nprofiles/]:::unprocessed\n  ProcVDJ1[/Process VDJ\\nprofile/]:::unprocessed --&gt; ConcatVDJ[/Concatenate\\nprofiles/]:::done --&gt; ProcVDJ[/Process VDJ\\nprofiles/]:::unprocessed\n  ProcGEX & ProcRNAV & ProcADT & ProcATAC & ProcVDJ --&gt; Merge[/Merge\\nmodalities/]:::done --&gt; SetupIntegration[/Setup\\nintegration/]:::done --&gt; Integration[/Integration/]:::done\n\n\nFigure¬†1: Status of implemented components. Green: implemented, orange: work in progress, purple: modality included in output but unprocessed,\nGEX: Gene-expression. RNAV: RNA Velocity. ADT: Antibody-Derived Tags. ATAC: Assay for Transposase-Accessible Chromatin."
  },
  {
    "objectID": "more_information/index.html",
    "href": "more_information/index.html",
    "title": "More information",
    "section": "",
    "text": "Cheat sheets: Cheat sheets for various tools\n  \n  \n    Code of conduct: Our DEI values\n  \n  \n    FAQ: Frequently Asked Questions\n  \n\n\nNo matching items"
  },
  {
    "objectID": "more_information/faq.html",
    "href": "more_information/faq.html",
    "title": "FAQ",
    "section": "",
    "text": "It is possible to add additional resources such as a file containing helper functions or other resources. All you need to do is list those files under the functionality.resources section of your component and refer to them in your script using meta[\"resources_dir\"] + \"/myresource.txt\". Please visit the Viash documentation for concrete examples on how to add helper functions and other resources to your component."
  },
  {
    "objectID": "more_information/faq.html#how-can-i-add-an-external-resource-to-my-viash-component",
    "href": "more_information/faq.html#how-can-i-add-an-external-resource-to-my-viash-component",
    "title": "FAQ",
    "section": "",
    "text": "It is possible to add additional resources such as a file containing helper functions or other resources. All you need to do is list those files under the functionality.resources section of your component and refer to them in your script using meta[\"resources_dir\"] + \"/myresource.txt\". Please visit the Viash documentation for concrete examples on how to add helper functions and other resources to your component."
  },
  {
    "objectID": "more_information/faq.html#what-does-__merge__-do",
    "href": "more_information/faq.html#what-does-__merge__-do",
    "title": "FAQ",
    "section": "What does __merge__ do?",
    "text": "What does __merge__ do?\nThe __merge__ field is used to merge another YAML into a Viash config. One of its uses is in making sure that all of the components in a task has the same API.\nEach task in OpenProblems contains strict definitions of the input/output file interface of its components and the file formats of those files. These interfaces are stored as YAML files in the api subdirectory of each task."
  },
  {
    "objectID": "user_guide/index.html",
    "href": "user_guide/index.html",
    "title": "User Guide",
    "section": "",
    "text": "Getting started: Setting up infrastructure\n  \n  \n    Running pipelines: Run a pipeline from CLI or Nextflow Tower\n  \n  \n    Passing parameter lists: Pass a large number of inputs to a workflow\n  \n  \n    Ingestion: From sequencing to count tables\n  \n  \n    Processing: From count tables to integrated data\n  \n  \n    Downstream: Celltyping and cell-cell communication\n  \n  \n    Bug reports: How to report bugs\n  \n\n\nNo matching items"
  },
  {
    "objectID": "contributing/pull_requests.html",
    "href": "contributing/pull_requests.html",
    "title": "Publishing your changes",
    "section": "",
    "text": "After ensuring that the implemented changes pass all relevant tests and meets the contribution guidelines, you can create a pull request following the steps below."
  },
  {
    "objectID": "contributing/pull_requests.html#step-1-merge-upstream-repository",
    "href": "contributing/pull_requests.html#step-1-merge-upstream-repository",
    "title": "Publishing your changes",
    "section": "Step 1: Merge upstream repository",
    "text": "Step 1: Merge upstream repository\nBefore you contribute your changes need to merge the upstream main branch into your fork. This ensures that your changes are based on the latest version of the code.\nTo do this, enter the following commands adapted from Syncing a Fork in your terminal or command prompt:\n# add the upstream repository to your local repository\ngit remote add upstream https://github.com/openpipelines-bio/openpipeline.git\n# download the changes from the openpipelines repo\ngit fetch upstream\n# change your current branch to the branch of the pull request\ngit checkout &lt;feature_branch&gt;\n# merge the changes from upstream into your branch\ngit merge upstream/main\n# push the updates, your pull request will also be updated\ngit push"
  },
  {
    "objectID": "contributing/pull_requests.html#step-2-edit-changelog",
    "href": "contributing/pull_requests.html#step-2-edit-changelog",
    "title": "Publishing your changes",
    "section": "Step 2: Edit changelog",
    "text": "Step 2: Edit changelog\nAdd an entry to the CHANGELOG.md file describing the proposed changes."
  },
  {
    "objectID": "contributing/pull_requests.html#step-3-create-pull-request",
    "href": "contributing/pull_requests.html#step-3-create-pull-request",
    "title": "Publishing your changes",
    "section": "Step 3: Create pull request",
    "text": "Step 3: Create pull request\nThe following steps were adapted from Creating a pull request from a fork\n\nGo to https://github.com/openpipelines-bio/openpipeline/pulls.\nClick on the New pull request button.\nOn the compare page click on the link compare across forks below the title. \nOn the right side in the head section select your fork repo and the correct branch you want to merge.\nClick on Create pull request.\nConstruct your PR by giving it a title and description.\nMake sure you select the box below the description Allow edits from maintainers.\nIf the PR is ready for review click the button Create Pull Request. Otherwise you can click the arrow next to the button and select Create Draft Pull Request and click the button when it changes."
  },
  {
    "objectID": "contributing/pull_requests.html#next-steps",
    "href": "contributing/pull_requests.html#next-steps",
    "title": "Publishing your changes",
    "section": "Next steps",
    "text": "Next steps\n\nGithub Actions\nWhenever a Pull Request (including draft) is created a github workflow will perform checks. These checks need to be succesful as a minimum requirement before a merge can be done. When there are errors in the checks, try to fix them while waiting on a review. If it is not possible to fix the error, add a comment to the PR to let the reviewers know.\n\n\nReview\nYour PR will be reviewed by maintainers of OpenPipelines. During the review, you can be asked for changes to the code."
  },
  {
    "objectID": "contributing/creating_components.html",
    "href": "contributing/creating_components.html",
    "title": "Creating components",
    "section": "",
    "text": "One of the core principals of OpenPipelines is to use MuData as a common data format troughout the whole pipeline. See the concepts page for more information on openpipelines uses MuData to store single-cell data."
  },
  {
    "objectID": "contributing/creating_components.html#a-common-file-format",
    "href": "contributing/creating_components.html#a-common-file-format",
    "title": "Creating components",
    "section": "",
    "text": "One of the core principals of OpenPipelines is to use MuData as a common data format troughout the whole pipeline. See the concepts page for more information on openpipelines uses MuData to store single-cell data."
  },
  {
    "objectID": "contributing/creating_components.html#component-location",
    "href": "contributing/creating_components.html#component-location",
    "title": "Creating components",
    "section": "Component location",
    "text": "Component location\nAs discussed in the project structure, components in the repository are stored within src. Additionally, components are grouped into namespaces, according to a common functionality. An example of such a namespace is the dimensionality reduction namespace (dimred), of which the components pca and umap are members. This means that within src, the namespace folders can be found that stores the components that belong to these namespaces.\nIn order to create a new component in OpenPipelines, you will need to create a new folder that will contain the different elements of the component:\nmkdir src/my_namespace/my_component\n\n\n\n\n\n\nTip\n\n\n\nTake a look at the components that are already in src/! There might be a component that already does something similar to what you need."
  },
  {
    "objectID": "contributing/creating_components.html#the-elements-of-a-component",
    "href": "contributing/creating_components.html#the-elements-of-a-component",
    "title": "Creating components",
    "section": "The elements of a component",
    "text": "The elements of a component\nA component consists of one or more scripts that provide the functionality of the component together with metadata of the component in a configuration file. The Viash config contains metadata of your dataset, which script is used to run it, and the required dependencies. An in-depth guide on how to create components is available on the viash website, but a few specifics and guidelines will be discussed here."
  },
  {
    "objectID": "contributing/creating_components.html#the-config",
    "href": "contributing/creating_components.html#the-config",
    "title": "Creating components",
    "section": "The config",
    "text": "The config\nfunctionality:\n  name: \"my_component\"\n  namespace: \"my_namespace\"\n  description: \"My new custom component\"\n  authors:\n    - __merge__: ../../authors/my_name.yaml\n      roles: [ author ]\n  arguments:\n    - name: \"--output\"\n      type: file\n      example: \"output_file.h5mu\"\n      description: \"Location were the output file should be written to.\"\n      direction: \"output\"\n  resources:\n    - type: python_script\n      path: script.py\nplatforms:\n  - type: docker\n    image: python:3.11\n    setup:\n      - type: python\n        packages: mudata~=0.2.3\n  - type: nextflow\n    directives:\n      label: [highcpu, midmem]\n\nBasic information\nEach component should have the name, a namespace, a description and author information defined in the config. Because a single author can contribute to multiple components, the author information is often duplicated across components, which was causing issues with the author information being out of date and not easy to maintain. Therefore, it was decided to move author information to ./src/authors. Each author has a yaml file containing the author information, and the viash __merge__ property is used to merge this information into the viash configs.\nBasic information checklist:\n\nGive the component a name\nAdd the component to an appropriate namespace\nAdd a description\nAdd author information\n\n\n\nArguments and argument groups\nIf you component requires arguments, they should be defined in arguments or argument_groups. Try tro group individual arguments into argument_groups when the number of arguments become too larg (10 or more as a rule of thumb).\nArgument checklist:\n\nAdd a description and name\nEach argument should have the appropriate type.\nInput and output files should be of type file instead of string and use the appropriate direction:\nIf possible: add an example\nIf the argument can accept multiple values, add multiple: true\nIf the possible input for an argument is limited to certain set of values, use choices:\n\n\n\n(Test)resources\nResources define files that are required for a component to perform its function. These can be scripts, but also additional files like settings for tools you might require. Defining resources is both a necessity because viash needs to know what code to execute, but defining resources also has the added benefit that these resources are automatically made available, regardless of the build environment. For example: resources are automatically mounted within a running docker container.\nThere is a difference between defining resources and test_resources. While resources are required for a component to function, test_resources only need to be included when testing the component (with for example viash test) in addition to the regular resources. Having a look at the example above, resources are defined using the resources: property. It takes a list of multiple files or folders.\nIn openpipelines, it was decided to not use a service like git lfs to include large resources into the repository. Instead, if large resources are required, there are two possibilities: * Large resources required for testing are to uploaded into an s3 bucket that is synced automatically before running tests (both locally and on github). Please ping a maintainer when you open a PR and ask them to upload the files for you. * Other large resources that are not needed for testing can be considered as input. This means that an argument of type: file needs to be created. The downside of this method is that viash is not able to natively support remote files f\nResources checklist: - Script resources are located next to the config and added to the config with the correct type (python_script, r_script, ‚Ä¶) - Small resources (&lt;50MB) that are not scripts can also be checked in into the repo, next to the\n\n\nThe script file\nTODO\n\n\nAuthor information\nTODO"
  },
  {
    "objectID": "contributing/creating_components.html#adding-dependencies",
    "href": "contributing/creating_components.html#adding-dependencies",
    "title": "Creating components",
    "section": "Adding dependencies",
    "text": "Adding dependencies\nTODO"
  },
  {
    "objectID": "contributing/creating_components.html#building-components-from-their-source",
    "href": "contributing/creating_components.html#building-components-from-their-source",
    "title": "Creating components",
    "section": "Building components from their source",
    "text": "Building components from their source\nWhen running or testing individual components, it is not necessary to execute an extra command to run the build step, viash test and viash run will build the component on the fly. However, before integrating components into a pipeline, you will need to build the components. More specifically, openpipelines uses Nextflow to combine components into pipelines, so we need to have at least the components build for nextflow platform as target. The easiest method to build the components is to use:\nviash ns build --parallel --setup cachedbuild\nAfter using viash ns build, the target folder will be populated with three subfolders, corresponding to the build platforms that viash supports: native, docker and nextflow.\nBuilding an individual component can still be useful, for example when debugging a component for which the build fails or if you want to create a standalone executable for a component to execute it without the need to use viash. To build an individual component, viash build can be used. Note that the default build directory of this viash base command is output, which is not the location where build components will be imported from when integrating them in pipelines. Using the --output argument, you can set it to any directory you want, for example:\nviash build src/filter/do_filter/config.vsh.yaml -o target/native/filter/do_filter/ -p native"
  },
  {
    "objectID": "contributing/creating_components.html#containerization",
    "href": "contributing/creating_components.html#containerization",
    "title": "Creating components",
    "section": "Containerization",
    "text": "Containerization\nOne of the key benefits of using Viash is that containers can be created that gather dependencies per component, which avoids building one container that has to encorporate all dependencies for a pipeline together. The containers for a single component can be reduced in size, defining the minimal requirements to run the component. That being said, building containers from scratch can be labour intensive and error prone, with base containers from reputable publishers often benefiting from improved reliability and security. Hence, a balance has to be made between reducing the container‚Äôs size and adding many dependencies to a small base container.\nThe preferred containerization setup in OpenPipelines uses the following guidelines:\n\nChoose a base container from a reputable source and use its latest version\nDo not use base containers that have not been updated in a while\nUse package managers to install dependencies as much as possible\nAvoid building depdencies from source.\n\nExamples of base containers that are currently being used are:\n\npython:3.11 for python environments\nubuntu:focal for general linux environments and bash scripts\neddelbuettel/r2u:22.04 for R\nnvcr.io/nvidia/pytorch:22.09-py3 for using GPU accelerated calculations using pytorch in python"
  },
  {
    "objectID": "contributing/index.html",
    "href": "contributing/index.html",
    "title": "Contributing",
    "section": "",
    "text": "Getting started: Install dependencies and fetch test resources\n  \n  \n    Project structure: The structure of OpenPipelines\n  \n  \n    Creating components: A guide on how to create new components\n  \n  \n    Creating pipelines: A guide on how to create new workflows\n  \n  \n    Running tests: How to run component and integration tests.\n  \n  \n    Publishing your changes: How to create a pull request\n  \n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OpenPipelines",
    "section": "",
    "text": "Fundamentals\n  \n  \n        \n  \n  Philosophy\n  \n    \n        \n  \n  Concepts\n  \n    \n        \n  \n  Architecture\n  \n    \n        \n  \n  Roadmap\n  \n    \n  \n\nNo matching items\n\n\n\n\n\n  \n  User Guide\n  \n  \n        \n  \n  Getting started\n  \n    \n        \n  \n  Running pipelines\n  \n    \n        \n  \n  Passing parameter lists\n  \n    \n        \n  \n  Ingestion\n  \n    \n        \n  \n  Processing\n  \n    \n        \n  \n  Downstream\n  \n    \n        \n  \n  Bug reports\n  \n    \n  \n\nNo matching items\n\n\n\n\n\n  \n  Contributing\n  \n  \n        \n  \n  Getting started\n  \n    \n        \n  \n  Project structure\n  \n    \n        \n  \n  Creating components\n  \n    \n        \n  \n  Creating pipelines\n  \n    \n        \n  \n  Running tests\n  \n    \n        \n  \n  Publishing your changes\n  \n    \n  \n\nNo matching items\n\n\n\n\n\n  \n  More information\n  \n  \n        \n  \n  Cheat sheets\n  \n    \n        \n  \n  Code of conduct\n  \n    \n        \n  \n  FAQ\n  \n    \n  \n\nNo matching items"
  },
  {
    "objectID": "components/modules/dimred/tsne.html",
    "href": "components/modules/dimred/tsne.html",
    "title": "Tsne",
    "section": "",
    "text": "ID: tsne\nNamespace: dimred\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/dimred/tsne.html#example-commands",
    "href": "components/modules/dimred/tsne.html#example-commands",
    "title": "Tsne",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/dimred/tsne/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: # please fill in - example: \"rna\"\nuse_rep: # please fill in - example: \"X_pca\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobsm_output: \"X_tsne\"\n\n# Arguments\nn_pcs: 50\nperplexity: 30.0\nmin_dist: 0.5\nmetric: \"euclidean\"\nearly_exaggeration: 12.0\nlearning_rate: 1000.0\nrandom_state: 0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dimred/tsne/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/dimred/tsne.html#argument-groups",
    "href": "components/modules/dimred/tsne.html#argument-groups",
    "title": "Tsne",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, required, default: \"rna\"\n\n\n--use_rep\nThe .obsm slot to use as input for the tSNE computation.\nstring, required, example: \"X_pca\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obsm_output\nThe .obsm key to use for storing the tSNE results.\nstring, default: \"X_tsne\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_pcs\nThe number of principal components to use for the tSNE computation.\ninteger, default: 50\n\n\n--perplexity\nThe perplexity is related to the number of nearest neighbors that is used in other manifold learning algorithms. Larger datasets usually require a larger perplexity. Consider selecting a value between 5 and 50. Different values can result in significantly different results.\ndouble, default: 30\n\n\n--min_dist\nThe effective minimum distance between embedded points. Smaller values will result in a more clustered/clumped embedding where nearby points on the manifold are drawn closer together, while larger values will result on a more even dispersal of points. The value should be set relative to the spread value, which determines the scale at which embedded points will be spread out.\ndouble, default: 0.5\n\n\n--metric\nDistance metric to calculate neighbors on.\nstring, default: \"euclidean\"\n\n\n--early_exaggeration\nControls how tight natural clusters in the original space are in the embedded space and how much space will be between them. For larger values, the space between natural clusters will be larger in the embedded space. Again, the choice of this parameter is not very critical. If the cost function increases during initial optimization, the early exaggeration factor or the learning rate might be too high.\ndouble, default: 12\n\n\n--learning_rate\nThe learning rate for t-SNE optimization. Typical values range between 10.0 and 1000.0.\ndouble, default: 1000\n\n\n--random_state\nThe random seed to use for the tSNE computation.\ninteger, default: 0"
  },
  {
    "objectID": "components/modules/dimred/tsne.html#authors",
    "href": "components/modules/dimred/tsne.html#authors",
    "title": "Tsne",
    "section": "Authors",
    "text": "Authors\n\nJakub Majercik   (maintainer)"
  },
  {
    "objectID": "components/modules/dimred/umap.html",
    "href": "components/modules/dimred/umap.html",
    "title": "Umap",
    "section": "",
    "text": "ID: umap\nNamespace: dimred\n\n\n\nSource\nBesides tending to be faster than tSNE, it optimizes the embedding such that it best reflects the topology of the data, which we represent throughout Scanpy using a neighborhood graph. tSNE, by contrast, optimizes the distribution of nearest-neighbor distances in the embedding such that these best match the distribution of distances in the high-dimensional space. We use the implementation of umap-learn [McInnes18]. For a few comparisons of UMAP with tSNE, see this preprint"
  },
  {
    "objectID": "components/modules/dimred/umap.html#example-commands",
    "href": "components/modules/dimred/umap.html#example-commands",
    "title": "Umap",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/dimred/umap/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nuns_neighbors: \"neighbors\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobsm_output: \"umap\"\n\n# Arguments\nmin_dist: 0.5\nspread: 1.0\nnum_components: 2\n# max_iter: 123\nalpha: 1.0\ngamma: 1.0\nnegative_sample_rate: 5\ninit_pos: \"spectral\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dimred/umap/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/dimred/umap.html#argument-groups",
    "href": "components/modules/dimred/umap.html#argument-groups",
    "title": "Umap",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--uns_neighbors\nThe .uns neighbors slot as output by the find_neighbors component.\nstring, default: \"neighbors\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obsm_output\nThe pre/postfix under which to store the UMAP results.\nstring, default: \"umap\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_dist\nThe effective minimum distance between embedded points. Smaller values will result in a more clustered/clumped embedding where nearby points on the manifold are drawn closer together, while larger values will result on a more even dispersal of points. The value should be set relative to the spread value, which determines the scale at which embedded points will be spread out.\ndouble, default: 0.5\n\n\n--spread\nThe effective scale of embedded points. In combination with min_dist this determines how clustered/clumped the embedded points are.\ndouble, default: 1\n\n\n--num_components\nThe number of dimensions of the embedding.\ninteger, default: 2\n\n\n--max_iter\nThe number of iterations (epochs) of the optimization. Called n_epochs in the original UMAP. Default is set to 500 if neighbors[‚Äòconnectivities‚Äô].shape[0] &lt;= 10000, else 200.\ninteger\n\n\n--alpha\nThe initial learning rate for the embedding optimization.\ndouble, default: 1\n\n\n--gamma\nWeighting applied to negative samples in low dimensional embedding optimization. Values higher than one will result in greater weight being given to negative samples.\ndouble, default: 1\n\n\n--negative_sample_rate\nThe number of negative edge/1-simplex samples to use per positive edge/1-simplex sample in optimizing the low dimensional embedding.\ninteger, default: 5\n\n\n--init_pos\nHow to initialize the low dimensional embedding. Called init in the original UMAP. Options are: * Any key from .obsm * 'paga': positions from paga() * 'spectral': use a spectral embedding of the graph * 'random': assign initial embedding positions at random.\nstring, default: \"spectral\""
  },
  {
    "objectID": "components/modules/dimred/umap.html#authors",
    "href": "components/modules/dimred/umap.html#authors",
    "title": "Umap",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)"
  },
  {
    "objectID": "components/modules/velocity/scvelo.html",
    "href": "components/modules/velocity/scvelo.html",
    "title": "Scvelo",
    "section": "",
    "text": "ID: scvelo\nNamespace: velocity\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/velocity/scvelo.html#example-commands",
    "href": "components/modules/velocity/scvelo.html#example-commands",
    "title": "Scvelo",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/velocity/scvelo/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"path/to/file\"\n\n# Outputs\n# output: \"$id.$key.output.output\"\n# output_compression: \"gzip\"\n\n# Filtering and normalization\n# min_counts: 123\n# min_counts_u: 123\n# min_cells: 123\n# min_cells_u: 123\n# min_shared_counts: 123\n# min_shared_cells: 123\n# n_top_genes: 123\nlog_transform: true\n\n# Fitting parameters\n# n_principal_components: 123\nn_neighbors: 30\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/velocity/scvelo/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/velocity/scvelo.html#argument-groups",
    "href": "components/modules/velocity/scvelo.html#argument-groups",
    "title": "Scvelo",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nVelocyto loom file.\nfile, required\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory. If it does not exist, will be created.\nfile, required\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n\n\n\nFiltering and normalization\nArguments for filtering, normalization an log transform (see scvelo.pp.filter_and_normalize function)\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts required for a gene to pass filtering (spliced).\ninteger\n\n\n--min_counts_u\nMinimum number of counts required for a gene to pass filtering (unspliced).\ninteger\n\n\n--min_cells\nMinimum number of cells expressed required to pass filtering (spliced).\ninteger\n\n\n--min_cells_u\nMinimum number of cells expressed required to pass filtering (unspliced).\ninteger\n\n\n--min_shared_counts\nMinimum number of counts (both unspliced and spliced) required for a gene.\ninteger\n\n\n--min_shared_cells\nMinimum number of cells required to be expressed (both unspliced and spliced).\ninteger\n\n\n--n_top_genes\nNumber of genes to keep.\ninteger\n\n\n--log_transform\nDo not log transform counts.\nboolean, default: TRUE\n\n\n\n\n\nFitting parameters\nArguments for fitting the data\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_principal_components\nNumber of principal components to use for calculating moments.\ninteger\n\n\n--n_neighbors\nNumber of neighbors to use. First/second-order moments are computed for each cell across its nearest neighbors, where the neighbor graph is obtained from euclidean distances in PCA space.\ninteger, default: 30"
  },
  {
    "objectID": "components/modules/velocity/scvelo.html#authors",
    "href": "components/modules/velocity/scvelo.html#authors",
    "title": "Scvelo",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/integrate/harmonypy.html",
    "href": "components/modules/integrate/harmonypy.html",
    "title": "Harmonypy",
    "section": "",
    "text": "ID: harmonypy\nNamespace: integrate\n\n\n\nSource\nBased on an implementation in python from https://github.com/slowkow/harmonypy"
  },
  {
    "objectID": "components/modules/integrate/harmonypy.html#example-commands",
    "href": "components/modules/integrate/harmonypy.html#example-commands",
    "title": "Harmonypy",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/integrate/harmonypy/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\n# output: \"$id.$key.output.output\"\n# output_compression: \"gzip\"\nmodality: \"rna\"\nobsm_input: \"X_pca\"\nobsm_output: \"X_pca_integrated\"\ntheta: [2]\nobs_covariates: # please fill in - example: [\"batch\", \"sample\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/harmonypy/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/integrate/harmonypy.html#argument-group",
    "href": "components/modules/integrate/harmonypy.html#argument-group",
    "title": "Harmonypy",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsm_input\nWhich .obsm slot to use as a starting PCA embedding.\nstring, default: \"X_pca\"\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_pca_integrated\"\n\n\n--theta\nDiversity clustering penalty parameter. Specify for each variable in group.by.vars. theta=0 does not encourage any diversity. Larger values of theta result in more diverse clusters.\nList of double, default: 2, multiple_sep: \";\"\n\n\n--obs_covariates\nThe .obs field(s) that define the covariate(s) to regress out.\nList of string, required, example: \"batch\", \"sample\", multiple_sep: \";\""
  },
  {
    "objectID": "components/modules/integrate/harmonypy.html#authors",
    "href": "components/modules/integrate/harmonypy.html#authors",
    "title": "Harmonypy",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)\nRobrecht Cannoodt    (contributor)"
  },
  {
    "objectID": "components/modules/integrate/scvi.html",
    "href": "components/modules/integrate/scvi.html",
    "title": "Scvi",
    "section": "",
    "text": "ID: scvi\nNamespace: integrate\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/integrate/scvi.html#example-commands",
    "href": "components/modules/integrate/scvi.html#example-commands",
    "title": "Scvi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/integrate/scvi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\n# input_layer: \"foo\"\nobs_batch: \"sample_id\"\n# var_input: \"foo\"\n# obs_labels: \"foo\"\n# obs_size_factor: \"foo\"\n# obs_categorical_covariate: [\"foo\"]\n# obs_continuous_covariate: [\"foo\"]\n\n# Outputs\n# output: \"$id.$key.output.output\"\n# output_model: \"$id.$key.output_model.output_model\"\n# output_compression: \"gzip\"\nobsm_output: \"X_scvi_integrated\"\n\n# SCVI options\nn_hidden_nodes: 128\nn_dimensions_latent_space: 30\nn_hidden_layers: 2\ndropout_rate: 0.1\ndispersion: \"gene\"\ngene_likelihood: \"nb\"\n\n# Variational auto-encoder model options\nuse_layer_normalization: \"both\"\nuse_batch_normalization: \"none\"\nencode_covariates: true\ndeeply_inject_covariates: false\nuse_observed_lib_size: false\n\n# Early stopping arguments\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n\n# Learning parameters\n# max_epochs: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30\n\n# Data validition\nn_obs_min_count: 0\nn_var_min_count: 0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/scvi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/integrate/scvi.html#argument-groups",
    "href": "components/modules/integrate/scvi.html#argument-groups",
    "title": "Scvi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\nInput layer to use. If None, X is used\nstring\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--var_input\n.var column containing highly variable genes. By default, do not subset genes.\nstring\n\n\n--obs_labels\nKey in adata.obs for label information. Categories will automatically be converted into integer categories and saved to adata.obs[‚Äô_scvi_labels‚Äô]. If None, assigns the same label to all the data.\nstring\n\n\n--obs_size_factor\nKey in adata.obs for size factor information. Instead of using library size as a size factor, the provided size factor column will be used as offset in the mean of the likelihood. Assumed to be on linear scale.\nstring\n\n\n--obs_categorical_covariate\nKeys in adata.obs that correspond to categorical data. These covariates can be added in addition to the batch covariate and are also treated as nuisance factors (i.e., the model tries to minimize their effects on the latent space). Thus, these should not be used for biologically-relevant factors that you do not want to correct for.\nList of string, multiple_sep: \";\"\n\n\n--obs_continuous_covariate\nKeys in adata.obs that correspond to continuous data. These covariates can be added in addition to the batch covariate and are also treated as nuisance factors (i.e., the model tries to minimize their effects on the latent space). Thus, these should not be used for biologically-relevant factors that you do not want to correct for.\nList of string, multiple_sep: \";\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--output_model\nFolder where the state of the trained model will be saved to.\nfile\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_scvi_integrated\"\n\n\n\n\n\nSCVI options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_hidden_nodes\nNumber of nodes per hidden layer.\ninteger, default: 128\n\n\n--n_dimensions_latent_space\nDimensionality of the latent space.\ninteger, default: 30\n\n\n--n_hidden_layers\nNumber of hidden layers used for encoder and decoder neural-networks.\ninteger, default: 2\n\n\n--dropout_rate\nDropout rate for the neural networks.\ndouble, default: 0.1\n\n\n--dispersion\nSet the behavior for the dispersion for negative binomial distributions: - gene: dispersion parameter of negative binomial is constant per gene across cells - gene-batch: dispersion can differ between different batches - gene-label: dispersion can differ between different labels - gene-cell: dispersion can differ for every gene in every cell\nstring, default: \"gene\"\n\n\n--gene_likelihood\nModel used to generate the expression data from a count-based likelihood distribution. - nb: Negative binomial distribution - zinb: Zero-inflated negative binomial distribution - poisson: Poisson distribution\nstring, default: \"nb\"\n\n\n\n\n\nVariational auto-encoder model options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--use_layer_normalization\nNeural networks for which to enable layer normalization.\nstring, default: \"both\"\n\n\n--use_batch_normalization\nNeural networks for which to enable batch normalization.\nstring, default: \"none\"\n\n\n--encode_covariates\nWhether to concatenate covariates to expression in encoder\nboolean_false\n\n\n--deeply_inject_covariates\nWhether to concatenate covariates into output of hidden layers in encoder/decoder. This option only applies when n_layers &gt; 1. The covariates are concatenated to the input of subsequent hidden layers.\nboolean_true\n\n\n--use_observed_lib_size\nUse observed library size for RNA as scaling factor in mean of conditional distribution.\nboolean_true\n\n\n\n\n\nEarly stopping arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e.¬†an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n\n\n\nLearning parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30\n\n\n\n\n\nData validition\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_obs_min_count\nMinimum number of cells threshold ensuring that every obs_batch category has sufficient observations (cells) for model training.\ninteger, default: 0\n\n\n--n_var_min_count\nMinimum number of genes threshold ensuring that every var_input filter has sufficient observations (genes) for model training.\ninteger, default: 0"
  },
  {
    "objectID": "components/modules/integrate/scvi.html#authors",
    "href": "components/modules/integrate/scvi.html#authors",
    "title": "Scvi",
    "section": "Authors",
    "text": "Authors\n\nMalte D. Luecken    (author)\nDries Schaumont    (maintainer)\nMatthias Beyens    (contributor)"
  },
  {
    "objectID": "components/modules/integrate/scanorama.html",
    "href": "components/modules/integrate/scanorama.html",
    "title": "Scanorama",
    "section": "",
    "text": "ID: scanorama\nNamespace: integrate\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/integrate/scanorama.html#example-commands",
    "href": "components/modules/integrate/scanorama.html#example-commands",
    "title": "Scanorama",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/integrate/scanorama/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\n# output: \"$id.$key.output.h5ad\"\n# output_compression: \"gzip\"\nobs_batch: \"batch\"\nobsm_input: \"X_pca\"\nobsm_output: \"X_scanorama\"\nknn: 20\nbatch_size: 5000\nsigma: 15\napprox: true\nalpha: 0.1\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/scanorama/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/integrate/scanorama.html#argument-group",
    "href": "components/modules/integrate/scanorama.html#argument-group",
    "title": "Scanorama",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--output\nOutput .h5mu file\nfile, required, default: \"output.h5ad\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"batch\"\n\n\n--obsm_input\nBasis obsm slot to run scanorama on.\nstring, default: \"X_pca\"\n\n\n--obsm_output\nThe name of the field in adata.obsm where the integrated embeddings will be stored after running this function. Defaults to X_scanorama.\nstring, default: \"X_scanorama\"\n\n\n--knn\nNumber of nearest neighbors to use for matching.\ninteger, default: 20\n\n\n--batch_size\nThe batch size used in the alignment vector computation. Useful when integrating very large (&gt;100k samples) datasets. Set to large value that runs within available memory.\ninteger, default: 5000\n\n\n--sigma\nCorrection smoothing parameter on Gaussian kernel.\ndouble, default: 15\n\n\n--approx\nUse approximate nearest neighbors with Python annoy; greatly speeds up matching runtime.\nboolean, default: TRUE\n\n\n--alpha\nAlignment score minimum cutoff\ndouble, default: 0.1"
  },
  {
    "objectID": "components/modules/integrate/scanorama.html#authors",
    "href": "components/modules/integrate/scanorama.html#authors",
    "title": "Scanorama",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/filter/remove_modality.html",
    "href": "components/modules/filter/remove_modality.html",
    "title": "Remove modality",
    "section": "",
    "text": "ID: remove_modality\nNamespace: filter\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/filter/remove_modality.html#example-commands",
    "href": "components/modules/filter/remove_modality.html#example-commands",
    "title": "Remove modality",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/filter/remove_modality/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: # please fill in - example: [\"foo\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/remove_modality/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/remove_modality.html#argument-group",
    "href": "components/modules/filter/remove_modality.html#argument-group",
    "title": "Remove modality",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nList of string, required, multiple_sep: \";\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/filter/remove_modality.html#authors",
    "href": "components/modules/filter/remove_modality.html#authors",
    "title": "Remove modality",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/filter/do_filter.html",
    "href": "components/modules/filter/do_filter.html",
    "title": "Do filter",
    "section": "",
    "text": "ID: do_filter\nNamespace: filter\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/filter/do_filter.html#example-commands",
    "href": "components/modules/filter/do_filter.html#example-commands",
    "title": "Do filter",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/filter/do_filter/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# obs_filter: [\"filter_with_x\"]\n# var_filter: [\"filter_with_x\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/do_filter/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/do_filter.html#argument-group",
    "href": "components/modules/filter/do_filter.html#argument-group",
    "title": "Do filter",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obs_filter\nWhich .obs columns to use to filter the observations by.\nList of string, example: \"filter_with_x\", multiple_sep: \";\"\n\n\n--var_filter\nWhich .var columns to use to filter the observations by.\nList of string, example: \"filter_with_x\", multiple_sep: \";\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/filter/do_filter.html#authors",
    "href": "components/modules/filter/do_filter.html#authors",
    "title": "Do filter",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer, contributor)"
  },
  {
    "objectID": "components/modules/filter/intersect_obs.html",
    "href": "components/modules/filter/intersect_obs.html",
    "title": "Intersect obs",
    "section": "",
    "text": "ID: intersect_obs\nNamespace: filter\n\n\n\nSource\nThis component removes any observations which are not present in all modalities."
  },
  {
    "objectID": "components/modules/filter/intersect_obs.html#example-commands",
    "href": "components/modules/filter/intersect_obs.html#example-commands",
    "title": "Intersect obs",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/filter/intersect_obs/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodalities: # please fill in - example: [\"rna\", \"prot\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/intersect_obs/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/intersect_obs.html#argument-group",
    "href": "components/modules/filter/intersect_obs.html#argument-group",
    "title": "Intersect obs",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modalities\n\nList of string, required, example: \"rna\", \"prot\", multiple_sep: \";\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/filter/intersect_obs.html#authors",
    "href": "components/modules/filter/intersect_obs.html#authors",
    "title": "Intersect obs",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)\nIsabelle Bergiers   (contributor)"
  },
  {
    "objectID": "components/modules/filter/subset_h5mu.html",
    "href": "components/modules/filter/subset_h5mu.html",
    "title": "Subset h5mu",
    "section": "",
    "text": "ID: subset_h5mu\nNamespace: filter\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/filter/subset_h5mu.html#example-commands",
    "href": "components/modules/filter/subset_h5mu.html#example-commands",
    "title": "Subset h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/filter/subset_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n# number_of_observations: 5\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/subset_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/subset_h5mu.html#argument-group",
    "href": "components/modules/filter/subset_h5mu.html#argument-group",
    "title": "Subset h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--number_of_observations\nNumber of observations to be selected from the h5mu file.\ninteger, example: 5"
  },
  {
    "objectID": "components/modules/filter/subset_h5mu.html#authors",
    "href": "components/modules/filter/subset_h5mu.html#authors",
    "title": "Subset h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/qc/multiqc.html",
    "href": "components/modules/qc/multiqc.html",
    "title": "Multiqc",
    "section": "",
    "text": "ID: multiqc\nNamespace: qc\n\n\n\nSource\nIt searches a given directory for analysis logs and compiles a HTML report. It‚Äôs a general use tool, perfect for summarising the output from numerous bioinformatics tools"
  },
  {
    "objectID": "components/modules/qc/multiqc.html#example-commands",
    "href": "components/modules/qc/multiqc.html#example-commands",
    "title": "Multiqc",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/qc/multiqc/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: [\"input.txt\"]\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/qc/multiqc/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/qc/multiqc.html#argument-group",
    "href": "components/modules/qc/multiqc.html#argument-group",
    "title": "Multiqc",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInputs for MultiQC.\nList of file, required, example: \"input.txt\", multiple_sep: \";\"\n\n\n--output\nCreate report in the specified output directory.\nfile, required, example: \"report\""
  },
  {
    "objectID": "components/modules/qc/fastqc.html",
    "href": "components/modules/qc/fastqc.html",
    "title": "Fastqc",
    "section": "",
    "text": "ID: fastqc\nNamespace: qc\n\n\n\nSource\nThis component can take one or more files (by means of shell globbing) or a complete directory"
  },
  {
    "objectID": "components/modules/qc/fastqc.html#example-commands",
    "href": "components/modules/qc/fastqc.html#example-commands",
    "title": "Fastqc",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/qc/fastqc/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nmode: \"files\"\ninput: # please fill in - example: \"fastq_dir/\"\n# output: \"$id.$key.output.output\"\n# threads: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/qc/fastqc/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/qc/fastqc.html#argument-group",
    "href": "components/modules/qc/fastqc.html#argument-group",
    "title": "Fastqc",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--mode\nThe mode in which the component works. Can be either files or dir.\nstring, default: \"files\"\n\n\n--input\nDirectory containing input fastq files.\nfile, required, example: \"fastq_dir\"\n\n\n--output\nOutput directory to write reports to.\nfile, required, example: \"qc\"\n\n\n--threads\nSpecifies the number of files which can be processed simultaneously. Each thread will be allocated 250MB of memory.\ninteger"
  },
  {
    "objectID": "components/modules/convert/from_bdrhap_to_h5mu.html",
    "href": "components/modules/convert/from_bdrhap_to_h5mu.html",
    "title": "From bdrhap to h5mu",
    "section": "",
    "text": "ID: from_bdrhap_to_h5mu\nNamespace: convert\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/convert/from_bdrhap_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_bdrhap_to_h5mu.html#example-commands",
    "title": "From bdrhap to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/convert/from_bdrhap_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"my_id\"\ninput: # please fill in - example: \"input_dir/\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_bdrhap_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_bdrhap_to_h5mu.html#argument-groups",
    "href": "components/modules/convert/from_bdrhap_to_h5mu.html#argument-groups",
    "title": "From bdrhap to h5mu",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nA sample ID.\nstring, required, example: \"my_id\"\n\n\n--input\nThe output of a BD Rhapsody workflow.\nfile, required, example: \"input_dir\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/convert/from_bdrhap_to_h5mu.html#authors",
    "href": "components/modules/convert/from_bdrhap_to_h5mu.html#authors",
    "title": "From bdrhap to h5mu",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html",
    "href": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html",
    "title": "From bd to 10x molecular barcode tags",
    "section": "",
    "text": "ID: from_bd_to_10x_molecular_barcode_tags\nNamespace: convert\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#example-commands",
    "href": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#example-commands",
    "title": "From bd to 10x molecular barcode tags",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/convert/from_bd_to_10x_molecular_barcode_tags/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.bam\"\n# output: \"$id.$key.output.sam\"\nbam: false\n# threads: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_bd_to_10x_molecular_barcode_tags/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#argument-group",
    "href": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#argument-group",
    "title": "From bd to 10x molecular barcode tags",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput SAM or BAM file.\nfile, required, example: \"input.bam\"\n\n\n--output\nOutput alignment file.\nfile, example: \"output.sam\"\n\n\n--bam\nOutput a BAM file.\nboolean_true\n\n\n--threads\nNumber of threads\ninteger"
  },
  {
    "objectID": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#authors",
    "href": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#authors",
    "title": "From bd to 10x molecular barcode tags",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_h5mu.html",
    "href": "components/modules/convert/from_h5ad_to_h5mu.html",
    "title": "From h5ad to h5mu",
    "section": "",
    "text": "ID: from_h5ad_to_h5mu\nNamespace: convert\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_h5ad_to_h5mu.html#example-commands",
    "title": "From h5ad to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/convert/from_h5ad_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: [\"input.h5ad\"]\nmodality: [\"rna\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_h5ad_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_h5mu.html#argument-group",
    "href": "components/modules/convert/from_h5ad_to_h5mu.html#argument-group",
    "title": "From h5ad to h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5ad files\nList of file, required, default: \"input.h5ad\", multiple_sep: \";\"\n\n\n--modality\n\nList of string, default: \"rna\", multiple_sep: \";\"\n\n\n--output\nOutput MuData file.\nfile, default: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_h5mu.html#authors",
    "href": "components/modules/convert/from_h5ad_to_h5mu.html#authors",
    "title": "From h5ad to h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)"
  },
  {
    "objectID": "components/modules/convert/from_cellranger_multi_to_h5mu.html",
    "href": "components/modules/convert/from_cellranger_multi_to_h5mu.html",
    "title": "From cellranger multi to h5mu",
    "section": "",
    "text": "ID: from_cellranger_multi_to_h5mu\nNamespace: convert\n\n\n\nSource\nBy default, will map the following library type names to modality names: - Gene Expression: rna - Peaks: atac - Antibody Capture: prot - VDJ: vdj - VDJ-T: vdj_t - VDJ-B: vdj_b - CRISPR Guide Capture: crispr - Multiplexing Capture: hashing\nOther library types have their whitepace removed and dashes replaced by underscores to generate the modality name.\nCurrently does not allow parsing the output from cell barcode demultiplexing."
  },
  {
    "objectID": "components/modules/convert/from_cellranger_multi_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_cellranger_multi_to_h5mu.html#example-commands",
    "title": "From cellranger multi to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/convert/from_cellranger_multi_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input_dir_containing_modalities\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nuns_metrics: \"metrics_cellranger\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_cellranger_multi_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_cellranger_multi_to_h5mu.html#argument-group",
    "href": "components/modules/convert/from_cellranger_multi_to_h5mu.html#argument-group",
    "title": "From cellranger multi to h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput folder. Must contain the output from a cellranger multi run.\nfile, required, example: \"input_dir_containing_modalities\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--uns_metrics\nName of the .uns slot under which to QC metrics (if any).\nstring, default: \"metrics_cellranger\""
  },
  {
    "objectID": "components/modules/convert/from_cellranger_multi_to_h5mu.html#authors",
    "href": "components/modules/convert/from_cellranger_multi_to_h5mu.html#authors",
    "title": "From cellranger multi to h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/neighbors/find_neighbors.html",
    "href": "components/modules/neighbors/find_neighbors.html",
    "title": "Find neighbors",
    "section": "",
    "text": "ID: find_neighbors\nNamespace: neighbors\n\n\n\nSource\nThe neighbor search efficiency of this heavily relies on UMAP [McInnes18], which also provides a method for estimating connectivities of data points - the connectivity of the manifold (method==‚Äòumap‚Äô). If method==‚Äògauss‚Äô, connectivities are computed according to [Coifman05], in the adaption of [Haghverdi16]."
  },
  {
    "objectID": "components/modules/neighbors/find_neighbors.html#example-commands",
    "href": "components/modules/neighbors/find_neighbors.html#example-commands",
    "title": "Find neighbors",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/neighbors/find_neighbors/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nobsm_input: \"X_pca\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nuns_output: \"neighbors\"\nobsp_distances: \"distances\"\nobsp_connectivities: \"connectivities\"\nmetric: \"euclidean\"\nnum_neighbors: 15\nseed: 0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/neighbors/find_neighbors/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/neighbors/find_neighbors.html#argument-group",
    "href": "components/modules/neighbors/find_neighbors.html#argument-group",
    "title": "Find neighbors",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsm_input\nWhich .obsm slot to use as a starting PCA embedding.\nstring, default: \"X_pca\"\n\n\n--output\nOutput h5mu file containing the found neighbors.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--uns_output\nMandatory .uns slot to store various neighbor output objects.\nstring, default: \"neighbors\"\n\n\n--obsp_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"distances\"\n\n\n--obsp_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"connectivities\"\n\n\n--metric\nThe distance metric to be used in the generation of the nearest neighborhood network.\nstring, default: \"euclidean\"\n\n\n--num_neighbors\nThe size of local neighborhood (in terms of number of neighboring data points) used for manifold approximation. Larger values result in more global views of the manifold, while smaller values result in more local data being preserved. In general values should be in the range 2 to 100. If knn is True, number of nearest neighbors to be searched. If knn is False, a Gaussian kernel width is set to the distance of the n_neighbors neighbor.\ninteger, default: 15\n\n\n--seed\nA random seed.\ninteger, default: 0"
  },
  {
    "objectID": "components/modules/neighbors/find_neighbors.html#authors",
    "href": "components/modules/neighbors/find_neighbors.html#authors",
    "title": "Find neighbors",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)\nRobrecht Cannoodt    (contributor)"
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background_v0_2.html",
    "href": "components/modules/correction/cellbender_remove_background_v0_2.html",
    "title": "Cellbender remove background v0 2",
    "section": "",
    "text": "ID: cellbender_remove_background_v0_2\nNamespace: correction\n\n\n\nSource\nThis module removes counts due to ambient RNA molecules and random barcode swapping from (raw) UMI-based scRNA-seq count matrices. At the moment, only the count matrices produced by the CellRanger count pipeline is supported. Support for additional tools and protocols will be added in the future. A quick start tutorial can be found here.\nFleming et al.¬†2022, bioRxiv."
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background_v0_2.html#example-commands",
    "href": "components/modules/correction/cellbender_remove_background_v0_2.html#example-commands",
    "title": "Cellbender remove background v0 2",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/correction/cellbender_remove_background_v0_2/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nlayer_output: \"corrected\"\nobs_latent_rt_efficiency: \"latent_rt_efficiency\"\nobs_latent_cell_probability: \"latent_cell_probability\"\nobs_latent_scale: \"latent_scale\"\nvar_ambient_expression: \"ambient_expression\"\nobsm_latent_gene_encoding: \"cellbender_latent_gene_encoding\"\n\n# Arguments\n# expected_cells: 1000\n# total_droplets_included: 25000\nexpected_cells_from_qc: true\nmodel: \"full\"\nepochs: 150\nlow_count_threshold: 15\nz_dim: 100\nz_layers: [500]\ntraining_fraction: 0.9\nempty_drop_training_fraction: 0.5\nfpr: [0.01]\nexclude_antibody_capture: false\n# learning_rate: 1.0E-4\ncuda: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/correction/cellbender_remove_background_v0_2/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background_v0_2.html#argument-groups",
    "href": "components/modules/correction/cellbender_remove_background_v0_2.html#argument-groups",
    "title": "Cellbender remove background v0 2",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nList of modalities to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nFull count matrix as an h5mu file, with background RNA removed. This file contains all the original droplet barcodes.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--layer_output\nOutput layer\nstring, default: \"corrected\"\n\n\n--obs_latent_rt_efficiency\n\nstring, default: \"latent_rt_efficiency\"\n\n\n--obs_latent_cell_probability\n\nstring, default: \"latent_cell_probability\"\n\n\n--obs_latent_scale\n\nstring, default: \"latent_scale\"\n\n\n--var_ambient_expression\n\nstring, default: \"ambient_expression\"\n\n\n--obsm_latent_gene_encoding\n\nstring, default: \"cellbender_latent_gene_encoding\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--expected_cells\nNumber of cells expected in the dataset (a rough estimate within a factor of 2 is sufficient).\ninteger, example: 1000\n\n\n--total_droplets_included\nThe number of droplets from the rank-ordered UMI plot that will be analyzed. The largest ‚Äòtotal_droplets‚Äô droplets will have their cell probabilities inferred as an output.\ninteger, example: 25000\n\n\n--expected_cells_from_qc\nWill use the Cell Ranger QC to determine the estimated number of cells\nboolean, default: TRUE\n\n\n--model\nWhich model is being used for count data. ‚Äòsimple‚Äô does not model either ambient RNA or random barcode swapping (for debugging purposes ‚Äì not recommended). ‚Äòambient‚Äô assumes background RNA is incorporated into droplets. ‚Äòswapping‚Äô assumes background RNA comes from random barcode swapping. ‚Äòfull‚Äô uses a combined ambient and swapping model.\nstring, default: \"full\"\n\n\n--epochs\nNumber of epochs to train.\ninteger, default: 150\n\n\n--low_count_threshold\nDroplets with UMI counts below this number are completely excluded from the analysis. This can help identify the correct prior for empty droplet counts in the rare case where empty counts are extremely high (over 200).\ninteger, default: 15\n\n\n--z_dim\nDimension of latent variable z.\ninteger, default: 100\n\n\n--z_layers\nDimension of hidden layers in the encoder for z.\nList of integer, default: 500, multiple_sep: \";\"\n\n\n--training_fraction\nTraining detail: the fraction of the data used for training. The rest is never seen by the inference algorithm. Speeds up learning.\ndouble, default: 0.9\n\n\n--empty_drop_training_fraction\nTraining detail: the fraction of the training data each epoch that is drawn (randomly sampled) from surely empty droplets.\ndouble, default: 0.5\n\n\n--fpr\nTarget false positive rate in (0, 1). A false positive is a true signal count that is erroneously removed. More background removal is accompanied by more signal removal at high values of FPR. You can specify multiple values, which will create multiple output files.\nList of double, default: 0.01, multiple_sep: \";\"\n\n\n--exclude_antibody_capture\nIncluding the flag ‚Äìexclude-antibody-capture will cause remove-background to operate on gene counts only, ignoring other features.\nboolean_true\n\n\n--learning_rate\nTraining detail: lower learning rate for inference. A OneCycle learning rate schedule is used, where the upper learning rate is ten times this value. (For this value, probably do not exceed 1e-3).\ndouble, example: 1e-04\n\n\n--cuda\nIncluding the flag ‚Äìcuda will run the inference on a GPU.\nboolean_true"
  },
  {
    "objectID": "components/modules/compression/compress_h5mu.html",
    "href": "components/modules/compression/compress_h5mu.html",
    "title": "Compress h5mu",
    "section": "",
    "text": "ID: compress_h5mu\nNamespace: compression\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/compression/compress_h5mu.html#example-commands",
    "href": "components/modules/compression/compress_h5mu.html#example-commands",
    "title": "Compress h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/compression/compress_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"sample_path\"\n# output: \"$id.$key.output.output\"\ncompression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/compression/compress_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/compression/compress_h5mu.html#argument-group",
    "href": "components/modules/compression/compress_h5mu.html#argument-group",
    "title": "Compress h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the input .h5mu.\nfile, required, example: \"sample_path\"\n\n\n--output\nlocation of output file.\nfile, required\n\n\n--compression\nCompression type.\nstring, default: \"gzip\""
  },
  {
    "objectID": "components/modules/compression/compress_h5mu.html#authors",
    "href": "components/modules/compression/compress_h5mu.html#authors",
    "title": "Compress h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/metadata/move_obsm_to_obs.html",
    "href": "components/modules/metadata/move_obsm_to_obs.html",
    "title": "Move obsm to obs",
    "section": "",
    "text": "ID: move_obsm_to_obs\nNamespace: metadata\n\n\n\nSource\nNewly created columns in .obs will be created from the .obsm key suffixed with an underscore and the name of the columns of the specified .obsm matrix"
  },
  {
    "objectID": "components/modules/metadata/move_obsm_to_obs.html#example-commands",
    "href": "components/modules/metadata/move_obsm_to_obs.html#example-commands",
    "title": "Move obsm to obs",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/metadata/move_obsm_to_obs/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# MuData Input\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nobsm_key: # please fill in - example: \"foo\"\n\n# MuData Output\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/move_obsm_to_obs/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/metadata/move_obsm_to_obs.html#argument-groups",
    "href": "components/modules/metadata/move_obsm_to_obs.html#argument-groups",
    "title": "Move obsm to obs",
    "section": "Argument groups",
    "text": "Argument groups\n\nMuData Input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsm_key\nKey of a data structure to move from .obsm to .obs.\nstring, required\n\n\n\n\n\nMuData Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/metadata/move_obsm_to_obs.html#authors",
    "href": "components/modules/metadata/move_obsm_to_obs.html#authors",
    "title": "Move obsm to obs",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/modules/metadata/join_uns_to_obs.html",
    "href": "components/modules/metadata/join_uns_to_obs.html",
    "title": "Join uns to obs",
    "section": "",
    "text": "ID: join_uns_to_obs\nNamespace: metadata\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/metadata/join_uns_to_obs.html#example-commands",
    "href": "components/modules/metadata/join_uns_to_obs.html#example-commands",
    "title": "Join uns to obs",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/metadata/join_uns_to_obs/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nuns_key: # please fill in - example: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/join_uns_to_obs/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/metadata/join_uns_to_obs.html#argument-group",
    "href": "components/modules/metadata/join_uns_to_obs.html#argument-group",
    "title": "Join uns to obs",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--uns_key\n\nstring, required\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/process_10xh5/filter_10xh5.html",
    "href": "components/modules/process_10xh5/filter_10xh5.html",
    "title": "Filter 10xh5",
    "section": "",
    "text": "ID: filter_10xh5\nNamespace: process_10xh5\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/process_10xh5/filter_10xh5.html#example-commands",
    "href": "components/modules/process_10xh5/filter_10xh5.html#example-commands",
    "title": "Filter 10xh5",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/process_10xh5/filter_10xh5/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n# output: \"$id.$key.output.h5\"\nmin_library_size: 0\nmin_cells_per_gene: 0\n# keep_feature_types: [\"Antibody Capture\"]\nverbose: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/process_10xh5/filter_10xh5/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/process_10xh5/filter_10xh5.html#argument-group",
    "href": "components/modules/process_10xh5/filter_10xh5.html#argument-group",
    "title": "Filter 10xh5",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nAn h5 file from the 10x genomics website.\nfile, required, example: \"pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n\n\n--output\nOutput h5 file.\nfile, required, example: \"pbmc_1k_protein_v3_raw_feature_bc_matrix_filtered.h5\"\n\n\n--min_library_size\nMinimum library size.\ninteger, default: 0\n\n\n--min_cells_per_gene\nMinimum number of cells per gene.\ninteger, default: 0\n\n\n--keep_feature_types\nSpecify which feature types will never be filtered out\nList of string, example: \"Antibody Capture\", multiple_sep: \";\"\n\n\n--verbose\nIncrease verbosity\nboolean_true"
  },
  {
    "objectID": "components/modules/process_10xh5/filter_10xh5.html#authors",
    "href": "components/modules/process_10xh5/filter_10xh5.html#authors",
    "title": "Filter 10xh5",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/mapping/bd_rhapsody.html",
    "href": "components/modules/mapping/bd_rhapsody.html",
    "title": "BD Rhapsody",
    "section": "",
    "text": "ID: bd_rhapsody\nNamespace: mapping\n\n\n\nSource\nA wrapper for the BD Rhapsody Analysis CWL v1.10.1 pipeline.\nThe CWL pipeline file is obtained by cloning ‚Äòhttps://bitbucket.org/CRSwDev/cwl/src/master/‚Äô and removing all objects with class ‚ÄòDockerRequirement‚Äô from the YML.\nThis pipeline can be used for a targeted analysis (with --mode targeted) or for a whole transcriptome analysis (with --mode wta).\nThe reference_genome and transcriptome_annotation files can be generated with the make_reference pipeline. Alternatively, BD also provides standard references which can be downloaded from these locations:"
  },
  {
    "objectID": "components/modules/mapping/bd_rhapsody.html#example-commands",
    "href": "components/modules/mapping/bd_rhapsody.html#example-commands",
    "title": "BD Rhapsody",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/mapping/bd_rhapsody/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nmode: # please fill in - example: \"wta\"\ninput: # please fill in - example: [\"input.fastq.gz\"]\nreference: # please fill in - example: [\"reference_genome.tar.gz|reference.fasta\"]\n# transcriptome_annotation: \"transcriptome.gtf\"\n# abseq_reference: [\"abseq_reference.fasta\"]\n# supplemental_reference: [\"supplemental_reference.fasta\"]\nsample_prefix: \"sample\"\n\n# Outputs\n# output: \"$id.$key.output.output\"\n\n# Putative cell calling settings\n# putative_cell_call: \"mRNA\"\n# exact_cell_count: 10000\ndisable_putative_calling: false\n\n# Subsample arguments\n# subsample: 0.01\n# subsample_seed: 3445\n\n# Multiplex arguments\n# sample_tags_version: \"human\"\n# tag_names: [\"4-mySample\", \"9-myOtherSample\", \"6-alsoThisSample\"]\n\n# VDJ arguments\n# vdj_version: \"human\"\n\n# CWL-runner arguments\nparallel: true\ntimestamps: false\ndryrun: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/bd_rhapsody/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/bd_rhapsody.html#argument-groups",
    "href": "components/modules/mapping/bd_rhapsody.html#argument-groups",
    "title": "BD Rhapsody",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--mode\nWhether to run a whole transcriptome analysis (WTA) or a targeted analysis.\nstring, required, example: \"wta\"\n\n\n--input\nPath to your read files in the FASTQ.GZ format. You may specify as many R1/R2 read pairs as you want.\nList of file, required, example: \"input.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nRefence to map to. For --mode wta, this is the path to STAR index as a tar.gz file. For --mode targeted, this is the path to mRNA reference file for pre-designed, supplemental, or custom panel, in FASTA format\nList of file, required, example: \"reference_genome.tar.gz&#124;reference.fasta\", multiple_sep: \";\"\n\n\n--transcriptome_annotation\nPath to GTF annotation file (only for --mode wta).\nfile, example: \"transcriptome.gtf\"\n\n\n--abseq_reference\nPath to the AbSeq reference file in FASTA format. Only needed if BD AbSeq Ab-Oligos are used.\nList of file, example: \"abseq_reference.fasta\", multiple_sep: \";\"\n\n\n--supplemental_reference\nPath to the supplemental reference file in FASTA format. Only needed if there are additional transgene sequences used in the experiment (only for --mode wta).\nList of file, example: \"supplemental_reference.fasta\", multiple_sep: \";\"\n\n\n--sample_prefix\nSpecify a run name to use as the output file base name. Use only letters, numbers, or hyphens. Do not use special characters or spaces.\nstring, default: \"sample\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput folder. Output still needs to be processed further.\nfile, required, example: \"output_dir\"\n\n\n\n\n\nPutative cell calling settings\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--putative_cell_call\nSpecify the dataset to be used for putative cell calling. For putative cell calling using an AbSeq dataset, please provide an AbSeq_Reference fasta file above.\nstring, example: \"mRNA\"\n\n\n--exact_cell_count\nExact cell count - Set a specific number (&gt;=1) of cells as putative, based on those with the highest error-corrected read count\ninteger, example: 10000\n\n\n--disable_putative_calling\nDisable Refined Putative Cell Calling - Determine putative cells using only the basic algorithm (minimum second derivative along the cumulative reads curve). The refined algorithm attempts to remove false positives and recover false negatives, but may not be ideal for certain complex mixtures of cell types. Does not apply if Exact Cell Count is set.\nboolean_true\n\n\n\n\n\nSubsample arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--subsample\nA number &gt;1 or fraction (0 &lt; n &lt; 1) to indicate the number or percentage of reads to subsample.\ndouble, example: 0.01\n\n\n--subsample_seed\nA seed for replicating a previous subsampled run.\ninteger, example: 3445\n\n\n\n\n\nMultiplex arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sample_tags_version\nSpecify if multiplexed run.\nstring, example: \"human\"\n\n\n--tag_names\nTag_Names (optional) - Specify the tag number followed by ‚Äò-‚Äô and the desired sample name to appear in Sample_Tag_Metrics.csv. Do not use the special characters: &, (), [], {}, &lt;&gt;, ?, |\nList of string, example: \"4-mySample\", \"9-myOtherSample\", \"6-alsoThisSample\", multiple_sep: \";\"\n\n\n\n\n\nVDJ arguments\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--vdj_version\nSpecify if VDJ run.\nstring, example: \"human\"\n\n\n\n\n\nCWL-runner arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--parallel\nRun jobs in parallel.\nboolean, default: TRUE\n\n\n--timestamps\nAdd timestamps to the errors, warnings, and notifications.\nboolean_true\n\n\n--dryrun\nIf true, the output directory will only contain the CWL input files, but the pipeline itself will not be executed.\nboolean_true"
  },
  {
    "objectID": "components/modules/mapping/bd_rhapsody.html#authors",
    "href": "components/modules/mapping/bd_rhapsody.html#authors",
    "title": "BD Rhapsody",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/mapping/star_align_v273a.html",
    "href": "components/modules/mapping/star_align_v273a.html",
    "title": "Star align v273a",
    "section": "",
    "text": "ID: star_align_v273a\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/star_align_v273a.html#example-commands",
    "href": "components/modules/mapping/star_align_v273a.html#example-commands",
    "title": "Star align v273a",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/mapping/star_align_v273a/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input/Output\ninput: # please fill in - example: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\nreference: # please fill in - example: \"/path/to/reference\"\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/star_align_v273a/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/star_align_v273a.html#argument-groups",
    "href": "components/modules/mapping/star_align_v273a.html#argument-groups",
    "title": "Star align v273a",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput/Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe FASTQ files to be analyzed. Corresponds to the ‚ÄìreadFilesIn in the STAR command.\nList of file, required, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nPath to the reference built by star_build_reference. Corresponds to the ‚ÄìgenomeDir in the STAR command.\nfile, required, example: \"/path/to/reference\"\n\n\n--output\nPath to output directory. Corresponds to the ‚ÄìoutFileNamePrefix in the STAR command.\nfile, required, example: \"/path/to/foo\"\n\n\n\n\n\nRun Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--runRNGseed\nrandom number generator seed.\ninteger, example: 777\n\n\n\n\n\nGenome Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genomeLoad\nmode of shared memory usage for the genome files. Only used with ‚ÄìrunMode alignReads. - LoadAndKeep ‚Ä¶ load genome into shared and keep it in memory after run - LoadAndRemove ‚Ä¶ load genome into shared but remove it after run - LoadAndExit ‚Ä¶ load genome into shared memory and exit, keeping the genome in memory for future runs - Remove ‚Ä¶ do not map anything, just remove loaded genome from memory - NoSharedMemory ‚Ä¶ do not use shared memory, each job will have its own private copy of the genome\nstring, example: \"NoSharedMemory\"\n\n\n--genomeFastaFiles\npath(s) to the fasta files with the genome sequences, separated by spaces. These files should be plain text FASTA files, they cannot be zipped. Required for the genome generation (‚ÄìrunMode genomeGenerate). Can also be used in the mapping (‚ÄìrunMode alignReads) to add extra (new) sequences to the genome (e.g.¬†spike-ins).\nList of file, multiple_sep: \";\"\n\n\n--genomeFileSizes\ngenome files exact sizes in bytes. Typically, this should not be defined by the user.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--genomeTransformOutput\nwhich output to transform back to original genome - SAM ‚Ä¶ SAM/BAM alignments - SJ ‚Ä¶ splice junctions (SJ.out.tab) - None ‚Ä¶ no transformation of the output\nList of string, multiple_sep: \";\"\n\n\n--genomeChrSetMitochondrial\nnames of the mitochondrial chromosomes. Presently only used for STARsolo statistics output/\nList of string, example: \"chrM\", \"M\", \"MT\", multiple_sep: \";\"\n\n\n\n\n\nSplice Junctions Database\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sjdbFileChrStartEnd\npath to the files with genomic coordinates (chr  start  end  strand) for the splice junction introns. Multiple files can be supplied and will be concatenated.\nList of string, multiple_sep: \";\"\n\n\n--sjdbGTFfile\npath to the GTF file with annotations\nfile\n\n\n--sjdbGTFchrPrefix\nprefix for chromosome names in a GTF file (e.g.¬†‚Äòchr‚Äô for using ENSMEBL annotations with UCSC genomes)\nstring\n\n\n--sjdbGTFfeatureExon\nfeature type in GTF file to be used as exons for building transcripts\nstring, example: \"exon\"\n\n\n--sjdbGTFtagExonParentTranscript\nGTF attribute name for parent transcript ID (default ‚Äútranscript_id‚Äù works for GTF files)\nstring, example: \"transcript_id\"\n\n\n--sjdbGTFtagExonParentGene\nGTF attribute name for parent gene ID (default ‚Äúgene_id‚Äù works for GTF files)\nstring, example: \"gene_id\"\n\n\n--sjdbGTFtagExonParentGeneName\nGTF attribute name for parent gene name\nList of string, example: \"gene_name\", multiple_sep: \";\"\n\n\n--sjdbGTFtagExonParentGeneType\nGTF attribute name for parent gene type\nList of string, example: \"gene_type\", \"gene_biotype\", multiple_sep: \";\"\n\n\n--sjdbOverhang\nlength of the donor/acceptor sequence on each side of the junctions, ideally = (mate_length - 1)\ninteger, example: 100\n\n\n--sjdbScore\nextra alignment score for alignments that cross database junctions\ninteger, example: 2\n\n\n--sjdbInsertSave\nwhich files to save when sjdb junctions are inserted on the fly at the mapping step - Basic ‚Ä¶ only small junction / transcript files - All ‚Ä¶ all files including big Genome, SA and SAindex - this will create a complete genome directory\nstring, example: \"Basic\"\n\n\n\n\n\nVariation parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--varVCFfile\npath to the VCF file that contains variation data. The 10th column should contain the genotype information, e.g.¬†0/1\nstring\n\n\n\n\n\nRead Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--readFilesType\nformat of input read files - Fastx ‚Ä¶ FASTA or FASTQ - SAM SE ‚Ä¶ SAM or BAM single-end reads; for BAM use ‚ÄìreadFilesCommand samtools view - SAM PE ‚Ä¶ SAM or BAM paired-end reads; for BAM use ‚ÄìreadFilesCommand samtools view\nstring, example: \"Fastx\"\n\n\n--readFilesSAMattrKeep\nfor ‚ÄìreadFilesType SAM SE/PE, which SAM tags to keep in the output BAM, e.g.: ‚ÄìreadFilesSAMtagsKeep RG PL - All ‚Ä¶ keep all tags - None ‚Ä¶ do not keep any tags\nList of string, example: \"All\", multiple_sep: \";\"\n\n\n--readFilesManifest\npath to the ‚Äúmanifest‚Äù file with the names of read files. The manifest file should contain 3 tab-separated columns: paired-end reads: read1_file_name \\(tab\\) read2_file_name \\(tab\\) read_group_line. single-end reads: read1_file_name \\(tab\\) - \\(tab\\) read_group_line. Spaces, but not tabs are allowed in file names. If read_group_line does not start with ID:, it can only contain one ID field, and ID: will be added to it. If read_group_line starts with ID:, it can contain several fields separated by \\(tab\\), and all fields will be be copied verbatim into SAM @RG header line.\nfile\n\n\n--readFilesPrefix\nprefix for the read files names, i.e.¬†it will be added in front of the strings in ‚ÄìreadFilesIn\nstring\n\n\n--readFilesCommand\ncommand line to execute for each of the input file. This command should generate FASTA or FASTQ text and send it to stdout For example: zcat - to uncompress .gz files, bzcat - to uncompress .bz2 files, etc.\nList of string, multiple_sep: \";\"\n\n\n--readMapNumber\nnumber of reads to map from the beginning of the file -1: map all reads\ninteger, example: -1\n\n\n--readMatesLengthsIn\nEqual/NotEqual - lengths of names,sequences,qualities for both mates are the same / not the same. NotEqual is safe in all situations.\nstring, example: \"NotEqual\"\n\n\n--readNameSeparator\ncharacter(s) separating the part of the read names that will be trimmed in output (read name after space is always trimmed)\nList of string, example: \"/\", multiple_sep: \";\"\n\n\n--readQualityScoreBase\nnumber to be subtracted from the ASCII code to get Phred quality score\ninteger, example: 33\n\n\n\n\n\nRead Clipping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--clipAdapterType\nadapter clipping type - Hamming ‚Ä¶ adapter clipping based on Hamming distance, with the number of mismatches controlled by ‚Äìclip5pAdapterMMp - CellRanger4 ‚Ä¶ 5p and 3p adapter clipping similar to CellRanger4. Utilizes Opal package by Martin Sosic: https://github.com/Martinsos/opal - None ‚Ä¶ no adapter clipping, all other clip* parameters are disregarded\nstring, example: \"Hamming\"\n\n\n--clip3pNbases\nnumber(s) of bases to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip3pAdapterSeq\nadapter sequences to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates. - polyA ‚Ä¶ polyA sequence with the length equal to read length\nList of string, multiple_sep: \";\"\n\n\n--clip3pAdapterMMp\nmax proportion of mismatches for 3p adapter clipping for each mate. If one value is given, it will be assumed the same for both mates.\nList of double, example: 0.1, multiple_sep: \";\"\n\n\n--clip3pAfterAdapterNbases\nnumber of bases to clip from 3p of each mate after the adapter clipping. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip5pNbases\nnumber(s) of bases to clip from 5p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n\n\n\nLimits\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--limitGenomeGenerateRAM\nmaximum available RAM (bytes) for genome generation\nlong, example: NA\n\n\n--limitIObufferSize\nmax available buffers size (bytes) for input/output, per thread\nList of long, example: 30000000, 50000000, multiple_sep: \";\"\n\n\n--limitOutSAMoneReadBytes\nmax size of the SAM record (bytes) for one read. Recommended value: &gt;(2(LengthMate1+LengthMate2+100)outFilterMultimapNmax\nlong, example: 100000\n\n\n--limitOutSJoneRead\nmax number of junctions for one read (including all multi-mappers)\ninteger, example: 1000\n\n\n--limitOutSJcollapsed\nmax number of collapsed junctions\ninteger, example: 1000000\n\n\n--limitBAMsortRAM\nmaximum available RAM (bytes) for sorting BAM. If =0, it will be set to the genome index size. 0 value can only be used with ‚ÄìgenomeLoad NoSharedMemory option.\nlong, example: 0\n\n\n--limitSjdbInsertNsj\nmaximum number of junctions to be inserted to the genome on the fly at the mapping stage, including those from annotations and those detected in the 1st step of the 2-pass run\ninteger, example: 1000000\n\n\n--limitNreadsSoft\nsoft limit on the number of reads\ninteger, example: -1\n\n\n\n\n\nOutput: general\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outTmpKeep\nwhether to keep the temporary files after STAR runs is finished - None ‚Ä¶ remove all temporary files - All ‚Ä¶ keep all files\nstring\n\n\n--outStd\nwhich output will be directed to stdout (standard out) - Log ‚Ä¶ log messages - SAM ‚Ä¶ alignments in SAM format (which normally are output to Aligned.out.sam file), normal standard output will go into Log.std.out - BAM_Unsorted ‚Ä¶ alignments in BAM format, unsorted. Requires ‚ÄìoutSAMtype BAM Unsorted - BAM_SortedByCoordinate ‚Ä¶ alignments in BAM format, sorted by coordinate. Requires ‚ÄìoutSAMtype BAM SortedByCoordinate - BAM_Quant ‚Ä¶ alignments to transcriptome in BAM format, unsorted. Requires ‚ÄìquantMode TranscriptomeSAM\nstring, example: \"Log\"\n\n\n--outReadsUnmapped\noutput of unmapped and partially mapped (i.e.¬†mapped only one mate of a paired end read) reads in separate file(s). - None ‚Ä¶ no output - Fastx ‚Ä¶ output in separate fasta/fastq files, Unmapped.out.mate1/2\nstring\n\n\n--outQSconversionAdd\nadd this number to the quality score (e.g.¬†to convert from Illumina to Sanger, use -31)\ninteger, example: 0\n\n\n--outMultimapperOrder\norder of multimapping alignments in the output files - Old_2.4 ‚Ä¶ quasi-random order used before 2.5.0 - Random ‚Ä¶ random order of alignments for each multi-mapper. Read mates (pairs) are always adjacent, all alignment for each read stay together. This option will become default in the future releases.\nstring, example: \"Old_2.4\"\n\n\n\n\n\nOutput: SAM and BAM\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSAMtype\ntype of SAM/BAM output 1st word: - BAM ‚Ä¶ output BAM without sorting - SAM ‚Ä¶ output SAM without sorting - None ‚Ä¶ no SAM/BAM output 2nd, 3rd: - Unsorted ‚Ä¶ standard unsorted - SortedByCoordinate ‚Ä¶ sorted by coordinate. This option will allocate extra memory for sorting which can be specified by ‚ÄìlimitBAMsortRAM.\nList of string, example: \"SAM\", multiple_sep: \";\"\n\n\n--outSAMmode\nmode of SAM output - None ‚Ä¶ no SAM output - Full ‚Ä¶ full SAM output - NoQS ‚Ä¶ full SAM but without quality scores\nstring, example: \"Full\"\n\n\n--outSAMstrandField\nCufflinks-like strand field flag - None ‚Ä¶ not used - intronMotif ‚Ä¶ strand derived from the intron motif. This option changes the output alignments: reads with inconsistent and/or non-canonical introns are filtered out.\nstring\n\n\n--outSAMattributes\na string of desired SAM attributes, in the order desired for the output SAM. Tags can be listed in any combination/order. Presets: - None ‚Ä¶ no attributes - Standard ‚Ä¶ NH HI AS nM - All ‚Ä¶ NH HI AS nM NM MD jM jI MC ch Alignment: - NH ‚Ä¶ number of loci the reads maps to: =1 for unique mappers, &gt;1 for multimappers. Standard SAM tag. - HI ‚Ä¶ multiple alignment index, starts with ‚ÄìoutSAMattrIHstart (=1 by default). Standard SAM tag. - AS ‚Ä¶ local alignment score, +1/-1 for matches/mismateches, score* penalties for indels and gaps. For PE reads, total score for two mates. Stadnard SAM tag. - nM ‚Ä¶ number of mismatches. For PE reads, sum over two mates. - NM ‚Ä¶ edit distance to the reference (number of mismatched + inserted + deleted bases) for each mate. Standard SAM tag. - MD ‚Ä¶ string encoding mismatched and deleted reference bases (see standard SAM specifications). Standard SAM tag. - jM ‚Ä¶ intron motifs for all junctions (i.e.¬†N in CIGAR): 0: non-canonical; 1: GT/AG, 2: CT/AC, 3: GC/AG, 4: CT/GC, 5: AT/AC, 6: GT/AT. If splice junctions database is used, and a junction is annotated, 20 is added to its motif value. - jI ‚Ä¶ start and end of introns for all junctions (1-based). - XS ‚Ä¶ alignment strand according to ‚ÄìoutSAMstrandField. - MC ‚Ä¶ mate‚Äôs CIGAR string. Standard SAM tag. - ch ‚Ä¶ marks all segment of all chimeric alingments for ‚ÄìchimOutType WithinBAM output. - cN ‚Ä¶ number of bases clipped from the read ends: 5‚Äô and 3‚Äô Variation: - vA ‚Ä¶ variant allele - vG ‚Ä¶ genomic coordinate of the variant overlapped by the read. - vW ‚Ä¶ 1 - alignment passes WASP filtering; 2,3,4,5,6,7 - alignment does not pass WASP filtering. Requires ‚ÄìwaspOutputMode SAMtag. STARsolo: - CR CY UR UY ‚Ä¶ sequences and quality scores of cell barcodes and UMIs for the solo* demultiplexing. - GX GN ‚Ä¶ gene ID and gene name for unique-gene reads. - gx gn ‚Ä¶ gene IDs and gene names for unique- and multi-gene reads. - CB UB ‚Ä¶ error-corrected cell barcodes and UMIs for solo* demultiplexing. Requires ‚ÄìoutSAMtype BAM SortedByCoordinate. - sM ‚Ä¶ assessment of CB and UMI. - sS ‚Ä¶ sequence of the entire barcode (CB,UMI,adapter). - sQ ‚Ä¶ quality of the entire barcode. ***Unsupported/undocumented: - ha ‚Ä¶ haplotype (1/2) when mapping to the diploid genome. Requires genome generated with ‚ÄìgenomeTransformType Diploid . - rB ‚Ä¶ alignment block read/genomic coordinates. - vR ‚Ä¶ read coordinate of the variant.\nList of string, example: \"Standard\", multiple_sep: \";\"\n\n\n--outSAMattrIHstart\nstart value for the IH attribute. 0 may be required by some downstream software, such as Cufflinks or StringTie.\ninteger, example: 1\n\n\n--outSAMunmapped\noutput of unmapped reads in the SAM format 1st word: - None ‚Ä¶ no output - Within ‚Ä¶ output unmapped reads within the main SAM file (i.e.¬†Aligned.out.sam) 2nd word: - KeepPairs ‚Ä¶ record unmapped mate for each alignment, and, in case of unsorted output, keep it adjacent to its mapped mate. Only affects multi-mapping reads.\nList of string, multiple_sep: \";\"\n\n\n--outSAMorder\ntype of sorting for the SAM output Paired: one mate after the other for all paired alignments PairedKeepInputOrder: one mate after the other for all paired alignments, the order is kept the same as in the input FASTQ files\nstring, example: \"Paired\"\n\n\n--outSAMprimaryFlag\nwhich alignments are considered primary - all others will be marked with 0x100 bit in the FLAG - OneBestScore ‚Ä¶ only one alignment with the best score is primary - AllBestScore ‚Ä¶ all alignments with the best score are primary\nstring, example: \"OneBestScore\"\n\n\n--outSAMreadID\nread ID record type - Standard ‚Ä¶ first word (until space) from the FASTx read ID line, removing /1,/2 from the end - Number ‚Ä¶ read number (index) in the FASTx file\nstring, example: \"Standard\"\n\n\n--outSAMmapqUnique\n0 to 255: the MAPQ value for unique mappers\ninteger, example: 255\n\n\n--outSAMflagOR\n0 to 65535: sam FLAG will be bitwise OR‚Äôd with this value, i.e.¬†FLAG=FLAG | outSAMflagOR. This is applied after all flags have been set by STAR, and after outSAMflagAND. Can be used to set specific bits that are not set otherwise.\ninteger, example: 0\n\n\n--outSAMflagAND\n0 to 65535: sam FLAG will be bitwise AND‚Äôd with this value, i.e.¬†FLAG=FLAG & outSAMflagOR. This is applied after all flags have been set by STAR, but before outSAMflagOR. Can be used to unset specific bits that are not set otherwise.\ninteger, example: 65535\n\n\n--outSAMattrRGline\nSAM/BAM read group line. The first word contains the read group identifier and must start with ‚ÄúID:‚Äù, e.g.¬†‚ÄìoutSAMattrRGline ID:xxx CN:yy ‚ÄúDS:z z z‚Äù. xxx will be added as RG tag to each output alignment. Any spaces in the tag values have to be double quoted. Comma separated RG lines correspons to different (comma separated) input files in ‚ÄìreadFilesIn. Commas have to be surrounded by spaces, e.g.¬†‚ÄìoutSAMattrRGline ID:xxx , ID:zzz ‚ÄúDS:z z‚Äù , ID:yyy DS:yyyy\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderHD\n@HD (header) line of the SAM header\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderPG\nextra @PG (software) line of the SAM header (in addition to STAR)\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderCommentFile\npath to the file with @CO (comment) lines of the SAM header\nstring\n\n\n--outSAMfilter\nfilter the output into main SAM/BAM files - KeepOnlyAddedReferences ‚Ä¶ only keep the reads for which all alignments are to the extra reference sequences added with ‚ÄìgenomeFastaFiles at the mapping stage. - KeepAllAddedReferences ‚Ä¶ keep all alignments to the extra reference sequences added with ‚ÄìgenomeFastaFiles at the mapping stage.\nList of string, multiple_sep: \";\"\n\n\n--outSAMmultNmax\nmax number of multiple alignments for a read that will be output to the SAM/BAM files. Note that if this value is not equal to -1, the top scoring alignment will be output first - -1 ‚Ä¶ all alignments (up to ‚ÄìoutFilterMultimapNmax) will be output\ninteger, example: -1\n\n\n--outSAMtlen\ncalculation method for the TLEN field in the SAM/BAM files - 1 ‚Ä¶ leftmost base of the (+)strand mate to rightmost base of the (-)mate. (+)sign for the (+)strand mate - 2 ‚Ä¶ leftmost base of any mate to rightmost base of any mate. (+)sign for the mate with the leftmost base. This is different from 1 for overlapping mates with protruding ends\ninteger, example: 1\n\n\n--outBAMcompression\n-1 to 10 BAM compression level, -1=default compression (6?), 0=no compression, 10=maximum compression\ninteger, example: 1\n\n\n--outBAMsortingThreadN\n&gt;=0: number of threads for BAM sorting. 0 will default to min(6,‚ÄìrunThreadN).\ninteger, example: 0\n\n\n--outBAMsortingBinsN\n&gt;0: number of genome bins for coordinate-sorting\ninteger, example: 50\n\n\n\n\n\nBAM processing\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--bamRemoveDuplicatesType\nmark duplicates in the BAM file, for now only works with (i) sorted BAM fed with inputBAMfile, and (ii) for paired-end alignments only - - ‚Ä¶ no duplicate removal/marking - UniqueIdentical ‚Ä¶ mark all multimappers, and duplicate unique mappers. The coordinates, FLAG, CIGAR must be identical - UniqueIdenticalNotMulti ‚Ä¶ mark duplicate unique mappers but not multimappers.\nstring\n\n\n--bamRemoveDuplicatesMate2basesN\nnumber of bases from the 5‚Äô of mate 2 to use in collapsing (e.g.¬†for RAMPAGE)\ninteger, example: 0\n\n\n\n\n\nOutput Wiggle\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outWigType\ntype of signal output, e.g.¬†‚ÄúbedGraph‚Äù OR ‚ÄúbedGraph read1_5p‚Äù. Requires sorted BAM: ‚ÄìoutSAMtype BAM SortedByCoordinate . 1st word: - None ‚Ä¶ no signal output - bedGraph ‚Ä¶ bedGraph format - wiggle ‚Ä¶ wiggle format 2nd word: - read1_5p ‚Ä¶ signal from only 5‚Äô of the 1st read, useful for CAGE/RAMPAGE etc - read2 ‚Ä¶ signal from only 2nd read\nList of string, multiple_sep: \";\"\n\n\n--outWigStrand\nstrandedness of wiggle/bedGraph output - Stranded ‚Ä¶ separate strands, str1 and str2 - Unstranded ‚Ä¶ collapsed strands\nstring, example: \"Stranded\"\n\n\n--outWigReferencesPrefix\nprefix matching reference names to include in the output wiggle file, e.g.¬†‚Äúchr‚Äù, default ‚Äú-‚Äù - include all references\nstring\n\n\n--outWigNorm\ntype of normalization for the signal - RPM ‚Ä¶ reads per million of mapped reads - None ‚Ä¶ no normalization, ‚Äúraw‚Äù counts\nstring, example: \"RPM\"\n\n\n\n\n\nOutput Filtering\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outFilterType\ntype of filtering - Normal ‚Ä¶ standard filtering using only current alignment - BySJout ‚Ä¶ keep only those reads that contain junctions that passed filtering into SJ.out.tab\nstring, example: \"Normal\"\n\n\n--outFilterMultimapScoreRange\nthe score range below the maximum score for multimapping alignments\ninteger, example: 1\n\n\n--outFilterMultimapNmax\nmaximum number of loci the read is allowed to map to. Alignments (all of them) will be output only if the read maps to no more loci than this value. Otherwise no alignments will be output, and the read will be counted as ‚Äúmapped to too many loci‚Äù in the Log.final.out .\ninteger, example: 10\n\n\n--outFilterMismatchNmax\nalignment will be output only if it has no more mismatches than this value.\ninteger, example: 10\n\n\n--outFilterMismatchNoverLmax\nalignment will be output only if its ratio of mismatches to mapped length is less than or equal to this value.\ndouble, example: 0.3\n\n\n--outFilterMismatchNoverReadLmax\nalignment will be output only if its ratio of mismatches to read length is less than or equal to this value.\ndouble, example: 1\n\n\n--outFilterScoreMin\nalignment will be output only if its score is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterScoreMinOverLread\nsame as outFilterScoreMin, but normalized to read length (sum of mates‚Äô lengths for paired-end reads)\ndouble, example: 0.66\n\n\n--outFilterMatchNmin\nalignment will be output only if the number of matched bases is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterMatchNminOverLread\nsam as outFilterMatchNmin, but normalized to the read length (sum of mates‚Äô lengths for paired-end reads).\ndouble, example: 0.66\n\n\n--outFilterIntronMotifs\nfilter alignment using their motifs - None ‚Ä¶ no filtering - RemoveNoncanonical ‚Ä¶ filter out alignments that contain non-canonical junctions - RemoveNoncanonicalUnannotated ‚Ä¶ filter out alignments that contain non-canonical unannotated junctions when using annotated splice junctions database. The annotated non-canonical junctions will be kept.\nstring\n\n\n--outFilterIntronStrands\nfilter alignments - RemoveInconsistentStrands ‚Ä¶ remove alignments that have junctions with inconsistent strands - None ‚Ä¶ no filtering\nstring, example: \"RemoveInconsistentStrands\"\n\n\n\n\n\nOutput splice junctions (SJ.out.tab)\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJtype\ntype of splice junction output - Standard ‚Ä¶ standard SJ.out.tab output - None ‚Ä¶ no splice junction output\nstring, example: \"Standard\"\n\n\n\n\n\nOutput Filtering: Splice Junctions\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJfilterReads\nwhich reads to consider for collapsed splice junctions output - All ‚Ä¶ all reads, unique- and multi-mappers - Unique ‚Ä¶ uniquely mapping reads only\nstring, example: \"All\"\n\n\n--outSJfilterOverhangMin\nminimum overhang length for splice junctions on both sides for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif does not apply to annotated junctions\nList of integer, example: 30, 12, 12, 12, multiple_sep: \";\"\n\n\n--outSJfilterCountUniqueMin\nminimum uniquely mapping read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterCountTotalMin\nminimum total (multi-mapping+unique) read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterDistToOtherSJmin\nminimum allowed distance to other junctions‚Äô donor/acceptor does not apply to annotated junctions\nList of integer, example: 10, 0, 5, 10, multiple_sep: \";\"\n\n\n--outSJfilterIntronMaxVsReadN\nmaximum gap allowed for junctions supported by 1,2,3,,,N reads i.e.¬†by default junctions supported by 1 read can have gaps &lt;=50000b, by 2 reads: &lt;=100000b, by 3 reads: &lt;=200000. by &gt;=4 reads any gap &lt;=alignIntronMax does not apply to annotated junctions\nList of integer, example: 50000, 100000, 200000, multiple_sep: \";\"\n\n\n\n\n\nScoring\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--scoreGap\nsplice junction penalty (independent on intron motif)\ninteger, example: 0\n\n\n--scoreGapNoncan\nnon-canonical junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGapGCAG\nGC/AG and CT/GC junction penalty (in addition to scoreGap)\ninteger, example: -4\n\n\n--scoreGapATAC\nAT/AC and GT/AT junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGenomicLengthLog2scale\nextra score logarithmically scaled with genomic length of the alignment: scoreGenomicLengthLog2scale*log2(genomicLength)\ninteger, example: 0\n\n\n--scoreDelOpen\ndeletion open penalty\ninteger, example: -2\n\n\n--scoreDelBase\ndeletion extension penalty per base (in addition to scoreDelOpen)\ninteger, example: -2\n\n\n--scoreInsOpen\ninsertion open penalty\ninteger, example: -2\n\n\n--scoreInsBase\ninsertion extension penalty per base (in addition to scoreInsOpen)\ninteger, example: -2\n\n\n--scoreStitchSJshift\nmaximum score reduction while searching for SJ boundaries in the stitching step\ninteger, example: 1\n\n\n\n\n\nAlignments and Seeding\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--seedSearchStartLmax\ndefines the search start point through the read - the read is split into pieces no longer than this value\ninteger, example: 50\n\n\n--seedSearchStartLmaxOverLread\nseedSearchStartLmax normalized to read length (sum of mates‚Äô lengths for paired-end reads)\ndouble, example: 1\n\n\n--seedSearchLmax\ndefines the maximum length of the seeds, if =0 seed length is not limited\ninteger, example: 0\n\n\n--seedMultimapNmax\nonly pieces that map fewer than this value are utilized in the stitching procedure\ninteger, example: 10000\n\n\n--seedPerReadNmax\nmax number of seeds per read\ninteger, example: 1000\n\n\n--seedPerWindowNmax\nmax number of seeds per window\ninteger, example: 50\n\n\n--seedNoneLociPerWindow\nmax number of one seed loci per window\ninteger, example: 10\n\n\n--seedSplitMin\nmin length of the seed sequences split by Ns or mate gap\ninteger, example: 12\n\n\n--seedMapMin\nmin length of seeds to be mapped\ninteger, example: 5\n\n\n--alignIntronMin\nminimum intron size, genomic gap is considered intron if its length&gt;=alignIntronMin, otherwise it is considered Deletion\ninteger, example: 21\n\n\n--alignIntronMax\nmaximum intron size, if 0, max intron size will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignMatesGapMax\nmaximum gap between two mates, if 0, max intron gap will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignSJoverhangMin\nminimum overhang (i.e.¬†block size) for spliced alignments\ninteger, example: 5\n\n\n--alignSJstitchMismatchNmax\nmaximum number of mismatches for stitching of the splice junctions (-1: no limit). (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif.\nList of integer, example: 0, -1, 0, 0, multiple_sep: \";\"\n\n\n--alignSJDBoverhangMin\nminimum overhang (i.e.¬†block size) for annotated (sjdb) spliced alignments\ninteger, example: 3\n\n\n--alignSplicedMateMapLmin\nminimum mapped length for a read mate that is spliced\ninteger, example: 0\n\n\n--alignSplicedMateMapLminOverLmate\nalignSplicedMateMapLmin normalized to mate length\ndouble, example: 0.66\n\n\n--alignWindowsPerReadNmax\nmax number of windows per read\ninteger, example: 10000\n\n\n--alignTranscriptsPerWindowNmax\nmax number of transcripts per window\ninteger, example: 100\n\n\n--alignTranscriptsPerReadNmax\nmax number of different alignments per read to consider\ninteger, example: 10000\n\n\n--alignEndsType\ntype of read ends alignment - Local ‚Ä¶ standard local alignment with soft-clipping allowed - EndToEnd ‚Ä¶ force end-to-end read alignment, do not soft-clip - Extend5pOfRead1 ‚Ä¶ fully extend only the 5p of the read1, all other ends: local alignment - Extend5pOfReads12 ‚Ä¶ fully extend only the 5p of the both read1 and read2, all other ends: local alignment\nstring, example: \"Local\"\n\n\n--alignEndsProtrude\nallow protrusion of alignment ends, i.e.¬†start (end) of the +strand mate downstream of the start (end) of the -strand mate 1st word: int: maximum number of protrusion bases allowed 2nd word: string: - ConcordantPair ‚Ä¶ report alignments with non-zero protrusion as concordant pairs - DiscordantPair ‚Ä¶ report alignments with non-zero protrusion as discordant pairs\nstring, example: \"0    ConcordantPair\"\n\n\n--alignSoftClipAtReferenceEnds\nallow the soft-clipping of the alignments past the end of the chromosomes - Yes ‚Ä¶ allow - No ‚Ä¶ prohibit, useful for compatibility with Cufflinks\nstring, example: \"Yes\"\n\n\n--alignInsertionFlush\nhow to flush ambiguous insertion positions - None ‚Ä¶ insertions are not flushed - Right ‚Ä¶ insertions are flushed to the right\nstring\n\n\n\n\n\nPaired-End reads\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--peOverlapNbasesMin\nminimum number of overlapping bases to trigger mates merging and realignment. Specify &gt;0 value to switch on the ‚Äúmerginf of overlapping mates‚Äù algorithm.\ninteger, example: 0\n\n\n--peOverlapMMp\nmaximum proportion of mismatched bases in the overlap area\ndouble, example: 0.01\n\n\n\n\n\nWindows, Anchors, Binning\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--winAnchorMultimapNmax\nmax number of loci anchors are allowed to map to\ninteger, example: 50\n\n\n--winBinNbits\n=log2(winBin), where winBin is the size of the bin for the windows/clustering, each window will occupy an integer number of bins.\ninteger, example: 16\n\n\n--winAnchorDistNbins\nmax number of bins between two anchors that allows aggregation of anchors into one window\ninteger, example: 9\n\n\n--winFlankNbins\nlog2(winFlank), where win Flank is the size of the left and right flanking regions for each window\ninteger, example: 4\n\n\n--winReadCoverageRelativeMin\nminimum relative coverage of the read sequence by the seeds in a window, for STARlong algorithm only.\ndouble, example: 0.5\n\n\n--winReadCoverageBasesMin\nminimum number of bases covered by the seeds in a window , for STARlong algorithm only.\ninteger, example: 0\n\n\n\n\n\nChimeric Alignments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--chimOutType\ntype of chimeric output - Junctions ‚Ä¶ Chimeric.out.junction - SeparateSAMold ‚Ä¶ output old SAM into separate Chimeric.out.sam file - WithinBAM ‚Ä¶ output into main aligned BAM files (Aligned.*.bam) - WithinBAM HardClip ‚Ä¶ (default) hard-clipping in the CIGAR for supplemental chimeric alignments (default if no 2nd word is present) - WithinBAM SoftClip ‚Ä¶ soft-clipping in the CIGAR for supplemental chimeric alignments\nList of string, example: \"Junctions\", multiple_sep: \";\"\n\n\n--chimSegmentMin\nminimum length of chimeric segment length, if ==0, no chimeric output\ninteger, example: 0\n\n\n--chimScoreMin\nminimum total (summed) score of the chimeric segments\ninteger, example: 0\n\n\n--chimScoreDropMax\nmax drop (difference) of chimeric score (the sum of scores of all chimeric segments) from the read length\ninteger, example: 20\n\n\n--chimScoreSeparation\nminimum difference (separation) between the best chimeric score and the next one\ninteger, example: 10\n\n\n--chimScoreJunctionNonGTAG\npenalty for a non-GT/AG chimeric junction\ninteger, example: -1\n\n\n--chimJunctionOverhangMin\nminimum overhang for a chimeric junction\ninteger, example: 20\n\n\n--chimSegmentReadGapMax\nmaximum gap in the read sequence between chimeric segments\ninteger, example: 0\n\n\n--chimFilter\ndifferent filters for chimeric alignments - None ‚Ä¶ no filtering - banGenomicN ‚Ä¶ Ns are not allowed in the genome sequence around the chimeric junction\nList of string, example: \"banGenomicN\", multiple_sep: \";\"\n\n\n--chimMainSegmentMultNmax\nmaximum number of multi-alignments for the main chimeric segment. =1 will prohibit multimapping main segments.\ninteger, example: 10\n\n\n--chimMultimapNmax\nmaximum number of chimeric multi-alignments - 0 ‚Ä¶ use the old scheme for chimeric detection which only considered unique alignments\ninteger, example: 0\n\n\n--chimMultimapScoreRange\nthe score range for multi-mapping chimeras below the best chimeric score. Only works with ‚ÄìchimMultimapNmax &gt; 1\ninteger, example: 1\n\n\n--chimNonchimScoreDropMin\nto trigger chimeric detection, the drop in the best non-chimeric alignment score with respect to the read length has to be greater than this value\ninteger, example: 20\n\n\n--chimOutJunctionFormat\nformatting type for the Chimeric.out.junction file - 0 ‚Ä¶ no comment lines/headers - 1 ‚Ä¶ comment lines at the end of the file: command line and Nreads: total, unique/multi-mapping\ninteger, example: 0\n\n\n\n\n\nQuantification of Annotations\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--quantMode\ntypes of quantification requested - - ‚Ä¶ none - TranscriptomeSAM ‚Ä¶ output SAM/BAM alignments to transcriptome into a separate file - GeneCounts ‚Ä¶ count reads per gene\nList of string, multiple_sep: \";\"\n\n\n--quantTranscriptomeBAMcompression\n-2 to 10 transcriptome BAM compression level - -2 ‚Ä¶ no BAM output - -1 ‚Ä¶ default compression (6?) - 0 ‚Ä¶ no compression - 10 ‚Ä¶ maximum compression\ninteger, example: 1\n\n\n--quantTranscriptomeBan\nprohibit various alignment type - IndelSoftclipSingleend ‚Ä¶ prohibit indels, soft clipping and single-end alignments - compatible with RSEM - Singleend ‚Ä¶ prohibit single-end alignments\nstring, example: \"IndelSoftclipSingleend\"\n\n\n\n\n\n2-pass Mapping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--twopassMode\n2-pass mapping mode. - None ‚Ä¶ 1-pass mapping - Basic ‚Ä¶ basic 2-pass mapping, with all 1st pass junctions inserted into the genome indices on the fly\nstring\n\n\n--twopass1readsN\nnumber of reads to process for the 1st step. Use very large number (or default -1) to map all reads in the first step.\ninteger, example: -1\n\n\n\n\n\nWASP parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--waspOutputMode\nWASP allele-specific output type. This is re-implementation of the original WASP mappability filtering by Bryce van de Geijn, Graham McVicker, Yoav Gilad & Jonathan K Pritchard. Please cite the original WASP paper: Nature Methods 12, 1061-1063 (2015), https://www.nature.com/articles/nmeth.3582 . - SAMtag ‚Ä¶ add WASP tags to the alignments that pass WASP filtering\nstring\n\n\n\n\n\nSTARsolo (single cell RNA-seq) parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--soloType\ntype of single-cell RNA-seq - CB_UMI_Simple ‚Ä¶ (a.k.a. Droplet) one UMI and one Cell Barcode of fixed length in read2, e.g.¬†Drop-seq and 10X Chromium. - CB_UMI_Complex ‚Ä¶ multiple Cell Barcodes of varying length, one UMI of fixed length and one adapter sequence of fixed length are allowed in read2 only (e.g.¬†inDrop, ddSeq). - CB_samTagOut ‚Ä¶ output Cell Barcode as CR and/or CB SAm tag. No UMI counting. ‚ÄìreadFilesIn cDNA_read1 [cDNA_read2 if paired-end] CellBarcode_read . Requires ‚ÄìoutSAMtype BAM Unsorted [and/or SortedByCoordinate] - SmartSeq ‚Ä¶ Smart-seq: each cell in a separate FASTQ (paired- or single-end), barcodes are corresponding read-groups, no UMI sequences, alignments deduplicated according to alignment start and end (after extending soft-clipped bases)\nList of string, multiple_sep: \";\"\n\n\n--soloCBwhitelist\nfile(s) with whitelist(s) of cell barcodes. Only ‚ÄìsoloType CB_UMI_Complex allows more than one whitelist file. - None ‚Ä¶ no whitelist: all cell barcodes are allowed\nList of string, multiple_sep: \";\"\n\n\n--soloCBstart\ncell barcode start base\ninteger, example: 1\n\n\n--soloCBlen\ncell barcode length\ninteger, example: 16\n\n\n--soloUMIstart\nUMI start base\ninteger, example: 17\n\n\n--soloUMIlen\nUMI length\ninteger, example: 10\n\n\n--soloBarcodeReadLength\nlength of the barcode read - 1 ‚Ä¶ equal to sum of soloCBlen+soloUMIlen - 0 ‚Ä¶ not defined, do not check\ninteger, example: 1\n\n\n--soloBarcodeMate\nidentifies which read mate contains the barcode (CB+UMI) sequence - 0 ‚Ä¶ barcode sequence is on separate read, which should always be the last file in the ‚ÄìreadFilesIn listed - 1 ‚Ä¶ barcode sequence is a part of mate 1 - 2 ‚Ä¶ barcode sequence is a part of mate 2\ninteger, example: 0\n\n\n--soloCBposition\nposition of Cell Barcode(s) on the barcode read. Presently only works with ‚ÄìsoloType CB_UMI_Complex, and barcodes are assumed to be on Read2. Format for each barcode: startAnchor_startPosition_endAnchor_endPosition start(end)Anchor defines the Anchor Base for the CB: 0: read start; 1: read end; 2: adapter start; 3: adapter end start(end)Position is the 0-based position with of the CB start(end) with respect to the Anchor Base String for different barcodes are separated by space. Example: inDrop (Zilionis et al, Nat. Protocols, 2017): ‚ÄìsoloCBposition 0_0_2_-1 3_1_3_8\nList of string, multiple_sep: \";\"\n\n\n--soloUMIposition\nposition of the UMI on the barcode read, same as soloCBposition Example: inDrop (Zilionis et al, Nat. Protocols, 2017): ‚ÄìsoloCBposition 3_9_3_14\nstring\n\n\n--soloAdapterSequence\nadapter sequence to anchor barcodes. Only one adapter sequence is allowed.\nstring\n\n\n--soloAdapterMismatchesNmax\nmaximum number of mismatches allowed in adapter sequence.\ninteger, example: 1\n\n\n--soloCBmatchWLtype\nmatching the Cell Barcodes to the WhiteList - Exact ‚Ä¶ only exact matches allowed - 1MM ‚Ä¶ only one match in whitelist with 1 mismatched base allowed. Allowed CBs have to have at least one read with exact match. - 1MM_multi ‚Ä¶ multiple matches in whitelist with 1 mismatched base allowed, posterior probability calculation is used choose one of the matches. Allowed CBs have to have at least one read with exact match. This option matches best with CellRanger 2.2.0 - 1MM_multi_pseudocounts ‚Ä¶ same as 1MM_Multi, but pseudocounts of 1 are added to all whitelist barcodes. - 1MM_multi_Nbase_pseudocounts ‚Ä¶ same as 1MM_multi_pseudocounts, multimatching to WL is allowed for CBs with N-bases. This option matches best with CellRanger &gt;= 3.0.0 - EditDist_2 ‚Ä¶ allow up to edit distance of 3 fpr each of the barcodes. May include one deletion + one insertion. Only works with ‚ÄìsoloType CB_UMI_Complex. Matches to multiple passlist barcdoes are not allowed. Similar to ParseBio Split-seq pipeline.\nstring, example: \"1MM_multi\"\n\n\n--soloInputSAMattrBarcodeSeq\nwhen inputting reads from a SAM file (‚ÄìreadsFileType SAM SE/PE), these SAM attributes mark the barcode sequence (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use ‚ÄìsoloInputSAMattrBarcodeSeq CR UR . This parameter is required when running STARsolo with input from SAM.\nList of string, multiple_sep: \";\"\n\n\n--soloInputSAMattrBarcodeQual\nwhen inputting reads from a SAM file (‚ÄìreadsFileType SAM SE/PE), these SAM attributes mark the barcode qualities (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use ‚ÄìsoloInputSAMattrBarcodeQual CY UY . If this parameter is ‚Äò-‚Äô (default), the quality ‚ÄòH‚Äô will be assigned to all bases.\nList of string, multiple_sep: \";\"\n\n\n--soloStrand\nstrandedness of the solo libraries: - Unstranded ‚Ä¶ no strand information - Forward ‚Ä¶ read strand same as the original RNA molecule - Reverse ‚Ä¶ read strand opposite to the original RNA molecule\nstring, example: \"Forward\"\n\n\n--soloFeatures\ngenomic features for which the UMI counts per Cell Barcode are collected - Gene ‚Ä¶ genes: reads match the gene transcript - SJ ‚Ä¶ splice junctions: reported in SJ.out.tab - GeneFull ‚Ä¶ full gene (pre-mRNA): count all reads overlapping genes‚Äô exons and introns - GeneFull_ExonOverIntron ‚Ä¶ full gene (pre-mRNA): count all reads overlapping genes‚Äô exons and introns: prioritize 100% overlap with exons - GeneFull_Ex50pAS ‚Ä¶ full gene (pre-RNA): count all reads overlapping genes‚Äô exons and introns: prioritize &gt;50% overlap with exons. Do not count reads with 100% exonic overlap in the antisense direction.\nList of string, example: \"Gene\", multiple_sep: \";\"\n\n\n--soloMultiMappers\ncounting method for reads mapping to multiple genes - Unique ‚Ä¶ count only reads that map to unique genes - Uniform ‚Ä¶ uniformly distribute multi-genic UMIs to all genes - Rescue ‚Ä¶ distribute UMIs proportionally to unique+uniform counts (~ first iteration of EM) - PropUnique ‚Ä¶ distribute UMIs proportionally to unique mappers, if present, and uniformly if not. - EM ‚Ä¶ multi-gene UMIs are distributed using Expectation Maximization algorithm\nList of string, example: \"Unique\", multiple_sep: \";\"\n\n\n--soloUMIdedup\ntype of UMI deduplication (collapsing) algorithm - 1MM_All ‚Ä¶ all UMIs with 1 mismatch distance to each other are collapsed (i.e.¬†counted once). - 1MM_Directional_UMItools ‚Ä¶ follows the ‚Äúdirectional‚Äù method from the UMI-tools by Smith, Heger and Sudbery (Genome Research 2017). - 1MM_Directional ‚Ä¶ same as 1MM_Directional_UMItools, but with more stringent criteria for duplicate UMIs - Exact ‚Ä¶ only exactly matching UMIs are collapsed. - NoDedup ‚Ä¶ no deduplication of UMIs, count all reads. - 1MM_CR ‚Ä¶ CellRanger2-4 algorithm for 1MM UMI collapsing.\nList of string, example: \"1MM_All\", multiple_sep: \";\"\n\n\n--soloUMIfiltering\ntype of UMI filtering (for reads uniquely mapping to genes) - - ‚Ä¶ basic filtering: remove UMIs with N and homopolymers (similar to CellRanger 2.2.0). - MultiGeneUMI ‚Ä¶ basic + remove lower-count UMIs that map to more than one gene. - MultiGeneUMI_All ‚Ä¶ basic + remove all UMIs that map to more than one gene. - MultiGeneUMI_CR ‚Ä¶ basic + remove lower-count UMIs that map to more than one gene, matching CellRanger &gt; 3.0.0 . Only works with ‚ÄìsoloUMIdedup 1MM_CR\nList of string, multiple_sep: \";\"\n\n\n--soloOutFileNames\nfile names for STARsolo output: file_name_prefix gene_names barcode_sequences cell_feature_count_matrix\nList of string, example: \"Solo.out/\", \"features.tsv\", \"barcodes.tsv\", \"matrix.mtx\", multiple_sep: \";\"\n\n\n--soloCellFilter\ncell filtering type and parameters - None ‚Ä¶ do not output filtered cells - TopCells ‚Ä¶ only report top cells by UMI count, followed by the exact number of cells - CellRanger2.2 ‚Ä¶ simple filtering of CellRanger 2.2. Can be followed by numbers: number of expected cells, robust maximum percentile for UMI count, maximum to minimum ratio for UMI count The harcoded values are from CellRanger: nExpectedCells=3000; maxPercentile=0.99; maxMinRatio=10 - EmptyDrops_CR ‚Ä¶ EmptyDrops filtering in CellRanger flavor. Please cite the original EmptyDrops paper: A.T.L Lun et al, Genome Biology, 20, 63 (2019): https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1662-y Can be followed by 10 numeric parameters: nExpectedCells maxPercentile maxMinRatio indMin indMax umiMin umiMinFracMedian candMaxN FDR simN The harcoded values are from CellRanger: 3000 0.99 10 45000 90000 500 0.01 20000 0.01 10000\nList of string, example: \"CellRanger2.2\", \"3000\", \"0.99\", \"10\", multiple_sep: \";\"\n\n\n--soloOutFormatFeaturesGeneField3\nfield 3 in the Gene features.tsv file. If ‚Äú-‚Äù, then no 3rd field is output.\nList of string, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--soloCellReadStats\nOutput reads statistics for each CB - Standard ‚Ä¶ standard output\nstring"
  },
  {
    "objectID": "components/modules/mapping/star_align_v273a.html#authors",
    "href": "components/modules/mapping/star_align_v273a.html#authors",
    "title": "Star align v273a",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/mapping/star_align.html",
    "href": "components/modules/mapping/star_align.html",
    "title": "Star align",
    "section": "",
    "text": "ID: star_align\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/star_align.html#example-commands",
    "href": "components/modules/mapping/star_align.html#example-commands",
    "title": "Star align",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/mapping/star_align/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input/Output\ninput: # please fill in - example: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\nreference: # please fill in - example: \"/path/to/reference\"\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/star_align/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/star_align.html#argument-groups",
    "href": "components/modules/mapping/star_align.html#argument-groups",
    "title": "Star align",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput/Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe FASTQ files to be analyzed. Corresponds to the ‚ÄìreadFilesIn argument in the STAR command.\nList of file, required, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nPath to the reference built by star_build_reference. Corresponds to the ‚ÄìgenomeDir argument in the STAR command.\nfile, required, example: \"/path/to/reference\"\n\n\n--output\nPath to output directory. Corresponds to the ‚ÄìoutFileNamePrefix argument in the STAR command.\nfile, required, example: \"/path/to/foo\"\n\n\n\n\n\nRun Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--runRNGseed\nrandom number generator seed.\ninteger, example: 777\n\n\n\n\n\nGenome Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genomeLoad\nmode of shared memory usage for the genome files. Only used with ‚ÄìrunMode alignReads. - LoadAndKeep ‚Ä¶ load genome into shared and keep it in memory after run - LoadAndRemove ‚Ä¶ load genome into shared but remove it after run - LoadAndExit ‚Ä¶ load genome into shared memory and exit, keeping the genome in memory for future runs - Remove ‚Ä¶ do not map anything, just remove loaded genome from memory - NoSharedMemory ‚Ä¶ do not use shared memory, each job will have its own private copy of the genome\nstring, example: \"NoSharedMemory\"\n\n\n--genomeFastaFiles\npath(s) to the fasta files with the genome sequences, separated by spaces. These files should be plain text FASTA files, they cannot be zipped. Required for the genome generation (‚ÄìrunMode genomeGenerate). Can also be used in the mapping (‚ÄìrunMode alignReads) to add extra (new) sequences to the genome (e.g.¬†spike-ins).\nList of file, multiple_sep: \";\"\n\n\n--genomeFileSizes\ngenome files exact sizes in bytes. Typically, this should not be defined by the user.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--genomeTransformOutput\nwhich output to transform back to original genome - SAM ‚Ä¶ SAM/BAM alignments - SJ ‚Ä¶ splice junctions (SJ.out.tab) - None ‚Ä¶ no transformation of the output\nList of string, multiple_sep: \";\"\n\n\n--genomeChrSetMitochondrial\nnames of the mitochondrial chromosomes. Presently only used for STARsolo statistics output/\nList of string, example: \"chrM\", \"M\", \"MT\", multiple_sep: \";\"\n\n\n\n\n\nSplice Junctions Database\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sjdbFileChrStartEnd\npath to the files with genomic coordinates (chr  start  end  strand) for the splice junction introns. Multiple files can be supplied and will be concatenated.\nList of string, multiple_sep: \";\"\n\n\n--sjdbGTFfile\npath to the GTF file with annotations\nfile\n\n\n--sjdbGTFchrPrefix\nprefix for chromosome names in a GTF file (e.g.¬†‚Äòchr‚Äô for using ENSMEBL annotations with UCSC genomes)\nstring\n\n\n--sjdbGTFfeatureExon\nfeature type in GTF file to be used as exons for building transcripts\nstring, example: \"exon\"\n\n\n--sjdbGTFtagExonParentTranscript\nGTF attribute name for parent transcript ID (default ‚Äútranscript_id‚Äù works for GTF files)\nstring, example: \"transcript_id\"\n\n\n--sjdbGTFtagExonParentGene\nGTF attribute name for parent gene ID (default ‚Äúgene_id‚Äù works for GTF files)\nstring, example: \"gene_id\"\n\n\n--sjdbGTFtagExonParentGeneName\nGTF attribute name for parent gene name\nList of string, example: \"gene_name\", multiple_sep: \";\"\n\n\n--sjdbGTFtagExonParentGeneType\nGTF attribute name for parent gene type\nList of string, example: \"gene_type\", \"gene_biotype\", multiple_sep: \";\"\n\n\n--sjdbOverhang\nlength of the donor/acceptor sequence on each side of the junctions, ideally = (mate_length - 1)\ninteger, example: 100\n\n\n--sjdbScore\nextra alignment score for alignments that cross database junctions\ninteger, example: 2\n\n\n--sjdbInsertSave\nwhich files to save when sjdb junctions are inserted on the fly at the mapping step - Basic ‚Ä¶ only small junction / transcript files - All ‚Ä¶ all files including big Genome, SA and SAindex - this will create a complete genome directory\nstring, example: \"Basic\"\n\n\n\n\n\nVariation parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--varVCFfile\npath to the VCF file that contains variation data. The 10th column should contain the genotype information, e.g.¬†0/1\nstring\n\n\n\n\n\nRead Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--readFilesType\nformat of input read files - Fastx ‚Ä¶ FASTA or FASTQ - SAM SE ‚Ä¶ SAM or BAM single-end reads; for BAM use ‚ÄìreadFilesCommand samtools view - SAM PE ‚Ä¶ SAM or BAM paired-end reads; for BAM use ‚ÄìreadFilesCommand samtools view\nstring, example: \"Fastx\"\n\n\n--readFilesSAMattrKeep\nfor ‚ÄìreadFilesType SAM SE/PE, which SAM tags to keep in the output BAM, e.g.: ‚ÄìreadFilesSAMtagsKeep RG PL - All ‚Ä¶ keep all tags - None ‚Ä¶ do not keep any tags\nList of string, example: \"All\", multiple_sep: \";\"\n\n\n--readFilesManifest\npath to the ‚Äúmanifest‚Äù file with the names of read files. The manifest file should contain 3 tab-separated columns: paired-end reads: read1_file_name \\(tab\\) read2_file_name \\(tab\\) read_group_line. single-end reads: read1_file_name \\(tab\\) - \\(tab\\) read_group_line. Spaces, but not tabs are allowed in file names. If read_group_line does not start with ID:, it can only contain one ID field, and ID: will be added to it. If read_group_line starts with ID:, it can contain several fields separated by \\(tab\\), and all fields will be be copied verbatim into SAM @RG header line.\nfile\n\n\n--readFilesPrefix\nprefix for the read files names, i.e.¬†it will be added in front of the strings in ‚ÄìreadFilesIn\nstring\n\n\n--readFilesCommand\ncommand line to execute for each of the input file. This command should generate FASTA or FASTQ text and send it to stdout For example: zcat - to uncompress .gz files, bzcat - to uncompress .bz2 files, etc.\nList of string, multiple_sep: \";\"\n\n\n--readMapNumber\nnumber of reads to map from the beginning of the file -1: map all reads\ninteger, example: -1\n\n\n--readMatesLengthsIn\nEqual/NotEqual - lengths of names,sequences,qualities for both mates are the same / not the same. NotEqual is safe in all situations.\nstring, example: \"NotEqual\"\n\n\n--readNameSeparator\ncharacter(s) separating the part of the read names that will be trimmed in output (read name after space is always trimmed)\nList of string, example: \"/\", multiple_sep: \";\"\n\n\n--readQualityScoreBase\nnumber to be subtracted from the ASCII code to get Phred quality score\ninteger, example: 33\n\n\n\n\n\nRead Clipping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--clipAdapterType\nadapter clipping type - Hamming ‚Ä¶ adapter clipping based on Hamming distance, with the number of mismatches controlled by ‚Äìclip5pAdapterMMp - CellRanger4 ‚Ä¶ 5p and 3p adapter clipping similar to CellRanger4. Utilizes Opal package by Martin Sosic: https://github.com/Martinsos/opal - None ‚Ä¶ no adapter clipping, all other clip* parameters are disregarded\nstring, example: \"Hamming\"\n\n\n--clip3pNbases\nnumber(s) of bases to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip3pAdapterSeq\nadapter sequences to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates. - polyA ‚Ä¶ polyA sequence with the length equal to read length\nList of string, multiple_sep: \";\"\n\n\n--clip3pAdapterMMp\nmax proportion of mismatches for 3p adapter clipping for each mate. If one value is given, it will be assumed the same for both mates.\nList of double, example: 0.1, multiple_sep: \";\"\n\n\n--clip3pAfterAdapterNbases\nnumber of bases to clip from 3p of each mate after the adapter clipping. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip5pNbases\nnumber(s) of bases to clip from 5p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n\n\n\nLimits\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--limitGenomeGenerateRAM\nmaximum available RAM (bytes) for genome generation\nlong, example: NA\n\n\n--limitIObufferSize\nmax available buffers size (bytes) for input/output, per thread\nList of long, example: 30000000, 50000000, multiple_sep: \";\"\n\n\n--limitOutSAMoneReadBytes\nmax size of the SAM record (bytes) for one read. Recommended value: &gt;(2(LengthMate1+LengthMate2+100)outFilterMultimapNmax\nlong, example: 100000\n\n\n--limitOutSJoneRead\nmax number of junctions for one read (including all multi-mappers)\ninteger, example: 1000\n\n\n--limitOutSJcollapsed\nmax number of collapsed junctions\ninteger, example: 1000000\n\n\n--limitBAMsortRAM\nmaximum available RAM (bytes) for sorting BAM. If =0, it will be set to the genome index size. 0 value can only be used with ‚ÄìgenomeLoad NoSharedMemory option.\nlong, example: 0\n\n\n--limitSjdbInsertNsj\nmaximum number of junctions to be inserted to the genome on the fly at the mapping stage, including those from annotations and those detected in the 1st step of the 2-pass run\ninteger, example: 1000000\n\n\n--limitNreadsSoft\nsoft limit on the number of reads\ninteger, example: -1\n\n\n\n\n\nOutput: general\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outTmpKeep\nwhether to keep the temporary files after STAR runs is finished - None ‚Ä¶ remove all temporary files - All ‚Ä¶ keep all files\nstring\n\n\n--outStd\nwhich output will be directed to stdout (standard out) - Log ‚Ä¶ log messages - SAM ‚Ä¶ alignments in SAM format (which normally are output to Aligned.out.sam file), normal standard output will go into Log.std.out - BAM_Unsorted ‚Ä¶ alignments in BAM format, unsorted. Requires ‚ÄìoutSAMtype BAM Unsorted - BAM_SortedByCoordinate ‚Ä¶ alignments in BAM format, sorted by coordinate. Requires ‚ÄìoutSAMtype BAM SortedByCoordinate - BAM_Quant ‚Ä¶ alignments to transcriptome in BAM format, unsorted. Requires ‚ÄìquantMode TranscriptomeSAM\nstring, example: \"Log\"\n\n\n--outReadsUnmapped\noutput of unmapped and partially mapped (i.e.¬†mapped only one mate of a paired end read) reads in separate file(s). - None ‚Ä¶ no output - Fastx ‚Ä¶ output in separate fasta/fastq files, Unmapped.out.mate1/2\nstring\n\n\n--outQSconversionAdd\nadd this number to the quality score (e.g.¬†to convert from Illumina to Sanger, use -31)\ninteger, example: 0\n\n\n--outMultimapperOrder\norder of multimapping alignments in the output files - Old_2.4 ‚Ä¶ quasi-random order used before 2.5.0 - Random ‚Ä¶ random order of alignments for each multi-mapper. Read mates (pairs) are always adjacent, all alignment for each read stay together. This option will become default in the future releases.\nstring, example: \"Old_2.4\"\n\n\n\n\n\nOutput: SAM and BAM\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSAMtype\ntype of SAM/BAM output 1st word: - BAM ‚Ä¶ output BAM without sorting - SAM ‚Ä¶ output SAM without sorting - None ‚Ä¶ no SAM/BAM output 2nd, 3rd: - Unsorted ‚Ä¶ standard unsorted - SortedByCoordinate ‚Ä¶ sorted by coordinate. This option will allocate extra memory for sorting which can be specified by ‚ÄìlimitBAMsortRAM.\nList of string, example: \"SAM\", multiple_sep: \";\"\n\n\n--outSAMmode\nmode of SAM output - None ‚Ä¶ no SAM output - Full ‚Ä¶ full SAM output - NoQS ‚Ä¶ full SAM but without quality scores\nstring, example: \"Full\"\n\n\n--outSAMstrandField\nCufflinks-like strand field flag - None ‚Ä¶ not used - intronMotif ‚Ä¶ strand derived from the intron motif. This option changes the output alignments: reads with inconsistent and/or non-canonical introns are filtered out.\nstring\n\n\n--outSAMattributes\na string of desired SAM attributes, in the order desired for the output SAM. Tags can be listed in any combination/order. Presets: - None ‚Ä¶ no attributes - Standard ‚Ä¶ NH HI AS nM - All ‚Ä¶ NH HI AS nM NM MD jM jI MC ch Alignment: - NH ‚Ä¶ number of loci the reads maps to: =1 for unique mappers, &gt;1 for multimappers. Standard SAM tag. - HI ‚Ä¶ multiple alignment index, starts with ‚ÄìoutSAMattrIHstart (=1 by default). Standard SAM tag. - AS ‚Ä¶ local alignment score, +1/-1 for matches/mismateches, score* penalties for indels and gaps. For PE reads, total score for two mates. Stadnard SAM tag. - nM ‚Ä¶ number of mismatches. For PE reads, sum over two mates. - NM ‚Ä¶ edit distance to the reference (number of mismatched + inserted + deleted bases) for each mate. Standard SAM tag. - MD ‚Ä¶ string encoding mismatched and deleted reference bases (see standard SAM specifications). Standard SAM tag. - jM ‚Ä¶ intron motifs for all junctions (i.e.¬†N in CIGAR): 0: non-canonical; 1: GT/AG, 2: CT/AC, 3: GC/AG, 4: CT/GC, 5: AT/AC, 6: GT/AT. If splice junctions database is used, and a junction is annotated, 20 is added to its motif value. - jI ‚Ä¶ start and end of introns for all junctions (1-based). - XS ‚Ä¶ alignment strand according to ‚ÄìoutSAMstrandField. - MC ‚Ä¶ mate‚Äôs CIGAR string. Standard SAM tag. - ch ‚Ä¶ marks all segment of all chimeric alingments for ‚ÄìchimOutType WithinBAM output. - cN ‚Ä¶ number of bases clipped from the read ends: 5‚Äô and 3‚Äô Variation: - vA ‚Ä¶ variant allele - vG ‚Ä¶ genomic coordinate of the variant overlapped by the read. - vW ‚Ä¶ 1 - alignment passes WASP filtering; 2,3,4,5,6,7 - alignment does not pass WASP filtering. Requires ‚ÄìwaspOutputMode SAMtag. STARsolo: - CR CY UR UY ‚Ä¶ sequences and quality scores of cell barcodes and UMIs for the solo* demultiplexing. - GX GN ‚Ä¶ gene ID and gene name for unique-gene reads. - gx gn ‚Ä¶ gene IDs and gene names for unique- and multi-gene reads. - CB UB ‚Ä¶ error-corrected cell barcodes and UMIs for solo* demultiplexing. Requires ‚ÄìoutSAMtype BAM SortedByCoordinate. - sM ‚Ä¶ assessment of CB and UMI. - sS ‚Ä¶ sequence of the entire barcode (CB,UMI,adapter). - sQ ‚Ä¶ quality of the entire barcode. ***Unsupported/undocumented: - ha ‚Ä¶ haplotype (1/2) when mapping to the diploid genome. Requires genome generated with ‚ÄìgenomeTransformType Diploid . - rB ‚Ä¶ alignment block read/genomic coordinates. - vR ‚Ä¶ read coordinate of the variant.\nList of string, example: \"Standard\", multiple_sep: \";\"\n\n\n--outSAMattrIHstart\nstart value for the IH attribute. 0 may be required by some downstream software, such as Cufflinks or StringTie.\ninteger, example: 1\n\n\n--outSAMunmapped\noutput of unmapped reads in the SAM format 1st word: - None ‚Ä¶ no output - Within ‚Ä¶ output unmapped reads within the main SAM file (i.e.¬†Aligned.out.sam) 2nd word: - KeepPairs ‚Ä¶ record unmapped mate for each alignment, and, in case of unsorted output, keep it adjacent to its mapped mate. Only affects multi-mapping reads.\nList of string, multiple_sep: \";\"\n\n\n--outSAMorder\ntype of sorting for the SAM output Paired: one mate after the other for all paired alignments PairedKeepInputOrder: one mate after the other for all paired alignments, the order is kept the same as in the input FASTQ files\nstring, example: \"Paired\"\n\n\n--outSAMprimaryFlag\nwhich alignments are considered primary - all others will be marked with 0x100 bit in the FLAG - OneBestScore ‚Ä¶ only one alignment with the best score is primary - AllBestScore ‚Ä¶ all alignments with the best score are primary\nstring, example: \"OneBestScore\"\n\n\n--outSAMreadID\nread ID record type - Standard ‚Ä¶ first word (until space) from the FASTx read ID line, removing /1,/2 from the end - Number ‚Ä¶ read number (index) in the FASTx file\nstring, example: \"Standard\"\n\n\n--outSAMmapqUnique\n0 to 255: the MAPQ value for unique mappers\ninteger, example: 255\n\n\n--outSAMflagOR\n0 to 65535: sam FLAG will be bitwise OR‚Äôd with this value, i.e.¬†FLAG=FLAG | outSAMflagOR. This is applied after all flags have been set by STAR, and after outSAMflagAND. Can be used to set specific bits that are not set otherwise.\ninteger, example: 0\n\n\n--outSAMflagAND\n0 to 65535: sam FLAG will be bitwise AND‚Äôd with this value, i.e.¬†FLAG=FLAG & outSAMflagOR. This is applied after all flags have been set by STAR, but before outSAMflagOR. Can be used to unset specific bits that are not set otherwise.\ninteger, example: 65535\n\n\n--outSAMattrRGline\nSAM/BAM read group line. The first word contains the read group identifier and must start with ‚ÄúID:‚Äù, e.g.¬†‚ÄìoutSAMattrRGline ID:xxx CN:yy ‚ÄúDS:z z z‚Äù. xxx will be added as RG tag to each output alignment. Any spaces in the tag values have to be double quoted. Comma separated RG lines correspons to different (comma separated) input files in ‚ÄìreadFilesIn. Commas have to be surrounded by spaces, e.g.¬†‚ÄìoutSAMattrRGline ID:xxx , ID:zzz ‚ÄúDS:z z‚Äù , ID:yyy DS:yyyy\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderHD\n@HD (header) line of the SAM header\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderPG\nextra @PG (software) line of the SAM header (in addition to STAR)\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderCommentFile\npath to the file with @CO (comment) lines of the SAM header\nstring\n\n\n--outSAMfilter\nfilter the output into main SAM/BAM files - KeepOnlyAddedReferences ‚Ä¶ only keep the reads for which all alignments are to the extra reference sequences added with ‚ÄìgenomeFastaFiles at the mapping stage. - KeepAllAddedReferences ‚Ä¶ keep all alignments to the extra reference sequences added with ‚ÄìgenomeFastaFiles at the mapping stage.\nList of string, multiple_sep: \";\"\n\n\n--outSAMmultNmax\nmax number of multiple alignments for a read that will be output to the SAM/BAM files. Note that if this value is not equal to -1, the top scoring alignment will be output first - -1 ‚Ä¶ all alignments (up to ‚ÄìoutFilterMultimapNmax) will be output\ninteger, example: -1\n\n\n--outSAMtlen\ncalculation method for the TLEN field in the SAM/BAM files - 1 ‚Ä¶ leftmost base of the (+)strand mate to rightmost base of the (-)mate. (+)sign for the (+)strand mate - 2 ‚Ä¶ leftmost base of any mate to rightmost base of any mate. (+)sign for the mate with the leftmost base. This is different from 1 for overlapping mates with protruding ends\ninteger, example: 1\n\n\n--outBAMcompression\n-1 to 10 BAM compression level, -1=default compression (6?), 0=no compression, 10=maximum compression\ninteger, example: 1\n\n\n--outBAMsortingThreadN\n&gt;=0: number of threads for BAM sorting. 0 will default to min(6,‚ÄìrunThreadN).\ninteger, example: 0\n\n\n--outBAMsortingBinsN\n&gt;0: number of genome bins for coordinate-sorting\ninteger, example: 50\n\n\n\n\n\nBAM processing\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--bamRemoveDuplicatesType\nmark duplicates in the BAM file, for now only works with (i) sorted BAM fed with inputBAMfile, and (ii) for paired-end alignments only - - ‚Ä¶ no duplicate removal/marking - UniqueIdentical ‚Ä¶ mark all multimappers, and duplicate unique mappers. The coordinates, FLAG, CIGAR must be identical - UniqueIdenticalNotMulti ‚Ä¶ mark duplicate unique mappers but not multimappers.\nstring\n\n\n--bamRemoveDuplicatesMate2basesN\nnumber of bases from the 5‚Äô of mate 2 to use in collapsing (e.g.¬†for RAMPAGE)\ninteger, example: 0\n\n\n\n\n\nOutput Wiggle\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outWigType\ntype of signal output, e.g.¬†‚ÄúbedGraph‚Äù OR ‚ÄúbedGraph read1_5p‚Äù. Requires sorted BAM: ‚ÄìoutSAMtype BAM SortedByCoordinate . 1st word: - None ‚Ä¶ no signal output - bedGraph ‚Ä¶ bedGraph format - wiggle ‚Ä¶ wiggle format 2nd word: - read1_5p ‚Ä¶ signal from only 5‚Äô of the 1st read, useful for CAGE/RAMPAGE etc - read2 ‚Ä¶ signal from only 2nd read\nList of string, multiple_sep: \";\"\n\n\n--outWigStrand\nstrandedness of wiggle/bedGraph output - Stranded ‚Ä¶ separate strands, str1 and str2 - Unstranded ‚Ä¶ collapsed strands\nstring, example: \"Stranded\"\n\n\n--outWigReferencesPrefix\nprefix matching reference names to include in the output wiggle file, e.g.¬†‚Äúchr‚Äù, default ‚Äú-‚Äù - include all references\nstring\n\n\n--outWigNorm\ntype of normalization for the signal - RPM ‚Ä¶ reads per million of mapped reads - None ‚Ä¶ no normalization, ‚Äúraw‚Äù counts\nstring, example: \"RPM\"\n\n\n\n\n\nOutput Filtering\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outFilterType\ntype of filtering - Normal ‚Ä¶ standard filtering using only current alignment - BySJout ‚Ä¶ keep only those reads that contain junctions that passed filtering into SJ.out.tab\nstring, example: \"Normal\"\n\n\n--outFilterMultimapScoreRange\nthe score range below the maximum score for multimapping alignments\ninteger, example: 1\n\n\n--outFilterMultimapNmax\nmaximum number of loci the read is allowed to map to. Alignments (all of them) will be output only if the read maps to no more loci than this value. Otherwise no alignments will be output, and the read will be counted as ‚Äúmapped to too many loci‚Äù in the Log.final.out .\ninteger, example: 10\n\n\n--outFilterMismatchNmax\nalignment will be output only if it has no more mismatches than this value.\ninteger, example: 10\n\n\n--outFilterMismatchNoverLmax\nalignment will be output only if its ratio of mismatches to mapped length is less than or equal to this value.\ndouble, example: 0.3\n\n\n--outFilterMismatchNoverReadLmax\nalignment will be output only if its ratio of mismatches to read length is less than or equal to this value.\ndouble, example: 1\n\n\n--outFilterScoreMin\nalignment will be output only if its score is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterScoreMinOverLread\nsame as outFilterScoreMin, but normalized to read length (sum of mates‚Äô lengths for paired-end reads)\ndouble, example: 0.66\n\n\n--outFilterMatchNmin\nalignment will be output only if the number of matched bases is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterMatchNminOverLread\nsam as outFilterMatchNmin, but normalized to the read length (sum of mates‚Äô lengths for paired-end reads).\ndouble, example: 0.66\n\n\n--outFilterIntronMotifs\nfilter alignment using their motifs - None ‚Ä¶ no filtering - RemoveNoncanonical ‚Ä¶ filter out alignments that contain non-canonical junctions - RemoveNoncanonicalUnannotated ‚Ä¶ filter out alignments that contain non-canonical unannotated junctions when using annotated splice junctions database. The annotated non-canonical junctions will be kept.\nstring\n\n\n--outFilterIntronStrands\nfilter alignments - RemoveInconsistentStrands ‚Ä¶ remove alignments that have junctions with inconsistent strands - None ‚Ä¶ no filtering\nstring, example: \"RemoveInconsistentStrands\"\n\n\n\n\n\nOutput splice junctions (SJ.out.tab)\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJtype\ntype of splice junction output - Standard ‚Ä¶ standard SJ.out.tab output - None ‚Ä¶ no splice junction output\nstring, example: \"Standard\"\n\n\n\n\n\nOutput Filtering: Splice Junctions\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJfilterReads\nwhich reads to consider for collapsed splice junctions output - All ‚Ä¶ all reads, unique- and multi-mappers - Unique ‚Ä¶ uniquely mapping reads only\nstring, example: \"All\"\n\n\n--outSJfilterOverhangMin\nminimum overhang length for splice junctions on both sides for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif does not apply to annotated junctions\nList of integer, example: 30, 12, 12, 12, multiple_sep: \";\"\n\n\n--outSJfilterCountUniqueMin\nminimum uniquely mapping read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterCountTotalMin\nminimum total (multi-mapping+unique) read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterDistToOtherSJmin\nminimum allowed distance to other junctions‚Äô donor/acceptor does not apply to annotated junctions\nList of integer, example: 10, 0, 5, 10, multiple_sep: \";\"\n\n\n--outSJfilterIntronMaxVsReadN\nmaximum gap allowed for junctions supported by 1,2,3,,,N reads i.e.¬†by default junctions supported by 1 read can have gaps &lt;=50000b, by 2 reads: &lt;=100000b, by 3 reads: &lt;=200000. by &gt;=4 reads any gap &lt;=alignIntronMax does not apply to annotated junctions\nList of integer, example: 50000, 100000, 200000, multiple_sep: \";\"\n\n\n\n\n\nScoring\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--scoreGap\nsplice junction penalty (independent on intron motif)\ninteger, example: 0\n\n\n--scoreGapNoncan\nnon-canonical junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGapGCAG\nGC/AG and CT/GC junction penalty (in addition to scoreGap)\ninteger, example: -4\n\n\n--scoreGapATAC\nAT/AC and GT/AT junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGenomicLengthLog2scale\nextra score logarithmically scaled with genomic length of the alignment: scoreGenomicLengthLog2scale*log2(genomicLength)\ninteger, example: 0\n\n\n--scoreDelOpen\ndeletion open penalty\ninteger, example: -2\n\n\n--scoreDelBase\ndeletion extension penalty per base (in addition to scoreDelOpen)\ninteger, example: -2\n\n\n--scoreInsOpen\ninsertion open penalty\ninteger, example: -2\n\n\n--scoreInsBase\ninsertion extension penalty per base (in addition to scoreInsOpen)\ninteger, example: -2\n\n\n--scoreStitchSJshift\nmaximum score reduction while searching for SJ boundaries in the stitching step\ninteger, example: 1\n\n\n\n\n\nAlignments and Seeding\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--seedSearchStartLmax\ndefines the search start point through the read - the read is split into pieces no longer than this value\ninteger, example: 50\n\n\n--seedSearchStartLmaxOverLread\nseedSearchStartLmax normalized to read length (sum of mates‚Äô lengths for paired-end reads)\ndouble, example: 1\n\n\n--seedSearchLmax\ndefines the maximum length of the seeds, if =0 seed length is not limited\ninteger, example: 0\n\n\n--seedMultimapNmax\nonly pieces that map fewer than this value are utilized in the stitching procedure\ninteger, example: 10000\n\n\n--seedPerReadNmax\nmax number of seeds per read\ninteger, example: 1000\n\n\n--seedPerWindowNmax\nmax number of seeds per window\ninteger, example: 50\n\n\n--seedNoneLociPerWindow\nmax number of one seed loci per window\ninteger, example: 10\n\n\n--seedSplitMin\nmin length of the seed sequences split by Ns or mate gap\ninteger, example: 12\n\n\n--seedMapMin\nmin length of seeds to be mapped\ninteger, example: 5\n\n\n--alignIntronMin\nminimum intron size, genomic gap is considered intron if its length&gt;=alignIntronMin, otherwise it is considered Deletion\ninteger, example: 21\n\n\n--alignIntronMax\nmaximum intron size, if 0, max intron size will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignMatesGapMax\nmaximum gap between two mates, if 0, max intron gap will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignSJoverhangMin\nminimum overhang (i.e.¬†block size) for spliced alignments\ninteger, example: 5\n\n\n--alignSJstitchMismatchNmax\nmaximum number of mismatches for stitching of the splice junctions (-1: no limit). (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif.\nList of integer, example: 0, -1, 0, 0, multiple_sep: \";\"\n\n\n--alignSJDBoverhangMin\nminimum overhang (i.e.¬†block size) for annotated (sjdb) spliced alignments\ninteger, example: 3\n\n\n--alignSplicedMateMapLmin\nminimum mapped length for a read mate that is spliced\ninteger, example: 0\n\n\n--alignSplicedMateMapLminOverLmate\nalignSplicedMateMapLmin normalized to mate length\ndouble, example: 0.66\n\n\n--alignWindowsPerReadNmax\nmax number of windows per read\ninteger, example: 10000\n\n\n--alignTranscriptsPerWindowNmax\nmax number of transcripts per window\ninteger, example: 100\n\n\n--alignTranscriptsPerReadNmax\nmax number of different alignments per read to consider\ninteger, example: 10000\n\n\n--alignEndsType\ntype of read ends alignment - Local ‚Ä¶ standard local alignment with soft-clipping allowed - EndToEnd ‚Ä¶ force end-to-end read alignment, do not soft-clip - Extend5pOfRead1 ‚Ä¶ fully extend only the 5p of the read1, all other ends: local alignment - Extend5pOfReads12 ‚Ä¶ fully extend only the 5p of the both read1 and read2, all other ends: local alignment\nstring, example: \"Local\"\n\n\n--alignEndsProtrude\nallow protrusion of alignment ends, i.e.¬†start (end) of the +strand mate downstream of the start (end) of the -strand mate 1st word: int: maximum number of protrusion bases allowed 2nd word: string: - ConcordantPair ‚Ä¶ report alignments with non-zero protrusion as concordant pairs - DiscordantPair ‚Ä¶ report alignments with non-zero protrusion as discordant pairs\nstring, example: \"0    ConcordantPair\"\n\n\n--alignSoftClipAtReferenceEnds\nallow the soft-clipping of the alignments past the end of the chromosomes - Yes ‚Ä¶ allow - No ‚Ä¶ prohibit, useful for compatibility with Cufflinks\nstring, example: \"Yes\"\n\n\n--alignInsertionFlush\nhow to flush ambiguous insertion positions - None ‚Ä¶ insertions are not flushed - Right ‚Ä¶ insertions are flushed to the right\nstring\n\n\n\n\n\nPaired-End reads\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--peOverlapNbasesMin\nminimum number of overlapping bases to trigger mates merging and realignment. Specify &gt;0 value to switch on the ‚Äúmerginf of overlapping mates‚Äù algorithm.\ninteger, example: 0\n\n\n--peOverlapMMp\nmaximum proportion of mismatched bases in the overlap area\ndouble, example: 0.01\n\n\n\n\n\nWindows, Anchors, Binning\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--winAnchorMultimapNmax\nmax number of loci anchors are allowed to map to\ninteger, example: 50\n\n\n--winBinNbits\n=log2(winBin), where winBin is the size of the bin for the windows/clustering, each window will occupy an integer number of bins.\ninteger, example: 16\n\n\n--winAnchorDistNbins\nmax number of bins between two anchors that allows aggregation of anchors into one window\ninteger, example: 9\n\n\n--winFlankNbins\nlog2(winFlank), where win Flank is the size of the left and right flanking regions for each window\ninteger, example: 4\n\n\n--winReadCoverageRelativeMin\nminimum relative coverage of the read sequence by the seeds in a window, for STARlong algorithm only.\ndouble, example: 0.5\n\n\n--winReadCoverageBasesMin\nminimum number of bases covered by the seeds in a window , for STARlong algorithm only.\ninteger, example: 0\n\n\n\n\n\nChimeric Alignments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--chimOutType\ntype of chimeric output - Junctions ‚Ä¶ Chimeric.out.junction - SeparateSAMold ‚Ä¶ output old SAM into separate Chimeric.out.sam file - WithinBAM ‚Ä¶ output into main aligned BAM files (Aligned.*.bam) - WithinBAM HardClip ‚Ä¶ (default) hard-clipping in the CIGAR for supplemental chimeric alignments (default if no 2nd word is present) - WithinBAM SoftClip ‚Ä¶ soft-clipping in the CIGAR for supplemental chimeric alignments\nList of string, example: \"Junctions\", multiple_sep: \";\"\n\n\n--chimSegmentMin\nminimum length of chimeric segment length, if ==0, no chimeric output\ninteger, example: 0\n\n\n--chimScoreMin\nminimum total (summed) score of the chimeric segments\ninteger, example: 0\n\n\n--chimScoreDropMax\nmax drop (difference) of chimeric score (the sum of scores of all chimeric segments) from the read length\ninteger, example: 20\n\n\n--chimScoreSeparation\nminimum difference (separation) between the best chimeric score and the next one\ninteger, example: 10\n\n\n--chimScoreJunctionNonGTAG\npenalty for a non-GT/AG chimeric junction\ninteger, example: -1\n\n\n--chimJunctionOverhangMin\nminimum overhang for a chimeric junction\ninteger, example: 20\n\n\n--chimSegmentReadGapMax\nmaximum gap in the read sequence between chimeric segments\ninteger, example: 0\n\n\n--chimFilter\ndifferent filters for chimeric alignments - None ‚Ä¶ no filtering - banGenomicN ‚Ä¶ Ns are not allowed in the genome sequence around the chimeric junction\nList of string, example: \"banGenomicN\", multiple_sep: \";\"\n\n\n--chimMainSegmentMultNmax\nmaximum number of multi-alignments for the main chimeric segment. =1 will prohibit multimapping main segments.\ninteger, example: 10\n\n\n--chimMultimapNmax\nmaximum number of chimeric multi-alignments - 0 ‚Ä¶ use the old scheme for chimeric detection which only considered unique alignments\ninteger, example: 0\n\n\n--chimMultimapScoreRange\nthe score range for multi-mapping chimeras below the best chimeric score. Only works with ‚ÄìchimMultimapNmax &gt; 1\ninteger, example: 1\n\n\n--chimNonchimScoreDropMin\nto trigger chimeric detection, the drop in the best non-chimeric alignment score with respect to the read length has to be greater than this value\ninteger, example: 20\n\n\n--chimOutJunctionFormat\nformatting type for the Chimeric.out.junction file - 0 ‚Ä¶ no comment lines/headers - 1 ‚Ä¶ comment lines at the end of the file: command line and Nreads: total, unique/multi-mapping\ninteger, example: 0\n\n\n\n\n\nQuantification of Annotations\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--quantMode\ntypes of quantification requested - - ‚Ä¶ none - TranscriptomeSAM ‚Ä¶ output SAM/BAM alignments to transcriptome into a separate file - GeneCounts ‚Ä¶ count reads per gene\nList of string, multiple_sep: \";\"\n\n\n--quantTranscriptomeBAMcompression\n-2 to 10 transcriptome BAM compression level - -2 ‚Ä¶ no BAM output - -1 ‚Ä¶ default compression (6?) - 0 ‚Ä¶ no compression - 10 ‚Ä¶ maximum compression\ninteger, example: 1\n\n\n--quantTranscriptomeBan\nprohibit various alignment type - IndelSoftclipSingleend ‚Ä¶ prohibit indels, soft clipping and single-end alignments - compatible with RSEM - Singleend ‚Ä¶ prohibit single-end alignments\nstring, example: \"IndelSoftclipSingleend\"\n\n\n\n\n\n2-pass Mapping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--twopassMode\n2-pass mapping mode. - None ‚Ä¶ 1-pass mapping - Basic ‚Ä¶ basic 2-pass mapping, with all 1st pass junctions inserted into the genome indices on the fly\nstring\n\n\n--twopass1readsN\nnumber of reads to process for the 1st step. Use very large number (or default -1) to map all reads in the first step.\ninteger, example: -1\n\n\n\n\n\nWASP parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--waspOutputMode\nWASP allele-specific output type. This is re-implementation of the original WASP mappability filtering by Bryce van de Geijn, Graham McVicker, Yoav Gilad & Jonathan K Pritchard. Please cite the original WASP paper: Nature Methods 12, 1061-1063 (2015), https://www.nature.com/articles/nmeth.3582 . - SAMtag ‚Ä¶ add WASP tags to the alignments that pass WASP filtering\nstring\n\n\n\n\n\nSTARsolo (single cell RNA-seq) parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--soloType\ntype of single-cell RNA-seq - CB_UMI_Simple ‚Ä¶ (a.k.a. Droplet) one UMI and one Cell Barcode of fixed length in read2, e.g.¬†Drop-seq and 10X Chromium. - CB_UMI_Complex ‚Ä¶ multiple Cell Barcodes of varying length, one UMI of fixed length and one adapter sequence of fixed length are allowed in read2 only (e.g.¬†inDrop, ddSeq). - CB_samTagOut ‚Ä¶ output Cell Barcode as CR and/or CB SAm tag. No UMI counting. ‚ÄìreadFilesIn cDNA_read1 [cDNA_read2 if paired-end] CellBarcode_read . Requires ‚ÄìoutSAMtype BAM Unsorted [and/or SortedByCoordinate] - SmartSeq ‚Ä¶ Smart-seq: each cell in a separate FASTQ (paired- or single-end), barcodes are corresponding read-groups, no UMI sequences, alignments deduplicated according to alignment start and end (after extending soft-clipped bases)\nList of string, multiple_sep: \";\"\n\n\n--soloCBwhitelist\nfile(s) with whitelist(s) of cell barcodes. Only ‚ÄìsoloType CB_UMI_Complex allows more than one whitelist file. - None ‚Ä¶ no whitelist: all cell barcodes are allowed\nList of string, multiple_sep: \";\"\n\n\n--soloCBstart\ncell barcode start base\ninteger, example: 1\n\n\n--soloCBlen\ncell barcode length\ninteger, example: 16\n\n\n--soloUMIstart\nUMI start base\ninteger, example: 17\n\n\n--soloUMIlen\nUMI length\ninteger, example: 10\n\n\n--soloBarcodeReadLength\nlength of the barcode read - 1 ‚Ä¶ equal to sum of soloCBlen+soloUMIlen - 0 ‚Ä¶ not defined, do not check\ninteger, example: 1\n\n\n--soloBarcodeMate\nidentifies which read mate contains the barcode (CB+UMI) sequence - 0 ‚Ä¶ barcode sequence is on separate read, which should always be the last file in the ‚ÄìreadFilesIn listed - 1 ‚Ä¶ barcode sequence is a part of mate 1 - 2 ‚Ä¶ barcode sequence is a part of mate 2\ninteger, example: 0\n\n\n--soloCBposition\nposition of Cell Barcode(s) on the barcode read. Presently only works with ‚ÄìsoloType CB_UMI_Complex, and barcodes are assumed to be on Read2. Format for each barcode: startAnchor_startPosition_endAnchor_endPosition start(end)Anchor defines the Anchor Base for the CB: 0: read start; 1: read end; 2: adapter start; 3: adapter end start(end)Position is the 0-based position with of the CB start(end) with respect to the Anchor Base String for different barcodes are separated by space. Example: inDrop (Zilionis et al, Nat. Protocols, 2017): ‚ÄìsoloCBposition 0_0_2_-1 3_1_3_8\nList of string, multiple_sep: \";\"\n\n\n--soloUMIposition\nposition of the UMI on the barcode read, same as soloCBposition Example: inDrop (Zilionis et al, Nat. Protocols, 2017): ‚ÄìsoloCBposition 3_9_3_14\nstring\n\n\n--soloAdapterSequence\nadapter sequence to anchor barcodes. Only one adapter sequence is allowed.\nstring\n\n\n--soloAdapterMismatchesNmax\nmaximum number of mismatches allowed in adapter sequence.\ninteger, example: 1\n\n\n--soloCBmatchWLtype\nmatching the Cell Barcodes to the WhiteList - Exact ‚Ä¶ only exact matches allowed - 1MM ‚Ä¶ only one match in whitelist with 1 mismatched base allowed. Allowed CBs have to have at least one read with exact match. - 1MM_multi ‚Ä¶ multiple matches in whitelist with 1 mismatched base allowed, posterior probability calculation is used choose one of the matches. Allowed CBs have to have at least one read with exact match. This option matches best with CellRanger 2.2.0 - 1MM_multi_pseudocounts ‚Ä¶ same as 1MM_Multi, but pseudocounts of 1 are added to all whitelist barcodes. - 1MM_multi_Nbase_pseudocounts ‚Ä¶ same as 1MM_multi_pseudocounts, multimatching to WL is allowed for CBs with N-bases. This option matches best with CellRanger &gt;= 3.0.0 - EditDist_2 ‚Ä¶ allow up to edit distance of 3 fpr each of the barcodes. May include one deletion + one insertion. Only works with ‚ÄìsoloType CB_UMI_Complex. Matches to multiple passlist barcdoes are not allowed. Similar to ParseBio Split-seq pipeline.\nstring, example: \"1MM_multi\"\n\n\n--soloInputSAMattrBarcodeSeq\nwhen inputting reads from a SAM file (‚ÄìreadsFileType SAM SE/PE), these SAM attributes mark the barcode sequence (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use ‚ÄìsoloInputSAMattrBarcodeSeq CR UR . This parameter is required when running STARsolo with input from SAM.\nList of string, multiple_sep: \";\"\n\n\n--soloInputSAMattrBarcodeQual\nwhen inputting reads from a SAM file (‚ÄìreadsFileType SAM SE/PE), these SAM attributes mark the barcode qualities (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use ‚ÄìsoloInputSAMattrBarcodeQual CY UY . If this parameter is ‚Äò-‚Äô (default), the quality ‚ÄòH‚Äô will be assigned to all bases.\nList of string, multiple_sep: \";\"\n\n\n--soloStrand\nstrandedness of the solo libraries: - Unstranded ‚Ä¶ no strand information - Forward ‚Ä¶ read strand same as the original RNA molecule - Reverse ‚Ä¶ read strand opposite to the original RNA molecule\nstring, example: \"Forward\"\n\n\n--soloFeatures\ngenomic features for which the UMI counts per Cell Barcode are collected - Gene ‚Ä¶ genes: reads match the gene transcript - SJ ‚Ä¶ splice junctions: reported in SJ.out.tab - GeneFull ‚Ä¶ full gene (pre-mRNA): count all reads overlapping genes‚Äô exons and introns - GeneFull_ExonOverIntron ‚Ä¶ full gene (pre-mRNA): count all reads overlapping genes‚Äô exons and introns: prioritize 100% overlap with exons - GeneFull_Ex50pAS ‚Ä¶ full gene (pre-RNA): count all reads overlapping genes‚Äô exons and introns: prioritize &gt;50% overlap with exons. Do not count reads with 100% exonic overlap in the antisense direction.\nList of string, example: \"Gene\", multiple_sep: \";\"\n\n\n--soloMultiMappers\ncounting method for reads mapping to multiple genes - Unique ‚Ä¶ count only reads that map to unique genes - Uniform ‚Ä¶ uniformly distribute multi-genic UMIs to all genes - Rescue ‚Ä¶ distribute UMIs proportionally to unique+uniform counts (~ first iteration of EM) - PropUnique ‚Ä¶ distribute UMIs proportionally to unique mappers, if present, and uniformly if not. - EM ‚Ä¶ multi-gene UMIs are distributed using Expectation Maximization algorithm\nList of string, example: \"Unique\", multiple_sep: \";\"\n\n\n--soloUMIdedup\ntype of UMI deduplication (collapsing) algorithm - 1MM_All ‚Ä¶ all UMIs with 1 mismatch distance to each other are collapsed (i.e.¬†counted once). - 1MM_Directional_UMItools ‚Ä¶ follows the ‚Äúdirectional‚Äù method from the UMI-tools by Smith, Heger and Sudbery (Genome Research 2017). - 1MM_Directional ‚Ä¶ same as 1MM_Directional_UMItools, but with more stringent criteria for duplicate UMIs - Exact ‚Ä¶ only exactly matching UMIs are collapsed. - NoDedup ‚Ä¶ no deduplication of UMIs, count all reads. - 1MM_CR ‚Ä¶ CellRanger2-4 algorithm for 1MM UMI collapsing.\nList of string, example: \"1MM_All\", multiple_sep: \";\"\n\n\n--soloUMIfiltering\ntype of UMI filtering (for reads uniquely mapping to genes) - - ‚Ä¶ basic filtering: remove UMIs with N and homopolymers (similar to CellRanger 2.2.0). - MultiGeneUMI ‚Ä¶ basic + remove lower-count UMIs that map to more than one gene. - MultiGeneUMI_All ‚Ä¶ basic + remove all UMIs that map to more than one gene. - MultiGeneUMI_CR ‚Ä¶ basic + remove lower-count UMIs that map to more than one gene, matching CellRanger &gt; 3.0.0 . Only works with ‚ÄìsoloUMIdedup 1MM_CR\nList of string, multiple_sep: \";\"\n\n\n--soloOutFileNames\nfile names for STARsolo output: file_name_prefix gene_names barcode_sequences cell_feature_count_matrix\nList of string, example: \"Solo.out/\", \"features.tsv\", \"barcodes.tsv\", \"matrix.mtx\", multiple_sep: \";\"\n\n\n--soloCellFilter\ncell filtering type and parameters - None ‚Ä¶ do not output filtered cells - TopCells ‚Ä¶ only report top cells by UMI count, followed by the exact number of cells - CellRanger2.2 ‚Ä¶ simple filtering of CellRanger 2.2. Can be followed by numbers: number of expected cells, robust maximum percentile for UMI count, maximum to minimum ratio for UMI count The harcoded values are from CellRanger: nExpectedCells=3000; maxPercentile=0.99; maxMinRatio=10 - EmptyDrops_CR ‚Ä¶ EmptyDrops filtering in CellRanger flavor. Please cite the original EmptyDrops paper: A.T.L Lun et al, Genome Biology, 20, 63 (2019): https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1662-y Can be followed by 10 numeric parameters: nExpectedCells maxPercentile maxMinRatio indMin indMax umiMin umiMinFracMedian candMaxN FDR simN The harcoded values are from CellRanger: 3000 0.99 10 45000 90000 500 0.01 20000 0.01 10000\nList of string, example: \"CellRanger2.2\", \"3000\", \"0.99\", \"10\", multiple_sep: \";\"\n\n\n--soloOutFormatFeaturesGeneField3\nfield 3 in the Gene features.tsv file. If ‚Äú-‚Äù, then no 3rd field is output.\nList of string, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--soloCellReadStats\nOutput reads statistics for each CB - Standard ‚Ä¶ standard output\nstring"
  },
  {
    "objectID": "components/modules/mapping/star_align.html#authors",
    "href": "components/modules/mapping/star_align.html#authors",
    "title": "Star align",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/mapping/multi_star.html",
    "href": "components/modules/mapping/multi_star.html",
    "title": "Multi star",
    "section": "",
    "text": "ID: multi_star\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/multi_star.html#example-commands",
    "href": "components/modules/mapping/multi_star.html#example-commands",
    "title": "Multi star",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/mapping/multi_star/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input/Output\ninput_id: # please fill in - example: [\"mysample\", \"mysample\"]\ninput_r1: # please fill in - example: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L002_R1_001.fastq.gz\"]\n# input_r2: [\"mysample_S1_L001_R2_001.fastq.gz\", \"mysample_S1_L002_R2_001.fastq.gz\"]\nreference_index: # please fill in - example: \"/path/to/reference\"\nreference_gtf: # please fill in - example: \"genes.gtf\"\n# output: \"$id.$key.output.output\"\n\n# Processing arguments\nrun_htseq_count: true\nrun_multiqc: true\nmin_success_rate: 0.5\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/multi_star/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/multi_star.html#argument-groups",
    "href": "components/modules/mapping/multi_star.html#argument-groups",
    "title": "Multi star",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput/Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_id\nThe ID of the sample being processed. This vector should have the same length as the --input_r1 argument.\nList of string, required, example: \"mysample\", \"mysample\", multiple_sep: \";\"\n\n\n--input_r1\nPaths to the sequences to be mapped. If using Illumina paired-end reads, only the R1 files should be passed.\nList of file, required, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L002_R1_001.fastq.gz\", multiple_sep: \";\"\n\n\n--input_r2\nPaths to the sequences to be mapped. If using Illumina paired-end reads, only the R2 files should be passed.\nList of file, example: \"mysample_S1_L001_R2_001.fastq.gz\", \"mysample_S1_L002_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference_index\nPath to the reference built by star_build_reference. Corresponds to the ‚ÄìgenomeDir argument in the STAR command.\nfile, required, example: \"/path/to/reference\"\n\n\n--reference_gtf\nPath to the gtf reference file.\nfile, required, example: \"genes.gtf\"\n\n\n--output\nPath to output directory. Corresponds to the ‚ÄìoutFileNamePrefix argument in the STAR command.\nfile, required, example: \"/path/to/foo\"\n\n\n\n\n\nProcessing arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--run_htseq_count\nWhether or not to also run htseq-count after STAR.\nboolean, default: TRUE\n\n\n--run_multiqc\nWhether or not to also run MultiQC at the end.\nboolean, default: TRUE\n\n\n--min_success_rate\nFail when the success rate is below this threshold.\ndouble, default: 0.5\n\n\n\n\n\nRun Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--runRNGseed\nrandom number generator seed.\ninteger, example: 777\n\n\n\n\n\nGenome Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genomeFastaFiles\npath(s) to the fasta files with the genome sequences, separated by spaces. These files should be plain text FASTA files, they cannot be zipped. Required for the genome generation (‚ÄìrunMode genomeGenerate). Can also be used in the mapping (‚ÄìrunMode alignReads) to add extra (new) sequences to the genome (e.g.¬†spike-ins).\nList of file, multiple_sep: \";\"\n\n\n\n\n\nSplice Junctions Database\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sjdbFileChrStartEnd\npath to the files with genomic coordinates (chr  start  end  strand) for the splice junction introns. Multiple files can be supplied and will be concatenated.\nList of string, multiple_sep: \";\"\n\n\n--sjdbGTFfile\npath to the GTF file with annotations\nfile\n\n\n--sjdbGTFchrPrefix\nprefix for chromosome names in a GTF file (e.g.¬†‚Äòchr‚Äô for using ENSMEBL annotations with UCSC genomes)\nstring\n\n\n--sjdbGTFfeatureExon\nfeature type in GTF file to be used as exons for building transcripts\nstring, example: \"exon\"\n\n\n--sjdbGTFtagExonParentTranscript\nGTF attribute name for parent transcript ID (default ‚Äútranscript_id‚Äù works for GTF files)\nstring, example: \"transcript_id\"\n\n\n--sjdbGTFtagExonParentGene\nGTF attribute name for parent gene ID (default ‚Äúgene_id‚Äù works for GTF files)\nstring, example: \"gene_id\"\n\n\n--sjdbGTFtagExonParentGeneName\nGTF attribute name for parent gene name\nList of string, example: \"gene_name\", multiple_sep: \";\"\n\n\n--sjdbGTFtagExonParentGeneType\nGTF attribute name for parent gene type\nList of string, example: \"gene_type\", \"gene_biotype\", multiple_sep: \";\"\n\n\n--sjdbOverhang\nlength of the donor/acceptor sequence on each side of the junctions, ideally = (mate_length - 1)\ninteger, example: 100\n\n\n--sjdbScore\nextra alignment score for alignments that cross database junctions\ninteger, example: 2\n\n\n--sjdbInsertSave\nwhich files to save when sjdb junctions are inserted on the fly at the mapping step - Basic ‚Ä¶ only small junction / transcript files - All ‚Ä¶ all files including big Genome, SA and SAindex - this will create a complete genome directory\nstring, example: \"Basic\"\n\n\n\n\n\nVariation parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--varVCFfile\npath to the VCF file that contains variation data. The 10th column should contain the genotype information, e.g.¬†0/1\nstring\n\n\n\n\n\nRead Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--readFilesType\nformat of input read files - Fastx ‚Ä¶ FASTA or FASTQ - SAM SE ‚Ä¶ SAM or BAM single-end reads; for BAM use ‚ÄìreadFilesCommand samtools view - SAM PE ‚Ä¶ SAM or BAM paired-end reads; for BAM use ‚ÄìreadFilesCommand samtools view\nstring, example: \"Fastx\"\n\n\n--readFilesSAMattrKeep\nfor ‚ÄìreadFilesType SAM SE/PE, which SAM tags to keep in the output BAM, e.g.: ‚ÄìreadFilesSAMtagsKeep RG PL - All ‚Ä¶ keep all tags - None ‚Ä¶ do not keep any tags\nList of string, example: \"All\", multiple_sep: \";\"\n\n\n--readFilesManifest\npath to the ‚Äúmanifest‚Äù file with the names of read files. The manifest file should contain 3 tab-separated columns: paired-end reads: read1_file_name \\(tab\\) read2_file_name \\(tab\\) read_group_line. single-end reads: read1_file_name \\(tab\\) - \\(tab\\) read_group_line. Spaces, but not tabs are allowed in file names. If read_group_line does not start with ID:, it can only contain one ID field, and ID: will be added to it. If read_group_line starts with ID:, it can contain several fields separated by \\(tab\\), and all fields will be be copied verbatim into SAM @RG header line.\nfile\n\n\n--readFilesPrefix\nprefix for the read files names, i.e.¬†it will be added in front of the strings in ‚ÄìreadFilesIn\nstring\n\n\n--readFilesCommand\ncommand line to execute for each of the input file. This command should generate FASTA or FASTQ text and send it to stdout For example: zcat - to uncompress .gz files, bzcat - to uncompress .bz2 files, etc.\nList of string, multiple_sep: \";\"\n\n\n--readMapNumber\nnumber of reads to map from the beginning of the file -1: map all reads\ninteger, example: -1\n\n\n--readMatesLengthsIn\nEqual/NotEqual - lengths of names,sequences,qualities for both mates are the same / not the same. NotEqual is safe in all situations.\nstring, example: \"NotEqual\"\n\n\n--readNameSeparator\ncharacter(s) separating the part of the read names that will be trimmed in output (read name after space is always trimmed)\nList of string, example: \"/\", multiple_sep: \";\"\n\n\n--readQualityScoreBase\nnumber to be subtracted from the ASCII code to get Phred quality score\ninteger, example: 33\n\n\n\n\n\nRead Clipping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--clipAdapterType\nadapter clipping type - Hamming ‚Ä¶ adapter clipping based on Hamming distance, with the number of mismatches controlled by ‚Äìclip5pAdapterMMp - CellRanger4 ‚Ä¶ 5p and 3p adapter clipping similar to CellRanger4. Utilizes Opal package by Martin Sosic: https://github.com/Martinsos/opal - None ‚Ä¶ no adapter clipping, all other clip* parameters are disregarded\nstring, example: \"Hamming\"\n\n\n--clip3pNbases\nnumber(s) of bases to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip3pAdapterSeq\nadapter sequences to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates. - polyA ‚Ä¶ polyA sequence with the length equal to read length\nList of string, multiple_sep: \";\"\n\n\n--clip3pAdapterMMp\nmax proportion of mismatches for 3p adapter clipping for each mate. If one value is given, it will be assumed the same for both mates.\nList of double, example: 0.1, multiple_sep: \";\"\n\n\n--clip3pAfterAdapterNbases\nnumber of bases to clip from 3p of each mate after the adapter clipping. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip5pNbases\nnumber(s) of bases to clip from 5p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n\n\n\nLimits\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--limitGenomeGenerateRAM\nmaximum available RAM (bytes) for genome generation\nlong, example: NA\n\n\n--limitIObufferSize\nmax available buffers size (bytes) for input/output, per thread\nList of long, example: 30000000, 50000000, multiple_sep: \";\"\n\n\n--limitOutSAMoneReadBytes\nmax size of the SAM record (bytes) for one read. Recommended value: &gt;(2(LengthMate1+LengthMate2+100)outFilterMultimapNmax\nlong, example: 100000\n\n\n--limitOutSJoneRead\nmax number of junctions for one read (including all multi-mappers)\ninteger, example: 1000\n\n\n--limitOutSJcollapsed\nmax number of collapsed junctions\ninteger, example: 1000000\n\n\n--limitBAMsortRAM\nmaximum available RAM (bytes) for sorting BAM. If =0, it will be set to the genome index size. 0 value can only be used with ‚ÄìgenomeLoad NoSharedMemory option.\nlong, example: 0\n\n\n--limitSjdbInsertNsj\nmaximum number of junctions to be inserted to the genome on the fly at the mapping stage, including those from annotations and those detected in the 1st step of the 2-pass run\ninteger, example: 1000000\n\n\n--limitNreadsSoft\nsoft limit on the number of reads\ninteger, example: -1\n\n\n\n\n\nOutput: general\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outTmpKeep\nwhether to keep the temporary files after STAR runs is finished - None ‚Ä¶ remove all temporary files - All ‚Ä¶ keep all files\nstring\n\n\n--outStd\nwhich output will be directed to stdout (standard out) - Log ‚Ä¶ log messages - SAM ‚Ä¶ alignments in SAM format (which normally are output to Aligned.out.sam file), normal standard output will go into Log.std.out - BAM_Unsorted ‚Ä¶ alignments in BAM format, unsorted. Requires ‚ÄìoutSAMtype BAM Unsorted - BAM_SortedByCoordinate ‚Ä¶ alignments in BAM format, sorted by coordinate. Requires ‚ÄìoutSAMtype BAM SortedByCoordinate - BAM_Quant ‚Ä¶ alignments to transcriptome in BAM format, unsorted. Requires ‚ÄìquantMode TranscriptomeSAM\nstring, example: \"Log\"\n\n\n--outReadsUnmapped\noutput of unmapped and partially mapped (i.e.¬†mapped only one mate of a paired end read) reads in separate file(s). - None ‚Ä¶ no output - Fastx ‚Ä¶ output in separate fasta/fastq files, Unmapped.out.mate1/2\nstring\n\n\n--outQSconversionAdd\nadd this number to the quality score (e.g.¬†to convert from Illumina to Sanger, use -31)\ninteger, example: 0\n\n\n--outMultimapperOrder\norder of multimapping alignments in the output files - Old_2.4 ‚Ä¶ quasi-random order used before 2.5.0 - Random ‚Ä¶ random order of alignments for each multi-mapper. Read mates (pairs) are always adjacent, all alignment for each read stay together. This option will become default in the future releases.\nstring, example: \"Old_2.4\"\n\n\n\n\n\nOutput: SAM and BAM\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSAMmode\nmode of SAM output - None ‚Ä¶ no SAM output - Full ‚Ä¶ full SAM output - NoQS ‚Ä¶ full SAM but without quality scores\nstring, example: \"Full\"\n\n\n--outSAMstrandField\nCufflinks-like strand field flag - None ‚Ä¶ not used - intronMotif ‚Ä¶ strand derived from the intron motif. This option changes the output alignments: reads with inconsistent and/or non-canonical introns are filtered out.\nstring\n\n\n--outSAMattributes\na string of desired SAM attributes, in the order desired for the output SAM. Tags can be listed in any combination/order. Presets: - None ‚Ä¶ no attributes - Standard ‚Ä¶ NH HI AS nM - All ‚Ä¶ NH HI AS nM NM MD jM jI MC ch Alignment: - NH ‚Ä¶ number of loci the reads maps to: =1 for unique mappers, &gt;1 for multimappers. Standard SAM tag. - HI ‚Ä¶ multiple alignment index, starts with ‚ÄìoutSAMattrIHstart (=1 by default). Standard SAM tag. - AS ‚Ä¶ local alignment score, +1/-1 for matches/mismateches, score* penalties for indels and gaps. For PE reads, total score for two mates. Stadnard SAM tag. - nM ‚Ä¶ number of mismatches. For PE reads, sum over two mates. - NM ‚Ä¶ edit distance to the reference (number of mismatched + inserted + deleted bases) for each mate. Standard SAM tag. - MD ‚Ä¶ string encoding mismatched and deleted reference bases (see standard SAM specifications). Standard SAM tag. - jM ‚Ä¶ intron motifs for all junctions (i.e.¬†N in CIGAR): 0: non-canonical; 1: GT/AG, 2: CT/AC, 3: GC/AG, 4: CT/GC, 5: AT/AC, 6: GT/AT. If splice junctions database is used, and a junction is annotated, 20 is added to its motif value. - jI ‚Ä¶ start and end of introns for all junctions (1-based). - XS ‚Ä¶ alignment strand according to ‚ÄìoutSAMstrandField. - MC ‚Ä¶ mate‚Äôs CIGAR string. Standard SAM tag. - ch ‚Ä¶ marks all segment of all chimeric alingments for ‚ÄìchimOutType WithinBAM output. - cN ‚Ä¶ number of bases clipped from the read ends: 5‚Äô and 3‚Äô Variation: - vA ‚Ä¶ variant allele - vG ‚Ä¶ genomic coordinate of the variant overlapped by the read. - vW ‚Ä¶ 1 - alignment passes WASP filtering; 2,3,4,5,6,7 - alignment does not pass WASP filtering. Requires ‚ÄìwaspOutputMode SAMtag. STARsolo: - CR CY UR UY ‚Ä¶ sequences and quality scores of cell barcodes and UMIs for the solo* demultiplexing. - GX GN ‚Ä¶ gene ID and gene name for unique-gene reads. - gx gn ‚Ä¶ gene IDs and gene names for unique- and multi-gene reads. - CB UB ‚Ä¶ error-corrected cell barcodes and UMIs for solo* demultiplexing. Requires ‚ÄìoutSAMtype BAM SortedByCoordinate. - sM ‚Ä¶ assessment of CB and UMI. - sS ‚Ä¶ sequence of the entire barcode (CB,UMI,adapter). - sQ ‚Ä¶ quality of the entire barcode. ***Unsupported/undocumented: - ha ‚Ä¶ haplotype (1/2) when mapping to the diploid genome. Requires genome generated with ‚ÄìgenomeTransformType Diploid . - rB ‚Ä¶ alignment block read/genomic coordinates. - vR ‚Ä¶ read coordinate of the variant.\nList of string, example: \"Standard\", multiple_sep: \";\"\n\n\n--outSAMattrIHstart\nstart value for the IH attribute. 0 may be required by some downstream software, such as Cufflinks or StringTie.\ninteger, example: 1\n\n\n--outSAMunmapped\noutput of unmapped reads in the SAM format 1st word: - None ‚Ä¶ no output - Within ‚Ä¶ output unmapped reads within the main SAM file (i.e.¬†Aligned.out.sam) 2nd word: - KeepPairs ‚Ä¶ record unmapped mate for each alignment, and, in case of unsorted output, keep it adjacent to its mapped mate. Only affects multi-mapping reads.\nList of string, multiple_sep: \";\"\n\n\n--outSAMorder\ntype of sorting for the SAM output Paired: one mate after the other for all paired alignments PairedKeepInputOrder: one mate after the other for all paired alignments, the order is kept the same as in the input FASTQ files\nstring, example: \"Paired\"\n\n\n--outSAMprimaryFlag\nwhich alignments are considered primary - all others will be marked with 0x100 bit in the FLAG - OneBestScore ‚Ä¶ only one alignment with the best score is primary - AllBestScore ‚Ä¶ all alignments with the best score are primary\nstring, example: \"OneBestScore\"\n\n\n--outSAMreadID\nread ID record type - Standard ‚Ä¶ first word (until space) from the FASTx read ID line, removing /1,/2 from the end - Number ‚Ä¶ read number (index) in the FASTx file\nstring, example: \"Standard\"\n\n\n--outSAMmapqUnique\n0 to 255: the MAPQ value for unique mappers\ninteger, example: 255\n\n\n--outSAMflagOR\n0 to 65535: sam FLAG will be bitwise OR‚Äôd with this value, i.e.¬†FLAG=FLAG | outSAMflagOR. This is applied after all flags have been set by STAR, and after outSAMflagAND. Can be used to set specific bits that are not set otherwise.\ninteger, example: 0\n\n\n--outSAMflagAND\n0 to 65535: sam FLAG will be bitwise AND‚Äôd with this value, i.e.¬†FLAG=FLAG & outSAMflagOR. This is applied after all flags have been set by STAR, but before outSAMflagOR. Can be used to unset specific bits that are not set otherwise.\ninteger, example: 65535\n\n\n--outSAMattrRGline\nSAM/BAM read group line. The first word contains the read group identifier and must start with ‚ÄúID:‚Äù, e.g.¬†‚ÄìoutSAMattrRGline ID:xxx CN:yy ‚ÄúDS:z z z‚Äù. xxx will be added as RG tag to each output alignment. Any spaces in the tag values have to be double quoted. Comma separated RG lines correspons to different (comma separated) input files in ‚ÄìreadFilesIn. Commas have to be surrounded by spaces, e.g.¬†‚ÄìoutSAMattrRGline ID:xxx , ID:zzz ‚ÄúDS:z z‚Äù , ID:yyy DS:yyyy\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderHD\n@HD (header) line of the SAM header\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderPG\nextra @PG (software) line of the SAM header (in addition to STAR)\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderCommentFile\npath to the file with @CO (comment) lines of the SAM header\nstring\n\n\n--outSAMfilter\nfilter the output into main SAM/BAM files - KeepOnlyAddedReferences ‚Ä¶ only keep the reads for which all alignments are to the extra reference sequences added with ‚ÄìgenomeFastaFiles at the mapping stage. - KeepAllAddedReferences ‚Ä¶ keep all alignments to the extra reference sequences added with ‚ÄìgenomeFastaFiles at the mapping stage.\nList of string, multiple_sep: \";\"\n\n\n--outSAMmultNmax\nmax number of multiple alignments for a read that will be output to the SAM/BAM files. Note that if this value is not equal to -1, the top scoring alignment will be output first - -1 ‚Ä¶ all alignments (up to ‚ÄìoutFilterMultimapNmax) will be output\ninteger, example: -1\n\n\n--outSAMtlen\ncalculation method for the TLEN field in the SAM/BAM files - 1 ‚Ä¶ leftmost base of the (+)strand mate to rightmost base of the (-)mate. (+)sign for the (+)strand mate - 2 ‚Ä¶ leftmost base of any mate to rightmost base of any mate. (+)sign for the mate with the leftmost base. This is different from 1 for overlapping mates with protruding ends\ninteger, example: 1\n\n\n--outBAMcompression\n-1 to 10 BAM compression level, -1=default compression (6?), 0=no compression, 10=maximum compression\ninteger, example: 1\n\n\n--outBAMsortingThreadN\n&gt;=0: number of threads for BAM sorting. 0 will default to min(6,‚ÄìrunThreadN).\ninteger, example: 0\n\n\n--outBAMsortingBinsN\n&gt;0: number of genome bins for coordinate-sorting\ninteger, example: 50\n\n\n\n\n\nBAM processing\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--bamRemoveDuplicatesType\nmark duplicates in the BAM file, for now only works with (i) sorted BAM fed with inputBAMfile, and (ii) for paired-end alignments only - - ‚Ä¶ no duplicate removal/marking - UniqueIdentical ‚Ä¶ mark all multimappers, and duplicate unique mappers. The coordinates, FLAG, CIGAR must be identical - UniqueIdenticalNotMulti ‚Ä¶ mark duplicate unique mappers but not multimappers.\nstring\n\n\n--bamRemoveDuplicatesMate2basesN\nnumber of bases from the 5‚Äô of mate 2 to use in collapsing (e.g.¬†for RAMPAGE)\ninteger, example: 0\n\n\n\n\n\nOutput Wiggle\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outWigType\ntype of signal output, e.g.¬†‚ÄúbedGraph‚Äù OR ‚ÄúbedGraph read1_5p‚Äù. Requires sorted BAM: ‚ÄìoutSAMtype BAM SortedByCoordinate . 1st word: - None ‚Ä¶ no signal output - bedGraph ‚Ä¶ bedGraph format - wiggle ‚Ä¶ wiggle format 2nd word: - read1_5p ‚Ä¶ signal from only 5‚Äô of the 1st read, useful for CAGE/RAMPAGE etc - read2 ‚Ä¶ signal from only 2nd read\nList of string, multiple_sep: \";\"\n\n\n--outWigStrand\nstrandedness of wiggle/bedGraph output - Stranded ‚Ä¶ separate strands, str1 and str2 - Unstranded ‚Ä¶ collapsed strands\nstring, example: \"Stranded\"\n\n\n--outWigReferencesPrefix\nprefix matching reference names to include in the output wiggle file, e.g.¬†‚Äúchr‚Äù, default ‚Äú-‚Äù - include all references\nstring\n\n\n--outWigNorm\ntype of normalization for the signal - RPM ‚Ä¶ reads per million of mapped reads - None ‚Ä¶ no normalization, ‚Äúraw‚Äù counts\nstring, example: \"RPM\"\n\n\n\n\n\nOutput Filtering\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outFilterType\ntype of filtering - Normal ‚Ä¶ standard filtering using only current alignment - BySJout ‚Ä¶ keep only those reads that contain junctions that passed filtering into SJ.out.tab\nstring, example: \"Normal\"\n\n\n--outFilterMultimapScoreRange\nthe score range below the maximum score for multimapping alignments\ninteger, example: 1\n\n\n--outFilterMultimapNmax\nmaximum number of loci the read is allowed to map to. Alignments (all of them) will be output only if the read maps to no more loci than this value. Otherwise no alignments will be output, and the read will be counted as ‚Äúmapped to too many loci‚Äù in the Log.final.out .\ninteger, example: 10\n\n\n--outFilterMismatchNmax\nalignment will be output only if it has no more mismatches than this value.\ninteger, example: 10\n\n\n--outFilterMismatchNoverLmax\nalignment will be output only if its ratio of mismatches to mapped length is less than or equal to this value.\ndouble, example: 0.3\n\n\n--outFilterMismatchNoverReadLmax\nalignment will be output only if its ratio of mismatches to read length is less than or equal to this value.\ndouble, example: 1\n\n\n--outFilterScoreMin\nalignment will be output only if its score is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterScoreMinOverLread\nsame as outFilterScoreMin, but normalized to read length (sum of mates‚Äô lengths for paired-end reads)\ndouble, example: 0.66\n\n\n--outFilterMatchNmin\nalignment will be output only if the number of matched bases is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterMatchNminOverLread\nsam as outFilterMatchNmin, but normalized to the read length (sum of mates‚Äô lengths for paired-end reads).\ndouble, example: 0.66\n\n\n--outFilterIntronMotifs\nfilter alignment using their motifs - None ‚Ä¶ no filtering - RemoveNoncanonical ‚Ä¶ filter out alignments that contain non-canonical junctions - RemoveNoncanonicalUnannotated ‚Ä¶ filter out alignments that contain non-canonical unannotated junctions when using annotated splice junctions database. The annotated non-canonical junctions will be kept.\nstring\n\n\n--outFilterIntronStrands\nfilter alignments - RemoveInconsistentStrands ‚Ä¶ remove alignments that have junctions with inconsistent strands - None ‚Ä¶ no filtering\nstring, example: \"RemoveInconsistentStrands\"\n\n\n\n\n\nOutput splice junctions (SJ.out.tab)\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJtype\ntype of splice junction output - Standard ‚Ä¶ standard SJ.out.tab output - None ‚Ä¶ no splice junction output\nstring, example: \"Standard\"\n\n\n\n\n\nOutput Filtering: Splice Junctions\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJfilterReads\nwhich reads to consider for collapsed splice junctions output - All ‚Ä¶ all reads, unique- and multi-mappers - Unique ‚Ä¶ uniquely mapping reads only\nstring, example: \"All\"\n\n\n--outSJfilterOverhangMin\nminimum overhang length for splice junctions on both sides for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif does not apply to annotated junctions\nList of integer, example: 30, 12, 12, 12, multiple_sep: \";\"\n\n\n--outSJfilterCountUniqueMin\nminimum uniquely mapping read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterCountTotalMin\nminimum total (multi-mapping+unique) read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterDistToOtherSJmin\nminimum allowed distance to other junctions‚Äô donor/acceptor does not apply to annotated junctions\nList of integer, example: 10, 0, 5, 10, multiple_sep: \";\"\n\n\n--outSJfilterIntronMaxVsReadN\nmaximum gap allowed for junctions supported by 1,2,3,,,N reads i.e.¬†by default junctions supported by 1 read can have gaps &lt;=50000b, by 2 reads: &lt;=100000b, by 3 reads: &lt;=200000. by &gt;=4 reads any gap &lt;=alignIntronMax does not apply to annotated junctions\nList of integer, example: 50000, 100000, 200000, multiple_sep: \";\"\n\n\n\n\n\nScoring\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--scoreGap\nsplice junction penalty (independent on intron motif)\ninteger, example: 0\n\n\n--scoreGapNoncan\nnon-canonical junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGapGCAG\nGC/AG and CT/GC junction penalty (in addition to scoreGap)\ninteger, example: -4\n\n\n--scoreGapATAC\nAT/AC and GT/AT junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGenomicLengthLog2scale\nextra score logarithmically scaled with genomic length of the alignment: scoreGenomicLengthLog2scale*log2(genomicLength)\ninteger, example: 0\n\n\n--scoreDelOpen\ndeletion open penalty\ninteger, example: -2\n\n\n--scoreDelBase\ndeletion extension penalty per base (in addition to scoreDelOpen)\ninteger, example: -2\n\n\n--scoreInsOpen\ninsertion open penalty\ninteger, example: -2\n\n\n--scoreInsBase\ninsertion extension penalty per base (in addition to scoreInsOpen)\ninteger, example: -2\n\n\n--scoreStitchSJshift\nmaximum score reduction while searching for SJ boundaries in the stitching step\ninteger, example: 1\n\n\n\n\n\nAlignments and Seeding\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--seedSearchStartLmax\ndefines the search start point through the read - the read is split into pieces no longer than this value\ninteger, example: 50\n\n\n--seedSearchStartLmaxOverLread\nseedSearchStartLmax normalized to read length (sum of mates‚Äô lengths for paired-end reads)\ndouble, example: 1\n\n\n--seedSearchLmax\ndefines the maximum length of the seeds, if =0 seed length is not limited\ninteger, example: 0\n\n\n--seedMultimapNmax\nonly pieces that map fewer than this value are utilized in the stitching procedure\ninteger, example: 10000\n\n\n--seedPerReadNmax\nmax number of seeds per read\ninteger, example: 1000\n\n\n--seedPerWindowNmax\nmax number of seeds per window\ninteger, example: 50\n\n\n--seedNoneLociPerWindow\nmax number of one seed loci per window\ninteger, example: 10\n\n\n--seedSplitMin\nmin length of the seed sequences split by Ns or mate gap\ninteger, example: 12\n\n\n--seedMapMin\nmin length of seeds to be mapped\ninteger, example: 5\n\n\n--alignIntronMin\nminimum intron size, genomic gap is considered intron if its length&gt;=alignIntronMin, otherwise it is considered Deletion\ninteger, example: 21\n\n\n--alignIntronMax\nmaximum intron size, if 0, max intron size will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignMatesGapMax\nmaximum gap between two mates, if 0, max intron gap will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignSJoverhangMin\nminimum overhang (i.e.¬†block size) for spliced alignments\ninteger, example: 5\n\n\n--alignSJstitchMismatchNmax\nmaximum number of mismatches for stitching of the splice junctions (-1: no limit). (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif.\nList of integer, example: 0, -1, 0, 0, multiple_sep: \";\"\n\n\n--alignSJDBoverhangMin\nminimum overhang (i.e.¬†block size) for annotated (sjdb) spliced alignments\ninteger, example: 3\n\n\n--alignSplicedMateMapLmin\nminimum mapped length for a read mate that is spliced\ninteger, example: 0\n\n\n--alignSplicedMateMapLminOverLmate\nalignSplicedMateMapLmin normalized to mate length\ndouble, example: 0.66\n\n\n--alignWindowsPerReadNmax\nmax number of windows per read\ninteger, example: 10000\n\n\n--alignTranscriptsPerWindowNmax\nmax number of transcripts per window\ninteger, example: 100\n\n\n--alignTranscriptsPerReadNmax\nmax number of different alignments per read to consider\ninteger, example: 10000\n\n\n--alignEndsType\ntype of read ends alignment - Local ‚Ä¶ standard local alignment with soft-clipping allowed - EndToEnd ‚Ä¶ force end-to-end read alignment, do not soft-clip - Extend5pOfRead1 ‚Ä¶ fully extend only the 5p of the read1, all other ends: local alignment - Extend5pOfReads12 ‚Ä¶ fully extend only the 5p of the both read1 and read2, all other ends: local alignment\nstring, example: \"Local\"\n\n\n--alignEndsProtrude\nallow protrusion of alignment ends, i.e.¬†start (end) of the +strand mate downstream of the start (end) of the -strand mate 1st word: int: maximum number of protrusion bases allowed 2nd word: string: - ConcordantPair ‚Ä¶ report alignments with non-zero protrusion as concordant pairs - DiscordantPair ‚Ä¶ report alignments with non-zero protrusion as discordant pairs\nstring, example: \"0    ConcordantPair\"\n\n\n--alignSoftClipAtReferenceEnds\nallow the soft-clipping of the alignments past the end of the chromosomes - Yes ‚Ä¶ allow - No ‚Ä¶ prohibit, useful for compatibility with Cufflinks\nstring, example: \"Yes\"\n\n\n--alignInsertionFlush\nhow to flush ambiguous insertion positions - None ‚Ä¶ insertions are not flushed - Right ‚Ä¶ insertions are flushed to the right\nstring\n\n\n\n\n\nPaired-End reads\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--peOverlapNbasesMin\nminimum number of overlapping bases to trigger mates merging and realignment. Specify &gt;0 value to switch on the ‚Äúmerginf of overlapping mates‚Äù algorithm.\ninteger, example: 0\n\n\n--peOverlapMMp\nmaximum proportion of mismatched bases in the overlap area\ndouble, example: 0.01\n\n\n\n\n\nWindows, Anchors, Binning\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--winAnchorMultimapNmax\nmax number of loci anchors are allowed to map to\ninteger, example: 50\n\n\n--winBinNbits\n=log2(winBin), where winBin is the size of the bin for the windows/clustering, each window will occupy an integer number of bins.\ninteger, example: 16\n\n\n--winAnchorDistNbins\nmax number of bins between two anchors that allows aggregation of anchors into one window\ninteger, example: 9\n\n\n--winFlankNbins\nlog2(winFlank), where win Flank is the size of the left and right flanking regions for each window\ninteger, example: 4\n\n\n--winReadCoverageRelativeMin\nminimum relative coverage of the read sequence by the seeds in a window, for STARlong algorithm only.\ndouble, example: 0.5\n\n\n--winReadCoverageBasesMin\nminimum number of bases covered by the seeds in a window , for STARlong algorithm only.\ninteger, example: 0\n\n\n\n\n\nChimeric Alignments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--chimOutType\ntype of chimeric output - Junctions ‚Ä¶ Chimeric.out.junction - SeparateSAMold ‚Ä¶ output old SAM into separate Chimeric.out.sam file - WithinBAM ‚Ä¶ output into main aligned BAM files (Aligned.*.bam) - WithinBAM HardClip ‚Ä¶ (default) hard-clipping in the CIGAR for supplemental chimeric alignments (default if no 2nd word is present) - WithinBAM SoftClip ‚Ä¶ soft-clipping in the CIGAR for supplemental chimeric alignments\nList of string, example: \"Junctions\", multiple_sep: \";\"\n\n\n--chimSegmentMin\nminimum length of chimeric segment length, if ==0, no chimeric output\ninteger, example: 0\n\n\n--chimScoreMin\nminimum total (summed) score of the chimeric segments\ninteger, example: 0\n\n\n--chimScoreDropMax\nmax drop (difference) of chimeric score (the sum of scores of all chimeric segments) from the read length\ninteger, example: 20\n\n\n--chimScoreSeparation\nminimum difference (separation) between the best chimeric score and the next one\ninteger, example: 10\n\n\n--chimScoreJunctionNonGTAG\npenalty for a non-GT/AG chimeric junction\ninteger, example: -1\n\n\n--chimJunctionOverhangMin\nminimum overhang for a chimeric junction\ninteger, example: 20\n\n\n--chimSegmentReadGapMax\nmaximum gap in the read sequence between chimeric segments\ninteger, example: 0\n\n\n--chimFilter\ndifferent filters for chimeric alignments - None ‚Ä¶ no filtering - banGenomicN ‚Ä¶ Ns are not allowed in the genome sequence around the chimeric junction\nList of string, example: \"banGenomicN\", multiple_sep: \";\"\n\n\n--chimMainSegmentMultNmax\nmaximum number of multi-alignments for the main chimeric segment. =1 will prohibit multimapping main segments.\ninteger, example: 10\n\n\n--chimMultimapNmax\nmaximum number of chimeric multi-alignments - 0 ‚Ä¶ use the old scheme for chimeric detection which only considered unique alignments\ninteger, example: 0\n\n\n--chimMultimapScoreRange\nthe score range for multi-mapping chimeras below the best chimeric score. Only works with ‚ÄìchimMultimapNmax &gt; 1\ninteger, example: 1\n\n\n--chimNonchimScoreDropMin\nto trigger chimeric detection, the drop in the best non-chimeric alignment score with respect to the read length has to be greater than this value\ninteger, example: 20\n\n\n--chimOutJunctionFormat\nformatting type for the Chimeric.out.junction file - 0 ‚Ä¶ no comment lines/headers - 1 ‚Ä¶ comment lines at the end of the file: command line and Nreads: total, unique/multi-mapping\ninteger, example: 0\n\n\n\n\n\nQuantification of Annotations\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--quantMode\ntypes of quantification requested - - ‚Ä¶ none - TranscriptomeSAM ‚Ä¶ output SAM/BAM alignments to transcriptome into a separate file - GeneCounts ‚Ä¶ count reads per gene\nList of string, multiple_sep: \";\"\n\n\n--quantTranscriptomeBAMcompression\n-2 to 10 transcriptome BAM compression level - -2 ‚Ä¶ no BAM output - -1 ‚Ä¶ default compression (6?) - 0 ‚Ä¶ no compression - 10 ‚Ä¶ maximum compression\ninteger, example: 1\n\n\n--quantTranscriptomeBan\nprohibit various alignment type - IndelSoftclipSingleend ‚Ä¶ prohibit indels, soft clipping and single-end alignments - compatible with RSEM - Singleend ‚Ä¶ prohibit single-end alignments\nstring, example: \"IndelSoftclipSingleend\"\n\n\n\n\n\n2-pass Mapping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--twopassMode\n2-pass mapping mode. - None ‚Ä¶ 1-pass mapping - Basic ‚Ä¶ basic 2-pass mapping, with all 1st pass junctions inserted into the genome indices on the fly\nstring\n\n\n--twopass1readsN\nnumber of reads to process for the 1st step. Use very large number (or default -1) to map all reads in the first step.\ninteger, example: -1\n\n\n\n\n\nWASP parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--waspOutputMode\nWASP allele-specific output type. This is re-implementation of the original WASP mappability filtering by Bryce van de Geijn, Graham McVicker, Yoav Gilad & Jonathan K Pritchard. Please cite the original WASP paper: Nature Methods 12, 1061-1063 (2015), https://www.nature.com/articles/nmeth.3582 . - SAMtag ‚Ä¶ add WASP tags to the alignments that pass WASP filtering\nstring\n\n\n\n\n\nSTARsolo (single cell RNA-seq) parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--soloType\ntype of single-cell RNA-seq - CB_UMI_Simple ‚Ä¶ (a.k.a. Droplet) one UMI and one Cell Barcode of fixed length in read2, e.g.¬†Drop-seq and 10X Chromium. - CB_UMI_Complex ‚Ä¶ multiple Cell Barcodes of varying length, one UMI of fixed length and one adapter sequence of fixed length are allowed in read2 only (e.g.¬†inDrop, ddSeq). - CB_samTagOut ‚Ä¶ output Cell Barcode as CR and/or CB SAm tag. No UMI counting. ‚ÄìreadFilesIn cDNA_read1 [cDNA_read2 if paired-end] CellBarcode_read . Requires ‚ÄìoutSAMtype BAM Unsorted [and/or SortedByCoordinate] - SmartSeq ‚Ä¶ Smart-seq: each cell in a separate FASTQ (paired- or single-end), barcodes are corresponding read-groups, no UMI sequences, alignments deduplicated according to alignment start and end (after extending soft-clipped bases)\nList of string, multiple_sep: \";\"\n\n\n--soloCBwhitelist\nfile(s) with whitelist(s) of cell barcodes. Only ‚ÄìsoloType CB_UMI_Complex allows more than one whitelist file. - None ‚Ä¶ no whitelist: all cell barcodes are allowed\nList of string, multiple_sep: \";\"\n\n\n--soloCBstart\ncell barcode start base\ninteger, example: 1\n\n\n--soloCBlen\ncell barcode length\ninteger, example: 16\n\n\n--soloUMIstart\nUMI start base\ninteger, example: 17\n\n\n--soloUMIlen\nUMI length\ninteger, example: 10\n\n\n--soloBarcodeReadLength\nlength of the barcode read - 1 ‚Ä¶ equal to sum of soloCBlen+soloUMIlen - 0 ‚Ä¶ not defined, do not check\ninteger, example: 1\n\n\n--soloBarcodeMate\nidentifies which read mate contains the barcode (CB+UMI) sequence - 0 ‚Ä¶ barcode sequence is on separate read, which should always be the last file in the ‚ÄìreadFilesIn listed - 1 ‚Ä¶ barcode sequence is a part of mate 1 - 2 ‚Ä¶ barcode sequence is a part of mate 2\ninteger, example: 0\n\n\n--soloCBposition\nposition of Cell Barcode(s) on the barcode read. Presently only works with ‚ÄìsoloType CB_UMI_Complex, and barcodes are assumed to be on Read2. Format for each barcode: startAnchor_startPosition_endAnchor_endPosition start(end)Anchor defines the Anchor Base for the CB: 0: read start; 1: read end; 2: adapter start; 3: adapter end start(end)Position is the 0-based position with of the CB start(end) with respect to the Anchor Base String for different barcodes are separated by space. Example: inDrop (Zilionis et al, Nat. Protocols, 2017): ‚ÄìsoloCBposition 0_0_2_-1 3_1_3_8\nList of string, multiple_sep: \";\"\n\n\n--soloUMIposition\nposition of the UMI on the barcode read, same as soloCBposition Example: inDrop (Zilionis et al, Nat. Protocols, 2017): ‚ÄìsoloCBposition 3_9_3_14\nstring\n\n\n--soloAdapterSequence\nadapter sequence to anchor barcodes. Only one adapter sequence is allowed.\nstring\n\n\n--soloAdapterMismatchesNmax\nmaximum number of mismatches allowed in adapter sequence.\ninteger, example: 1\n\n\n--soloCBmatchWLtype\nmatching the Cell Barcodes to the WhiteList - Exact ‚Ä¶ only exact matches allowed - 1MM ‚Ä¶ only one match in whitelist with 1 mismatched base allowed. Allowed CBs have to have at least one read with exact match. - 1MM_multi ‚Ä¶ multiple matches in whitelist with 1 mismatched base allowed, posterior probability calculation is used choose one of the matches. Allowed CBs have to have at least one read with exact match. This option matches best with CellRanger 2.2.0 - 1MM_multi_pseudocounts ‚Ä¶ same as 1MM_Multi, but pseudocounts of 1 are added to all whitelist barcodes. - 1MM_multi_Nbase_pseudocounts ‚Ä¶ same as 1MM_multi_pseudocounts, multimatching to WL is allowed for CBs with N-bases. This option matches best with CellRanger &gt;= 3.0.0 - EditDist_2 ‚Ä¶ allow up to edit distance of 3 fpr each of the barcodes. May include one deletion + one insertion. Only works with ‚ÄìsoloType CB_UMI_Complex. Matches to multiple passlist barcdoes are not allowed. Similar to ParseBio Split-seq pipeline.\nstring, example: \"1MM_multi\"\n\n\n--soloInputSAMattrBarcodeSeq\nwhen inputting reads from a SAM file (‚ÄìreadsFileType SAM SE/PE), these SAM attributes mark the barcode sequence (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use ‚ÄìsoloInputSAMattrBarcodeSeq CR UR . This parameter is required when running STARsolo with input from SAM.\nList of string, multiple_sep: \";\"\n\n\n--soloInputSAMattrBarcodeQual\nwhen inputting reads from a SAM file (‚ÄìreadsFileType SAM SE/PE), these SAM attributes mark the barcode qualities (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use ‚ÄìsoloInputSAMattrBarcodeQual CY UY . If this parameter is ‚Äò-‚Äô (default), the quality ‚ÄòH‚Äô will be assigned to all bases.\nList of string, multiple_sep: \";\"\n\n\n--soloStrand\nstrandedness of the solo libraries: - Unstranded ‚Ä¶ no strand information - Forward ‚Ä¶ read strand same as the original RNA molecule - Reverse ‚Ä¶ read strand opposite to the original RNA molecule\nstring, example: \"Forward\"\n\n\n--soloFeatures\ngenomic features for which the UMI counts per Cell Barcode are collected - Gene ‚Ä¶ genes: reads match the gene transcript - SJ ‚Ä¶ splice junctions: reported in SJ.out.tab - GeneFull ‚Ä¶ full gene (pre-mRNA): count all reads overlapping genes‚Äô exons and introns - GeneFull_ExonOverIntron ‚Ä¶ full gene (pre-mRNA): count all reads overlapping genes‚Äô exons and introns: prioritize 100% overlap with exons - GeneFull_Ex50pAS ‚Ä¶ full gene (pre-RNA): count all reads overlapping genes‚Äô exons and introns: prioritize &gt;50% overlap with exons. Do not count reads with 100% exonic overlap in the antisense direction.\nList of string, example: \"Gene\", multiple_sep: \";\"\n\n\n--soloMultiMappers\ncounting method for reads mapping to multiple genes - Unique ‚Ä¶ count only reads that map to unique genes - Uniform ‚Ä¶ uniformly distribute multi-genic UMIs to all genes - Rescue ‚Ä¶ distribute UMIs proportionally to unique+uniform counts (~ first iteration of EM) - PropUnique ‚Ä¶ distribute UMIs proportionally to unique mappers, if present, and uniformly if not. - EM ‚Ä¶ multi-gene UMIs are distributed using Expectation Maximization algorithm\nList of string, example: \"Unique\", multiple_sep: \";\"\n\n\n--soloUMIdedup\ntype of UMI deduplication (collapsing) algorithm - 1MM_All ‚Ä¶ all UMIs with 1 mismatch distance to each other are collapsed (i.e.¬†counted once). - 1MM_Directional_UMItools ‚Ä¶ follows the ‚Äúdirectional‚Äù method from the UMI-tools by Smith, Heger and Sudbery (Genome Research 2017). - 1MM_Directional ‚Ä¶ same as 1MM_Directional_UMItools, but with more stringent criteria for duplicate UMIs - Exact ‚Ä¶ only exactly matching UMIs are collapsed. - NoDedup ‚Ä¶ no deduplication of UMIs, count all reads. - 1MM_CR ‚Ä¶ CellRanger2-4 algorithm for 1MM UMI collapsing.\nList of string, example: \"1MM_All\", multiple_sep: \";\"\n\n\n--soloUMIfiltering\ntype of UMI filtering (for reads uniquely mapping to genes) - - ‚Ä¶ basic filtering: remove UMIs with N and homopolymers (similar to CellRanger 2.2.0). - MultiGeneUMI ‚Ä¶ basic + remove lower-count UMIs that map to more than one gene. - MultiGeneUMI_All ‚Ä¶ basic + remove all UMIs that map to more than one gene. - MultiGeneUMI_CR ‚Ä¶ basic + remove lower-count UMIs that map to more than one gene, matching CellRanger &gt; 3.0.0 . Only works with ‚ÄìsoloUMIdedup 1MM_CR\nList of string, multiple_sep: \";\"\n\n\n--soloOutFileNames\nfile names for STARsolo output: file_name_prefix gene_names barcode_sequences cell_feature_count_matrix\nList of string, example: \"Solo.out/\", \"features.tsv\", \"barcodes.tsv\", \"matrix.mtx\", multiple_sep: \";\"\n\n\n--soloCellFilter\ncell filtering type and parameters - None ‚Ä¶ do not output filtered cells - TopCells ‚Ä¶ only report top cells by UMI count, followed by the exact number of cells - CellRanger2.2 ‚Ä¶ simple filtering of CellRanger 2.2. Can be followed by numbers: number of expected cells, robust maximum percentile for UMI count, maximum to minimum ratio for UMI count The harcoded values are from CellRanger: nExpectedCells=3000; maxPercentile=0.99; maxMinRatio=10 - EmptyDrops_CR ‚Ä¶ EmptyDrops filtering in CellRanger flavor. Please cite the original EmptyDrops paper: A.T.L Lun et al, Genome Biology, 20, 63 (2019): https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1662-y Can be followed by 10 numeric parameters: nExpectedCells maxPercentile maxMinRatio indMin indMax umiMin umiMinFracMedian candMaxN FDR simN The harcoded values are from CellRanger: 3000 0.99 10 45000 90000 500 0.01 20000 0.01 10000\nList of string, example: \"CellRanger2.2\", \"3000\", \"0.99\", \"10\", multiple_sep: \";\"\n\n\n--soloOutFormatFeaturesGeneField3\nfield 3 in the Gene features.tsv file. If ‚Äú-‚Äù, then no 3rd field is output.\nList of string, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--soloCellReadStats\nOutput reads statistics for each CB - Standard ‚Ä¶ standard output\nstring\n\n\n\n\n\nHTSeq arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--stranded\nWhether the data is from a strand-specific assay. ‚Äòreverse‚Äô means ‚Äòyes‚Äô with reversed strand interpretation.\nstring, default: \"yes\"\n\n\n--minimum_alignment_quality\nSkip all reads with MAPQ alignment quality lower than the given minimum value. MAPQ is the 5th column of a SAM/BAM file and its usage depends on the software used to map the reads.\ninteger, default: 10\n\n\n--type\nFeature type (3rd column in GTF file) to be used, all features of other type are ignored (default, suitable for Ensembl GTF files: exon)\nstring, example: \"exon\"\n\n\n--id_attribute\nGTF attribute to be used as feature ID (default, suitable for Ensembl GTF files: gene_id). All feature of the right type (see -t option) within the same GTF attribute will be added together. The typical way of using this option is to count all exonic reads from each gene and add the exons but other uses are possible as well. You can call this option multiple times: in that case, the combination of all attributes separated by colons (:) will be used as a unique identifier, e.g.¬†for exons you might use -i gene_id -i exon_number.\nList of string, example: \"gene_id\", multiple_sep: \";\"\n\n\n--additional_attributes\nAdditional feature attributes (suitable for Ensembl GTF files: gene_name). Use multiple times for more than one additional attribute. These attributes are only used as annotations in the output, while the determination of how the counts are added together is done based on option -i.\nList of string, example: \"gene_name\", multiple_sep: \";\"\n\n\n--add_chromosome_info\nStore information about the chromosome of each feature as an additional attribute (e.g.¬†colunm in the TSV output file).\nboolean_true\n\n\n--mode\nMode to handle reads overlapping more than one feature.\nstring, default: \"union\"\n\n\n--non_unique\nWhether and how to score reads that are not uniquely aligned or ambiguously assigned to features.\nstring, default: \"none\"\n\n\n--secondary_alignments\nWhether to score secondary alignments (0x100 flag).\nstring\n\n\n--supplementary_alignments\nWhether to score supplementary alignments (0x800 flag).\nstring\n\n\n--counts_output_sparse\nStore the counts as a sparse matrix (mtx, h5ad, loom).\nboolean_true"
  },
  {
    "objectID": "components/modules/mapping/multi_star.html#authors",
    "href": "components/modules/mapping/multi_star.html#authors",
    "title": "Multi star",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/mapping/multi_star_to_h5mu.html",
    "href": "components/modules/mapping/multi_star_to_h5mu.html",
    "title": "Multi star to h5mu",
    "section": "",
    "text": "ID: multi_star_to_h5mu\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/multi_star_to_h5mu.html#example-commands",
    "href": "components/modules/mapping/multi_star_to_h5mu.html#example-commands",
    "title": "Multi star to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/mapping/multi_star_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"/path/to/foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/multi_star_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/multi_star_to_h5mu.html#argument-group",
    "href": "components/modules/mapping/multi_star_to_h5mu.html#argument-group",
    "title": "Multi star to h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe directory created by multi_star\nfile, required, example: \"/path/to/foo\"\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/mapping/multi_star_to_h5mu.html#authors",
    "href": "components/modules/mapping/multi_star_to_h5mu.html#authors",
    "title": "Multi star to h5mu",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)\nAngela Oliveira Pisco    (author)"
  },
  {
    "objectID": "components/modules/mapping/cellranger_multi.html",
    "href": "components/modules/mapping/cellranger_multi.html",
    "title": "Cellranger multi",
    "section": "",
    "text": "ID: cellranger_multi\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/cellranger_multi.html#example-commands",
    "href": "components/modules/mapping/cellranger_multi.html#example-commands",
    "title": "Cellranger multi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/mapping/cellranger_multi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Outputs\n# output: \"$id.$key.output.output\"\n\n# Input files\n# input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\ngex_reference: # please fill in - example: \"reference_genome.tar.gz\"\n# vdj_reference: \"reference_vdj.tar.gz\"\n# vdj_inner_enrichment_primers: \"enrichment_primers.txt\"\n# feature_reference: \"feature_reference.csv\"\n\n# Feature type-specific input files\n# gex_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# abc_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# cgc_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# mux_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_t_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_t_gd_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_b_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# agc_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n\n# Library arguments\n# library_id: [\"mysample1\"]\n# library_type: [\"Gene Expression\"]\n# library_subsample: [\"0.5\"]\n# library_lanes: [\"1-4\"]\n\n# Gene expression arguments\n# gex_expect_cells: 3000\ngex_chemistry: \"auto\"\ngex_secondary_analysis: false\ngex_generate_bam: false\ngex_include_introns: true\n\n# Cell multiplexing parameters\n# cell_multiplex_sample_id: \"foo\"\n# cell_multiplex_oligo_ids: \"foo\"\n# cell_multiplex_description: \"foo\"\n\n# Executor arguments\ndryrun: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/cellranger_multi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/cellranger_multi.html#argument-groups",
    "href": "components/modules/mapping/cellranger_multi.html#argument-groups",
    "title": "Cellranger multi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput files\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe FASTQ files to be analyzed. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--gex_reference\nGenome refence index built by Cell Ranger mkref.\nfile, required, example: \"reference_genome.tar.gz\"\n\n\n--vdj_reference\nVDJ refence index built by Cell Ranger mkref.\nfile, example: \"reference_vdj.tar.gz\"\n\n\n--vdj_inner_enrichment_primers\nV(D)J Immune Profiling libraries: if inner enrichment primers other than those provided in the 10x Genomics kits are used, they need to be specified here as a text file with one primer per line.\nfile, example: \"enrichment_primers.txt\"\n\n\n--feature_reference\nPath to the Feature reference CSV file, declaring Feature Barcode constructs and associated barcodes. Required only for Antibody Capture or CRISPR Guide Capture libraries. See https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/using/feature-bc-analysis#feature-ref for more information.\nfile, example: \"feature_reference.csv\"\n\n\n\n\n\nFeature type-specific input files\nHelper functionality to allow feature type-specific input files, without the need to specify library_type or library_id. The library_id will be inferred from the input paths.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--gex_input\nThe FASTQ files to be analyzed for Gene Expression. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--abc_input\nThe FASTQ files to be analyzed for Antibody Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--cgc_input\nThe FASTQ files to be analyzed for CRISPR Guide Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--mux_input\nThe FASTQ files to be analyzed for Multiplexing Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_input\nThe FASTQ files to be analyzed for VDJ. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_t_input\nThe FASTQ files to be analyzed for VDJ-T. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_t_gd_input\nThe FASTQ files to be analyzed for VDJ-T-GD. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_b_input\nThe FASTQ files to be analyzed for VDJ-B. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--agc_input\nThe FASTQ files to be analyzed for Antigen Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n\n\n\nLibrary arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--library_id\nThe Illumina sample name to analyze. This must exactly match the ‚ÄòSample Name‚Äô part of the FASTQ files specified in the --input argument.\nList of string, example: \"mysample1\", multiple_sep: \";\"\n\n\n--library_type\nThe underlying feature type of the library. Possible values: ‚ÄúGene Expression‚Äù, ‚ÄúVDJ‚Äù, ‚ÄúVDJ-T‚Äù, ‚ÄúVDJ-B‚Äù, ‚ÄúAntibody Capture‚Äù, ‚ÄúCRISPR Guide Capture‚Äù, ‚ÄúMultiplexing Capture‚Äù\nList of string, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--library_subsample\nOptional. The rate at which reads from the provided FASTQ files are sampled. Must be strictly greater than 0 and less than or equal to 1.\nList of string, example: \"0.5\", multiple_sep: \";\"\n\n\n--library_lanes\nLanes associated with this sample. Defaults to using all lanes.\nList of string, example: \"1-4\", multiple_sep: \";\"\n\n\n\n\n\nGene expression arguments\nArguments relevant to the analysis of gene expression data.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--gex_expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\ninteger, example: 3000\n\n\n--gex_chemistry\nAssay configuration. - auto: autodetect mode - threeprime: Single Cell 3‚Äô - fiveprime: Single Cell 5‚Äô - SC3Pv1: Single Cell 3‚Äô v1 - SC3Pv2: Single Cell 3‚Äô v2 - SC3Pv3: Single Cell 3‚Äô v3 - SC3Pv3LT: Single Cell 3‚Äô v3 LT - SC3Pv3HT: Single Cell 3‚Äô v3 HT - SC5P-PE: Single Cell 5‚Äô paired-end - SC5P-R2: Single Cell 5‚Äô R2-only - SC-FB: Single Cell Antibody-only 3‚Äô v2 or 5‚Äô See https://kb.10xgenomics.com/hc/en-us/articles/115003764132-How-does-Cell-Ranger-auto-detect-chemistry- for more information.\nstring, default: \"auto\"\n\n\n--gex_secondary_analysis\nWhether or not to run the secondary analysis e.g.¬†clustering.\nboolean, default: FALSE\n\n\n--gex_generate_bam\nWhether to generate a BAM file.\nboolean, default: FALSE\n\n\n--gex_include_introns\nInclude intronic reads in count (default=true unless ‚Äìtarget-panel is specified in which case default=false)\nboolean, default: TRUE\n\n\n\n\n\nCell multiplexing parameters\nArguments related to cell multiplexing.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_multiplex_sample_id\nA name to identify a multiplexed sample. Must be alphanumeric with hyphens and/or underscores, and less than 64 characters. Required for Cell Multiplexing libraries.\nstring\n\n\n--cell_multiplex_oligo_ids\nThe Cell Multiplexing oligo IDs used to multiplex this sample. If multiple CMOs were used for a sample, separate IDs with a pipe (e.g., CMO301|CMO302). Required for Cell Multiplexing libraries.\nstring\n\n\n--cell_multiplex_description\nA description for the sample.\nstring\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe folder to store the alignment results.\nfile, required, example: \"/path/to/output\"\n\n\n\n\n\nExecutor arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--dryrun\nIf true, the output directory will only contain the CWL input files, but the pipeline itself will not be executed.\nboolean_true"
  },
  {
    "objectID": "components/modules/mapping/cellranger_multi.html#authors",
    "href": "components/modules/mapping/cellranger_multi.html#authors",
    "title": "Cellranger multi",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)\nDries De Maeyer   (author)"
  },
  {
    "objectID": "components/modules/labels_transfer/knn.html",
    "href": "components/modules/labels_transfer/knn.html",
    "title": "Knn",
    "section": "",
    "text": "ID: knn\nNamespace: labels_transfer\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/labels_transfer/knn.html#example-commands",
    "href": "components/modules/labels_transfer/knn.html#example-commands",
    "title": "Knn",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/labels_transfer/knn/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Learning parameters\nn_neighbors: # please fill in - example: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/labels_transfer/knn/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/labels_transfer/knn.html#argument-groups",
    "href": "components/modules/labels_transfer/knn.html#argument-groups",
    "title": "Knn",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput dataset (query) arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe query data to transfer the labels to. Should be a .h5mu file.\nfile, required\n\n\n--modality\nWhich modality to use.\nstring, default: \"rna\"\n\n\n--input_obsm_features\nThe .obsm key of the embedding to use for the classifier‚Äôs inference. If not provided, the .X slot will be used instead. Make sure that embedding was obtained in the same way as the reference embedding (e.g.¬†by the same model or preprocessing).\nstring, example: \"X_integrated_scanvi\"\n\n\n\n\n\nReference dataset arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nThe reference data to train classifiers on.\nfile, example: \"https:/zenodo.org/record/6337966/files/HLCA_emb_and_metadata.h5ad\"\n\n\n--reference_obsm_features\nThe .obsm key of the embedding to use for the classifier‚Äôs training. Make sure that embedding was obtained in the same way as the query embedding (e.g.¬†by the same model or preprocessing).\nstring, required, default: \"X_integrated_scanvi\"\n\n\n--reference_obs_targets\nThe .obs key of the target labels to tranfer.\nList of string, default: \"ann_level_1\", \"ann_level_2\", \"ann_level_3\", \"ann_level_4\", \"ann_level_5\", \"ann_finest_level\", multiple_sep: \";\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe query data in .h5mu format with predicted labels transfered from the reference.\nfile, required\n\n\n--output_obs_predictions\nIn which .obs slots to store the predicted information. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_pred\" suffix.\nList of string, multiple_sep: \";\"\n\n\n--output_obs_uncertainty\nIn which .obs slots to store the uncertainty of the predictions. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_uncertainty\" suffix.\nList of string, multiple_sep: \";\"\n\n\n--output_uns_parameters\nThe .uns key to store additional information about the parameters used for the label transfer.\nstring, default: \"labels_transfer\"\n\n\n\n\n\nLearning parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_neighbors\nNumber of nearest neighbors to use for classification\ninteger, required"
  },
  {
    "objectID": "components/modules/labels_transfer/knn.html#authors",
    "href": "components/modules/labels_transfer/knn.html#authors",
    "title": "Knn",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov    (author)"
  },
  {
    "objectID": "components/modules/files/make_params.html",
    "href": "components/modules/files/make_params.html",
    "title": "Make params",
    "section": "",
    "text": "ID: make_params\nNamespace: files\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/files/make_params.html#example-commands",
    "href": "components/modules/files/make_params.html#example-commands",
    "title": "Make params",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/files/make_params/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nbase_dir: # please fill in - example: \"/path/to/dir\"\npattern: # please fill in - example: \"*.fastq.gz\"\nn_dirname_drop: 0\nn_basename_id: 0\nid_name: \"id\"\npath_name: \"path\"\n# group_name: \"param_list\"\n# output: \"$id.$key.output.yaml\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/files/make_params/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/files/make_params.html#argument-group",
    "href": "components/modules/files/make_params.html#argument-group",
    "title": "Make params",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--base_dir\nBase directory to search recursively\nfile, required, example: \"/path/to/dir\"\n\n\n--pattern\nAn optional regular expression. Only file names which match the regular expression will be matched.\nstring, required, example: \"*.fastq.gz\"\n\n\n--n_dirname_drop\nFor every matched file, the parent directory will be traversed N times.\ninteger, default: 0\n\n\n--n_basename_id\nThe unique identifiers will consist of at least N dirnames.\ninteger, default: 0\n\n\n--id_name\nThe name for storing the identifier field in the yaml.\nstring, default: \"id\"\n\n\n--path_name\nThe name for storing the path field in the yaml.\nstring, default: \"path\"\n\n\n--group_name\nTop level name for the group of entries.\nstring, example: \"param_list\"\n\n\n--output\nOutput YAML file.\nfile, required, example: \"params.yaml\""
  },
  {
    "objectID": "components/modules/files/make_params.html#authors",
    "href": "components/modules/files/make_params.html#authors",
    "title": "Make params",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (maintainer, author)"
  },
  {
    "objectID": "components/modules/transform/normalize_total.html",
    "href": "components/modules/transform/normalize_total.html",
    "title": "Normalize total",
    "section": "",
    "text": "ID: normalize_total\nNamespace: transform\n\n\n\nSource\nNormalize each cell by total counts over all genes, so that every cell has the same total count after normalization. If choosing target_sum=1e6, this is CPM normalization.\nIf exclude_highly_expressed=True, very highly expressed genes are excluded from the computation of the normalization factor (size factor) for each cell. This is meaningful as these can strongly influence the resulting normalized values for all other genes [Weinreb17]."
  },
  {
    "objectID": "components/modules/transform/normalize_total.html#example-commands",
    "href": "components/modules/transform/normalize_total.html#example-commands",
    "title": "Normalize total",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/transform/normalize_total/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n# output_layer: \"foo\"\ntarget_sum: 10000\nexclude_highly_expressed: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/normalize_total/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transform/normalize_total.html#argument-group",
    "href": "components/modules/transform/normalize_total.html#argument-group",
    "title": "Normalize total",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\nInput layer to use. By default, X is normalized\nstring\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--output_layer\nOutput layer to use. By default, use X.\nstring\n\n\n--target_sum\nIf None, after normalization, each observation (cell) has a total count equal to the median of total counts for observations (cells) before normalization.\ninteger, default: 10000\n\n\n--exclude_highly_expressed\nExclude (very) highly expressed genes for the computation of the normalization factor (size factor) for each cell. A gene is considered highly expressed, if it has more than max_fraction of the total counts in at least one cell. The not-excluded genes will sum up to target_sum.\nboolean_true"
  },
  {
    "objectID": "components/modules/transform/normalize_total.html#authors",
    "href": "components/modules/transform/normalize_total.html#authors",
    "title": "Normalize total",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)\nRobrecht Cannoodt    (contributor)"
  },
  {
    "objectID": "components/modules/transform/move_layer.html",
    "href": "components/modules/transform/move_layer.html",
    "title": "Move layer",
    "section": "",
    "text": "ID: move_layer\nNamespace: transform\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/transform/move_layer.html#example-commands",
    "href": "components/modules/transform/move_layer.html#example-commands",
    "title": "Move layer",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/transform/move_layer/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_layer: \"foo\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/move_layer/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transform/move_layer.html#argument-group",
    "href": "components/modules/transform/move_layer.html#argument-group",
    "title": "Move layer",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\n\nstring\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_layer\n\nstring\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/transform/regress_out.html",
    "href": "components/modules/transform/regress_out.html",
    "title": "Regress out",
    "section": "",
    "text": "ID: regress_out\nNamespace: transform\n\n\n\nSource\nUses simple linear regression. This is inspired by Seurat‚Äôs regressOut function in R [Satija15]. Note that this function tends to overcorrect in certain circumstances as described in issue theislab/scanpy#526. See https://github.com/theislab/scanpy/issues/526"
  },
  {
    "objectID": "components/modules/transform/regress_out.html#example-commands",
    "href": "components/modules/transform/regress_out.html#example-commands",
    "title": "Regress out",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/transform/regress_out/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nmodality: \"rna\"\n# obs_keys: [\"foo\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/regress_out/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transform/regress_out.html#argument-group",
    "href": "components/modules/transform/regress_out.html#argument-group",
    "title": "Regress out",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--modality\nWhich modality (one or more) to run this component on.\nstring, default: \"rna\"\n\n\n--obs_keys\nWhich .obs keys to regress on.\nList of string, multiple_sep: \";\""
  },
  {
    "objectID": "components/modules/transform/regress_out.html#authors",
    "href": "components/modules/transform/regress_out.html#authors",
    "title": "Regress out",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer, contributor)"
  },
  {
    "objectID": "components/modules/feature_annotation/highly_variable_features_scanpy.html",
    "href": "components/modules/feature_annotation/highly_variable_features_scanpy.html",
    "title": "Highly variable features scanpy",
    "section": "",
    "text": "ID: highly_variable_features_scanpy\nNamespace: feature_annotation\n\n\n\nSource\nExpects logarithmized data, except when flavor=‚Äòseurat_v3‚Äô in which count data is expected.\nDepending on flavor, this reproduces the R-implementations of Seurat [Satija15], Cell Ranger [Zheng17], and Seurat v3 [Stuart19].\nFor the dispersion-based methods ([Satija15] and [Zheng17]), the normalized dispersion is obtained by scaling with the mean and standard deviation of the dispersions for features falling into a given bin for mean expression of features. This means that for each bin of mean expression, highly variable features are selected.\nFor [Stuart19], a normalized variance for each feature is computed. First, the data are standardized (i.e., z-score normalization per feature) with a regularized standard deviation. Next, the normalized variance is computed as the variance of each feature after the transformation. Features are ranked by the normalized variance."
  },
  {
    "objectID": "components/modules/feature_annotation/highly_variable_features_scanpy.html#example-commands",
    "href": "components/modules/feature_annotation/highly_variable_features_scanpy.html#example-commands",
    "title": "Highly variable features scanpy",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/feature_annotation/highly_variable_features_scanpy/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nvar_name_filter: \"filter_with_hvg\"\nvarm_name: \"hvg\"\nflavor: \"seurat\"\n# n_top_features: 123\nmin_mean: 0.0125\nmax_mean: 3\nmin_disp: 0.5\n# max_disp: 123.0\nspan: 0.3\nn_bins: 20\n# obs_batch_key: \"foo\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/feature_annotation/highly_variable_features_scanpy/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/feature_annotation/highly_variable_features_scanpy.html#argument-group",
    "href": "components/modules/feature_annotation/highly_variable_features_scanpy.html#argument-group",
    "title": "Highly variable features scanpy",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nuse adata.layers[layer] for expression values instead of adata.X.\nstring\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--var_name_filter\nIn which .var slot to store a boolean array corresponding to which observations should be filtered out.\nstring, default: \"filter_with_hvg\"\n\n\n--varm_name\nIn which .varm slot to store additional metadata.\nstring, default: \"hvg\"\n\n\n--flavor\nChoose the flavor for identifying highly variable features. For the dispersion based methods in their default workflows, Seurat passes the cutoffs whereas Cell Ranger passes n_top_features.\nstring, default: \"seurat\"\n\n\n--n_top_features\nNumber of highly-variable features to keep. Mandatory if flavor=‚Äòseurat_v3‚Äô.\ninteger\n\n\n--min_mean\nIf n_top_features is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‚Äòseurat_v3‚Äô.\ndouble, default: 0.0125\n\n\n--max_mean\nIf n_top_features is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‚Äòseurat_v3‚Äô.\ndouble, default: 3\n\n\n--min_disp\nIf n_top_features is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‚Äòseurat_v3‚Äô.\ndouble, default: 0.5\n\n\n--max_disp\nIf n_top_features is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‚Äòseurat_v3‚Äô. Default is +inf.\ndouble\n\n\n--span\nThe fraction of the data (cells) used when estimating the variance in the loess model fit if flavor=‚Äòseurat_v3‚Äô.\ndouble, default: 0.3\n\n\n--n_bins\nNumber of bins for binning the mean feature expression. Normalization is done with respect to each bin. If just a single feature falls into a bin, the normalized dispersion is artificially set to 1.\ninteger, default: 20\n\n\n--obs_batch_key\nIf specified, highly-variable features are selected within each batch separately and merged. This simple process avoids the selection of batch-specific features and acts as a lightweight batch correction method. For all flavors, features are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If flavor = ‚Äòseurat_v3‚Äô, ties are broken by the median (across batches) rank based on within-batch normalized variance.\nstring"
  },
  {
    "objectID": "components/modules/feature_annotation/highly_variable_features_scanpy.html#authors",
    "href": "components/modules/feature_annotation/highly_variable_features_scanpy.html#authors",
    "title": "Highly variable features scanpy",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (contributor)\nRobrecht Cannoodt    (maintainer, contributor)"
  },
  {
    "objectID": "components/modules/demux/cellranger_mkfastq.html",
    "href": "components/modules/demux/cellranger_mkfastq.html",
    "title": "Cellranger mkfastq",
    "section": "",
    "text": "ID: cellranger_mkfastq\nNamespace: demux\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/demux/cellranger_mkfastq.html#example-commands",
    "href": "components/modules/demux/cellranger_mkfastq.html#example-commands",
    "title": "Cellranger mkfastq",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/demux/cellranger_mkfastq/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"/path/to/bcl\"\nsample_sheet: # please fill in - example: \"SampleSheet.csv\"\n# output: \"$id.$key.output.output\"\n# reports: \"$id.$key.reports.reports\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/demux/cellranger_mkfastq/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/demux/cellranger_mkfastq.html#argument-group",
    "href": "components/modules/demux/cellranger_mkfastq.html#argument-group",
    "title": "Cellranger mkfastq",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the (untarred) BCL files. Expects ‚ÄòRunParameters.xml‚Äô at ‚Äò./‚Äô.\nfile, required, example: \"/path/to/bcl\"\n\n\n--sample_sheet\nThe path to the sample sheet.\nfile, required, example: \"SampleSheet.csv\"\n\n\n--output\nThe folder to store the demux results\nfile, required, default: \"fastqs\", example: \"/path/to/output\"\n\n\n--reports\nReports directory\nfile, example: \"reports_dir\""
  },
  {
    "objectID": "components/modules/demux/cellranger_mkfastq.html#authors",
    "href": "components/modules/demux/cellranger_mkfastq.html#authors",
    "title": "Cellranger mkfastq",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nSamuel D‚ÄôSouza   (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/cluster/leiden.html",
    "href": "components/modules/cluster/leiden.html",
    "title": "Leiden",
    "section": "",
    "text": "ID: leiden\nNamespace: cluster\n\n\n\nSource\nLeiden is an improved version of the [Louvain algorithm] [Blondel08]. It has been proposed for single-cell analysis by [Levine15] [Levine15]. This requires having ran neighbors/find_neighbors or neighbors/bbknn first.\n[Blondel08]: Blondel et al.¬†(2008), Fast unfolding of communities in large networks, J. Stat. Mech.\n[Levine15]: Levine et al.¬†(2015), Data-Driven Phenotypic Dissection of AML Reveals Progenitor-like Cells that Correlate with Prognosis, Cell.\n[Traag18]: Traag et al.¬†(2018), From Louvain to Leiden: guaranteeing well-connected communities arXiv.\n[Wolf18]: Wolf et al.¬†(2018), Scanpy: large-scale single-cell gene expression data analysis, Genome Biology."
  },
  {
    "objectID": "components/modules/cluster/leiden.html#example-commands",
    "href": "components/modules/cluster/leiden.html#example-commands",
    "title": "Leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/cluster/leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nobsp_connectivities: \"connectivities\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobsm_name: \"leiden\"\nresolution: # please fill in - example: [1]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/cluster/leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/cluster/leiden.html#argument-group",
    "href": "components/modules/cluster/leiden.html#argument-group",
    "title": "Leiden",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsp_connectivities\nIn which .obsp slot the neighbor connectivities can be found.\nstring, default: \"connectivities\"\n\n\n--output\nOutput file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--obsm_name\nName of the .obsm key under which to add the cluster labels. The name of the columns in the matrix will correspond to the resolutions.\nstring, default: \"leiden\"\n\n\n--resolution\nA parameter value controlling the coarseness of the clustering. Higher values lead to more clusters. Multiple values will result in clustering being performed multiple times.\nList of double, required, default: 1, multiple_sep: \";\""
  },
  {
    "objectID": "components/modules/cluster/leiden.html#authors",
    "href": "components/modules/cluster/leiden.html#authors",
    "title": "Leiden",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)"
  },
  {
    "objectID": "components/modules/dataflow/concatenate_h5mu.html",
    "href": "components/modules/dataflow/concatenate_h5mu.html",
    "title": "Concatenate h5mu",
    "section": "",
    "text": "ID: concatenate_h5mu\nNamespace: dataflow\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/dataflow/concatenate_h5mu.html#example-commands",
    "href": "components/modules/dataflow/concatenate_h5mu.html#example-commands",
    "title": "Concatenate h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/dataflow/concatenate_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: [\"sample_paths\"]\n# input_id: [\"foo\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobs_sample_name: \"sample_id\"\nother_axis_mode: \"move\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dataflow/concatenate_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/dataflow/concatenate_h5mu.html#argument-group",
    "href": "components/modules/dataflow/concatenate_h5mu.html#argument-group",
    "title": "Concatenate h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPaths to the different samples to be concatenated.\nList of file, required, example: \"sample_paths\", multiple_sep: \";\"\n\n\n--input_id\nNames of the different samples that have to be concatenated. Must be specified when using ‚Äò‚Äìmode move‚Äô. In this case, the ids will be used for the columns names of the dataframes registring the conflicts. If specified, must be of same length as --input.\nList of string, multiple_sep: \";\"\n\n\n--output\n\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obs_sample_name\nName of the .obs key under which to add the sample names.\nstring, default: \"sample_id\"\n\n\n--other_axis_mode\nHow to handle the merging of other axis (var, obs, ‚Ä¶). - None: keep no data - same: only keep elements of the matrices which are the same in each of the samples - unique: only keep elements for which there is only 1 possible value (1 value that can occur in multiple samples) - first: keep the annotation from the first sample - only: keep elements that show up in only one of the objects (1 unique element in only 1 sample) - move: identical to ‚Äòsame‚Äô, but moving the conflicting values to .varm or .obsm\nstring, default: \"move\""
  },
  {
    "objectID": "components/modules/dataflow/concatenate_h5mu.html#authors",
    "href": "components/modules/dataflow/concatenate_h5mu.html#authors",
    "title": "Concatenate h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/dataflow/merge.html",
    "href": "components/modules/dataflow/merge.html",
    "title": "Merge",
    "section": "",
    "text": "ID: merge\nNamespace: dataflow\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/dataflow/merge.html#example-commands",
    "href": "components/modules/dataflow/merge.html#example-commands",
    "title": "Merge",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/dataflow/merge/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: [\"sample_paths\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dataflow/merge/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/dataflow/merge.html#argument-group",
    "href": "components/modules/dataflow/merge.html#argument-group",
    "title": "Merge",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPaths to the single-modality .h5mu files that need to be combined\nList of file, required, default: \"sample_paths\", multiple_sep: \";\"\n\n\n--output\nPath to the output file.\nfile, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/dataflow/merge.html#authors",
    "href": "components/modules/dataflow/merge.html#authors",
    "title": "Merge",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/genetic_demux/freemuxlet.html",
    "href": "components/modules/genetic_demux/freemuxlet.html",
    "title": "Freemuxlet",
    "section": "",
    "text": "ID: freemuxlet\nNamespace: genetic_demux\n\n\n\nSource\nIf external genotyping data is not available, the genotyping-free version demuxlet, freemuxlet, would be recommended"
  },
  {
    "objectID": "components/modules/genetic_demux/freemuxlet.html#example-commands",
    "href": "components/modules/genetic_demux/freemuxlet.html#example-commands",
    "title": "Freemuxlet",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/genetic_demux/freemuxlet/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# plp: \"foo\"\n# init_cluster: \"path/to/file\"\nnsample: 2\naux_files: false\nverbose: 100\ndoublet_prior: 0.5\ngeno_error: 0.1\nbf_thres: 5.41\nfrac_init_clust: 1\niter_init: 10\nkeep_init_missing: false\nrandomize_singlet_score: false\nseed: 0\ncap_bq: 20\nmin_bq: 13\n# group_list: \"foo\"\nmin_total: 0\nmin_umi: 0\nmin_snp: 0\n\n# Output\n# output: \"$id.$key.output.output\"\n# out: \"freemuxlet\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/freemuxlet/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/genetic_demux/freemuxlet.html#argument-groups",
    "href": "components/modules/genetic_demux/freemuxlet.html#argument-groups",
    "title": "Freemuxlet",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--plp\nPrefix of input files generated by dsc-pileup\nstring\n\n\n--init_cluster\nInput file containing the initial cluster information.\nfile\n\n\n--nsample\nNumber of samples multiplexed together\ninteger, default: 2\n\n\n--aux_files\nTurn on writing auxilary output files\nboolean_true\n\n\n--verbose\nTurn on verbose mode with specific verbosity threshold. 0: fully verbose, 100 : no verbose messages.\ninteger, default: 100\n\n\n--doublet_prior\nPrior of doublet.\ndouble, default: 0.5\n\n\n--geno_error\nGenotype error parameter per cluster.\ndouble, default: 0.1\n\n\n--bf_thres\nBayes Factor Threshold used in the initial clustering.\ndouble, default: 5.41\n\n\n--frac_init_clust\nFraction of droplets to be clustered in the very first round of initial clustering procedure.\ndouble, default: 1\n\n\n--iter_init\nIteration for initial cluster assignment (set to zero to skip the iterations).\ninteger, default: 10\n\n\n--keep_init_missing\nKeep missing cluster assignment as missing in the initial iteration.\nboolean_true\n\n\n--randomize_singlet_score\nRandomize the singlet scores to test its effect.\nboolean_true\n\n\n--seed\nSeed for random number (use clocks if not set).\ninteger, default: 0\n\n\n--cap_bq\nMaximum base quality (higher BQ will be capped).\ninteger, default: 20\n\n\n--min_bq\nMinimum base quality to consider (lower BQ will be skipped).\ninteger, default: 13\n\n\n--group_list\nList of tag readgroup/cell barcode to consider in this run. All other barcodes will be ignored. This is useful for parallelized run.\nstring\n\n\n--min_total\nMinimum number of total reads for a droplet/cell to be considered.\ninteger, default: 0\n\n\n--min_umi\nMinimum number of UMIs for a droplet/cell to be considered.\ninteger, default: 0\n\n\n--min_snp\nMinimum number of SNPs with coverage for a droplet/cell to be considered.\ninteger, default: 0\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory\nfile, example: \"freemux\"\n\n\n--out\nfreemuxlet Output file prefix\nstring, example: \"freemuxlet\""
  },
  {
    "objectID": "components/modules/genetic_demux/freemuxlet.html#authors",
    "href": "components/modules/genetic_demux/freemuxlet.html#authors",
    "title": "Freemuxlet",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)"
  },
  {
    "objectID": "components/modules/genetic_demux/demuxlet.html",
    "href": "components/modules/genetic_demux/demuxlet.html",
    "title": "Demuxlet",
    "section": "",
    "text": "ID: demuxlet\nNamespace: genetic_demux\n\n\n\nSource\nIf external genotyping data for each sample is available (e.g.¬†from SNP arrays), demuxlet would be recommended. Be careful that the parameters on the github is not in line with the newest help version"
  },
  {
    "objectID": "components/modules/genetic_demux/demuxlet.html#example-commands",
    "href": "components/modules/genetic_demux/demuxlet.html#example-commands",
    "title": "Demuxlet",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/genetic_demux/demuxlet/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# sam: \"path/to/file\"\ntag_group: \"CB\"\ntag_umi: \"UB\"\n# plp: \"foo\"\n# vcf: \"path/to/file\"\nfield: \"GT\"\ngeno_error_offset: 0.1\ngeno_error_coeff: 0.0\nr2_info: \"R2\"\nmin_mac: 1\nmin_call_rate: 0.5\nalpha: \"0.5\"\ndoublet_prior: 0.5\n# sm: \"foo\"\n# sm_list: \"foo\"\nsam_verbose: 1000000\nvcf_verbose: 1000\ncap_bq: 20\nmin_bq: 13\nmin_mq: 20\nmin_td: 0\nexcl_flag: 3844\n# group_list: \"foo\"\nmin_total: 0\nmin_snp: 0\nmin_umi: 0\n\n# Output\n# output: \"$id.$key.output.output\"\n# out: \"demuxlet\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/demuxlet/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/genetic_demux/demuxlet.html#argument-groups",
    "href": "components/modules/genetic_demux/demuxlet.html#argument-groups",
    "title": "Demuxlet",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sam\nInput SAM/BAM/CRAM file. Must be sorted by coordinates and indexed.\nfile\n\n\n--tag_group\nTag representing readgroup or cell barcodes, in the case to partition the BAM file into multiple groups. For 10x genomics, use CB.\nstring, default: \"CB\"\n\n\n--tag_umi\nTag representing UMIs. For 10x genomiucs, use UB.\nstring, default: \"UB\"\n\n\n--plp\nInput pileup format. If the value is a string, it will be considered as the path of the plp file. If the value is boolean true, it will perform dscpileup.\nstring\n\n\n--vcf\nInput VCF/BCF file, containing the individual genotypes (GT), posterior probability (GP), or genotype likelihood (PL).\nfile\n\n\n--field\nFORMAT field to extract the genotype, likelihood, or posterior from\nstring, default: \"GT\"\n\n\n--geno_error_offset\nOffset of genotype error rate. [error] = [offset] + [1-offset][coeff][1-r2]\ndouble, default: 0.1\n\n\n--geno_error_coeff\nSlope of genotype error rate. [error] = [offset] + [1-offset][coeff][1-r2]\ndouble, default: 0\n\n\n--r2_info\nINFO field name representing R2 value. Used for representing imputation quality.\nstring, default: \"R2\"\n\n\n--min_mac\nMinimum minor allele frequency.\ninteger, default: 1\n\n\n--min_call_rate\nMinimum call rate.\ndouble, default: 0.5\n\n\n--alpha\nGrid of alpha to search for (default is 0.1, 0.2, 0.3, 0.4, 0.5)\nstring, default: \"0.5\"\n\n\n--doublet_prior\nPrior of doublet\ndouble, default: 0.5\n\n\n--sm\nList of sample IDs to compare to (default: use all).\nstring\n\n\n--sm_list\nFile containing the list of sample IDs to compare.\nstring\n\n\n--sam_verbose\nVerbose message frequency for SAM/BAM/CRAM.\ninteger, default: 1000000\n\n\n--vcf_verbose\nVerbose message frequency for VCF/BCF.\ninteger, default: 1000\n\n\n--cap_bq\nMaximum base quality (higher BQ will be capped).\ninteger, default: 20\n\n\n--min_bq\nMinimum base quality to consider (lower BQ will be skipped).\ninteger, default: 13\n\n\n--min_mq\nMinimum mapping quality to consider (lower MQ will be ignored).\ninteger, default: 20\n\n\n--min_td\nMinimum distance to the tail (lower will be ignored).\ninteger, default: 0\n\n\n--excl_flag\nSAM/BAM FLAGs to be excluded.\ninteger, default: 3844\n\n\n--group_list\nList of tag readgroup/cell barcode to consider in this run. All other barcodes will be ignored. This is useful for parallelized run.\nstring\n\n\n--min_total\nMinimum number of total reads for a droplet/cell to be considered.\ninteger, default: 0\n\n\n--min_snp\nMinimum number of SNPs with coverage for a droplet/cell to be considered.\ninteger, default: 0\n\n\n--min_umi\nMinimum number of UMIs for a droplet/cell to be considered.\ninteger, default: 0\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory\nfile, example: \"demux\"\n\n\n--out\ndemuxlet output file prefix\nstring, example: \"demuxlet\""
  },
  {
    "objectID": "components/modules/genetic_demux/demuxlet.html#authors",
    "href": "components/modules/genetic_demux/demuxlet.html#authors",
    "title": "Demuxlet",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)"
  },
  {
    "objectID": "components/modules/genetic_demux/bcftools.html",
    "href": "components/modules/genetic_demux/bcftools.html",
    "title": "Bcftools",
    "section": "",
    "text": "ID: bcftools\nNamespace: genetic_demux\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/genetic_demux/bcftools.html#example-commands",
    "href": "components/modules/genetic_demux/bcftools.html#example-commands",
    "title": "Bcftools",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/genetic_demux/bcftools/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nvcf: # please fill in - example: [\"path/to/file\"]\nconcat: false\nfilter: false\nfilter_qual: 30\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/bcftools/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/genetic_demux/bcftools.html#argument-group",
    "href": "components/modules/genetic_demux/bcftools.html#argument-group",
    "title": "Bcftools",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--vcf\nVCF files, must have the same sample columns appearing in the same order.\nList of file, required, multiple_sep: \";\"\n\n\n--concat\nConcatenate or combine VCFs and sort them.\nboolean_true\n\n\n--filter\nFilter VCFs.\nboolean_true\n\n\n--filter_qual\nFilter VCFs with specified QUAL threshold.\ninteger, default: 30\n\n\n--output\nbcftools output directory\nfile, example: \"bcftools_out\""
  },
  {
    "objectID": "components/modules/genetic_demux/bcftools.html#authors",
    "href": "components/modules/genetic_demux/bcftools.html#authors",
    "title": "Bcftools",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)"
  },
  {
    "objectID": "components/modules/genetic_demux/vireo.html",
    "href": "components/modules/genetic_demux/vireo.html",
    "title": "Vireo",
    "section": "",
    "text": "ID: vireo\nNamespace: genetic_demux\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/genetic_demux/vireo.html#example-commands",
    "href": "components/modules/genetic_demux/vireo.html#example-commands",
    "title": "Vireo",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/genetic_demux/vireo/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# cell_data: \"path/to/file\"\nn_donor: 2\n# vartrix_data: \"path/to/file\"\n# donor_file: \"path/to/file\"\ngeno_tag: \"PL\"\nno_doublet: false\nn_init: 50\nextra_donor: 0\n# extra_donorMode: \"foo\"\nforce_learn_gt: false\nase_mode: false\nno_plot: false\n# rand_seed: 123\n# cell_range: \"foo\"\ncall_ambient_rnas: false\n\n# Output\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/vireo/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/genetic_demux/vireo.html#argument-groups",
    "href": "components/modules/genetic_demux/vireo.html#argument-groups",
    "title": "Vireo",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_data\nThe cell genotype file in VCF format or cellSNP folder with sparse matrices.\nfile\n\n\n--n_donor\nNumber of donors to demultiplex; can be larger than provided in donor_file.\ninteger, default: 2\n\n\n--vartrix_data\nThe cell genotype files in vartrix outputs.\nfile\n\n\n--donor_file\nThe donor genotype file in VCF format. Please filter the sample and region with bcftools first!\nfile\n\n\n--geno_tag\nThe tag for donor genotype.\nstring, default: \"PL\"\n\n\n--no_doublet\nIf use, not checking doublets.\nboolean, default: FALSE\n\n\n--n_init\nNumber of random initializations, when GT needs to learn.\ninteger, default: 50\n\n\n--extra_donor\nNumber of extra donor in pre-cluster, when GT needs to learn.\ninteger, default: 0\n\n\n--extra_donorMode\nMethod for searching from extra donors. size: n_cell per donor; distance: GT distance between donors\nstring\n\n\n--force_learn_gt\nIf use, treat donor GT as prior only.\nboolean, default: FALSE\n\n\n--ase_mode\nIf use, turn on SNP specific allelic ratio.\nboolean, default: FALSE\n\n\n--no_plot\nIf use, turn off plotting GT distance.\nboolean, default: FALSE\n\n\n--rand_seed\nSeed for random initialization\ninteger\n\n\n--cell_range\nRange of cells to process.\nstring\n\n\n--call_ambient_rnas\nIf use, detect ambient RNAs in each cell.\nboolean, default: FALSE\n\n\n\n\n\nOutput\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory\nfile, example: \"vireo\""
  },
  {
    "objectID": "components/modules/genetic_demux/vireo.html#authors",
    "href": "components/modules/genetic_demux/vireo.html#authors",
    "title": "Vireo",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)"
  },
  {
    "objectID": "components/modules/genetic_demux/scsplit.html",
    "href": "components/modules/genetic_demux/scsplit.html",
    "title": "Scsplit",
    "section": "",
    "text": "ID: scsplit\nNamespace: genetic_demux\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/genetic_demux/scsplit.html#example-commands",
    "href": "components/modules/genetic_demux/scsplit.html#example-commands",
    "title": "Scsplit",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/genetic_demux/scsplit/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# vcf: \"path/to/file\"\n# bam: \"path/to/file\"\n# bar: \"path/to/file\"\ntag: \"CB\"\n# com: \"path/to/file\"\n# num: 123\nsub: 10\nems: 30\n# dbl: 123.0\n# vcf_known: \"path/to/file\"\ngeno: false\n\n# Output\n# output: \"$id.$key.output.output\"\n# ref: \"foo\"\n# alt: \"foo\"\n# psc: \"foo\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/scsplit/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/genetic_demux/scsplit.html#argument-groups",
    "href": "components/modules/genetic_demux/scsplit.html#argument-groups",
    "title": "Scsplit",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--vcf\nVCF from mixed BAM\nfile\n\n\n--bam\nmixed sample BAM\nfile\n\n\n--bar\nbarcodes whitelist\nfile\n\n\n--tag\ntag for barcode\nstring, default: \"CB\"\n\n\n--com\ncommon SNVs\nfile\n\n\n--num\nexpected number of mixed samples\ninteger\n\n\n--sub\nmaximum number of subpopulations in autodetect mode\ninteger, default: 10\n\n\n--ems\nnumber of EM repeats to avoid local maximum\ninteger, default: 30\n\n\n--dbl\ncorrection for doublets. There will be no refinement on the results if this optional parameter is not specified or specified percentage is less than doublet rates detected during the run.\ndouble\n\n\n--vcf_known\nknown individual genotypes to limit distinguishing variants to available variants, so that users do not need to redo genotyping on selected variants, otherwise any variants could be selected as distinguishing variants.\nfile\n\n\n--geno\ngenerate sample genotypes based on the split result.\nboolean_true\n\n\n\n\n\nOutput\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory\nfile, example: \"scSplit_out\"\n\n\n--ref\noutput Ref count matrix\nstring\n\n\n--alt\noutput Alt count matrix\nstring\n\n\n--psc\ngenerated P(S|C)\nstring"
  },
  {
    "objectID": "components/modules/genetic_demux/scsplit.html#authors",
    "href": "components/modules/genetic_demux/scsplit.html#authors",
    "title": "Scsplit",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)"
  },
  {
    "objectID": "components/modules/download/sync_test_resources.html",
    "href": "components/modules/download/sync_test_resources.html",
    "title": "Sync test resources",
    "section": "",
    "text": "ID: sync_test_resources\nNamespace: download\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/download/sync_test_resources.html#example-commands",
    "href": "components/modules/download/sync_test_resources.html#example-commands",
    "title": "Sync test resources",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/download/sync_test_resources/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: \"s3://openpipelines-data\"\n# output: \"$id.$key.output.output\"\nquiet: false\ndryrun: false\ndelete: false\n# exclude: [\"foo\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/download/sync_test_resources/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/download/sync_test_resources.html#argument-group",
    "href": "components/modules/download/sync_test_resources.html#argument-group",
    "title": "Sync test resources",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the S3 bucket to sync from.\nstring, default: \"s3://openpipelines-data\"\n\n\n--output\nPath to the test resource directory.\nfile, default: \"resources_test\"\n\n\n--quiet\nDisplays the operations that would be performed using the specified command without actually running them.\nboolean_true\n\n\n--dryrun\nDoes not display the operations performed from the specified command.\nboolean_true\n\n\n--delete\nFiles that exist in the destination but not in the source are deleted during sync.\nboolean_true\n\n\n--exclude\nExclude all files or objects from the command that matches the specified pattern.\nList of string, multiple_sep: \";\""
  },
  {
    "objectID": "components/modules/download/sync_test_resources.html#authors",
    "href": "components/modules/download/sync_test_resources.html#authors",
    "title": "Sync test resources",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/reference/make_reference.html",
    "href": "components/modules/reference/make_reference.html",
    "title": "Make reference",
    "section": "",
    "text": "ID: make_reference\nNamespace: reference\n\n\n\nSource\nExample input files are: - genome_fasta: https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/GRCh38.primary_assembly.genome.fa.gz - transcriptome_gtf: https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/gencode.v41.annotation.gtf.gz - ercc: https://assets.thermofisher.com/TFS-Assets/LSG/manuals/ERCC92.zip"
  },
  {
    "objectID": "components/modules/reference/make_reference.html#example-commands",
    "href": "components/modules/reference/make_reference.html#example-commands",
    "title": "Make reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/reference/make_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ngenome_fasta: # please fill in - example: \"genome_fasta.fa.gz\"\ntranscriptome_gtf: # please fill in - example: \"transcriptome.gtf.gz\"\n# ercc: \"ercc.zip\"\n# subset_regex: \"(ERCC-00002|chr1)\"\n# output_fasta: \"$id.$key.output_fasta.gz\"\n# output_gtf: \"$id.$key.output_gtf.gz\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/reference/make_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/reference/make_reference.html#argument-group",
    "href": "components/modules/reference/make_reference.html#argument-group",
    "title": "Make reference",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genome_fasta\nReference genome fasta. Example:\nfile, required, example: \"genome_fasta.fa.gz\"\n\n\n--transcriptome_gtf\nReference transcriptome annotation.\nfile, required, example: \"transcriptome.gtf.gz\"\n\n\n--ercc\nERCC sequence and annotation file.\nfile, example: \"ercc.zip\"\n\n\n--subset_regex\nWill subset the reference chromosomes using the given regex.\nstring, example: \"(ERCC-00002&#124;chr1)\"\n\n\n--output_fasta\nOutput genome sequence fasta.\nfile, required, example: \"genome_sequence.fa.gz\"\n\n\n--output_gtf\nOutput transcriptome annotation gtf.\nfile, required, example: \"transcriptome_annotation.gtf.gz\""
  },
  {
    "objectID": "components/modules/reference/make_reference.html#authors",
    "href": "components/modules/reference/make_reference.html#authors",
    "title": "Make reference",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/reference/build_bdrhap_reference.html",
    "href": "components/modules/reference/build_bdrhap_reference.html",
    "title": "Build bdrhap reference",
    "section": "",
    "text": "ID: build_bdrhap_reference\nNamespace: reference\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/reference/build_bdrhap_reference.html#example-commands",
    "href": "components/modules/reference/build_bdrhap_reference.html#example-commands",
    "title": "Build bdrhap reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/reference/build_bdrhap_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ngenome_fasta: # please fill in - example: \"genome_sequence.fa.gz\"\ntranscriptome_gtf: # please fill in - example: \"transcriptome_annotation.gtf.gz\"\n# output: \"$id.$key.output.gz\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/reference/build_bdrhap_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/reference/build_bdrhap_reference.html#argument-group",
    "href": "components/modules/reference/build_bdrhap_reference.html#argument-group",
    "title": "Build bdrhap reference",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genome_fasta\nReference genome fasta.\nfile, required, example: \"genome_sequence.fa.gz\"\n\n\n--transcriptome_gtf\nReference transcriptome annotation.\nfile, required, example: \"transcriptome_annotation.gtf.gz\"\n\n\n--output\nStar index\nfile, required, example: \"star_index.tar.gz\""
  },
  {
    "objectID": "components/modules/reference/build_bdrhap_reference.html#authors",
    "href": "components/modules/reference/build_bdrhap_reference.html#authors",
    "title": "Build bdrhap reference",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/index.html",
    "href": "components/index.html",
    "title": "Components",
    "section": "",
    "text": "Order By\n       Default\n         \n          Name\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nName\n\n\nNamespace\n\n\nDescription\n\n\n\n\n\n\nWorkflows\n\n\n¬†\n\n\n\n\n\n\n\nBD Rhapsody\n\n\nIngestion\n\n\nA generic pipeline for running BD Rhapsody WTA or Targeted mapping, with support for AbSeq, VDJ and/or SMK.\n\n\n\n\nBD Rhapsody\n\n\nWorkflows/ingestion\n\n\nA generic pipeline for running BD Rhapsody WTA or Targeted mapping, with support for AbSeq, VDJ and/or SMK.\n\n\n\n\nBbknn leiden\n\n\nMultiomics/integration\n\n\nRun bbknn followed by leiden clustering and run umap on the result.\n\n\n\n\nBbknn leiden\n\n\nWorkflows/integration\n\n\nRun bbknn followed by leiden clustering and run umap on the result.\n\n\n\n\nCell Ranger mapping\n\n\nIngestion\n\n\nA pipeline for running Cell Ranger mapping.\n\n\n\n\nCell Ranger mapping\n\n\nWorkflows/ingestion\n\n\nA pipeline for running Cell Ranger mapping.\n\n\n\n\nCell Ranger multi\n\n\nIngestion\n\n\nA pipeline for running Cell Ranger multi.\n\n\n\n\nCell Ranger multi\n\n\nWorkflows/ingestion\n\n\nA pipeline for running Cell Ranger multi.\n\n\n\n\nCell Ranger post-processing\n\n\nIngestion\n\n\nPost-processing Cell Ranger datasets.\n\n\n\n\nCell Ranger post-processing\n\n\nWorkflows/ingestion\n\n\nPost-processing Cell Ranger datasets.\n\n\n\n\nConversion\n\n\nIngestion\n\n\nA pipeline to convert different file formats to .h5mu.\n\n\n\n\nConversion\n\n\nWorkflows/ingestion\n\n\nA pipeline to convert different file formats to .h5mu.\n\n\n\n\nDemux\n\n\nIngestion\n\n\nA generic pipeline for running bcl2fastq, bcl-convert or Cell Ranger mkfastq.\n\n\n\n\nDemux\n\n\nWorkflows/ingestion\n\n\nA generic pipeline for running bcl2fastq, bcl-convert or Cell Ranger mkfastq.\n\n\n\n\nDimensionality reduction\n\n\nWorkflows/multiomics\n\n\nRun calculations that output information required for most integration methods: PCA, nearest neighbour and UMAP.\n\n\n\n\nFull pipeline\n\n\nMultiomics\n\n\nA pipeline to analyse multiple multiomics samples.\n\n\n\n\nGdo singlesample\n\n\nWorkflows/gdo\n\n\nProcessing unimodal single-sample guide-derived oligonucleotide (GDO) data.\n\n\n\n\nHarmony leiden\n\n\nIntegration/common\n\n\nRun harmony integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nHarmony leiden\n\n\nMultiomics/integration\n\n\nRun harmony integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nHarmony leiden\n\n\nWorkflows/integration\n\n\nRun harmony integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nInitialize integration\n\n\nIntegration/initialize integration\n\n\nRun calculations that output information required for most integration methods: PCA, nearest neighbour and UMAP.\n\n\n\n\nInitialize integration\n\n\nMultiomics/integration\n\n\nRun calculations that output information required for most integration methods: PCA, nearest neighbour and UMAP.\n\n\n\n\nIntegration\n\n\nMultiomics\n\n\nA pipeline for demultiplexing multimodal multi-sample RNA transcriptomics data.\n\n\n\n\nLeiden scvi\n\n\nMultiomics/integration\n\n\nRun scvi integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nMake reference\n\n\nIngestion\n\n\nBuild a transcriptomics reference into one of many formats\n\n\n\n\nMake reference\n\n\nWorkflows/ingestion\n\n\nBuild a transcriptomics reference into one of many formats\n\n\n\n\nMultisample\n\n\nMultiomics\n\n\nThis workflow serves as an entrypoint into the ‚Äòfull_pipeline‚Äô in order to re-run the multisample processing and the integration setup.\n\n\n\n\nProcess batches\n\n\nWorkflows/multiomics\n\n\nThis workflow serves as an entrypoint into the ‚Äòfull_pipeline‚Äô in order to re-run the multisample processing and the integration setup.\n\n\n\n\nProcess samples\n\n\nWorkflows/multiomics\n\n\nA pipeline to analyse multiple multiomics samples.\n\n\n\n\nProt multisample\n\n\nMultiomics\n\n\nProcessing unimodal multi-sample ADT data.\n\n\n\n\nProt multisample\n\n\nWorkflows/prot\n\n\nProcessing unimodal multi-sample ADT data.\n\n\n\n\nProt singlesample\n\n\nMultiomics\n\n\nProcessing unimodal single-sample CITE-seq data.\n\n\n\n\nProt singlesample\n\n\nWorkflows/prot\n\n\nProcessing unimodal single-sample CITE-seq data.\n\n\n\n\nQc\n\n\nQc\n\n\nA pipeline to add basic qc statistics to a MuData\n\n\n\n\nQc\n\n\nWorkflows/qc\n\n\nA pipeline to add basic qc statistics to a MuData\n\n\n\n\nRna multisample\n\n\nMultiomics\n\n\nProcessing unimodal multi-sample RNA transcriptomics data.\n\n\n\n\nRna multisample\n\n\nWorkflows/rna\n\n\nProcessing unimodal multi-sample RNA transcriptomics data.\n\n\n\n\nRna singlesample\n\n\nMultiomics\n\n\nProcessing unimodal single-sample RNA transcriptomics data.\n\n\n\n\nRna singlesample\n\n\nWorkflows/rna\n\n\nProcessing unimodal single-sample RNA transcriptomics data.\n\n\n\n\nScanorama leiden\n\n\nIntegration/scanorama leiden\n\n\nRun scanorama integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScanorama leiden\n\n\nMultiomics/integration\n\n\nRun scanorama integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScanorama leiden\n\n\nWorkflows/integration\n\n\nRun scanorama integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScvi\n\n\nIntegration/scvi\n\n\nRun scvi integration followed by neighbour calculations and run umap on the result.\n\n\n\n\nScvi leiden\n\n\nMultiomics/integration\n\n\nRun scvi integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScvi leiden\n\n\nWorkflows/integration\n\n\nRun scvi integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nSplit modalities\n\n\nWorkflows/multiomics\n\n\nA pipeline to split a multimodal mudata files into several unimodal mudata files.\n\n\n\n\nTotalvi leiden\n\n\nMultiomics/integration\n\n\nRun totalVI integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nTotalvi leiden\n\n\nWorkflows/integration\n\n\nRun totalVI integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "components/index.html#workflows",
    "href": "components/index.html#workflows",
    "title": "Components",
    "section": "",
    "text": "Order By\n       Default\n         \n          Name\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nName\n\n\nNamespace\n\n\nDescription\n\n\n\n\n\n\nWorkflows\n\n\n¬†\n\n\n\n\n\n\n\nBD Rhapsody\n\n\nIngestion\n\n\nA generic pipeline for running BD Rhapsody WTA or Targeted mapping, with support for AbSeq, VDJ and/or SMK.\n\n\n\n\nBD Rhapsody\n\n\nWorkflows/ingestion\n\n\nA generic pipeline for running BD Rhapsody WTA or Targeted mapping, with support for AbSeq, VDJ and/or SMK.\n\n\n\n\nBbknn leiden\n\n\nMultiomics/integration\n\n\nRun bbknn followed by leiden clustering and run umap on the result.\n\n\n\n\nBbknn leiden\n\n\nWorkflows/integration\n\n\nRun bbknn followed by leiden clustering and run umap on the result.\n\n\n\n\nCell Ranger mapping\n\n\nIngestion\n\n\nA pipeline for running Cell Ranger mapping.\n\n\n\n\nCell Ranger mapping\n\n\nWorkflows/ingestion\n\n\nA pipeline for running Cell Ranger mapping.\n\n\n\n\nCell Ranger multi\n\n\nIngestion\n\n\nA pipeline for running Cell Ranger multi.\n\n\n\n\nCell Ranger multi\n\n\nWorkflows/ingestion\n\n\nA pipeline for running Cell Ranger multi.\n\n\n\n\nCell Ranger post-processing\n\n\nIngestion\n\n\nPost-processing Cell Ranger datasets.\n\n\n\n\nCell Ranger post-processing\n\n\nWorkflows/ingestion\n\n\nPost-processing Cell Ranger datasets.\n\n\n\n\nConversion\n\n\nIngestion\n\n\nA pipeline to convert different file formats to .h5mu.\n\n\n\n\nConversion\n\n\nWorkflows/ingestion\n\n\nA pipeline to convert different file formats to .h5mu.\n\n\n\n\nDemux\n\n\nIngestion\n\n\nA generic pipeline for running bcl2fastq, bcl-convert or Cell Ranger mkfastq.\n\n\n\n\nDemux\n\n\nWorkflows/ingestion\n\n\nA generic pipeline for running bcl2fastq, bcl-convert or Cell Ranger mkfastq.\n\n\n\n\nDimensionality reduction\n\n\nWorkflows/multiomics\n\n\nRun calculations that output information required for most integration methods: PCA, nearest neighbour and UMAP.\n\n\n\n\nFull pipeline\n\n\nMultiomics\n\n\nA pipeline to analyse multiple multiomics samples.\n\n\n\n\nGdo singlesample\n\n\nWorkflows/gdo\n\n\nProcessing unimodal single-sample guide-derived oligonucleotide (GDO) data.\n\n\n\n\nHarmony leiden\n\n\nIntegration/common\n\n\nRun harmony integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nHarmony leiden\n\n\nMultiomics/integration\n\n\nRun harmony integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nHarmony leiden\n\n\nWorkflows/integration\n\n\nRun harmony integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nInitialize integration\n\n\nIntegration/initialize integration\n\n\nRun calculations that output information required for most integration methods: PCA, nearest neighbour and UMAP.\n\n\n\n\nInitialize integration\n\n\nMultiomics/integration\n\n\nRun calculations that output information required for most integration methods: PCA, nearest neighbour and UMAP.\n\n\n\n\nIntegration\n\n\nMultiomics\n\n\nA pipeline for demultiplexing multimodal multi-sample RNA transcriptomics data.\n\n\n\n\nLeiden scvi\n\n\nMultiomics/integration\n\n\nRun scvi integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nMake reference\n\n\nIngestion\n\n\nBuild a transcriptomics reference into one of many formats\n\n\n\n\nMake reference\n\n\nWorkflows/ingestion\n\n\nBuild a transcriptomics reference into one of many formats\n\n\n\n\nMultisample\n\n\nMultiomics\n\n\nThis workflow serves as an entrypoint into the ‚Äòfull_pipeline‚Äô in order to re-run the multisample processing and the integration setup.\n\n\n\n\nProcess batches\n\n\nWorkflows/multiomics\n\n\nThis workflow serves as an entrypoint into the ‚Äòfull_pipeline‚Äô in order to re-run the multisample processing and the integration setup.\n\n\n\n\nProcess samples\n\n\nWorkflows/multiomics\n\n\nA pipeline to analyse multiple multiomics samples.\n\n\n\n\nProt multisample\n\n\nMultiomics\n\n\nProcessing unimodal multi-sample ADT data.\n\n\n\n\nProt multisample\n\n\nWorkflows/prot\n\n\nProcessing unimodal multi-sample ADT data.\n\n\n\n\nProt singlesample\n\n\nMultiomics\n\n\nProcessing unimodal single-sample CITE-seq data.\n\n\n\n\nProt singlesample\n\n\nWorkflows/prot\n\n\nProcessing unimodal single-sample CITE-seq data.\n\n\n\n\nQc\n\n\nQc\n\n\nA pipeline to add basic qc statistics to a MuData\n\n\n\n\nQc\n\n\nWorkflows/qc\n\n\nA pipeline to add basic qc statistics to a MuData\n\n\n\n\nRna multisample\n\n\nMultiomics\n\n\nProcessing unimodal multi-sample RNA transcriptomics data.\n\n\n\n\nRna multisample\n\n\nWorkflows/rna\n\n\nProcessing unimodal multi-sample RNA transcriptomics data.\n\n\n\n\nRna singlesample\n\n\nMultiomics\n\n\nProcessing unimodal single-sample RNA transcriptomics data.\n\n\n\n\nRna singlesample\n\n\nWorkflows/rna\n\n\nProcessing unimodal single-sample RNA transcriptomics data.\n\n\n\n\nScanorama leiden\n\n\nIntegration/scanorama leiden\n\n\nRun scanorama integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScanorama leiden\n\n\nMultiomics/integration\n\n\nRun scanorama integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScanorama leiden\n\n\nWorkflows/integration\n\n\nRun scanorama integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScvi\n\n\nIntegration/scvi\n\n\nRun scvi integration followed by neighbour calculations and run umap on the result.\n\n\n\n\nScvi leiden\n\n\nMultiomics/integration\n\n\nRun scvi integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScvi leiden\n\n\nWorkflows/integration\n\n\nRun scvi integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nSplit modalities\n\n\nWorkflows/multiomics\n\n\nA pipeline to split a multimodal mudata files into several unimodal mudata files.\n\n\n\n\nTotalvi leiden\n\n\nMultiomics/integration\n\n\nRun totalVI integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nTotalvi leiden\n\n\nWorkflows/integration\n\n\nRun totalVI integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "components/index.html#modules",
    "href": "components/index.html#modules",
    "title": "Components",
    "section": "Modules",
    "text": "Modules\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Name\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nName\n\n\nNamespace\n\n\nDescription\n\n\n\n\n\n\nModules\n\n\n¬†\n\n\n\n\n\n\n\nAdd id\n\n\nMetadata\n\n\nAdd id of .obs.\n\n\n\n\nBD Rhapsody\n\n\nMapping\n\n\nA wrapper for the BD Rhapsody Analysis CWL v1.10.1 pipeline\n\n\n\n\nBbknn\n\n\nNeighbors\n\n\nBBKNN network generation\n\n\n\n\nBcftools\n\n\nGenetic demux\n\n\nFilter the variants called by freebayes or cellSNP\n\n\n\n\nBcl convert\n\n\nDemux\n\n\nConvert bcl files to fastq files using bcl-convert.\n\n\n\n\nBcl2fastq\n\n\nDemux\n\n\nConvert bcl files to fastq files using bcl2fastq\n\n\n\n\nBuild bdrhap reference\n\n\nReference\n\n\nCompile a reference into a STAR index compatible with the BD Rhapsody pipeline.\n\n\n\n\nBuild cellranger reference\n\n\nReference\n\n\nBuild a Cell Ranger-compatible reference folder from user-supplied genome FASTA and gene GTF files.\n\n\n\n\nCalculate qc metrics\n\n\nQc\n\n\nAdd basic quality control metrics to an .h5mu file.\n\n\n\n\nCellbender remove background\n\n\nCorrection\n\n\nEliminating technical artifacts from high-throughput single-cell RNA sequencing data.\n\n\n\n\nCellbender remove background v0 2\n\n\nCorrection\n\n\nEliminating technical artifacts from high-throughput single-cell RNA sequencing data.\n\n\n\n\nCellranger count\n\n\nMapping\n\n\nAlign fastq files using Cell Ranger count.\n\n\n\n\nCellranger count split\n\n\nMapping\n\n\nSplit 10x Cell Ranger output directory into separate output fields.\n\n\n\n\nCellranger mkfastq\n\n\nDemux\n\n\nDemultiplex raw sequencing data\n\n\n\n\nCellranger multi\n\n\nMapping\n\n\nAlign fastq files using Cell Ranger multi.\n\n\n\n\nCellsnp\n\n\nGenetic demux\n\n\ncellSNP aims to pileup the expressed alleles in single-cell or bulk RNA-seq data.\n\n\n\n\nCellxgene census\n\n\nQuery\n\n\nQuery cells from a CellxGene Census or custom TileDBSoma object.\n\n\n\n\nClr\n\n\nTransform\n\n\nPerform CLR normalization on CITE-seq data (Stoeckius et al., 2017)\n\n\n\n\nCompress h5mu\n\n\nCompression\n\n\nCompress a MuData file.\n\n\n\n\nConcat\n\n\nDataflow\n\n\nConcatenates several uni-modal samples in .h5mu files into a single file\n\n\n\n\nConcatenate h5mu\n\n\nDataflow\n\n\nConcatenates several uni-modal samples in .h5mu files into a single file\n\n\n\n\nDelete layer\n\n\nTransform\n\n\nDelete an anndata layer from one or more modalities\n\n\n\n\nDelimit fraction\n\n\nFilter\n\n\nTurns a column containing values between 0 and 1 into a boolean column based on thresholds\n\n\n\n\nDemuxlet\n\n\nGenetic demux\n\n\nDemuxlet is a software tool to deconvolute sample identity and identify multiplets when multiple samples are pooled by barcoded single cell sequencing.\n\n\n\n\nDo filter\n\n\nFilter\n\n\nRemove observations and variables based on specified .obs and .var columns\n\n\n\n\nDownload file\n\n\nDownload\n\n\nDownload a file\n\n\n\n\nDsc pileup\n\n\nGenetic demux\n\n\nDsc-pileup is a software tool to pileup reads and corresponding base quality for each overlapping SNPs and each barcode.\n\n\n\n\nFastqc\n\n\nQc\n\n\nFastqc component, please see https://www.bioinformatics.babraham.ac.uk/projects/fastqc/.\n\n\n\n\nFilter 10xh5\n\n\nProcess 10xh5\n\n\nFilter a 10x h5 dataset\n\n\n\n\nFilter with counts\n\n\nFilter\n\n\nFilter scRNA-seq data based on the primary QC metrics.\n\n\n\n\nFilter with hvg\n\n\nFilter\n\n\nAnnotate highly variable genes [Satija15] [Zheng17] [Stuart19].\n\n\n\n\nFilter with scrublet\n\n\nFilter\n\n\nDoublet detection using the Scrublet method (Wolock, Lopez and Klein, 2019).\n\n\n\n\nFind neighbors\n\n\nNeighbors\n\n\nCompute a neighborhood graph of observations [McInnes18].\n\n\n\n\nFreebayes\n\n\nGenetic demux\n\n\nFreebayes is a Bayesian genetic variant detector designed to find small polymorphisms, specifically SNPs\n\n\n\n\nFreemuxlet\n\n\nGenetic demux\n\n\nFreemuxlet is a software tool to deconvolute sample identity and identify multiplets when multiple samples are pooled by barcoded single cell sequencing.\n\n\n\n\nFrom 10xh5 to h5mu\n\n\nConvert\n\n\nConverts a 10x h5 into an h5mu file\n\n\n\n\nFrom 10xmtx to h5mu\n\n\nConvert\n\n\nConverts a 10x mtx into an h5mu file\n\n\n\n\nFrom bd to 10x molecular barcode tags\n\n\nConvert\n\n\nConvert the molecular barcode sequence SAM tag from BD format (MA) to 10X format (UB)\n\n\n\n\nFrom bdrhap to h5mu\n\n\nConvert\n\n\nConvert the output of a BD Rhapsody WTA pipeline to a MuData h5 file\n\n\n\n\nFrom cellranger multi to h5mu\n\n\nConvert\n\n\nConverts the output from cellranger multi to a single .h5mu file.\n\n\n\n\nFrom h5ad to h5mu\n\n\nConvert\n\n\nConverts a single layer h5ad file into a single MuData object\n\n\n\n\nFrom h5mu to h5ad\n\n\nConvert\n\n\nConverts a h5mu file into a h5ad file\n\n\n\n\nFrom h5mu to seurat\n\n\nConvert\n\n\nConverts an h5mu file into a Seurat file.\n\n\n\n\nGrep annotation column\n\n\nMetadata\n\n\nPerform a regex lookup on a column from the annotation matrices .obs or .var.\n\n\n\n\nHarmonypy\n\n\nIntegrate\n\n\nPerforms Harmony integration based as described in https://github.com/immunogenomics/harmony.\n\n\n\n\nHighly variable features scanpy\n\n\nFeature annotation\n\n\nAnnotate highly variable features [Satija15] [Zheng17] [Stuart19].\n\n\n\n\nHtseq count\n\n\nMapping\n\n\nQuantify gene expression for subsequent testing for differential expression.\n\n\n\n\nHtseq count to h5mu\n\n\nMapping\n\n\nConvert the htseq table to a h5mu\n\n\n\n\nIntersect obs\n\n\nFilter\n\n\nCreate an intersection between two or more modalities.\n\n\n\n\nJoin csv\n\n\nMetadata\n\n\nJoin a csv containing metadata to the .obs or .var field of a mudata file.\n\n\n\n\nJoin uns to obs\n\n\nMetadata\n\n\nJoin a data frame of length 1 (1 row index value) in .uns containing metadata to the .obs of a mudata file.\n\n\n\n\nKnn\n\n\nLabels transfer\n\n\nPerforms label transfer from reference to query using KNN classifier\n\n\n\n\nLeiden\n\n\nCluster\n\n\nCluster cells using the [Leiden algorithm] [Traag18] implemented in the [Scanpy framework] [Wolf18].\n\n\n\n\nLianapy\n\n\nInterpret\n\n\nPerforms LIANA integration based as described in https://github.com/saezlab/liana-py\n\n\n\n\nLog1p\n\n\nTransform\n\n\nLogarithmize the data matrix.\n\n\n\n\nMake params\n\n\nFiles\n\n\nLooks for files in a directory and turn it in a params file.\n\n\n\n\nMake reference\n\n\nReference\n\n\nPreprocess and build a transcriptome reference.\n\n\n\n\nMerge\n\n\nDataflow\n\n\nCombine one or more single-modality .h5mu files together into one .h5mu file\n\n\n\n\nMermaid\n\n\nReport\n\n\nGenerates a network from mermaid code\n\n\n\n\nMove layer\n\n\nTransform\n\n\nMove a data matrix stored at the .layers or .X attributes in a MuData object to another layer.\n\n\n\n\nMove obsm to obs\n\n\nMetadata\n\n\nMove a matrix from .obsm to .obs.\n\n\n\n\nMulti star\n\n\nMapping\n\n\nAlign fastq files using STAR.\n\n\n\n\nMulti star to h5mu\n\n\nMapping\n\n\nConvert the output of multi_star to a h5mu\n\n\n\n\nMultiqc\n\n\nQc\n\n\nMultiQC aggregates results from bioinformatics analyses across many samples into a single report.\n\n\n\n\nNormalize total\n\n\nTransform\n\n\nNormalize counts per cell.\n\n\n\n\nPca\n\n\nDimred\n\n\nComputes PCA coordinates, loadings and variance decomposition.\n\n\n\n\nPopv\n\n\nAnnotate\n\n\nPerforms popular major vote cell typing on single cell sequence data using multiple algorithms.\n\n\n\n\nPublish\n\n\nTransfer\n\n\nPublish an artifact and optionally rename with parameters\n\n\n\n\nRegress out\n\n\nTransform\n\n\nRegress out (mostly) unwanted sources of variation.\n\n\n\n\nRemove modality\n\n\nFilter\n\n\nRemove a modality from a .h5mu file\n\n\n\n\nSamtools\n\n\nGenetic demux\n\n\nFilter the BAM according to the instruction of scSplit via Samtools.\n\n\n\n\nSamtools sort\n\n\nMapping\n\n\nSort and (optionally) index alignments.\n\n\n\n\nScale\n\n\nTransform\n\n\nScale data to unit variance and zero mean\n\n\n\n\nScanorama\n\n\nIntegrate\n\n\nUse Scanorama to integrate different experiments\n\n\n\n\nScarches\n\n\nIntegrate\n\n\nPerforms reference mapping with scArches\n\n\n\n\nScsplit\n\n\nGenetic demux\n\n\nscsplit is a genotype-free demultiplexing methode of pooled single-cell RNA-seq, using a hidden state model for identifying genetically distinct samples within a mixed population.\n\n\n\n\nScvelo\n\n\nVelocity\n\n\n\n\n\n\n\nScvi\n\n\nIntegrate\n\n\nPerforms scvi integration as done in the human lung cell atlas https://github.com/LungCellAtlas/HLCA\n\n\n\n\nSouporcell\n\n\nGenetic demux\n\n\nsouporcell is a method for clustering mixed-genotype scRNAseq experiments by individual.\n\n\n\n\nSplit modalities\n\n\nDataflow\n\n\nSplit the modalities from a single .h5mu multimodal sample into seperate .h5mu files.\n\n\n\n\nStar align\n\n\nMapping\n\n\nAlign fastq files using STAR.\n\n\n\n\nStar align v273a\n\n\nMapping\n\n\nAlign fastq files using STAR.\n\n\n\n\nStar build reference\n\n\nMapping\n\n\nCreate a reference for STAR from a set of fasta files.\n\n\n\n\nSubset h5mu\n\n\nFilter\n\n\nCreate a subset of a mudata file by selecting the first number of observations\n\n\n\n\nSync test resources\n\n\nDownload\n\n\nSynchronise the test resources from s3://openpipelines-data to resources_test\n\n\n\n\nTotalvi\n\n\nIntegrate\n\n\nPerforms mapping to the reference by totalvi model: https://docs.scvi-tools.org/en/stable/tutorials/notebooks/scarches_scvi_tools.html#Reference-mapping-with-TOTALVI\n\n\n\n\nTsne\n\n\nDimred\n\n\nt-SNE (t-Distributed Stochastic Neighbor Embedding) is a dimensionality reduction technique used to visualize high-dimensional data in a low-dimensional space, revealing patterns and clusters by preserving local data similarities\n\n\n\n\nUmap\n\n\nDimred\n\n\nUMAP (Uniform Manifold Approximation and Projection) is a manifold learning technique suitable for visualizing high-dimensional data.\n\n\n\n\nVelocyto\n\n\nVelocity\n\n\nRuns the velocity analysis on a BAM file, outputting a loom file.\n\n\n\n\nVelocyto to h5mu\n\n\nConvert\n\n\nConvert a velocyto loom file to a h5mu file.\n\n\n\n\nVireo\n\n\nGenetic demux\n\n\nVireo is primarily designed for demultiplexing cells into donors by modelling of expressed alleles.\n\n\n\n\nXgboost\n\n\nLabels transfer\n\n\nPerforms label transfer from reference to query using XGBoost classifier\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "components/workflows/multiomics/prot_singlesample.html",
    "href": "components/workflows/multiomics/prot_singlesample.html",
    "title": "Prot singlesample",
    "section": "",
    "text": "ID: prot_singlesample\nNamespace: multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/prot_singlesample.html#example-commands",
    "href": "components/workflows/multiomics/prot_singlesample.html#example-commands",
    "title": "Prot singlesample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/multiomics/prot_singlesample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\n\n# Filtering options\n# min_counts: 200\n# max_counts: 5000000\n# min_proteins_per_cell: 200\n# max_proteins_per_cell: 1500000\n# min_cells_per_protein: 3\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/prot_singlesample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/prot_singlesample.html#argument-groups",
    "href": "components/workflows/multiomics/prot_singlesample.html#argument-groups",
    "title": "Prot singlesample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nFiltering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--min_proteins_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--max_proteins_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--min_cells_per_protein\nMinimum of non-zero values per gene.\ninteger, example: 3"
  },
  {
    "objectID": "components/workflows/multiomics/prot_singlesample.html#authors",
    "href": "components/workflows/multiomics/prot_singlesample.html#authors",
    "title": "Prot singlesample",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (author, maintainer)\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/prot_singlesample.html#visualisation",
    "href": "components/workflows/multiomics/prot_singlesample.html#visualisation",
    "title": "Prot singlesample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v3(toSortedList)\n    v5(flatMap)\n    v10(filter)\n    v16(grep_annotation_column)\n    v18(join)\n    v22(mix)\n    v21(filter)\n    v28(calculate_qc_metrics)\n    v30(join)\n    v38(publish)\n    v40(join)\n    v49(filter_with_counts)\n    v51(join)\n    v59(do_filter)\n    v61(join)\n    v65(toSortedList)\n    v67(Output)\n    v21--&gt;v22\n    v0--&gt;v3\n    v3--&gt;v5\n    v5--&gt;v10\n    v5--&gt;v21\n    v10--&gt;v18\n    v10--&gt;v16\n    v16--&gt;v18\n    v18--&gt;v22\n    v22--&gt;v30\n    v22--&gt;v28\n    v28--&gt;v30\n    v30--&gt;v40\n    v30--&gt;v38\n    v38--&gt;v40\n    v40--&gt;v51\n    v40--&gt;v49\n    v49--&gt;v51\n    v51--&gt;v61\n    v51--&gt;v59\n    v59--&gt;v61\n    v61--&gt;v65\n    v65--&gt;v67"
  },
  {
    "objectID": "components/workflows/multiomics/integration/totalvi_leiden.html",
    "href": "components/workflows/multiomics/integration/totalvi_leiden.html",
    "title": "Totalvi leiden",
    "section": "",
    "text": "ID: totalvi_leiden\nNamespace: multiomics/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration/totalvi_leiden.html#example-commands",
    "href": "components/workflows/multiomics/integration/totalvi_leiden.html#example-commands",
    "title": "Totalvi leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/multiomics/integration/totalvi_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\nprot_modality: \"prot\"\nreference: # please fill in - example: \"path/to/file\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# reference_model_path: \"$id.$key.reference_model_path.reference_model_path\"\n# query_model_path: \"$id.$key.query_model_path.query_model_path\"\n\n# General TotalVI Options\nobs_batch: \"sample_id\"\nmax_epochs: 400\nmax_query_epochs: 200\nweight_decay: 0.0\nforce_retrain: false\n# var_input: \"foo\"\n\n# TotalVI integration options RNA\nrna_reference_modality: \"rna\"\nrna_obsm_output: \"X_totalvi\"\n\n# TotalVI integration options ADT\nprot_reference_modality: \"prot\"\nprot_obsm_output: \"X_totalvi\"\n\n# Neighbour calculation RNA\nrna_uns_neighbors: \"totalvi_integration_neighbors\"\nrna_obsp_neighbor_distances: \"totalvi_integration_distances\"\nrna_obsp_neighbor_connectivities: \"totalvi_integration_connectivities\"\n\n# Neighbour calculation ADT\nprot_uns_neighbors: \"totalvi_integration_neighbors\"\nprot_obsp_neighbor_distances: \"totalvi_integration_distances\"\nprot_obsp_neighbor_connectivities: \"totalvi_integration_connectivities\"\n\n# Clustering options RNA\nrna_obs_cluster: \"totalvi_integration_leiden\"\nrna_leiden_resolution: [1]\n\n# Clustering options ADT\nprot_obs_cluster: \"totalvi_integration_leiden\"\nprot_leiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_totalvi_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/integration/totalvi_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration/totalvi_leiden.html#argument-groups",
    "href": "components/workflows/multiomics/integration/totalvi_leiden.html#argument-groups",
    "title": "Totalvi leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--prot_modality\nWhich modality to process.\nstring, default: \"prot\"\n\n\n--reference\nInput h5mu file with reference data to train the TOTALVI model.\nfile, required\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n--reference_model_path\nDirectory with the reference model. If not exists, trained model will be saved there\nfile, default: \"totalvi_model_reference\"\n\n\n--query_model_path\nDirectory, where the query model will be saved\nfile, default: \"totalvi_model_query\"\n\n\n\n\n\nGeneral TotalVI Options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\n.Obs column name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--max_epochs\nNumber of passes through the dataset\ninteger, default: 400\n\n\n--max_query_epochs\nNumber of passes through the dataset, when fine-tuning model for query\ninteger, default: 200\n\n\n--weight_decay\nWeight decay, when fine-tuning model for query\ndouble, default: 0\n\n\n--force_retrain\nIf true, retrain the model and save it to reference_model_path\nboolean_true\n\n\n--var_input\nBoolean .var column to subset data with (e.g.¬†containing highly variable genes). By default, do not subset genes.\nstring\n\n\n\n\n\nTotalVI integration options RNA\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_reference_modality\n\nstring, default: \"rna\"\n\n\n--rna_obsm_output\nIn which .obsm slot to store the normalized RNA from TOTALVI.\nstring, default: \"X_totalvi\"\n\n\n\n\n\nTotalVI integration options ADT\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_reference_modality\nName of the modality containing proteins in the reference\nstring, default: \"prot\"\n\n\n--prot_obsm_output\nIn which .obsm slot to store the normalized protein data from TOTALVI.\nstring, default: \"X_totalvi\"\n\n\n\n\n\nNeighbour calculation RNA\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"totalvi_integration_neighbors\"\n\n\n--rna_obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_distances\"\n\n\n--rna_obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_connectivities\"\n\n\n\n\n\nNeighbour calculation ADT\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"totalvi_integration_neighbors\"\n\n\n--prot_obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_distances\"\n\n\n--prot_obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_connectivities\"\n\n\n\n\n\nClustering options RNA\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‚Äò‚Äìobs_cluster‚Äô suffixed with an underscore and one of the resolutions resolutions specified in ‚Äò‚Äìleiden_resolution‚Äô.\nstring, default: \"totalvi_integration_leiden\"\n\n\n--rna_leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \":\"\n\n\n\n\n\nClustering options ADT\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‚Äò‚Äìobs_cluster‚Äô suffixed with an underscore and one of the resolutions resolutions specified in ‚Äò‚Äìleiden_resolution‚Äô.\nstring, default: \"totalvi_integration_leiden\"\n\n\n--prot_leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \":\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_totalvi_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration/totalvi_leiden.html#authors",
    "href": "components/workflows/multiomics/integration/totalvi_leiden.html#authors",
    "title": "Totalvi leiden",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration/totalvi_leiden.html#visualisation",
    "href": "components/workflows/multiomics/integration/totalvi_leiden.html#visualisation",
    "title": "Totalvi leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v3(toSortedList)\n    v5(flatMap)\n    v12(totalvi)\n    v14(join)\n    v23(find_neighbors)\n    v25(join)\n    v28(filter)\n    v34(leiden)\n    v36(join)\n    v44(move_obsm_to_obs)\n    v46(join)\n    v50(mix)\n    v49(filter)\n    v56(umap)\n    v58(join)\n    v67(test_wf:run_wf:test_wf:run_wf:neighbors_leiden_umap:find_neighbors:find_neighbors_process1)\n    v69(join)\n    v72(filter)\n    v78(test_wf:run_wf:test_wf:run_wf:neighbors_leiden_umap:leiden:leiden_process1)\n    v80(join)\n    v88(test_wf:run_wf:test_wf:run_wf:neighbors_leiden_umap:move_obsm_to_obs:move_obsm_to_obs_process1)\n    v90(join)\n    v94(mix)\n    v93(filter)\n    v100(test_wf:run_wf:test_wf:run_wf:neighbors_leiden_umap:umap:umap_process1)\n    v102(join)\n    v110(publish)\n    v112(join)\n    v118(Output)\n    v49--&gt;v50\n    v93--&gt;v94\n    v0--&gt;v3\n    v3--&gt;v5\n    v5--&gt;v14\n    v5--&gt;v12\n    v12--&gt;v14\n    v14--&gt;v25\n    v14--&gt;v23\n    v23--&gt;v25\n    v25--&gt;v28\n    v25--&gt;v49\n    v28--&gt;v36\n    v28--&gt;v34\n    v34--&gt;v36\n    v36--&gt;v46\n    v36--&gt;v44\n    v44--&gt;v46\n    v46--&gt;v50\n    v50--&gt;v58\n    v50--&gt;v56\n    v56--&gt;v58\n    v58--&gt;v69\n    v58--&gt;v67\n    v67--&gt;v69\n    v69--&gt;v72\n    v69--&gt;v93\n    v72--&gt;v80\n    v72--&gt;v78\n    v78--&gt;v80\n    v80--&gt;v90\n    v80--&gt;v88\n    v88--&gt;v90\n    v90--&gt;v94\n    v94--&gt;v102\n    v94--&gt;v100\n    v100--&gt;v102\n    v102--&gt;v112\n    v102--&gt;v110\n    v110--&gt;v112\n    v112--&gt;v118"
  },
  {
    "objectID": "components/workflows/multiomics/integration/bbknn_leiden.html",
    "href": "components/workflows/multiomics/integration/bbknn_leiden.html",
    "title": "Bbknn leiden",
    "section": "",
    "text": "ID: bbknn_leiden\nNamespace: multiomics/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration/bbknn_leiden.html#example-commands",
    "href": "components/workflows/multiomics/integration/bbknn_leiden.html#example-commands",
    "title": "Bbknn leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/multiomics/integration/bbknn_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Bbknn\nobsm_input: \"X_pca\"\nobs_batch: \"sample_id\"\nuns_output: \"bbknn_integration_neighbors\"\nobsp_distances: \"bbknn_integration_distances\"\nobsp_connectivities: \"bbknn_integration_connectivities\"\nn_neighbors_within_batch: 3\nn_pcs: 50\n# n_trim: 123\n\n# Clustering options\nobs_cluster: \"bbknn_integration_leiden\"\nleiden_resolution: [1]\n\n# UMAP options\nobsm_umap: \"X_leiden_bbknn_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/integration/bbknn_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration/bbknn_leiden.html#argument-groups",
    "href": "components/workflows/multiomics/integration/bbknn_leiden.html#argument-groups",
    "title": "Bbknn leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nBbknn\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_input\nThe dimensionality reduction in .obsm to use for neighbour detection. Defaults to X_pca.\nstring, default: \"X_pca\"\n\n\n--obs_batch\n.obs column name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--uns_output\nMandatory .uns slot to store various neighbor output objects.\nstring, default: \"bbknn_integration_neighbors\"\n\n\n--obsp_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"bbknn_integration_distances\"\n\n\n--obsp_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"bbknn_integration_connectivities\"\n\n\n--n_neighbors_within_batch\nHow many top neighbours to report for each batch; total number of neighbours in the initial k-nearest-neighbours computation will be this number times the number of batches.\ninteger, default: 3\n\n\n--n_pcs\nHow many dimensions (in case of PCA, principal components) to use in the analysis.\ninteger, default: 50\n\n\n--n_trim\nTrim the neighbours of each cell to these many top connectivities. May help with population independence and improve the tidiness of clustering. The lower the value the more independent the individual populations, at the cost of more conserved batch effect. If None (default), sets the parameter value automatically to 10 times neighbors_within_batch times the number of batches. Set to 0 to skip.\ninteger\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‚Äò‚Äìobs_cluster‚Äô suffixed with an underscore and one of the resolutions resolutions specified in ‚Äò‚Äìleiden_resolution‚Äô.\nstring, default: \"bbknn_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \":\"\n\n\n\n\n\nUMAP options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_bbknn_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration/bbknn_leiden.html#authors",
    "href": "components/workflows/multiomics/integration/bbknn_leiden.html#authors",
    "title": "Bbknn leiden",
    "section": "Authors",
    "text": "Authors\n\nMauro Saporita   (author)\nPovilas Gibas   (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration/bbknn_leiden.html#visualisation",
    "href": "components/workflows/multiomics/integration/bbknn_leiden.html#visualisation",
    "title": "Bbknn leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v10(bbknn)\n    v12(join)\n    v15(filter)\n    v21(leiden)\n    v23(join)\n    v31(move_obsm_to_obs)\n    v33(join)\n    v37(mix)\n    v36(filter)\n    v43(umap)\n    v45(join)\n    v51(Output)\n    v36--&gt;v37\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v12\n    v4--&gt;v10\n    v10--&gt;v12\n    v12--&gt;v15\n    v12--&gt;v36\n    v15--&gt;v23\n    v15--&gt;v21\n    v21--&gt;v23\n    v23--&gt;v33\n    v23--&gt;v31\n    v31--&gt;v33\n    v33--&gt;v37\n    v37--&gt;v45\n    v37--&gt;v43\n    v43--&gt;v45\n    v45--&gt;v51"
  },
  {
    "objectID": "components/workflows/multiomics/integration/leiden_scvi.html",
    "href": "components/workflows/multiomics/integration/leiden_scvi.html",
    "title": "Leiden scvi",
    "section": "",
    "text": "ID: leiden_scvi\nNamespace: multiomics/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration/leiden_scvi.html#example-commands",
    "href": "components/workflows/multiomics/integration/leiden_scvi.html#example-commands",
    "title": "Leiden scvi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.10.0 -latest \\\n  -main-script ./workflows/multiomics/integration/scvi_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_model: \"$id.$key.output_model.output_model\"\n\n# Neighbour calculation\nuns_neighbors: \"scvi_integration_neighbors\"\nobsp_neighbor_distances: \"scvi_integration_distances\"\nobsp_neighbor_connectivities: \"scvi_integration_connectivities\"\n\n# Scvi integration options\nobs_batch: # please fill in - example: \"foo\"\nobsm_output: \"X_scvi_integrated\"\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n# max_epochs: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30\n\n# Clustering options\nobs_cluster: \"scvi_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_scvi_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.10.0 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/integration/scvi_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration/leiden_scvi.html#argument-groups",
    "href": "components/workflows/multiomics/integration/leiden_scvi.html#argument-groups",
    "title": "Leiden scvi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n--output_model\nFolder where the state of the trained model will be saved to.\nfile, required, example: \"output_dir\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"scvi_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"scvi_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"scvi_integration_connectivities\"\n\n\n\n\n\nScvi integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, required\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_scvi_integrated\"\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e.¬†an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‚Äò‚Äìobs_cluster‚Äô suffixed with an underscore and one of the resolutions resolutions specified in ‚Äò‚Äìleiden_resolution‚Äô.\nstring, default: \"scvi_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \":\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_scvi_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration/leiden_scvi.html#authors",
    "href": "components/workflows/multiomics/integration/leiden_scvi.html#authors",
    "title": "Leiden scvi",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration/leiden_scvi.html#visualisation",
    "href": "components/workflows/multiomics/integration/leiden_scvi.html#visualisation",
    "title": "Leiden scvi",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    p0(Input)\n    p3(toSortedList)\n    p5(flatMap)\n    p12(scvi)\n    p14(join)\n    p23(find_neighbors)\n    p25(join)\n    p33(leiden)\n    p35(join)\n    p43(umap)\n    p45(join)\n    p53(move_obsm_to_obs)\n    p55(join)\n    p62(Output)\n    p0--&gt;p3\n    p3--&gt;p5\n    p5--&gt;p14\n    p5--&gt;p12\n    p12--&gt;p14\n    p14--&gt;p25\n    p14--&gt;p23\n    p23--&gt;p25\n    p25--&gt;p35\n    p25--&gt;p33\n    p33--&gt;p35\n    p35--&gt;p45\n    p35--&gt;p43\n    p43--&gt;p45\n    p45--&gt;p55\n    p45--&gt;p53\n    p53--&gt;p55\n    p55--&gt;p62"
  },
  {
    "objectID": "components/workflows/multiomics/integration/initialize_integration.html",
    "href": "components/workflows/multiomics/integration/initialize_integration.html",
    "title": "Initialize integration",
    "section": "",
    "text": "ID: initialize_integration\nNamespace: multiomics/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration/initialize_integration.html#example-commands",
    "href": "components/workflows/multiomics/integration/initialize_integration.html#example-commands",
    "title": "Initialize integration",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/multiomics/integration/initialize_integration/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# PCA options\nobsm_pca: \"X_pca\"\n# var_pca_feature_selection: \"foo\"\npca_overwrite: false\n\n# Neighbour calculation\nuns_neighbors: \"neighbors\"\nobsp_neighbor_distances: \"distances\"\nobsp_neighbor_connectivities: \"connectivities\"\n\n# Umap options\nobsm_umap: \"X_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/integration/initialize_integration/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration/initialize_integration.html#argument-groups",
    "href": "components/workflows/multiomics/integration/initialize_integration.html#argument-groups",
    "title": "Initialize integration",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_pca\nIn which .obsm slot to store the resulting PCA embedding.\nstring, default: \"X_pca\"\n\n\n--var_pca_feature_selection\nColumn name in .var matrix that will be used to select which genes to run the PCA on.\nstring\n\n\n--pca_overwrite\nAllow overwriting slots for PCA output.\nboolean_true\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"connectivities\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration/initialize_integration.html#authors",
    "href": "components/workflows/multiomics/integration/initialize_integration.html#authors",
    "title": "Initialize integration",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration/initialize_integration.html#visualisation",
    "href": "components/workflows/multiomics/integration/initialize_integration.html#visualisation",
    "title": "Initialize integration",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v11(pca)\n    v13(join)\n    v22(find_neighbors)\n    v24(join)\n    v33(umap)\n    v35(join)\n    v40(toSortedList)\n    v42(Output)\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v13\n    v4--&gt;v11\n    v11--&gt;v13\n    v13--&gt;v24\n    v13--&gt;v22\n    v22--&gt;v24\n    v24--&gt;v35\n    v24--&gt;v33\n    v33--&gt;v35\n    v35--&gt;v40\n    v40--&gt;v42"
  },
  {
    "objectID": "components/workflows/multiomics/integration.html",
    "href": "components/workflows/multiomics/integration.html",
    "title": "Integration",
    "section": "",
    "text": "ID: integration\nNamespace: multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration.html#example-commands",
    "href": "components/workflows/multiomics/integration.html#example-commands",
    "title": "Integration",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.8.0 -latest \\\n  -main-script workflows/multiomics/integration/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# PCA options\nobsm_pca: \"X_pca\"\n# var_pca_feature_selection: \"foo\"\n\n# Harmony integration options\nobsm_integrated: \"X_pca_integrated\"\nobs_covariates: # please fill in - example: [\"batch\", \"sample\"]\nrna_theta: [2]\n\n# Neighbour calculation\nuns_neighbors: \"neighbors\"\nobsp_neighbor_distances: \"distances\"\nobsp_neighbor_connectivities: \"connectivities\"\n\n# Clustering options\nobs_cluster: \"leiden\"\nleiden_resolution: 1\n\n# Umap options\nobsm_umap: \"X_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.8.0 -latest \\\n  -profile docker \\\n  -main-script workflows/multiomics/integration/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration.html#argument-groups",
    "href": "components/workflows/multiomics/integration.html#argument-groups",
    "title": "Integration",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_pca\nIn which .obsm slot to store the resulting PCA embedding.\nstring, default: \"X_pca\"\n\n\n--var_pca_feature_selection\nColumn name in .var matrix that will be used to select which genes to run the PCA on.\nstring\n\n\n\n\n\nHarmony integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_integrated\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_pca_integrated\"\n\n\n--obs_covariates\nThe .obs field(s) that define the covariate(s) to regress out.\nstring, required, example: \"batch\", example: \"sample\"\n\n\n--rna_theta\nDiversity clustering penalty parameter. Specify for each variable in group.by.vars. theta=0 does not encourage any diversity. Larger values of theta result in more diverse clusters.‚Äù\ndouble, default: 2\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"connectivities\"\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nName of the .obs key under which to add the cluster labels.\nstring, default: \"leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\ndouble, default: 1\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration.html#authors",
    "href": "components/workflows/multiomics/integration.html#authors",
    "title": "Integration",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer  (author)\nRobrecht Cannoodt   (author, maintainer)\nDries Schaumont   (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration.html#visualisation",
    "href": "components/workflows/multiomics/integration.html#visualisation",
    "title": "Integration",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    p0(Input)\n    p2(toSortedList)\n    p4(flatMap)\n    p15(join)\n    p13(pca)\n    p18(filter)\n    p29(concat)\n    p19(filter)\n    p27(join)\n    p25(harmonypy)\n    p38(join)\n    p36(find_neighbors)\n    p48(join)\n    p46(leiden)\n    p58(join)\n    p56(umap)\n    p64(Output)\n    p18--&gt;p29\n    p0--&gt;p2\n    p2--&gt;p4\n    p4--&gt;p15\n    p4--&gt;p13\n    p13--&gt;p15\n    p15--&gt;p18\n    p15--&gt;p19\n    p19--&gt;p27\n    p19--&gt;p25\n    p25--&gt;p27\n    p27--&gt;p29\n    p29--&gt;p38\n    p29--&gt;p36\n    p36--&gt;p38\n    p38--&gt;p48\n    p38--&gt;p46\n    p46--&gt;p48\n    p48--&gt;p58\n    p48--&gt;p56\n    p56--&gt;p58\n    p58--&gt;p64"
  },
  {
    "objectID": "components/workflows/multiomics/full_pipeline.html",
    "href": "components/workflows/multiomics/full_pipeline.html",
    "title": "Full pipeline",
    "section": "",
    "text": "ID: full_pipeline\nNamespace: multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/full_pipeline.html#example-commands",
    "href": "components/workflows/multiomics/full_pipeline.html#example-commands",
    "title": "Full pipeline",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/multiomics/full_pipeline/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Sample ID options\nadd_id_to_obs: true\nadd_id_obs_output: \"sample_id\"\nadd_id_make_observation_keys_unique: true\n\n# RNA filtering options\n# rna_min_counts: 200\n# rna_max_counts: 5000000\n# rna_min_genes_per_cell: 200\n# rna_max_genes_per_cell: 1500000\n# rna_min_cells_per_gene: 3\n# rna_min_fraction_mito: 0\n# rna_max_fraction_mito: 0.2\n\n# CITE-seq filtering options\n# prot_min_counts: 3\n# prot_max_counts: 5000000\n# prot_min_proteins_per_cell: 200\n# prot_max_proteins_per_cell: 100000000\n# prot_min_cells_per_protein: 3\n\n# Highly variable gene detection\nfilter_with_hvg_var_output: \"filter_with_hvg\"\nfilter_with_hvg_obs_batch_key: \"sample_id\"\n\n# Mitochondrial Gene Detection\n# var_name_mitochondrial_genes: \"foo\"\n# obs_name_mitochondrial_fraction: \"foo\"\n# var_gene_names: \"gene_symbol\"\nmitochondrial_gene_regex: \"^[mM][tT]-\"\n\n# QC metrics calculation options\n# var_qc_metrics: [\"ercc\", \"highly_variable\"]\ntop_n_vars: [50, 100, 200, 500]\n\n# PCA options\npca_overwrite: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/full_pipeline/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/full_pipeline.html#argument-groups",
    "href": "components/workflows/multiomics/full_pipeline.html#argument-groups",
    "title": "Full pipeline",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"input.h5mu\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nSample ID options\nOptions for adding the id to .obs on the MuData object. Having a sample id present in a requirement of several components for this pipeline.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--add_id_to_obs\nAdd the value passed with ‚Äìid to .obs.\nboolean, default: TRUE\n\n\n--add_id_obs_output\n.Obs column to add the sample IDs to. Required and only used when ‚Äìadd_id_to_obs is set to ‚Äòtrue‚Äô\nstring, default: \"sample_id\"\n\n\n--add_id_make_observation_keys_unique\nJoin the id to the .obs index (.obs_names). Only used when ‚Äìadd_id_to_obs is set to ‚Äòtrue‚Äô.\nboolean, default: TRUE\n\n\n\n\n\nRNA filtering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--rna_max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--rna_min_genes_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--rna_max_genes_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--rna_min_cells_per_gene\nMinimum of non-zero values per gene.\ninteger, example: 3\n\n\n--rna_min_fraction_mito\nMinimum fraction of UMIs that are mitochondrial.\ndouble, example: 0\n\n\n--rna_max_fraction_mito\nMaximum fraction of UMIs that are mitochondrial.\ndouble, example: 0.2\n\n\n\n\n\nCITE-seq filtering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_min_counts\nMinimum number of counts per cell.\ninteger, example: 3\n\n\n--prot_max_counts\nMinimum number of counts per cell.\ninteger, example: 5000000\n\n\n--prot_min_proteins_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--prot_max_proteins_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 100000000\n\n\n--prot_min_cells_per_protein\nMinimum of non-zero values per protein.\ninteger, example: 3\n\n\n\n\n\nHighly variable gene detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--filter_with_hvg_var_output\nIn which .var slot to store a boolean array corresponding to the highly variable genes.\nstring, default: \"filter_with_hvg\"\n\n\n--filter_with_hvg_obs_batch_key\nIf specified, highly-variable genes are selected within each batch separately and merged. This simple process avoids the selection of batch-specific genes and acts as a lightweight batch correction method.\nstring, default: \"sample_id\"\n\n\n\n\n\nMitochondrial Gene Detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_name_mitochondrial_genes\nIn which .var slot to store a boolean array corresponding the mitochondrial genes.\nstring\n\n\n--obs_name_mitochondrial_fraction\nWhen specified, write the fraction of counts originating from mitochondrial genes (based on ‚Äìmitochondrial_gene_regex) to an .obs column with the specified name. Requires ‚Äìvar_name_mitochondrial_genes.\nstring\n\n\n--var_gene_names\n.var column name to be used to detect mitochondrial genes instead of .var_names (default if not set). Gene names matching with the regex value from ‚Äìmitochondrial_gene_regex will be identified as a mitochondrial gene.\nstring, example: \"gene_symbol\"\n\n\n--mitochondrial_gene_regex\nRegex string that identifies mitochondrial genes from ‚Äìvar_gene_names. By default will detect human and mouse mitochondrial genes from a gene symbol.\nstring, default: \"^[mM][tT]-\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‚ÄòTrue‚Äô, compared to the total sum of the values for all genes. Defaults to the combined values specified for ‚Äìvar_name_mitochondrial_genes and ‚Äìfilter_with_hvg_var_output.\nList of string, example: \"ercc,highly_variable\", multiple_sep: \",\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pca_overwrite\nAllow overwriting slots for PCA output.\nboolean_true"
  },
  {
    "objectID": "components/workflows/multiomics/full_pipeline.html#authors",
    "href": "components/workflows/multiomics/full_pipeline.html#authors",
    "title": "Full pipeline",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/multiomics/full_pipeline.html#visualisation",
    "href": "components/workflows/multiomics/full_pipeline.html#visualisation",
    "title": "Full pipeline",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v7(toSortedList)\n    v9(Output)\n    v11(filter)\n    v17(add_id)\n    v19(join)\n    v24(mix)\n    v22(filter)\n    v27(filter)\n    v32(split_modalities)\n    v34(join)\n    v41(concat)\n    v37(filter)\n    v39(test_wf:run_wf:split_modalities_workflow:splitStub)\n    v42(flatMap)\n    v44(filter)\n    v47(toSortedList)\n    v49(flatMap)\n    v55(filter)\n    v61(grep_annotation_column)\n    v63(join)\n    v67(mix)\n    v66(filter)\n    v73(calculate_qc_metrics)\n    v75(join)\n    v83(publish)\n    v85(join)\n    v89(filter)\n    v96(delimit_fraction)\n    v98(join)\n    v102(mix)\n    v101(filter)\n    v108(filter_with_counts)\n    v110(join)\n    v118(do_filter)\n    v120(join)\n    v128(filter_with_scrublet)\n    v130(join)\n    v199(concat)\n    v133(filter)\n    v136(toSortedList)\n    v138(flatMap)\n    v143(filter)\n    v149(test_wf:run_wf:singlesample_processing_workflow:prot_singlesample:unfiltered_counts_qc_metrics_prot:grep_annotation_column:grep_annotation_column_process1)\n    v151(join)\n    v155(mix)\n    v154(filter)\n    v161(test_wf:run_wf:singlesample_processing_workflow:prot_singlesample:unfiltered_counts_qc_metrics_prot:calculate_qc_metrics:calculate_qc_metrics_process1)\n    v163(join)\n    v171(test_wf:run_wf:singlesample_processing_workflow:prot_singlesample:unfiltered_counts_qc_metrics_prot:publish:publish_process1)\n    v173(join)\n    v182(test_wf:run_wf:singlesample_processing_workflow:prot_singlesample:filter_with_counts:filter_with_counts_process1)\n    v184(join)\n    v192(test_wf:run_wf:singlesample_processing_workflow:prot_singlesample:do_filter:do_filter_process1)\n    v194(join)\n    v197(filter)\n    v203(groupTuple)\n    v209(concat)\n    v211(join)\n    v215(filter)\n    v218(toSortedList)\n    v220(flatMap)\n    v222(toSortedList)\n    v224(Output)\n    v230(normalize_total)\n    v232(join)\n    v241(log1p)\n    v243(join)\n    v252(delete_layer)\n    v254(join)\n    v263(filter_with_hvg)\n    v265(join)\n    v274(rna_calculate_qc_metrics)\n    v276(join)\n    v340(concat)\n    v281(filter)\n    v284(toSortedList)\n    v286(flatMap)\n    v287(toSortedList)\n    v289(Output)\n    v295(clr)\n    v297(join)\n    v303(filter)\n    v309(test_wf:run_wf:multisample_processing_workflow:prot_multisample:prot_qc:grep_annotation_column:grep_annotation_column_process2)\n    v311(join)\n    v315(mix)\n    v314(filter)\n    v321(test_wf:run_wf:multisample_processing_workflow:prot_multisample:prot_qc:calculate_qc_metrics:calculate_qc_metrics_process2)\n    v323(join)\n    v331(test_wf:run_wf:multisample_processing_workflow:prot_multisample:prot_qc:publish:publish_process2)\n    v333(join)\n    v337(filter)\n    v342(toSortedList)\n    v348(merge)\n    v350(join)\n    v354(filter)\n    v358(toSortedList)\n    v360(flatMap)\n    v367(pca)\n    v369(join)\n    v378(find_neighbors)\n    v380(join)\n    v389(umap)\n    v391(join)\n    v397(concat)\n    v396(filter)\n    v398(filter)\n    v402(toSortedList)\n    v404(flatMap)\n    v411(pca)\n    v413(join)\n    v422(find_neighbors)\n    v424(join)\n    v433(test_wf:run_wf:integration_setup_workflow:initialize_integration_prot:umap:umap_process1)\n    v435(join)\n    v441(concat)\n    v440(filter)\n    v449(test_wf:run_wf:publish:publish_process3)\n    v451(join)\n    v456(toSortedList)\n    v458(Output)\n    v41--&gt;v42\n    v66--&gt;v67\n    v101--&gt;v102\n    v154--&gt;v155\n    v286--&gt;v287\n    v314--&gt;v315\n    v396--&gt;v397\n    v397--&gt;v398\n    v397--&gt;v440\n    v440--&gt;v441\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v7\n    v7--&gt;v9\n    v4--&gt;v11\n    v4--&gt;v22\n    v11--&gt;v19\n    v11--&gt;v17\n    v17--&gt;v19\n    v19--&gt;v24\n    v22--&gt;v24\n    v24--&gt;v27\n    v24--&gt;v37\n    v27--&gt;v34\n    v27--&gt;v32\n    v32--&gt;v34\n    v34--&gt;v41\n    v37--&gt;v39\n    v39--&gt;v41\n    v42--&gt;v44\n    v42--&gt;v133\n    v42--&gt;v197\n    v44--&gt;v47\n    v47--&gt;v49\n    v49--&gt;v55\n    v49--&gt;v66\n    v55--&gt;v63\n    v55--&gt;v61\n    v61--&gt;v63\n    v63--&gt;v67\n    v67--&gt;v75\n    v67--&gt;v73\n    v73--&gt;v75\n    v75--&gt;v85\n    v75--&gt;v83\n    v83--&gt;v85\n    v85--&gt;v89\n    v85--&gt;v101\n    v89--&gt;v98\n    v89--&gt;v96\n    v96--&gt;v98\n    v98--&gt;v102\n    v102--&gt;v110\n    v102--&gt;v108\n    v108--&gt;v110\n    v110--&gt;v120\n    v110--&gt;v118\n    v118--&gt;v120\n    v120--&gt;v130\n    v120--&gt;v128\n    v128--&gt;v130\n    v130--&gt;v199\n    v133--&gt;v136\n    v136--&gt;v138\n    v138--&gt;v143\n    v138--&gt;v154\n    v143--&gt;v151\n    v143--&gt;v149\n    v149--&gt;v151\n    v151--&gt;v155\n    v155--&gt;v163\n    v155--&gt;v161\n    v161--&gt;v163\n    v163--&gt;v173\n    v163--&gt;v171\n    v171--&gt;v173\n    v173--&gt;v184\n    v173--&gt;v182\n    v182--&gt;v184\n    v184--&gt;v194\n    v184--&gt;v192\n    v192--&gt;v194\n    v194--&gt;v199\n    v197--&gt;v199\n    v199--&gt;v203\n    v203--&gt;v211\n    v203--&gt;v209\n    v209--&gt;v211\n    v211--&gt;v215\n    v211--&gt;v281\n    v211--&gt;v337\n    v215--&gt;v218\n    v218--&gt;v220\n    v220--&gt;v222\n    v222--&gt;v224\n    v220--&gt;v232\n    v220--&gt;v230\n    v230--&gt;v232\n    v232--&gt;v243\n    v232--&gt;v241\n    v241--&gt;v243\n    v243--&gt;v254\n    v243--&gt;v252\n    v252--&gt;v254\n    v254--&gt;v265\n    v254--&gt;v263\n    v263--&gt;v265\n    v265--&gt;v276\n    v265--&gt;v274\n    v274--&gt;v276\n    v276--&gt;v340\n    v281--&gt;v284\n    v284--&gt;v286\n    v287--&gt;v289\n    v286--&gt;v297\n    v286--&gt;v295\n    v295--&gt;v297\n    v297--&gt;v303\n    v297--&gt;v314\n    v303--&gt;v311\n    v303--&gt;v309\n    v309--&gt;v311\n    v311--&gt;v315\n    v315--&gt;v323\n    v315--&gt;v321\n    v321--&gt;v323\n    v323--&gt;v333\n    v323--&gt;v331\n    v331--&gt;v333\n    v333--&gt;v340\n    v337--&gt;v340\n    v340--&gt;v342\n    v342--&gt;v350\n    v342--&gt;v348\n    v348--&gt;v350\n    v350--&gt;v354\n    v350--&gt;v396\n    v354--&gt;v358\n    v358--&gt;v360\n    v360--&gt;v369\n    v360--&gt;v367\n    v367--&gt;v369\n    v369--&gt;v380\n    v369--&gt;v378\n    v378--&gt;v380\n    v380--&gt;v391\n    v380--&gt;v389\n    v389--&gt;v391\n    v391--&gt;v397\n    v398--&gt;v402\n    v402--&gt;v404\n    v404--&gt;v413\n    v404--&gt;v411\n    v411--&gt;v413\n    v413--&gt;v424\n    v413--&gt;v422\n    v422--&gt;v424\n    v424--&gt;v435\n    v424--&gt;v433\n    v433--&gt;v435\n    v435--&gt;v441\n    v441--&gt;v451\n    v441--&gt;v449\n    v449--&gt;v451\n    v451--&gt;v456\n    v456--&gt;v458"
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html",
    "href": "components/workflows/ingestion/conversion.html",
    "title": "Conversion",
    "section": "",
    "text": "ID: conversion\nNamespace: ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html#example-commands",
    "href": "components/workflows/ingestion/conversion.html#example-commands",
    "title": "Conversion",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/ingestion/conversion/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: [\"input.h5mu\"]\ninput_type: # please fill in - example: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Conversion from h5ad\n# modality: [\"foo\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/ingestion/conversion/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html#argument-groups",
    "href": "components/workflows/ingestion/conversion.html#argument-groups",
    "title": "Conversion",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nList of file, required, example: \"input.h5mu\", multiple_sep: \";\"\n\n\n--input_type\nType of the input file\nstring, required\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nName or template for the output files.\nfile, example: \"output.h5mu\"\n\n\n\n\n\nConversion from h5ad\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--modality\nName of the modality where the h5ad is stored in the h5mu object.\nList of string, multiple_sep: \":\""
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html#authors",
    "href": "components/workflows/ingestion/conversion.html#authors",
    "title": "Conversion",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)\nDries De Maeyer   (author)"
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html#visualisation",
    "href": "components/workflows/ingestion/conversion.html#visualisation",
    "title": "Conversion",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v5(filter)\n    v10(from_10xh5_to_h5mu)\n    v12(join)\n    v35(mix)\n    v15(filter)\n    v20(from_10xmtx_to_h5mu)\n    v22(join)\n    v25(filter)\n    v30(from_h5ad_to_h5mu)\n    v32(join)\n    v37(toSortedList)\n    v39(Output)\n    v4--&gt;v5\n    v4--&gt;v15\n    v4--&gt;v25\n    v0--&gt;v2\n    v2--&gt;v4\n    v5--&gt;v12\n    v5--&gt;v10\n    v10--&gt;v12\n    v12--&gt;v35\n    v15--&gt;v22\n    v15--&gt;v20\n    v20--&gt;v22\n    v22--&gt;v35\n    v25--&gt;v32\n    v25--&gt;v30\n    v30--&gt;v32\n    v32--&gt;v35\n    v35--&gt;v37\n    v37--&gt;v39"
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html",
    "href": "components/workflows/ingestion/bd_rhapsody.html",
    "title": "BD Rhapsody",
    "section": "",
    "text": "ID: bd_rhapsody\nNamespace: ingestion\n\n\n\nSource\nA wrapper for the BD Rhapsody Analysis CWL v1.10.1 pipeline.\nThis pipeline can be used for a targeted analysis (with --mode targeted) or for a whole transcriptome analysis (with --mode wta).\nThe reference_genome and transcriptome_annotation files can be generated with the make_reference pipeline. Alternatively, BD also provides standard references which can be downloaded from these locations:"
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html#example-commands",
    "href": "components/workflows/ingestion/bd_rhapsody.html#example-commands",
    "title": "BD Rhapsody",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/ingestion/bd_rhapsody/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nmode: # please fill in - example: \"wta\"\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: [\"input.fastq.gz\"]\nreference: # please fill in - example: [\"reference_genome.tar.gz|reference.fasta\"]\n# transcriptome_annotation: \"transcriptome.gtf\"\n# abseq_reference: [\"abseq_reference.fasta\"]\n# supplemental_reference: [\"supplemental_reference.fasta\"]\nsample_prefix: \"sample\"\n\n# Outputs\n# output_raw: \"$id.$key.output_raw.output_raw\"\n# output_h5mu: \"$id.$key.output_h5mu.h5mu\"\n\n# Putative cell calling settings\n# putative_cell_call: \"mRNA\"\n# exact_cell_count: 10000\ndisable_putative_calling: false\n\n# Subsample arguments\n# subsample: 0.01\n# subsample_seed: 3445\n\n# Multiplex arguments\n# sample_tags_version: \"human\"\n# tag_names: [\"4-mySample\", \"9-myOtherSample\", \"6-alsoThisSample\"]\n\n# VDJ arguments\n# vdj_version: \"human\"\n\n# CWL-runner arguments\nparallel: true\ntimestamps: false\ndryrun: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/ingestion/bd_rhapsody/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html#argument-groups",
    "href": "components/workflows/ingestion/bd_rhapsody.html#argument-groups",
    "title": "BD Rhapsody",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--mode\nWhether to run a whole transcriptome analysis (WTA) or a targeted analysis.\nstring, required, example: \"wta\"\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to your read files in the FASTQ.GZ format. You may specify as many R1/R2 read pairs as you want.\nList of file, required, example: \"input.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nRefence to map to. For --mode wta, this is the path to STAR index as a tar.gz file. For --mode targeted, this is the path to mRNA reference file for pre-designed, supplemental, or custom panel, in FASTA format\nList of file, required, example: \"reference_genome.tar.gz&#124;reference.fasta\", multiple_sep: \";\"\n\n\n--transcriptome_annotation\nPath to GTF annotation file (only for --mode wta).\nfile, example: \"transcriptome.gtf\"\n\n\n--abseq_reference\nPath to the AbSeq reference file in FASTA format. Only needed if BD AbSeq Ab-Oligos are used.\nList of file, example: \"abseq_reference.fasta\", multiple_sep: \";\"\n\n\n--supplemental_reference\nPath to the supplemental reference file in FASTA format. Only needed if there are additional transgene sequences used in the experiment (only for --mode wta).\nList of file, example: \"supplemental_reference.fasta\", multiple_sep: \";\"\n\n\n--sample_prefix\nSpecify a run name to use as the output file base name. Use only letters, numbers, or hyphens. Do not use special characters or spaces.\nstring, default: \"sample\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_raw\nThe BD Rhapsody output folder as it comes out of the BD Rhapsody pipeline\nfile, required, example: \"output_dir\"\n\n\n--output_h5mu\nThe converted h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nPutative cell calling settings\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--putative_cell_call\nSpecify the dataset to be used for putative cell calling. For putative cell calling using an AbSeq dataset, please provide an AbSeq_Reference fasta file above.\nstring, example: \"mRNA\"\n\n\n--exact_cell_count\nExact cell count - Set a specific number (&gt;=1) of cells as putative, based on those with the highest error-corrected read count\ninteger, example: 10000\n\n\n--disable_putative_calling\nDisable Refined Putative Cell Calling - Determine putative cells using only the basic algorithm (minimum second derivative along the cumulative reads curve). The refined algorithm attempts to remove false positives and recover false negatives, but may not be ideal for certain complex mixtures of cell types. Does not apply if Exact Cell Count is set.\nboolean_true\n\n\n\n\n\nSubsample arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--subsample\nA number &gt;1 or fraction (0 &lt; n &lt; 1) to indicate the number or percentage of reads to subsample.\ndouble, example: 0.01\n\n\n--subsample_seed\nA seed for replicating a previous subsampled run.\ninteger, example: 3445\n\n\n\n\n\nMultiplex arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sample_tags_version\nSpecify if multiplexed run.\nstring, example: \"human\"\n\n\n--tag_names\nTag_Names (optional) - Specify the tag number followed by ‚Äò-‚Äô and the desired sample name to appear in Sample_Tag_Metrics.csv. Do not use the special characters: &, (), [], {}, &lt;&gt;, ?, |\nList of string, example: \"4-mySample\", \"9-myOtherSample\", \"6-alsoThisSample\", multiple_sep: \":\"\n\n\n\n\n\nVDJ arguments\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--vdj_version\nSpecify if VDJ run.\nstring, example: \"human\"\n\n\n\n\n\nCWL-runner arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--parallel\nRun jobs in parallel.\nboolean, default: TRUE\n\n\n--timestamps\nAdd timestamps to the errors, warnings, and notifications.\nboolean_true\n\n\n--dryrun\nIf true, the output directory will only contain the CWL input files, but the pipeline itself will not be executed.\nboolean_true"
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html#authors",
    "href": "components/workflows/ingestion/bd_rhapsody.html#authors",
    "title": "BD Rhapsody",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html#visualisation",
    "href": "components/workflows/ingestion/bd_rhapsody.html#visualisation",
    "title": "BD Rhapsody",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v10(bd_rhapsody)\n    v12(join)\n    v21(from_bdrhap_to_h5mu)\n    v23(join)\n    v29(Output)\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v12\n    v4--&gt;v10\n    v10--&gt;v12\n    v12--&gt;v23\n    v12--&gt;v21\n    v21--&gt;v23\n    v23--&gt;v29"
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html",
    "href": "components/workflows/ingestion/make_reference.html",
    "title": "Make reference",
    "section": "",
    "text": "ID: make_reference\nNamespace: ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html#example-commands",
    "href": "components/workflows/ingestion/make_reference.html#example-commands",
    "title": "Make reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/ingestion/make_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ngenome_fasta: # please fill in - example: \"https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/GRCh38.primary_assembly.genome.fa.gz\"\ntranscriptome_gtf: # please fill in - example: \"https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/gencode.v41.annotation.gtf.gz\"\n# ercc: \"https://assets.thermofisher.com/TFS-Assets/LSG/manuals/ERCC92.zip\"\n\n# Outputs\ntarget: [\"star\"]\n# output_fasta: \"$id.$key.output_fasta.gz\"\n# output_gtf: \"$id.$key.output_gtf.gz\"\n# output_cellranger: \"$id.$key.output_cellranger.gz\"\n# output_bd_rhapsody: \"$id.$key.output_bd_rhapsody.gz\"\n# output_star: \"$id.$key.output_star.gz\"\n\n# Arguments\n# subset_regex: \"(ERCC-00002|chr1)\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/ingestion/make_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html#argument-groups",
    "href": "components/workflows/ingestion/make_reference.html#argument-groups",
    "title": "Make reference",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the reference.\nstring, required, example: \"foo\"\n\n\n--genome_fasta\nReference genome fasta.\nfile, required, example: \"https:/ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/GRCh38.primary_assembly.genome.fa.gz\"\n\n\n--transcriptome_gtf\nReference transcriptome annotation.\nfile, required, example: \"https:/ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/gencode.v41.annotation.gtf.gz\"\n\n\n--ercc\nERCC sequence and annotation file.\nfile, example: \"https:/assets.thermofisher.com/TFS-Assets/LSG/manuals/ERCC92.zip\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--target\nWhich reference indices to generate.\nList of string, default: \"star\", multiple_sep: \":\"\n\n\n--output_fasta\nOutput genome sequence fasta.\nfile, example: \"genome_sequence.fa.gz\"\n\n\n--output_gtf\nOutput transcriptome annotation gtf.\nfile, example: \"transcriptome_annotation.gtf.gz\"\n\n\n--output_cellranger\nOutput index\nfile, example: \"cellranger_index.tar.gz\"\n\n\n--output_bd_rhapsody\nOutput index\nfile, example: \"bdrhap_index.tar.gz\"\n\n\n--output_star\nOutput index\nfile, example: \"star_index.tar.gz\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--subset_regex\nWill subset the reference chromosomes using the given regex.\nstring, example: \"(ERCC-00002&#124;chr1)\""
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html#authors",
    "href": "components/workflows/ingestion/make_reference.html#authors",
    "title": "Make reference",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html#visualisation",
    "href": "components/workflows/ingestion/make_reference.html#visualisation",
    "title": "Make reference",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v11(make_reference)\n    v13(join)\n    v17(filter)\n    v22(build_cellranger_reference)\n    v24(join)\n    v54(join)\n    v29(filter)\n    v34(build_bdrhap_reference)\n    v36(join)\n    v55(join)\n    v41(filter)\n    v46(star_build_reference)\n    v48(join)\n    v56(join)\n    v57(join)\n    v62(Output)\n    v54--&gt;v55\n    v55--&gt;v56\n    v56--&gt;v57\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v13\n    v4--&gt;v11\n    v11--&gt;v13\n    v13--&gt;v17\n    v17--&gt;v24\n    v17--&gt;v22\n    v22--&gt;v24\n    v24--&gt;v54\n    v13--&gt;v29\n    v29--&gt;v36\n    v29--&gt;v34\n    v34--&gt;v36\n    v36--&gt;v55\n    v13--&gt;v41\n    v41--&gt;v48\n    v41--&gt;v46\n    v46--&gt;v48\n    v48--&gt;v56\n    v0--&gt;v57\n    v13--&gt;v54\n    v57--&gt;v62"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html",
    "href": "components/workflows/ingestion/cellranger_multi.html",
    "title": "Cell Ranger multi",
    "section": "",
    "text": "ID: cellranger_multi\nNamespace: ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html#example-commands",
    "href": "components/workflows/ingestion/cellranger_multi.html#example-commands",
    "title": "Cell Ranger multi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/ingestion/cellranger_multi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: [\"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\"]\ngex_reference: # please fill in - example: \"reference_genome.tar.gz\"\n# vdj_reference: \"reference_vdj.tar.gz\"\n# feature_reference: \"feature_reference.csv\"\n# vdj_inner_enrichment_primers: \"enrichment_primers.txt\"\n\n# Outputs\n# output_raw: \"$id.$key.output_raw.output_raw\"\n# output_h5mu: \"$id.$key.output_h5mu.h5mu\"\nuns_metrics: \"metrics_cellranger\"\n\n# Cell multiplexing parameters\n# cell_multiplex_sample_id: \"foo\"\n# cell_multiplex_oligo_ids: \"foo\"\n# cell_multiplex_description: \"foo\"\n\n# Gene expression arguments\n# gex_expect_cells: 3000\ngex_chemistry: \"auto\"\ngex_secondary_analysis: false\ngex_generate_bam: true\ngex_include_introns: true\n\n# Library arguments\nlibrary_id: # please fill in - example: [\"mysample1\"]\nlibrary_type: # please fill in - example: [\"Gene Expression\"]\n# library_subsample: [\"0.5\"]\n# library_lanes: [\"1-4\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/ingestion/cellranger_multi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html#argument-groups",
    "href": "components/workflows/ingestion/cellranger_multi.html#argument-groups",
    "title": "Cell Ranger multi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nThe fastq.gz files to align. Can also be a single directory containing fastq.gz files.\nList of file, required, example: \"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--gex_reference\nGenome refence index built by Cell Ranger mkref.\nfile, required, example: \"reference_genome.tar.gz\"\n\n\n--vdj_reference\nVDJ refence index built by Cell Ranger mkref.\nfile, example: \"reference_vdj.tar.gz\"\n\n\n--feature_reference\nPath to the Feature reference CSV file, declaring Feature Barcode constructs and associated barcodes. Required only for Antibody Capture or CRISPR Guide Capture libraries. See https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/using/feature-bc-analysis#feature-ref for more information.\nfile, example: \"feature_reference.csv\"\n\n\n--vdj_inner_enrichment_primers\nV(D)J Immune Profiling libraries: if inner enrichment primers other than those provided in the 10x Genomics kits are used, they need to be specified here as a text file with one primer per line.\nfile, example: \"enrichment_primers.txt\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_raw\nThe raw output folder.\nfile, required, example: \"output_dir\"\n\n\n--output_h5mu\nThe converted h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--uns_metrics\nName of the .uns slot under which to QC metrics (if any).\nstring, default: \"metrics_cellranger\"\n\n\n\n\n\nCell multiplexing parameters\nArguments related to cell multiplexing.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_multiplex_sample_id\nA name to identify a multiplexed sample. Must be alphanumeric with hyphens and/or underscores, and less than 64 characters. Required for Cell Multiplexing libraries.\nstring\n\n\n--cell_multiplex_oligo_ids\nThe Cell Multiplexing oligo IDs used to multiplex this sample. If multiple CMOs were used for a sample, separate IDs with a pipe (e.g., CMO301|CMO302). Required for Cell Multiplexing libraries.\nstring\n\n\n--cell_multiplex_description\nA description for the sample.\nstring\n\n\n\n\n\nGene expression arguments\nArguments relevant to the analysis of gene expression data.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--gex_expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\ninteger, example: 3000\n\n\n--gex_chemistry\nAssay configuration. - auto: autodetect mode - threeprime: Single Cell 3‚Äô - fiveprime: Single Cell 5‚Äô - SC3Pv1: Single Cell 3‚Äô v1 - SC3Pv2: Single Cell 3‚Äô v2 - SC3Pv3: Single Cell 3‚Äô v3 - SC3Pv3LT: Single Cell 3‚Äô v3 LT - SC3Pv3HT: Single Cell 3‚Äô v3 HT - SC5P-PE: Single Cell 5‚Äô paired-end - SC5P-R2: Single Cell 5‚Äô R2-only - SC-FB: Single Cell Antibody-only 3‚Äô v2 or 5‚Äô See https://kb.10xgenomics.com/hc/en-us/articles/115003764132-How-does-Cell-Ranger-auto-detect-chemistry- for more information.\nstring, default: \"auto\"\n\n\n--gex_secondary_analysis\nWhether or not to run the secondary analysis e.g.¬†clustering.\nboolean, default: FALSE\n\n\n--gex_generate_bam\nWhether to generate a BAM file.\nboolean, default: TRUE\n\n\n--gex_include_introns\nInclude intronic reads in count (default=true unless ‚Äìtarget-panel is specified in which case default=false)\nboolean, default: TRUE\n\n\n\n\n\nLibrary arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--library_id\nThe Illumina sample name to analyze. This must exactly match the ‚ÄòSample Name‚Äô part of the FASTQ files specified in the --input argument.\nList of string, required, example: \"mysample1\", multiple_sep: \";\"\n\n\n--library_type\nThe underlying feature type of the library. Possible values: ‚ÄúGene Expression‚Äù, ‚ÄúVDJ‚Äù, ‚ÄúVDJ-T‚Äù, ‚ÄúVDJ-B‚Äù, ‚ÄúAntibody Capture‚Äù, ‚ÄúCRISPR Guide Capture‚Äù, ‚ÄúMultiplexing Capture‚Äù\nList of string, required, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--library_subsample\nOptional. The rate at which reads from the provided FASTQ files are sampled. Must be strictly greater than 0 and less than or equal to 1.\nList of string, example: \"0.5\", multiple_sep: \";\"\n\n\n--library_lanes\nLanes associated with this sample. Defaults to using all lanes.\nList of string, example: \"1-4\", multiple_sep: \";\""
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html#authors",
    "href": "components/workflows/ingestion/cellranger_multi.html#authors",
    "title": "Cell Ranger multi",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html#visualisation",
    "href": "components/workflows/ingestion/cellranger_multi.html#visualisation",
    "title": "Cell Ranger multi",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v11(cellranger_multi)\n    v13(join)\n    v21(from_cellranger_multi_to_h5mu)\n    v23(join)\n    v30(Output)\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v13\n    v4--&gt;v11\n    v11--&gt;v13\n    v13--&gt;v23\n    v13--&gt;v21\n    v21--&gt;v23\n    v23--&gt;v30"
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html",
    "href": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html",
    "title": "Scanorama leiden",
    "section": "",
    "text": "ID: scanorama_leiden\nNamespace: integration/scanorama_leiden\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#example-commands",
    "href": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#example-commands",
    "title": "Scanorama leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -main-script workflows/multiomics/integration/scanorama_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Neighbour calculation\nuns_neighbors: \"scanorama_integration_neighbors\"\nobsp_neighbor_distances: \"scanorama_integration_distances\"\nobsp_neighbor_connectivities: \"scanorama_integration_connectivities\"\n\n# Scanorama integration options\nobs_batch: \"sample_id\"\nobsm_input: \"X_pca\"\nobsm_output: \"X_scanorama\"\nknn: 20\nbatch_size: 5000\nsigma: 15\napprox: true\nalpha: 0.1\n\n# Clustering options\nobs_cluster: \"scanorama_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_leiden_scanorama_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -profile docker \\\n  -main-script workflows/multiomics/integration/scanorama_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#argument-groups",
    "href": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#argument-groups",
    "title": "Scanorama leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"scanorama_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"scanorama_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"scanorama_integration_connectivities\"\n\n\n\n\n\nScanorama integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--obsm_input\n.osbm slot that points to embedding to run scanorama on.\nstring, default: \"X_pca\"\n\n\n--obsm_output\nThe name of the field in adata.obsm where the integrated embeddings will be stored after running this function. Defaults to X_scanorama.\nstring, default: \"X_scanorama\"\n\n\n--knn\nNumber of nearest neighbors to use for matching.\ninteger, default: 20\n\n\n--batch_size\nThe batch size used in the alignment vector computation. Useful when integrating very large (&gt;100k samples) datasets. Set to large value that runs within available memory.\ninteger, default: 5000\n\n\n--sigma\nCorrection smoothing parameter on Gaussian kernel.\ndouble, default: 15\n\n\n--approx\nUse approximate nearest neighbors with Python annoy; greatly speeds up matching runtime.\nboolean, default: TRUE\n\n\n--alpha\nAlignment score minimum cutoff\ndouble, default: 0.1\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nName of the .obs key under which to add the cluster labels.\nstring, default: \"scanorama_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\ndouble, default: 1\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_scanorama_umap\""
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#authors",
    "href": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#authors",
    "title": "Scanorama leiden",
    "section": "Authors",
    "text": "Authors\n\nMauro Saporita   (author)\nPovilas Gibas   (author)"
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#visualisation",
    "href": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#visualisation",
    "title": "Scanorama leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    p0(Input)\n    p2(toSortedList)\n    p4(flatMap)\n    p12(scanorama)\n    p22(find_neighbors)\n    p32(leiden)\n    p42(umap)\n    p52(move_obsm_to_obs)\n    p60(Output)\n    p0--&gt;p2\n    p2--&gt;p4\n    p4--&gt;p12\n    p12--&gt;p22\n    p22--&gt;p32\n    p32--&gt;p42\n    p42--&gt;p52\n    p52--&gt;p60"
  },
  {
    "objectID": "components/workflows/integration/common/harmony_leiden.html",
    "href": "components/workflows/integration/common/harmony_leiden.html",
    "title": "Harmony leiden",
    "section": "",
    "text": "ID: harmony_leiden\nNamespace: integration/common\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/integration/common/harmony_leiden.html#example-commands",
    "href": "components/workflows/integration/common/harmony_leiden.html#example-commands",
    "title": "Harmony leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -main-script workflows/multiomics/integration/harmony_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Neighbour calculation\nuns_neighbors: \"harmonypy_integration_neighbors\"\nobsp_neighbor_distances: \"harmonypy_integration_distances\"\nobsp_neighbor_connectivities: \"harmonypy_integration_connectivities\"\n\n# Harmony integration options\nembedding: \"X_pca\"\nobsm_integrated: \"X_pca_integrated\"\nobs_covariates: # please fill in - example: [\"batch\", \"sample\"]\ntheta: [2]\n\n# Clustering options\nobs_cluster: \"harmony_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_leiden_harmony_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -profile docker \\\n  -main-script workflows/multiomics/integration/harmony_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/integration/common/harmony_leiden.html#argument-groups",
    "href": "components/workflows/integration/common/harmony_leiden.html#argument-groups",
    "title": "Harmony leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"harmonypy_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"harmonypy_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"harmonypy_integration_connectivities\"\n\n\n\n\n\nHarmony integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--embedding\nEmbedding to use as input\nstring, default: \"X_pca\"\n\n\n--obsm_integrated\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_pca_integrated\"\n\n\n--obs_covariates\nThe .obs field(s) that define the covariate(s) to regress out.\nstring, required, example: \"batch\", example: \"sample\"\n\n\n--theta\nDiversity clustering penalty parameter. Specify for each variable in group.by.vars. theta=0 does not encourage any diversity. Larger values of theta result in more diverse clusters.‚Äù\ndouble, default: 2\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nName of the .obs key under which to add the cluster labels.\nstring, default: \"harmony_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\ndouble, default: 1\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_harmony_umap\""
  },
  {
    "objectID": "components/workflows/integration/common/harmony_leiden.html#authors",
    "href": "components/workflows/integration/common/harmony_leiden.html#authors",
    "title": "Harmony leiden",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/integration/common/harmony_leiden.html#visualisation",
    "href": "components/workflows/integration/common/harmony_leiden.html#visualisation",
    "title": "Harmony leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    p0(Input)\n    p2(toSortedList)\n    p4(flatMap)\n    p12(harmonypy)\n    p22(find_neighbors)\n    p32(leiden)\n    p42(umap)\n    p52(move_obsm_to_obs)\n    p60(Output)\n    p0--&gt;p2\n    p2--&gt;p4\n    p4--&gt;p12\n    p12--&gt;p22\n    p22--&gt;p32\n    p32--&gt;p42\n    p42--&gt;p52\n    p52--&gt;p60"
  },
  {
    "objectID": "components/workflows/workflows/gdo/gdo_singlesample.html",
    "href": "components/workflows/workflows/gdo/gdo_singlesample.html",
    "title": "Gdo singlesample",
    "section": "",
    "text": "ID: gdo_singlesample\nNamespace: workflows/gdo\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/gdo/gdo_singlesample.html#example-commands",
    "href": "components/workflows/workflows/gdo/gdo_singlesample.html#example-commands",
    "title": "Gdo singlesample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/gdo/gdo_singlesample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\n# layer: \"foo\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\n\n# Filtering options\n# min_counts: 200\n# max_counts: 5000000\n# min_guides_per_cell: 200\n# max_guides_per_cell: 1500000\n# min_cells_per_guide: 3\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/gdo/gdo_singlesample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/gdo/gdo_singlesample.html#argument-groups",
    "href": "components/workflows/workflows/gdo/gdo_singlesample.html#argument-groups",
    "title": "Gdo singlesample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nInput layer to start from. By default, .X will be used.\nstring\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nFiltering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--min_guides_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--max_guides_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--min_cells_per_guide\nMinimum of non-zero values per gene.\ninteger, example: 3"
  },
  {
    "objectID": "components/workflows/workflows/gdo/gdo_singlesample.html#authors",
    "href": "components/workflows/workflows/gdo/gdo_singlesample.html#authors",
    "title": "Gdo singlesample",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/workflows/multiomics/split_modalities.html",
    "href": "components/workflows/workflows/multiomics/split_modalities.html",
    "title": "Split modalities",
    "section": "",
    "text": "ID: split_modalities\nNamespace: workflows/multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/multiomics/split_modalities.html#example-commands",
    "href": "components/workflows/workflows/multiomics/split_modalities.html#example-commands",
    "title": "Split modalities",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/multiomics/split_modalities/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\n\n# Outputs\n# output: \"$id.$key.output.output\"\n# output_types: \"$id.$key.output_types.csv\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/multiomics/split_modalities/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/multiomics/split_modalities.html#argument-groups",
    "href": "components/workflows/workflows/multiomics/split_modalities.html#argument-groups",
    "title": "Split modalities",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"input.h5mu\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory containing multiple h5mu files.\nfile, required, example: \"/path/to/output\"\n\n\n--output_types\nA csv containing the base filename and modality type per output file.\nfile, required, example: \"types.csv\""
  },
  {
    "objectID": "components/workflows/workflows/multiomics/split_modalities.html#authors",
    "href": "components/workflows/workflows/multiomics/split_modalities.html#authors",
    "title": "Split modalities",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/workflows/multiomics/process_samples.html",
    "href": "components/workflows/workflows/multiomics/process_samples.html",
    "title": "Process samples",
    "section": "",
    "text": "ID: process_samples\nNamespace: workflows/multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/multiomics/process_samples.html#example-commands",
    "href": "components/workflows/workflows/multiomics/process_samples.html#example-commands",
    "title": "Process samples",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/multiomics/process_samples/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\n# rna_layer: \"foo\"\n# prot_layer: \"foo\"\n# gdo_layer: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Sample ID options\nadd_id_to_obs: true\nadd_id_obs_output: \"sample_id\"\nadd_id_make_observation_keys_unique: true\n\n# RNA filtering options\n# rna_min_counts: 200\n# rna_max_counts: 5000000\n# rna_min_genes_per_cell: 200\n# rna_max_genes_per_cell: 1500000\n# rna_min_cells_per_gene: 3\n# rna_min_fraction_mito: 0\n# rna_max_fraction_mito: 0.2\n\n# CITE-seq filtering options\n# prot_min_counts: 3\n# prot_max_counts: 5000000\n# prot_min_proteins_per_cell: 200\n# prot_max_proteins_per_cell: 100000000\n# prot_min_cells_per_protein: 3\n\n# GDO filtering options\n# gdo_min_counts: 3\n# gdo_max_counts: 5000000\n# gdo_min_guides_per_cell: 200\n# gdo_max_guides_per_cell: 100000000\n# gdo_min_cells_per_guide: 3\n\n# Highly variable features detection\nhighly_variable_features_var_output: \"filter_with_hvg\"\nhighly_variable_features_obs_batch_key: \"sample_id\"\n\n# Mitochondrial Gene Detection\n# var_name_mitochondrial_genes: \"foo\"\n# obs_name_mitochondrial_fraction: \"foo\"\n# var_gene_names: \"gene_symbol\"\nmitochondrial_gene_regex: \"^[mM][tT]-\"\n\n# QC metrics calculation options\n# var_qc_metrics: [\"ercc\", \"highly_variable\"]\ntop_n_vars: [50, 100, 200, 500]\n\n# PCA options\npca_overwrite: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/multiomics/process_samples/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/multiomics/process_samples.html#argument-groups",
    "href": "components/workflows/workflows/multiomics/process_samples.html#argument-groups",
    "title": "Process samples",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"input.h5mu\"\n\n\n--rna_layer\nInput layer for the gene expression modality. If not specified, .X is used.\nstring\n\n\n--prot_layer\nInput layer for the antibody capture modality. If not specified, .X is used.\nstring\n\n\n--gdo_layer\nInput layer for the guide-derived oligonucleotide (GDO) data. If not specified, .X is used.\nstring\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nSample ID options\nOptions for adding the id to .obs on the MuData object. Having a sample id present in a requirement of several components for this pipeline.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--add_id_to_obs\nAdd the value passed with ‚Äìid to .obs.\nboolean, default: TRUE\n\n\n--add_id_obs_output\n.Obs column to add the sample IDs to. Required and only used when ‚Äìadd_id_to_obs is set to ‚Äòtrue‚Äô\nstring, default: \"sample_id\"\n\n\n--add_id_make_observation_keys_unique\nJoin the id to the .obs index (.obs_names). Only used when ‚Äìadd_id_to_obs is set to ‚Äòtrue‚Äô.\nboolean, default: TRUE\n\n\n\n\n\nRNA filtering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--rna_max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--rna_min_genes_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--rna_max_genes_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--rna_min_cells_per_gene\nMinimum of non-zero values per gene.\ninteger, example: 3\n\n\n--rna_min_fraction_mito\nMinimum fraction of UMIs that are mitochondrial.\ndouble, example: 0\n\n\n--rna_max_fraction_mito\nMaximum fraction of UMIs that are mitochondrial.\ndouble, example: 0.2\n\n\n\n\n\nCITE-seq filtering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_min_counts\nMinimum number of counts per cell.\ninteger, example: 3\n\n\n--prot_max_counts\nMinimum number of counts per cell.\ninteger, example: 5000000\n\n\n--prot_min_proteins_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--prot_max_proteins_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 100000000\n\n\n--prot_min_cells_per_protein\nMinimum of non-zero values per protein.\ninteger, example: 3\n\n\n\n\n\nGDO filtering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--gdo_min_counts\nMinimum number of counts per cell.\ninteger, example: 3\n\n\n--gdo_max_counts\nMinimum number of counts per cell.\ninteger, example: 5000000\n\n\n--gdo_min_guides_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--gdo_max_guides_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 100000000\n\n\n--gdo_min_cells_per_guide\nMinimum of non-zero values per guide.\ninteger, example: 3\n\n\n\n\n\nHighly variable features detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--highly_variable_features_var_output\nIn which .var slot to store a boolean array corresponding to the highly variable genes.\nstring, default: \"filter_with_hvg\"\n\n\n--highly_variable_features_obs_batch_key\nIf specified, highly-variable genes are selected within each batch separately and merged. This simple process avoids the selection of batch-specific genes and acts as a lightweight batch correction method.\nstring, default: \"sample_id\"\n\n\n\n\n\nMitochondrial Gene Detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_name_mitochondrial_genes\nIn which .var slot to store a boolean array corresponding the mitochondrial genes.\nstring\n\n\n--obs_name_mitochondrial_fraction\nWhen specified, write the fraction of counts originating from mitochondrial genes (based on ‚Äìmitochondrial_gene_regex) to an .obs column with the specified name. Requires ‚Äìvar_name_mitochondrial_genes.\nstring\n\n\n--var_gene_names\n.var column name to be used to detect mitochondrial genes instead of .var_names (default if not set). Gene names matching with the regex value from ‚Äìmitochondrial_gene_regex will be identified as a mitochondrial gene.\nstring, example: \"gene_symbol\"\n\n\n--mitochondrial_gene_regex\nRegex string that identifies mitochondrial genes from ‚Äìvar_gene_names. By default will detect human and mouse mitochondrial genes from a gene symbol.\nstring, default: \"^[mM][tT]-\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‚ÄòTrue‚Äô, compared to the total sum of the values for all genes. Defaults to the combined values specified for ‚Äìvar_name_mitochondrial_genes and ‚Äìhighly_variable_features_var_output.\nList of string, example: \"ercc,highly_variable\", multiple_sep: \";\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \";\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pca_overwrite\nAllow overwriting slots for PCA output.\nboolean_true"
  },
  {
    "objectID": "components/workflows/workflows/multiomics/process_samples.html#authors",
    "href": "components/workflows/workflows/multiomics/process_samples.html#authors",
    "title": "Process samples",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/conversion.html",
    "href": "components/workflows/workflows/ingestion/conversion.html",
    "title": "Conversion",
    "section": "",
    "text": "ID: conversion\nNamespace: workflows/ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/conversion.html#example-commands",
    "href": "components/workflows/workflows/ingestion/conversion.html#example-commands",
    "title": "Conversion",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/ingestion/conversion/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\ninput_type: # please fill in - example: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Conversion from h5ad\n# modality: [\"foo\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/ingestion/conversion/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/ingestion/conversion.html#argument-groups",
    "href": "components/workflows/workflows/ingestion/conversion.html#argument-groups",
    "title": "Conversion",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"input.h5mu\"\n\n\n--input_type\nType of the input file\nstring, required\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nName or template for the output files.\nfile, example: \"output.h5mu\"\n\n\n\n\n\nConversion from h5ad\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--modality\nName of the modality where the h5ad is stored in the h5mu object.\nList of string, multiple_sep: \";\""
  },
  {
    "objectID": "components/workflows/workflows/ingestion/conversion.html#authors",
    "href": "components/workflows/workflows/ingestion/conversion.html#authors",
    "title": "Conversion",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)\nDries De Maeyer   (author)"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/bd_rhapsody.html",
    "href": "components/workflows/workflows/ingestion/bd_rhapsody.html",
    "title": "BD Rhapsody",
    "section": "",
    "text": "ID: bd_rhapsody\nNamespace: workflows/ingestion\n\n\n\nSource\nA wrapper for the BD Rhapsody Analysis CWL v1.10.1 pipeline.\nThis pipeline can be used for a targeted analysis (with --mode targeted) or for a whole transcriptome analysis (with --mode wta).\nThe reference_genome and transcriptome_annotation files can be generated with the make_reference pipeline. Alternatively, BD also provides standard references which can be downloaded from these locations:"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/bd_rhapsody.html#example-commands",
    "href": "components/workflows/workflows/ingestion/bd_rhapsody.html#example-commands",
    "title": "BD Rhapsody",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/ingestion/bd_rhapsody/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nmode: # please fill in - example: \"wta\"\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: [\"input.fastq.gz\"]\nreference: # please fill in - example: [\"reference_genome.tar.gz|reference.fasta\"]\n# transcriptome_annotation: \"transcriptome.gtf\"\n# abseq_reference: [\"abseq_reference.fasta\"]\n# supplemental_reference: [\"supplemental_reference.fasta\"]\nsample_prefix: \"sample\"\n\n# Outputs\n# output_raw: \"$id.$key.output_raw.output_raw\"\n# output_h5mu: \"$id.$key.output_h5mu.h5mu\"\n\n# Putative cell calling settings\n# putative_cell_call: \"mRNA\"\n# exact_cell_count: 10000\ndisable_putative_calling: false\n\n# Subsample arguments\n# subsample: 0.01\n# subsample_seed: 3445\n\n# Multiplex arguments\n# sample_tags_version: \"human\"\n# tag_names: [\"4-mySample\", \"9-myOtherSample\", \"6-alsoThisSample\"]\n\n# VDJ arguments\n# vdj_version: \"human\"\n\n# CWL-runner arguments\nparallel: true\ntimestamps: false\ndryrun: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/ingestion/bd_rhapsody/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/ingestion/bd_rhapsody.html#argument-groups",
    "href": "components/workflows/workflows/ingestion/bd_rhapsody.html#argument-groups",
    "title": "BD Rhapsody",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--mode\nWhether to run a whole transcriptome analysis (WTA) or a targeted analysis.\nstring, required, example: \"wta\"\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to your read files in the FASTQ.GZ format. You may specify as many R1/R2 read pairs as you want.\nList of file, required, example: \"input.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nRefence to map to. For --mode wta, this is the path to STAR index as a tar.gz file. For --mode targeted, this is the path to mRNA reference file for pre-designed, supplemental, or custom panel, in FASTA format\nList of file, required, example: \"reference_genome.tar.gz&#124;reference.fasta\", multiple_sep: \";\"\n\n\n--transcriptome_annotation\nPath to GTF annotation file (only for --mode wta).\nfile, example: \"transcriptome.gtf\"\n\n\n--abseq_reference\nPath to the AbSeq reference file in FASTA format. Only needed if BD AbSeq Ab-Oligos are used.\nList of file, example: \"abseq_reference.fasta\", multiple_sep: \";\"\n\n\n--supplemental_reference\nPath to the supplemental reference file in FASTA format. Only needed if there are additional transgene sequences used in the experiment (only for --mode wta).\nList of file, example: \"supplemental_reference.fasta\", multiple_sep: \";\"\n\n\n--sample_prefix\nSpecify a run name to use as the output file base name. Use only letters, numbers, or hyphens. Do not use special characters or spaces.\nstring, default: \"sample\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_raw\nThe BD Rhapsody output folder as it comes out of the BD Rhapsody pipeline\nfile, required, example: \"output_dir\"\n\n\n--output_h5mu\nThe converted h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nPutative cell calling settings\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--putative_cell_call\nSpecify the dataset to be used for putative cell calling. For putative cell calling using an AbSeq dataset, please provide an AbSeq_Reference fasta file above.\nstring, example: \"mRNA\"\n\n\n--exact_cell_count\nExact cell count - Set a specific number (&gt;=1) of cells as putative, based on those with the highest error-corrected read count\ninteger, example: 10000\n\n\n--disable_putative_calling\nDisable Refined Putative Cell Calling - Determine putative cells using only the basic algorithm (minimum second derivative along the cumulative reads curve). The refined algorithm attempts to remove false positives and recover false negatives, but may not be ideal for certain complex mixtures of cell types. Does not apply if Exact Cell Count is set.\nboolean_true\n\n\n\n\n\nSubsample arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--subsample\nA number &gt;1 or fraction (0 &lt; n &lt; 1) to indicate the number or percentage of reads to subsample.\ndouble, example: 0.01\n\n\n--subsample_seed\nA seed for replicating a previous subsampled run.\ninteger, example: 3445\n\n\n\n\n\nMultiplex arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sample_tags_version\nSpecify if multiplexed run.\nstring, example: \"human\"\n\n\n--tag_names\nTag_Names (optional) - Specify the tag number followed by ‚Äò-‚Äô and the desired sample name to appear in Sample_Tag_Metrics.csv. Do not use the special characters: &, (), [], {}, &lt;&gt;, ?, |\nList of string, example: \"4-mySample\", \"9-myOtherSample\", \"6-alsoThisSample\", multiple_sep: \";\"\n\n\n\n\n\nVDJ arguments\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--vdj_version\nSpecify if VDJ run.\nstring, example: \"human\"\n\n\n\n\n\nCWL-runner arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--parallel\nRun jobs in parallel.\nboolean, default: TRUE\n\n\n--timestamps\nAdd timestamps to the errors, warnings, and notifications.\nboolean_true\n\n\n--dryrun\nIf true, the output directory will only contain the CWL input files, but the pipeline itself will not be executed.\nboolean_true"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/bd_rhapsody.html#authors",
    "href": "components/workflows/workflows/ingestion/bd_rhapsody.html#authors",
    "title": "BD Rhapsody",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/make_reference.html",
    "href": "components/workflows/workflows/ingestion/make_reference.html",
    "title": "Make reference",
    "section": "",
    "text": "ID: make_reference\nNamespace: workflows/ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/make_reference.html#example-commands",
    "href": "components/workflows/workflows/ingestion/make_reference.html#example-commands",
    "title": "Make reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/ingestion/make_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ngenome_fasta: # please fill in - example: \"https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/GRCh38.primary_assembly.genome.fa.gz\"\ntranscriptome_gtf: # please fill in - example: \"https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/gencode.v41.annotation.gtf.gz\"\n# ercc: \"https://assets.thermofisher.com/TFS-Assets/LSG/manuals/ERCC92.zip\"\n\n# Outputs\ntarget: [\"star\"]\n# output_fasta: \"$id.$key.output_fasta.gz\"\n# output_gtf: \"$id.$key.output_gtf.gz\"\n# output_cellranger: \"$id.$key.output_cellranger.gz\"\n# output_bd_rhapsody: \"$id.$key.output_bd_rhapsody.gz\"\n# output_star: \"$id.$key.output_star.gz\"\n\n# Arguments\n# subset_regex: \"(ERCC-00002|chr1)\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/ingestion/make_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/ingestion/make_reference.html#argument-groups",
    "href": "components/workflows/workflows/ingestion/make_reference.html#argument-groups",
    "title": "Make reference",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the reference.\nstring, required, example: \"foo\"\n\n\n--genome_fasta\nReference genome fasta.\nfile, required, example: \"https:/ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/GRCh38.primary_assembly.genome.fa.gz\"\n\n\n--transcriptome_gtf\nReference transcriptome annotation.\nfile, required, example: \"https:/ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/gencode.v41.annotation.gtf.gz\"\n\n\n--ercc\nERCC sequence and annotation file.\nfile, example: \"https:/assets.thermofisher.com/TFS-Assets/LSG/manuals/ERCC92.zip\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--target\nWhich reference indices to generate.\nList of string, default: \"star\", multiple_sep: \";\"\n\n\n--output_fasta\nOutput genome sequence fasta.\nfile, example: \"genome_sequence.fa.gz\"\n\n\n--output_gtf\nOutput transcriptome annotation gtf.\nfile, example: \"transcriptome_annotation.gtf.gz\"\n\n\n--output_cellranger\nOutput index\nfile, example: \"cellranger_index.tar.gz\"\n\n\n--output_bd_rhapsody\nOutput index\nfile, example: \"bdrhap_index.tar.gz\"\n\n\n--output_star\nOutput index\nfile, example: \"star_index.tar.gz\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--subset_regex\nWill subset the reference chromosomes using the given regex.\nstring, example: \"(ERCC-00002&#124;chr1)\""
  },
  {
    "objectID": "components/workflows/workflows/ingestion/make_reference.html#authors",
    "href": "components/workflows/workflows/ingestion/make_reference.html#authors",
    "title": "Make reference",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/cellranger_multi.html",
    "href": "components/workflows/workflows/ingestion/cellranger_multi.html",
    "title": "Cell Ranger multi",
    "section": "",
    "text": "ID: cellranger_multi\nNamespace: workflows/ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/cellranger_multi.html#example-commands",
    "href": "components/workflows/workflows/ingestion/cellranger_multi.html#example-commands",
    "title": "Cell Ranger multi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/ingestion/cellranger_multi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\n# input: [\"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\"]\ngex_reference: # please fill in - example: \"reference_genome.tar.gz\"\n# vdj_reference: \"reference_vdj.tar.gz\"\n# feature_reference: \"feature_reference.csv\"\n# vdj_inner_enrichment_primers: \"enrichment_primers.txt\"\n\n# Outputs\n# output_raw: \"$id.$key.output_raw.output_raw\"\n# output_h5mu: \"$id.$key.output_h5mu.h5mu\"\nuns_metrics: \"metrics_cellranger\"\n\n# Feature type-specific input files\n# gex_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# abc_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# cgc_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# mux_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_t_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_t_gd_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# vdj_b_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n# agc_input: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\n\n# Cell multiplexing parameters\n# cell_multiplex_sample_id: \"foo\"\n# cell_multiplex_oligo_ids: \"foo\"\n# cell_multiplex_description: \"foo\"\n\n# Gene expression arguments\n# gex_expect_cells: 3000\ngex_chemistry: \"auto\"\ngex_secondary_analysis: false\ngex_generate_bam: true\ngex_include_introns: true\n\n# Library arguments\n# library_id: [\"mysample1\"]\n# library_type: [\"Gene Expression\"]\n# library_subsample: [\"0.5\"]\n# library_lanes: [\"1-4\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/ingestion/cellranger_multi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/ingestion/cellranger_multi.html#argument-groups",
    "href": "components/workflows/workflows/ingestion/cellranger_multi.html#argument-groups",
    "title": "Cell Ranger multi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nThe fastq.gz files to align. Can also be a single directory containing fastq.gz files.\nList of file, example: \"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--gex_reference\nGenome refence index built by Cell Ranger mkref.\nfile, required, example: \"reference_genome.tar.gz\"\n\n\n--vdj_reference\nVDJ refence index built by Cell Ranger mkref.\nfile, example: \"reference_vdj.tar.gz\"\n\n\n--feature_reference\nPath to the Feature reference CSV file, declaring Feature Barcode constructs and associated barcodes. Required only for Antibody Capture or CRISPR Guide Capture libraries. See https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/using/feature-bc-analysis#feature-ref for more information.\nfile, example: \"feature_reference.csv\"\n\n\n--vdj_inner_enrichment_primers\nV(D)J Immune Profiling libraries: if inner enrichment primers other than those provided in the 10x Genomics kits are used, they need to be specified here as a text file with one primer per line.\nfile, example: \"enrichment_primers.txt\"\n\n\n\n\n\nFeature type-specific input files\nHelper functionality to allow feature type-specific input files, without the need to specify library_type or library_id. The library_id will be inferred from the input paths.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--gex_input\nThe FASTQ files to be analyzed for Gene Expression. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--abc_input\nThe FASTQ files to be analyzed for Antibody Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--cgc_input\nThe FASTQ files to be analyzed for CRISPR Guide Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--mux_input\nThe FASTQ files to be analyzed for Multiplexing Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_input\nThe FASTQ files to be analyzed for VDJ. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_t_input\nThe FASTQ files to be analyzed for VDJ-T. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_t_gd_input\nThe FASTQ files to be analyzed for VDJ-T-GD. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--vdj_b_input\nThe FASTQ files to be analyzed for VDJ-B. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--agc_input\nThe FASTQ files to be analyzed for Antigen Capture. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_raw\nThe raw output folder.\nfile, required, example: \"output_dir\"\n\n\n--output_h5mu\nThe converted h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--uns_metrics\nName of the .uns slot under which to QC metrics (if any).\nstring, default: \"metrics_cellranger\"\n\n\n\n\n\nCell multiplexing parameters\nArguments related to cell multiplexing.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_multiplex_sample_id\nA name to identify a multiplexed sample. Must be alphanumeric with hyphens and/or underscores, and less than 64 characters. Required for Cell Multiplexing libraries.\nstring\n\n\n--cell_multiplex_oligo_ids\nThe Cell Multiplexing oligo IDs used to multiplex this sample. If multiple CMOs were used for a sample, separate IDs with a pipe (e.g., CMO301|CMO302). Required for Cell Multiplexing libraries.\nstring\n\n\n--cell_multiplex_description\nA description for the sample.\nstring\n\n\n\n\n\nGene expression arguments\nArguments relevant to the analysis of gene expression data.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--gex_expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\ninteger, example: 3000\n\n\n--gex_chemistry\nAssay configuration. - auto: autodetect mode - threeprime: Single Cell 3‚Äô - fiveprime: Single Cell 5‚Äô - SC3Pv1: Single Cell 3‚Äô v1 - SC3Pv2: Single Cell 3‚Äô v2 - SC3Pv3: Single Cell 3‚Äô v3 - SC3Pv3LT: Single Cell 3‚Äô v3 LT - SC3Pv3HT: Single Cell 3‚Äô v3 HT - SC5P-PE: Single Cell 5‚Äô paired-end - SC5P-R2: Single Cell 5‚Äô R2-only - SC-FB: Single Cell Antibody-only 3‚Äô v2 or 5‚Äô See https://kb.10xgenomics.com/hc/en-us/articles/115003764132-How-does-Cell-Ranger-auto-detect-chemistry- for more information.\nstring, default: \"auto\"\n\n\n--gex_secondary_analysis\nWhether or not to run the secondary analysis e.g.¬†clustering.\nboolean, default: FALSE\n\n\n--gex_generate_bam\nWhether to generate a BAM file.\nboolean, default: TRUE\n\n\n--gex_include_introns\nInclude intronic reads in count (default=true unless ‚Äìtarget-panel is specified in which case default=false)\nboolean, default: TRUE\n\n\n\n\n\nLibrary arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--library_id\nThe Illumina sample name to analyze. This must exactly match the ‚ÄòSample Name‚Äô part of the FASTQ files specified in the --input argument.\nList of string, example: \"mysample1\", multiple_sep: \";\"\n\n\n--library_type\nThe underlying feature type of the library. Possible values: ‚ÄúGene Expression‚Äù, ‚ÄúVDJ‚Äù, ‚ÄúVDJ-T‚Äù, ‚ÄúVDJ-B‚Äù, ‚ÄúAntibody Capture‚Äù, ‚ÄúCRISPR Guide Capture‚Äù, ‚ÄúMultiplexing Capture‚Äù\nList of string, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--library_subsample\nOptional. The rate at which reads from the provided FASTQ files are sampled. Must be strictly greater than 0 and less than or equal to 1.\nList of string, example: \"0.5\", multiple_sep: \";\"\n\n\n--library_lanes\nLanes associated with this sample. Defaults to using all lanes.\nList of string, example: \"1-4\", multiple_sep: \";\""
  },
  {
    "objectID": "components/workflows/workflows/ingestion/cellranger_multi.html#authors",
    "href": "components/workflows/workflows/ingestion/cellranger_multi.html#authors",
    "title": "Cell Ranger multi",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/workflows/rna/rna_singlesample.html",
    "href": "components/workflows/workflows/rna/rna_singlesample.html",
    "title": "Rna singlesample",
    "section": "",
    "text": "ID: rna_singlesample\nNamespace: workflows/rna\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/rna/rna_singlesample.html#example-commands",
    "href": "components/workflows/workflows/rna/rna_singlesample.html#example-commands",
    "title": "Rna singlesample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/rna/rna_singlesample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\n# layer: \"foo\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\n\n# Filtering options\n# min_counts: 200\n# max_counts: 5000000\n# min_genes_per_cell: 200\n# max_genes_per_cell: 1500000\n# min_cells_per_gene: 3\n# min_fraction_mito: 0\n# max_fraction_mito: 0.2\n\n# Mitochondrial gene detection\n# var_name_mitochondrial_genes: \"foo\"\n# obs_name_mitochondrial_fraction: \"foo\"\n# var_gene_names: \"gene_symbol\"\nmitochondrial_gene_regex: \"^[mM][tT]-\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/rna/rna_singlesample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/rna/rna_singlesample.html#argument-groups",
    "href": "components/workflows/workflows/rna/rna_singlesample.html#argument-groups",
    "title": "Rna singlesample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nInput layer to start from. By default, .X will be used.\nstring\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nFiltering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--min_genes_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--max_genes_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--min_cells_per_gene\nMinimum of non-zero values per gene.\ninteger, example: 3\n\n\n--min_fraction_mito\nMinimum fraction of UMIs that are mitochondrial. Requires ‚Äìobs_name_mitochondrial_fraction.\ndouble, example: 0\n\n\n--max_fraction_mito\nMaximum fraction of UMIs that are mitochondrial. Requires ‚Äìobs_name_mitochondrial_fraction.\ndouble, example: 0.2\n\n\n\n\n\nMitochondrial gene detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_name_mitochondrial_genes\nIn which .var slot to store a boolean array corresponding the mitochondrial genes.\nstring\n\n\n--obs_name_mitochondrial_fraction\nWhen specified, write the fraction of counts originating from mitochondrial genes (based on ‚Äìmitochondrial_gene_regex) to an .obs column with the specified name. Requires ‚Äìvar_name_mitochondrial_genes.\nstring\n\n\n--var_gene_names\n.var column name to be used to detect mitochondrial genes instead of .var_names (default if not set). Gene names matching with the regex value from ‚Äìmitochondrial_gene_regex will be identified as a mitochondrial gene.\nstring, example: \"gene_symbol\"\n\n\n--mitochondrial_gene_regex\nRegex string that identifies mitochondrial genes from ‚Äìvar_gene_names. By default will detect human and mouse mitochondrial genes from a gene symbol.\nstring, default: \"^[mM][tT]-\""
  },
  {
    "objectID": "components/workflows/workflows/rna/rna_singlesample.html#authors",
    "href": "components/workflows/workflows/rna/rna_singlesample.html#authors",
    "title": "Rna singlesample",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (author, maintainer)\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/workflows/integration/harmony_leiden.html",
    "href": "components/workflows/workflows/integration/harmony_leiden.html",
    "title": "Harmony leiden",
    "section": "",
    "text": "ID: harmony_leiden\nNamespace: workflows/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/integration/harmony_leiden.html#example-commands",
    "href": "components/workflows/workflows/integration/harmony_leiden.html#example-commands",
    "title": "Harmony leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/integration/harmony_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Neighbour calculation\nuns_neighbors: \"harmonypy_integration_neighbors\"\nobsp_neighbor_distances: \"harmonypy_integration_distances\"\nobsp_neighbor_connectivities: \"harmonypy_integration_connectivities\"\n\n# Harmony integration options\nembedding: \"X_pca\"\nobsm_integrated: \"X_pca_integrated\"\nobs_covariates: # please fill in - example: [\"batch\", \"sample\"]\ntheta: [2]\n\n# Clustering options\nobs_cluster: \"harmony_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_leiden_harmony_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/integration/harmony_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/integration/harmony_leiden.html#argument-groups",
    "href": "components/workflows/workflows/integration/harmony_leiden.html#argument-groups",
    "title": "Harmony leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"harmonypy_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"harmonypy_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"harmonypy_integration_connectivities\"\n\n\n\n\n\nHarmony integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--embedding\nEmbedding to use as input\nstring, default: \"X_pca\"\n\n\n--obsm_integrated\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_pca_integrated\"\n\n\n--obs_covariates\nThe .obs field(s) that define the covariate(s) to regress out.\nList of string, required, example: \"batch\", \"sample\", multiple_sep: \";\"\n\n\n--theta\nDiversity clustering penalty parameter. Specify for each variable in group.by.vars. theta=0 does not encourage any diversity. Larger values of theta result in more diverse clusters.‚Äù\nList of double, default: 2, multiple_sep: \";\"\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‚Äò‚Äìobs_cluster‚Äô suffixed with an underscore and one of the resolutions resolutions specified in ‚Äò‚Äìleiden_resolution‚Äô.\nstring, default: \"harmony_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_harmony_umap\""
  },
  {
    "objectID": "components/workflows/workflows/integration/harmony_leiden.html#authors",
    "href": "components/workflows/workflows/integration/harmony_leiden.html#authors",
    "title": "Harmony leiden",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/workflows/integration/scanorama_leiden.html",
    "href": "components/workflows/workflows/integration/scanorama_leiden.html",
    "title": "Scanorama leiden",
    "section": "",
    "text": "ID: scanorama_leiden\nNamespace: workflows/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/integration/scanorama_leiden.html#example-commands",
    "href": "components/workflows/workflows/integration/scanorama_leiden.html#example-commands",
    "title": "Scanorama leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/integration/scanorama_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Neighbour calculation\nuns_neighbors: \"scanorama_integration_neighbors\"\nobsp_neighbor_distances: \"scanorama_integration_distances\"\nobsp_neighbor_connectivities: \"scanorama_integration_connectivities\"\n\n# Scanorama integration options\nobs_batch: \"sample_id\"\nobsm_input: \"X_pca\"\nobsm_output: \"X_scanorama\"\nknn: 20\nbatch_size: 5000\nsigma: 15\napprox: true\nalpha: 0.1\n\n# Clustering options\nobs_cluster: \"scanorama_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_leiden_scanorama_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/integration/scanorama_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/integration/scanorama_leiden.html#argument-groups",
    "href": "components/workflows/workflows/integration/scanorama_leiden.html#argument-groups",
    "title": "Scanorama leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"scanorama_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"scanorama_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"scanorama_integration_connectivities\"\n\n\n\n\n\nScanorama integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--obsm_input\n.obsm slot that points to embedding to run scanorama on.\nstring, default: \"X_pca\"\n\n\n--obsm_output\nThe name of the field in adata.obsm where the integrated embeddings will be stored after running this function. Defaults to X_scanorama.\nstring, default: \"X_scanorama\"\n\n\n--knn\nNumber of nearest neighbors to use for matching.\ninteger, default: 20\n\n\n--batch_size\nThe batch size used in the alignment vector computation. Useful when integrating very large (&gt;100k samples) datasets. Set to large value that runs within available memory.\ninteger, default: 5000\n\n\n--sigma\nCorrection smoothing parameter on Gaussian kernel.\ndouble, default: 15\n\n\n--approx\nUse approximate nearest neighbors with Python annoy; greatly speeds up matching runtime.\nboolean, default: TRUE\n\n\n--alpha\nAlignment score minimum cutoff\ndouble, default: 0.1\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‚Äò‚Äìobs_cluster‚Äô suffixed with an underscore and one of the resolutions specified in ‚Äò‚Äìleiden_resolution‚Äô.\nstring, default: \"scanorama_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_scanorama_umap\""
  },
  {
    "objectID": "components/workflows/workflows/integration/scanorama_leiden.html#authors",
    "href": "components/workflows/workflows/integration/scanorama_leiden.html#authors",
    "title": "Scanorama leiden",
    "section": "Authors",
    "text": "Authors\n\nMauro Saporita   (author)\nPovilas Gibas   (author)"
  },
  {
    "objectID": "components/workflows/workflows/prot/prot_multisample.html",
    "href": "components/workflows/workflows/prot/prot_multisample.html",
    "title": "Prot multisample",
    "section": "",
    "text": "ID: prot_multisample\nNamespace: workflows/prot\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/prot/prot_multisample.html#example-commands",
    "href": "components/workflows/workflows/prot/prot_multisample.html#example-commands",
    "title": "Prot multisample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/prot/prot_multisample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"concatenated\"\ninput: # please fill in - example: \"dataset.h5mu\"\n# layer: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# QC metrics calculation options\n# var_qc_metrics: [\"ercc\", \"highly_variable\"]\ntop_n_vars: [50, 100, 200, 500]\noutput_obs_num_nonzero_vars: \"num_nonzero_vars\"\noutput_obs_total_counts_vars: \"total_counts\"\noutput_var_num_nonzero_obs: \"num_nonzero_obs\"\noutput_var_total_counts_obs: \"total_counts\"\noutput_var_obs_mean: \"obs_mean\"\noutput_var_pct_dropout: \"pct_dropout\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/prot/prot_multisample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/prot/prot_multisample.html#argument-groups",
    "href": "components/workflows/workflows/prot/prot_multisample.html#argument-groups",
    "title": "Prot multisample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the concatenated file\nstring, required, example: \"concatenated\"\n\n\n--input\nPath to the samples.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nInput layer to use. If not specified, .X is used.\nstring\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‚ÄòTrue‚Äô, compared to the total sum of the values for all genes. Defaults to the value from ‚Äìvar_name_mitochondrial_genes.\nList of string, example: \"ercc,highly_variable\", multiple_sep: \";\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \";\"\n\n\n--output_obs_num_nonzero_vars\nName of column in .obs describing, for each observation, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each row the number of columns that contain data.\nstring, default: \"num_nonzero_vars\"\n\n\n--output_obs_total_counts_vars\nName of the column for .obs describing, for each observation (row), the sum of the stored values in the columns.\nstring, default: \"total_counts\"\n\n\n--output_var_num_nonzero_obs\nName of column describing, for each feature, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each column the number of rows that contain data.\nstring, default: \"num_nonzero_obs\"\n\n\n--output_var_total_counts_obs\nName of the column in .var describing, for each feature (column), the sum of the stored values in the rows.\nstring, default: \"total_counts\"\n\n\n--output_var_obs_mean\nName of the column in .obs providing the mean of the values in each row.\nstring, default: \"obs_mean\"\n\n\n--output_var_pct_dropout\nName of the column in .obs providing for each feature the percentage of observations the feature does not appear on (i.e.¬†is missing). Same as --output_var_num_nonzero_obs but percentage based.\nstring, default: \"pct_dropout\""
  },
  {
    "objectID": "components/workflows/workflows/prot/prot_multisample.html#authors",
    "href": "components/workflows/workflows/prot/prot_multisample.html#authors",
    "title": "Prot multisample",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/workflows/prot/prot_singlesample.html",
    "href": "components/workflows/workflows/prot/prot_singlesample.html",
    "title": "Prot singlesample",
    "section": "",
    "text": "ID: prot_singlesample\nNamespace: workflows/prot\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/prot/prot_singlesample.html#example-commands",
    "href": "components/workflows/workflows/prot/prot_singlesample.html#example-commands",
    "title": "Prot singlesample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/prot/prot_singlesample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\n# layer: \"foo\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\n\n# Filtering options\n# min_counts: 200\n# max_counts: 5000000\n# min_proteins_per_cell: 200\n# max_proteins_per_cell: 1500000\n# min_cells_per_protein: 3\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/prot/prot_singlesample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/prot/prot_singlesample.html#argument-groups",
    "href": "components/workflows/workflows/prot/prot_singlesample.html#argument-groups",
    "title": "Prot singlesample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nInput layer to start from. By default, .X will be used.\nstring\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nFiltering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--min_proteins_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--max_proteins_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--min_cells_per_protein\nMinimum of non-zero values per gene.\ninteger, example: 3"
  },
  {
    "objectID": "components/workflows/workflows/prot/prot_singlesample.html#authors",
    "href": "components/workflows/workflows/prot/prot_singlesample.html#authors",
    "title": "Prot singlesample",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (author, maintainer)\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/workflows/integration/scvi_leiden.html",
    "href": "components/workflows/workflows/integration/scvi_leiden.html",
    "title": "Scvi leiden",
    "section": "",
    "text": "ID: scvi_leiden\nNamespace: workflows/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/integration/scvi_leiden.html#example-commands",
    "href": "components/workflows/workflows/integration/scvi_leiden.html#example-commands",
    "title": "Scvi leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/integration/scvi_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_model: \"$id.$key.output_model.output_model\"\n\n# Neighbour calculation\nuns_neighbors: \"scvi_integration_neighbors\"\nobsp_neighbor_distances: \"scvi_integration_distances\"\nobsp_neighbor_connectivities: \"scvi_integration_connectivities\"\n\n# Scvi integration options\nobs_batch: # please fill in - example: \"foo\"\nobsm_output: \"X_scvi_integrated\"\n# var_input: \"foo\"\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n# max_epochs: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30\n\n# Clustering options\nobs_cluster: \"scvi_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_scvi_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/integration/scvi_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/integration/scvi_leiden.html#argument-groups",
    "href": "components/workflows/workflows/integration/scvi_leiden.html#argument-groups",
    "title": "Scvi leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n--output_model\nFolder where the state of the trained model will be saved to.\nfile, required, example: \"output_dir\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"scvi_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"scvi_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"scvi_integration_connectivities\"\n\n\n\n\n\nScvi integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, required\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_scvi_integrated\"\n\n\n--var_input\n.var column containing highly variable genes. By default, do not subset genes.\nstring\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e.¬†an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‚Äò‚Äìobs_cluster‚Äô suffixed with an underscore and one of the resolutions resolutions specified in ‚Äò‚Äìleiden_resolution‚Äô.\nstring, default: \"scvi_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_scvi_umap\""
  },
  {
    "objectID": "components/workflows/workflows/integration/scvi_leiden.html#authors",
    "href": "components/workflows/workflows/integration/scvi_leiden.html#authors",
    "title": "Scvi leiden",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/workflows/integration/bbknn_leiden.html",
    "href": "components/workflows/workflows/integration/bbknn_leiden.html",
    "title": "Bbknn leiden",
    "section": "",
    "text": "ID: bbknn_leiden\nNamespace: workflows/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/integration/bbknn_leiden.html#example-commands",
    "href": "components/workflows/workflows/integration/bbknn_leiden.html#example-commands",
    "title": "Bbknn leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/integration/bbknn_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Bbknn\nobsm_input: \"X_pca\"\nobs_batch: \"sample_id\"\nuns_output: \"bbknn_integration_neighbors\"\nobsp_distances: \"bbknn_integration_distances\"\nobsp_connectivities: \"bbknn_integration_connectivities\"\nn_neighbors_within_batch: 3\nn_pcs: 50\n# n_trim: 123\n\n# Clustering options\nobs_cluster: \"bbknn_integration_leiden\"\nleiden_resolution: [1]\n\n# UMAP options\nobsm_umap: \"X_leiden_bbknn_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/integration/bbknn_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/integration/bbknn_leiden.html#argument-groups",
    "href": "components/workflows/workflows/integration/bbknn_leiden.html#argument-groups",
    "title": "Bbknn leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nBbknn\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_input\nThe dimensionality reduction in .obsm to use for neighbour detection. Defaults to X_pca.\nstring, default: \"X_pca\"\n\n\n--obs_batch\n.obs column name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--uns_output\nMandatory .uns slot to store various neighbor output objects.\nstring, default: \"bbknn_integration_neighbors\"\n\n\n--obsp_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"bbknn_integration_distances\"\n\n\n--obsp_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"bbknn_integration_connectivities\"\n\n\n--n_neighbors_within_batch\nHow many top neighbours to report for each batch; total number of neighbours in the initial k-nearest-neighbours computation will be this number times the number of batches.\ninteger, default: 3\n\n\n--n_pcs\nHow many dimensions (in case of PCA, principal components) to use in the analysis.\ninteger, default: 50\n\n\n--n_trim\nTrim the neighbours of each cell to these many top connectivities. May help with population independence and improve the tidiness of clustering. The lower the value the more independent the individual populations, at the cost of more conserved batch effect. If None (default), sets the parameter value automatically to 10 times neighbors_within_batch times the number of batches. Set to 0 to skip.\ninteger\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‚Äò‚Äìobs_cluster‚Äô suffixed with an underscore and one of the resolutions resolutions specified in ‚Äò‚Äìleiden_resolution‚Äô.\nstring, default: \"bbknn_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nUMAP options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_bbknn_umap\""
  },
  {
    "objectID": "components/workflows/workflows/integration/bbknn_leiden.html#authors",
    "href": "components/workflows/workflows/integration/bbknn_leiden.html#authors",
    "title": "Bbknn leiden",
    "section": "Authors",
    "text": "Authors\n\nMauro Saporita   (author)\nPovilas Gibas   (author)"
  },
  {
    "objectID": "components/workflows/workflows/integration/totalvi_leiden.html",
    "href": "components/workflows/workflows/integration/totalvi_leiden.html",
    "title": "Totalvi leiden",
    "section": "",
    "text": "ID: totalvi_leiden\nNamespace: workflows/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/integration/totalvi_leiden.html#example-commands",
    "href": "components/workflows/workflows/integration/totalvi_leiden.html#example-commands",
    "title": "Totalvi leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/integration/totalvi_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\nprot_modality: \"prot\"\nreference: # please fill in - example: \"path/to/file\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# reference_model_path: \"$id.$key.reference_model_path.reference_model_path\"\n# query_model_path: \"$id.$key.query_model_path.query_model_path\"\n\n# General TotalVI Options\nobs_batch: \"sample_id\"\nmax_epochs: 400\nmax_query_epochs: 200\nweight_decay: 0.0\nforce_retrain: false\n# var_input: \"foo\"\n\n# TotalVI integration options RNA\nrna_reference_modality: \"rna\"\nrna_obsm_output: \"X_totalvi\"\n\n# TotalVI integration options ADT\nprot_reference_modality: \"prot\"\nprot_obsm_output: \"X_totalvi\"\n\n# Neighbour calculation RNA\nrna_uns_neighbors: \"totalvi_integration_neighbors\"\nrna_obsp_neighbor_distances: \"totalvi_integration_distances\"\nrna_obsp_neighbor_connectivities: \"totalvi_integration_connectivities\"\n\n# Neighbour calculation ADT\nprot_uns_neighbors: \"totalvi_integration_neighbors\"\nprot_obsp_neighbor_distances: \"totalvi_integration_distances\"\nprot_obsp_neighbor_connectivities: \"totalvi_integration_connectivities\"\n\n# Clustering options RNA\nrna_obs_cluster: \"totalvi_integration_leiden\"\nrna_leiden_resolution: [1]\n\n# Clustering options ADT\nprot_obs_cluster: \"totalvi_integration_leiden\"\nprot_leiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_totalvi_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/integration/totalvi_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/integration/totalvi_leiden.html#argument-groups",
    "href": "components/workflows/workflows/integration/totalvi_leiden.html#argument-groups",
    "title": "Totalvi leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--prot_modality\nWhich modality to process.\nstring, default: \"prot\"\n\n\n--reference\nInput h5mu file with reference data to train the TOTALVI model.\nfile, required\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n--reference_model_path\nDirectory with the reference model. If not exists, trained model will be saved there\nfile, default: \"totalvi_model_reference\"\n\n\n--query_model_path\nDirectory, where the query model will be saved\nfile, default: \"totalvi_model_query\"\n\n\n\n\n\nGeneral TotalVI Options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\n.Obs column name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--max_epochs\nNumber of passes through the dataset\ninteger, default: 400\n\n\n--max_query_epochs\nNumber of passes through the dataset, when fine-tuning model for query\ninteger, default: 200\n\n\n--weight_decay\nWeight decay, when fine-tuning model for query\ndouble, default: 0\n\n\n--force_retrain\nIf true, retrain the model and save it to reference_model_path\nboolean_true\n\n\n--var_input\nBoolean .var column to subset data with (e.g.¬†containing highly variable genes). By default, do not subset genes.\nstring\n\n\n\n\n\nTotalVI integration options RNA\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_reference_modality\n\nstring, default: \"rna\"\n\n\n--rna_obsm_output\nIn which .obsm slot to store the normalized RNA from TOTALVI.\nstring, default: \"X_totalvi\"\n\n\n\n\n\nTotalVI integration options ADT\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_reference_modality\nName of the modality containing proteins in the reference\nstring, default: \"prot\"\n\n\n--prot_obsm_output\nIn which .obsm slot to store the normalized protein data from TOTALVI.\nstring, default: \"X_totalvi\"\n\n\n\n\n\nNeighbour calculation RNA\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"totalvi_integration_neighbors\"\n\n\n--rna_obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_distances\"\n\n\n--rna_obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_connectivities\"\n\n\n\n\n\nNeighbour calculation ADT\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"totalvi_integration_neighbors\"\n\n\n--prot_obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_distances\"\n\n\n--prot_obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_connectivities\"\n\n\n\n\n\nClustering options RNA\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‚Äò‚Äìobs_cluster‚Äô suffixed with an underscore and one of the resolutions resolutions specified in ‚Äò‚Äìleiden_resolution‚Äô.\nstring, default: \"totalvi_integration_leiden\"\n\n\n--rna_leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nClustering options ADT\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‚Äò‚Äìobs_cluster‚Äô suffixed with an underscore and one of the resolutions resolutions specified in ‚Äò‚Äìleiden_resolution‚Äô.\nstring, default: \"totalvi_integration_leiden\"\n\n\n--prot_leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \";\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_totalvi_umap\""
  },
  {
    "objectID": "components/workflows/workflows/integration/totalvi_leiden.html#authors",
    "href": "components/workflows/workflows/integration/totalvi_leiden.html#authors",
    "title": "Totalvi leiden",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/workflows/rna/rna_multisample.html",
    "href": "components/workflows/workflows/rna/rna_multisample.html",
    "title": "Rna multisample",
    "section": "",
    "text": "ID: rna_multisample\nNamespace: workflows/rna\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/rna/rna_multisample.html#example-commands",
    "href": "components/workflows/workflows/rna/rna_multisample.html#example-commands",
    "title": "Rna multisample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/rna/rna_multisample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"concatenated\"\ninput: # please fill in - example: \"dataset.h5mu\"\nmodality: \"rna\"\n# layer: \"foo\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\n\n# Filtering highly variable features\nhighly_variable_features_var_output: \"filter_with_hvg\"\nhighly_variable_features_obs_batch_key: \"sample_id\"\nhighly_variable_features_flavor: \"seurat\"\n# highly_variable_features_n_top_features: 123\n\n# QC metrics calculation options\nvar_qc_metrics: [\"filter_with_hvg\"]\ntop_n_vars: [50, 100, 200, 500]\noutput_obs_num_nonzero_vars: \"num_nonzero_vars\"\noutput_obs_total_counts_vars: \"total_counts\"\noutput_var_num_nonzero_obs: \"num_nonzero_obs\"\noutput_var_total_counts_obs: \"total_counts\"\noutput_var_obs_mean: \"obs_mean\"\noutput_var_pct_dropout: \"pct_dropout\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/rna/rna_multisample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/rna/rna_multisample.html#argument-groups",
    "href": "components/workflows/workflows/rna/rna_multisample.html#argument-groups",
    "title": "Rna multisample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the concatenated file\nstring, required, example: \"concatenated\"\n\n\n--input\nPath to the samples.\nfile, required, example: \"dataset.h5mu\"\n\n\n--modality\nModality to process.\nstring, default: \"rna\"\n\n\n--layer\nInput layer to use. If not specified, .X is used.\nstring\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nFiltering highly variable features\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--highly_variable_features_var_output\nIn which .var slot to store a boolean array corresponding to the highly variable features.\nstring, default: \"filter_with_hvg\"\n\n\n--highly_variable_features_obs_batch_key\nIf specified, highly-variable features are selected within each batch separately and merged. This simple process avoids the selection of batch-specific features and acts as a lightweight batch correction method. For all flavors, featues are first sorted by how many batches they are highly variable. For dispersion-based flavors ties are broken by normalized dispersion. If flavor = ‚Äòseurat_v3‚Äô, ties are broken by the median (across batches) rank based on within-batch normalized variance.\nstring, default: \"sample_id\"\n\n\n--highly_variable_features_flavor\nChoose the flavor for identifying highly variable features. For the dispersion based methods in their default workflows, Seurat passes the cutoffs whereas Cell Ranger passes n_top_features.\nstring, default: \"seurat\"\n\n\n--highly_variable_features_n_top_features\nNumber of highly-variable features to keep. Mandatory if filter_with_hvg_flavor is set to ‚Äòseurat_v3‚Äô.\ninteger\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‚ÄòTrue‚Äô, compared to the total sum of the values for all genes.\nList of string, default: \"filter_with_hvg\", example: \"ercc,highly_variable\", multiple_sep: \";\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \";\"\n\n\n--output_obs_num_nonzero_vars\nName of column in .obs describing, for each observation, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each row the number of columns that contain data.\nstring, default: \"num_nonzero_vars\"\n\n\n--output_obs_total_counts_vars\nName of the column for .obs describing, for each observation (row), the sum of the stored values in the columns.\nstring, default: \"total_counts\"\n\n\n--output_var_num_nonzero_obs\nName of column describing, for each feature, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each column the number of rows that contain data.\nstring, default: \"num_nonzero_obs\"\n\n\n--output_var_total_counts_obs\nName of the column in .var describing, for each feature (column), the sum of the stored values in the rows.\nstring, default: \"total_counts\"\n\n\n--output_var_obs_mean\nName of the column in .obs providing the mean of the values in each row.\nstring, default: \"obs_mean\"\n\n\n--output_var_pct_dropout\nName of the column in .obs providing for each feature the percentage of observations the feature does not appear on (i.e.¬†is missing). Same as --num_nonzero_obs but percentage based.\nstring, default: \"pct_dropout\""
  },
  {
    "objectID": "components/workflows/workflows/rna/rna_multisample.html#authors",
    "href": "components/workflows/workflows/rna/rna_multisample.html#authors",
    "title": "Rna multisample",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (author, maintainer)\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/cellranger_mapping.html",
    "href": "components/workflows/workflows/ingestion/cellranger_mapping.html",
    "title": "Cell Ranger mapping",
    "section": "",
    "text": "ID: cellranger_mapping\nNamespace: workflows/ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/cellranger_mapping.html#example-commands",
    "href": "components/workflows/workflows/ingestion/cellranger_mapping.html#example-commands",
    "title": "Cell Ranger mapping",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/ingestion/cellranger_mapping/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: [\"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\"]\nreference: # please fill in - example: \"reference.tar.gz\"\n\n# Outputs\n# output_raw: \"$id.$key.output_raw.output_raw\"\n# output_h5mu: \"$id.$key.output_h5mu.h5mu\"\nuns_metrics: \"metrics_summary\"\noutput_type: \"raw\"\n\n# Cell Ranger arguments\n# expect_cells: 3000\nchemistry: \"auto\"\nsecondary_analysis: false\ngenerate_bam: true\ninclude_introns: true\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/ingestion/cellranger_mapping/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/ingestion/cellranger_mapping.html#argument-groups",
    "href": "components/workflows/workflows/ingestion/cellranger_mapping.html#argument-groups",
    "title": "Cell Ranger mapping",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nThe fastq.gz files to align. Can also be a single directory containing fastq.gz files.\nList of file, required, example: \"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nThe path to Cell Ranger reference tar.gz file.\nfile, required, example: \"reference.tar.gz\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_raw\nLocation where the output folder from Cell Ranger will be stored.\nfile, required, example: \"output_dir\"\n\n\n--output_h5mu\nThe output from Cell Ranger, converted to h5mu.\nfile, required, example: \"output.h5mu\"\n\n\n--uns_metrics\nName of the .uns slot under which to QC metrics (if any).\nstring, default: \"metrics_summary\"\n\n\n--output_type\nWhich Cell Ranger output to use for converting to h5mu.\nstring, default: \"raw\"\n\n\n\n\n\nCell Ranger arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\ninteger, example: 3000\n\n\n--chemistry\nAssay configuration. - auto: autodetect mode - threeprime: Single Cell 3‚Äô - fiveprime: Single Cell 5‚Äô - SC3Pv1: Single Cell 3‚Äô v1 - SC3Pv2: Single Cell 3‚Äô v2 - SC3Pv3: Single Cell 3‚Äô v3 - SC3Pv3LT: Single Cell 3‚Äô v3 LT - SC3Pv3HT: Single Cell 3‚Äô v3 HT - SC5P-PE: Single Cell 5‚Äô paired-end - SC5P-R2: Single Cell 5‚Äô R2-only - SC-FB: Single Cell Antibody-only 3‚Äô v2 or 5‚Äô See https://kb.10xgenomics.com/hc/en-us/articles/115003764132-How-does-Cell-Ranger-auto-detect-chemistry- for more information.\nstring, default: \"auto\"\n\n\n--secondary_analysis\nWhether or not to run the secondary analysis e.g.¬†clustering.\nboolean, default: FALSE\n\n\n--generate_bam\nWhether to generate a BAM file.\nboolean, default: TRUE\n\n\n--include_introns\nInclude intronic reads in count (default=true unless ‚Äìtarget-panel is specified in which case default=false)\nboolean, default: TRUE"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/cellranger_mapping.html#authors",
    "href": "components/workflows/workflows/ingestion/cellranger_mapping.html#authors",
    "title": "Cell Ranger mapping",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)\nDries De Maeyer   (author)"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/demux.html",
    "href": "components/workflows/workflows/ingestion/demux.html",
    "title": "Demux",
    "section": "",
    "text": "ID: demux\nNamespace: workflows/ingestion\n\n\n\nSource\nConvert .bcl files to .fastq files using bcl2fastq, bcl-convert or Cell Ranger mkfastq."
  },
  {
    "objectID": "components/workflows/workflows/ingestion/demux.html#example-commands",
    "href": "components/workflows/workflows/ingestion/demux.html#example-commands",
    "title": "Demux",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/ingestion/demux/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"bcl_dir\"\nsample_sheet: # please fill in - example: \"bcl_dir\"\ndemultiplexer: \"bcl2fastq\"\n# ignore_missing: true\n# output_fastq: \"$id.$key.output_fastq.output_fastq\"\n# output_fastqc: \"$id.$key.output_fastqc.output_fastqc\"\n# output_multiqc: \"$id.$key.output_multiqc.output_multiqc\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/ingestion/demux/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/ingestion/demux.html#argument-group",
    "href": "components/workflows/workflows/ingestion/demux.html#argument-group",
    "title": "Demux",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nInput run directory\nfile, required, example: \"bcl_dir\"\n\n\n--sample_sheet\nPointer to the sample sheet\nfile, required, example: \"bcl_dir\"\n\n\n--demultiplexer\nThe multiplexer to use, one of bclconvert or mkfastq\nstring, default: \"bcl2fastq\"\n\n\n--ignore_missing\nShould the demultiplexer ignore missing entities (filter, ‚Ä¶)\nboolean\n\n\n--output_fastq\nOutput directory containig fastq files\nfile, required, example: \"fastq_dir\"\n\n\n--output_fastqc\nReports directory produced by FastQC\nfile, example: \"reports_dir\"\n\n\n--output_multiqc\nReports directory produced by MultiQC\nfile, example: \"reports_dir\""
  },
  {
    "objectID": "components/workflows/workflows/ingestion/demux.html#authors",
    "href": "components/workflows/workflows/ingestion/demux.html#authors",
    "title": "Demux",
    "section": "Authors",
    "text": "Authors\n\nToni Verbeiren   (author, maintainer)\nMarijke Van Moerbeke    (author)\nAngela Oliveira Pisco    (author)\nSamuel D‚ÄôSouza   (author)\nRobrecht Cannoodt    (author)"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/cellranger_postprocessing.html",
    "href": "components/workflows/workflows/ingestion/cellranger_postprocessing.html",
    "title": "Cell Ranger post-processing",
    "section": "",
    "text": "ID: cellranger_postprocessing\nNamespace: workflows/ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/cellranger_postprocessing.html#example-commands",
    "href": "components/workflows/workflows/ingestion/cellranger_postprocessing.html#example-commands",
    "title": "Cell Ranger post-processing",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/ingestion/cellranger_postprocessing/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\n\n# Outputs\n# output: \"$id.$key.output.output\"\n\n# Correction arguments\nperform_correction: false\ncellbender_epochs: 150\n\n# Filtering arguments\n# min_genes: 100\n# min_counts: 1000\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/ingestion/cellranger_postprocessing/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/ingestion/cellranger_postprocessing.html#argument-groups",
    "href": "components/workflows/workflows/ingestion/cellranger_postprocessing.html#argument-groups",
    "title": "Cell Ranger post-processing",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nInput h5mu file created by running Cell Ranger and converting its output to h5mu.\nfile, required, example: \"input.h5mu\"\n\n\n\n\n\nOutputs\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe converted h5mu file.\nfile\n\n\n\n\n\nCorrection arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--perform_correction\nWhether or not to run CellBender to perform count correction.\nboolean_true\n\n\n--cellbender_epochs\nNumber of epochs to run CellBender for.\ninteger, default: 150\n\n\n\n\n\nFiltering arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_genes\nMinimum number of counts required for a cell to pass filtering.\ninteger, example: 100\n\n\n--min_counts\nMinimum number of genes expressed required for a cell to pass filtering.\ninteger, example: 1000"
  },
  {
    "objectID": "components/workflows/workflows/ingestion/cellranger_postprocessing.html#authors",
    "href": "components/workflows/workflows/ingestion/cellranger_postprocessing.html#authors",
    "title": "Cell Ranger post-processing",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/workflows/qc/qc.html",
    "href": "components/workflows/workflows/qc/qc.html",
    "title": "Qc",
    "section": "",
    "text": "ID: qc\nNamespace: workflows/qc\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/qc/qc.html#example-commands",
    "href": "components/workflows/workflows/qc/qc.html#example-commands",
    "title": "Qc",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/qc/qc/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"raw_counts\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Mitochondrial Gene Detection\n# var_name_mitochondrial_genes: \"foo\"\n# obs_name_mitochondrial_fraction: \"foo\"\n# var_gene_names: \"gene_symbol\"\nmitochondrial_gene_regex: \"^[mM][tT]-\"\n\n# QC metrics calculation options\n# var_qc_metrics: [\"ercc\", \"highly_variable\"]\ntop_n_vars: [50, 100, 200, 500]\noutput_obs_num_nonzero_vars: \"num_nonzero_vars\"\noutput_obs_total_counts_vars: \"total_counts\"\noutput_var_num_nonzero_obs: \"num_nonzero_obs\"\noutput_var_total_counts_obs: \"total_counts\"\noutput_var_obs_mean: \"obs_mean\"\noutput_var_pct_dropout: \"pct_dropout\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/qc/qc/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/qc/qc.html#argument-groups",
    "href": "components/workflows/workflows/qc/qc.html#argument-groups",
    "title": "Qc",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--layer\nLayer to calculate qc metrics for.\nstring, example: \"raw_counts\"\n\n\n\n\n\nMitochondrial Gene Detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_name_mitochondrial_genes\nIn which .var slot to store a boolean array corresponding the mitochondrial genes.\nstring\n\n\n--obs_name_mitochondrial_fraction\n.Obs slot to store the fraction of reads found to be mitochondrial. Defaults to ‚Äòfraction_‚Äô suffixed by the value of ‚Äìvar_name_mitochondrial_genes\nstring\n\n\n--var_gene_names\n.var column name to be used to detect mitochondrial genes instead of .var_names (default if not set). Gene names matching with the regex value from ‚Äìmitochondrial_gene_regex will be identified as a mitochondrial gene.\nstring, example: \"gene_symbol\"\n\n\n--mitochondrial_gene_regex\nRegex string that identifies mitochondrial genes from ‚Äìvar_gene_names. By default will detect human and mouse mitochondrial genes from a gene symbol.\nstring, default: \"^[mM][tT]-\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‚ÄòTrue‚Äô, compared to the total sum of the values for all genes. Defaults to the value from ‚Äìvar_name_mitochondrial_genes.\nList of string, example: \"ercc,highly_variable\", multiple_sep: \";\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \";\"\n\n\n--output_obs_num_nonzero_vars\nName of column in .obs describing, for each observation, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each row the number of columns that contain data.\nstring, default: \"num_nonzero_vars\"\n\n\n--output_obs_total_counts_vars\nName of the column for .obs describing, for each observation (row), the sum of the stored values in the columns.\nstring, default: \"total_counts\"\n\n\n--output_var_num_nonzero_obs\nName of column describing, for each feature, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each column the number of rows that contain data.\nstring, default: \"num_nonzero_obs\"\n\n\n--output_var_total_counts_obs\nName of the column in .var describing, for each feature (column), the sum of the stored values in the rows.\nstring, default: \"total_counts\"\n\n\n--output_var_obs_mean\nName of the column in .obs providing the mean of the values in each row.\nstring, default: \"obs_mean\"\n\n\n--output_var_pct_dropout\nName of the column in .obs providing for each feature the percentage of observations the feature does not appear on (i.e.¬†is missing). Same as --output_var_num_nonzero_obs but percentage based.\nstring, default: \"pct_dropout\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\""
  },
  {
    "objectID": "components/workflows/workflows/qc/qc.html#authors",
    "href": "components/workflows/workflows/qc/qc.html#authors",
    "title": "Qc",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/workflows/multiomics/process_batches.html",
    "href": "components/workflows/workflows/multiomics/process_batches.html",
    "title": "Process batches",
    "section": "",
    "text": "ID: process_batches\nNamespace: workflows/multiomics\n\n\n\nSource\nAn input .h5mu file will first be split in order to run the multisample processing per modality. Next, the modalities are merged again and the integration setup pipeline is executed. Please note that this workflow assumes that samples from multiple pipelines are already concatenated."
  },
  {
    "objectID": "components/workflows/workflows/multiomics/process_batches.html#example-commands",
    "href": "components/workflows/workflows/multiomics/process_batches.html#example-commands",
    "title": "Process batches",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/multiomics/process_batches/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: [\"input.h5mu\"]\n# rna_layer: \"foo\"\n# prot_layer: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Highly variable features detection\nhighly_variable_features_var_output: \"filter_with_hvg\"\nhighly_variable_features_obs_batch_key: \"sample_id\"\n\n# QC metrics calculation options\nvar_qc_metrics: [\"filter_with_hvg\"]\ntop_n_vars: [50, 100, 200, 500]\n\n# PCA options\npca_overwrite: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/multiomics/process_batches/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/multiomics/process_batches.html#argument-groups",
    "href": "components/workflows/workflows/multiomics/process_batches.html#argument-groups",
    "title": "Process batches",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nList of file, required, example: \"input.h5mu\", multiple_sep: \";\"\n\n\n--rna_layer\nInput layer for the gene expression modality. If not specified, .X is used.\nstring\n\n\n--prot_layer\nInput layer for the antibody capture modality. If not specified, .X is used.\nstring\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nHighly variable features detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--highly_variable_features_var_output\nIn which .var slot to store a boolean array corresponding to the highly variable genes.\nstring, default: \"filter_with_hvg\"\n\n\n--highly_variable_features_obs_batch_key\nIf specified, highly-variable genes are selected within each batch separately and merged. This simple process avoids the selection of batch-specific genes and acts as a lightweight batch correction method.\nstring, default: \"sample_id\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‚ÄòTrue‚Äô, compared to the total sum of the values for all genes.\nList of string, default: \"filter_with_hvg\", example: \"ercc,highly_variable\", multiple_sep: \";\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \";\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pca_overwrite\nAllow overwriting slots for PCA output.\nboolean_true"
  },
  {
    "objectID": "components/workflows/workflows/multiomics/process_batches.html#authors",
    "href": "components/workflows/workflows/multiomics/process_batches.html#authors",
    "title": "Process batches",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/workflows/multiomics/dimensionality_reduction.html",
    "href": "components/workflows/workflows/multiomics/dimensionality_reduction.html",
    "title": "Dimensionality reduction",
    "section": "",
    "text": "ID: dimensionality_reduction\nNamespace: workflows/multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/workflows/multiomics/dimensionality_reduction.html#example-commands",
    "href": "components/workflows/workflows/multiomics/dimensionality_reduction.html#example-commands",
    "title": "Dimensionality reduction",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script ./src/workflows/multiomics/dimensionality_reduction/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# PCA options\nobsm_pca: \"X_pca\"\n# var_pca_feature_selection: \"foo\"\npca_overwrite: false\n\n# Neighbour calculation\nuns_neighbors: \"neighbors\"\nobsp_neighbor_distances: \"distances\"\nobsp_neighbor_connectivities: \"connectivities\"\n\n# Umap options\nobsm_umap: \"X_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script ./src/workflows/multiomics/dimensionality_reduction/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/workflows/multiomics/dimensionality_reduction.html#argument-groups",
    "href": "components/workflows/workflows/multiomics/dimensionality_reduction.html#argument-groups",
    "title": "Dimensionality reduction",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_pca\nIn which .obsm slot to store the resulting PCA embedding.\nstring, default: \"X_pca\"\n\n\n--var_pca_feature_selection\nColumn name in .var matrix that will be used to select which genes to run the PCA on.\nstring\n\n\n--pca_overwrite\nAllow overwriting slots for PCA output.\nboolean_true\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"connectivities\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_umap\""
  },
  {
    "objectID": "components/workflows/workflows/multiomics/dimensionality_reduction.html#authors",
    "href": "components/workflows/workflows/multiomics/dimensionality_reduction.html#authors",
    "title": "Dimensionality reduction",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/integration/scvi/scvi.html",
    "href": "components/workflows/integration/scvi/scvi.html",
    "title": "Scvi",
    "section": "",
    "text": "ID: scvi\nNamespace: integration/scvi\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/integration/scvi/scvi.html#example-commands",
    "href": "components/workflows/integration/scvi/scvi.html#example-commands",
    "title": "Scvi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -main-script workflows/multiomics/integration/scvi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_model: \"$id.$key.output_model.output_model\"\n\n# Neighbour calculation\nuns_neighbors: \"scvi_integration_neighbors\"\nobsp_neighbor_distances: \"scvi_integration_distances\"\nobsp_neighbor_connectivities: \"scvi_integration_connectivities\"\n\n# Scvi integration options\nobs_batch: # please fill in - example: \"foo\"\nobsm_output: \"X_scvi_integrated\"\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n# max_epochs: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30\n\n# Umap options\nobsm_umap: \"X_scvi_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -profile docker \\\n  -main-script workflows/multiomics/integration/scvi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/integration/scvi/scvi.html#argument-groups",
    "href": "components/workflows/integration/scvi/scvi.html#argument-groups",
    "title": "Scvi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n--output_model\nFolder where the state of the trained model will be saved to.\nfile, required, example: \"output_dir\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"scvi_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"scvi_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"scvi_integration_connectivities\"\n\n\n\n\n\nScvi integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, required\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_scvi_integrated\"\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e.¬†an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_scvi_umap\""
  },
  {
    "objectID": "components/workflows/integration/scvi/scvi.html#authors",
    "href": "components/workflows/integration/scvi/scvi.html#authors",
    "title": "Scvi",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/integration/scvi/scvi.html#visualisation",
    "href": "components/workflows/integration/scvi/scvi.html#visualisation",
    "title": "Scvi",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    p0(Input)\n    p3(toSortedList)\n    p5(flatMap)\n    p13(scvi)\n    p24(find_neighbors)\n    p34(umap)\n    p42(Output)\n    p0--&gt;p3\n    p3--&gt;p5\n    p5--&gt;p13\n    p13--&gt;p24\n    p24--&gt;p34\n    p34--&gt;p42"
  },
  {
    "objectID": "components/workflows/integration/initialize_integration/initialize_integration.html",
    "href": "components/workflows/integration/initialize_integration/initialize_integration.html",
    "title": "Initialize integration",
    "section": "",
    "text": "ID: initialize_integration\nNamespace: integration/initialize_integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/integration/initialize_integration/initialize_integration.html#example-commands",
    "href": "components/workflows/integration/initialize_integration/initialize_integration.html#example-commands",
    "title": "Initialize integration",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -main-script workflows/multiomics/integration/initialize_integration/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# PCA options\nobsm_pca: \"X_pca\"\n# var_pca_feature_selection: \"foo\"\n\n# Neighbour calculation\nuns_neighbors: \"neighbors\"\nobsp_neighbor_distances: \"distances\"\nobsp_neighbor_connectivities: \"connectivities\"\n\n# Umap options\nobsm_umap: \"X_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -profile docker \\\n  -main-script workflows/multiomics/integration/initialize_integration/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/integration/initialize_integration/initialize_integration.html#argument-groups",
    "href": "components/workflows/integration/initialize_integration/initialize_integration.html#argument-groups",
    "title": "Initialize integration",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_pca\nIn which .obsm slot to store the resulting PCA embedding.\nstring, default: \"X_pca\"\n\n\n--var_pca_feature_selection\nColumn name in .var matrix that will be used to select which genes to run the PCA on.\nstring\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"connectivities\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_umap\""
  },
  {
    "objectID": "components/workflows/integration/initialize_integration/initialize_integration.html#authors",
    "href": "components/workflows/integration/initialize_integration/initialize_integration.html#authors",
    "title": "Initialize integration",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/integration/initialize_integration/initialize_integration.html#visualisation",
    "href": "components/workflows/integration/initialize_integration/initialize_integration.html#visualisation",
    "title": "Initialize integration",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    p0(Input)\n    p2(toSortedList)\n    p4(flatMap)\n    p12(pca)\n    p22(find_neighbors)\n    p32(umap)\n    p40(Output)\n    p0--&gt;p2\n    p2--&gt;p4\n    p4--&gt;p12\n    p12--&gt;p22\n    p22--&gt;p32\n    p32--&gt;p40"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html",
    "href": "components/workflows/ingestion/cellranger_mapping.html",
    "title": "Cell Ranger mapping",
    "section": "",
    "text": "ID: cellranger_mapping\nNamespace: ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html#example-commands",
    "href": "components/workflows/ingestion/cellranger_mapping.html#example-commands",
    "title": "Cell Ranger mapping",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/ingestion/cellranger_mapping/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: [\"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\"]\nreference: # please fill in - example: \"reference.tar.gz\"\n\n# Outputs\n# output_raw: \"$id.$key.output_raw.output_raw\"\n# output_h5mu: \"$id.$key.output_h5mu.h5mu\"\nobsm_metrics: \"metrics_summary\"\noutput_type: \"raw\"\n\n# Cell Ranger arguments\n# expect_cells: 3000\nchemistry: \"auto\"\nsecondary_analysis: false\ngenerate_bam: true\ninclude_introns: true\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/ingestion/cellranger_mapping/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html#argument-groups",
    "href": "components/workflows/ingestion/cellranger_mapping.html#argument-groups",
    "title": "Cell Ranger mapping",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nThe fastq.gz files to align. Can also be a single directory containing fastq.gz files.\nList of file, required, example: \"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nThe path to Cell Ranger reference tar.gz file.\nfile, required, example: \"reference.tar.gz\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_raw\nLocation where the output folder from Cell Ranger will be stored.\nfile, required, example: \"output_dir\"\n\n\n--output_h5mu\nThe output from Cell Ranger, converted to h5mu.\nfile, required, example: \"output.h5mu\"\n\n\n--obsm_metrics\nName of the .obsm slot under which to QC metrics (if any).\nstring, default: \"metrics_summary\"\n\n\n--output_type\nWhich Cell Ranger output to use for converting to h5mu.\nstring, default: \"raw\"\n\n\n\n\n\nCell Ranger arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\ninteger, example: 3000\n\n\n--chemistry\nAssay configuration. - auto: autodetect mode - threeprime: Single Cell 3‚Äô - fiveprime: Single Cell 5‚Äô - SC3Pv1: Single Cell 3‚Äô v1 - SC3Pv2: Single Cell 3‚Äô v2 - SC3Pv3: Single Cell 3‚Äô v3 - SC3Pv3LT: Single Cell 3‚Äô v3 LT - SC3Pv3HT: Single Cell 3‚Äô v3 HT - SC5P-PE: Single Cell 5‚Äô paired-end - SC5P-R2: Single Cell 5‚Äô R2-only - SC-FB: Single Cell Antibody-only 3‚Äô v2 or 5‚Äô See https://kb.10xgenomics.com/hc/en-us/articles/115003764132-How-does-Cell-Ranger-auto-detect-chemistry- for more information.\nstring, default: \"auto\"\n\n\n--secondary_analysis\nWhether or not to run the secondary analysis e.g.¬†clustering.\nboolean, default: FALSE\n\n\n--generate_bam\nWhether to generate a BAM file.\nboolean, default: TRUE\n\n\n--include_introns\nInclude intronic reads in count (default=true unless ‚Äìtarget-panel is specified in which case default=false)\nboolean, default: TRUE"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html#authors",
    "href": "components/workflows/ingestion/cellranger_mapping.html#authors",
    "title": "Cell Ranger mapping",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)\nDries De Maeyer   (author)"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html#visualisation",
    "href": "components/workflows/ingestion/cellranger_mapping.html#visualisation",
    "title": "Cell Ranger mapping",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v11(cellranger_count)\n    v13(join)\n    v21(cellranger_count_split)\n    v23(join)\n    v31(from_10xh5_to_h5mu)\n    v33(join)\n    v40(Output)\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v13\n    v4--&gt;v11\n    v11--&gt;v13\n    v13--&gt;v23\n    v13--&gt;v21\n    v21--&gt;v23\n    v23--&gt;v33\n    v23--&gt;v31\n    v31--&gt;v33\n    v33--&gt;v40"
  },
  {
    "objectID": "components/workflows/ingestion/demux.html",
    "href": "components/workflows/ingestion/demux.html",
    "title": "Demux",
    "section": "",
    "text": "ID: demux\nNamespace: ingestion\n\n\n\nSource\nConvert .bcl files to .fastq files using bcl2fastq, bcl-convert or Cell Ranger mkfastq."
  },
  {
    "objectID": "components/workflows/ingestion/demux.html#example-commands",
    "href": "components/workflows/ingestion/demux.html#example-commands",
    "title": "Demux",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/ingestion/demux/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"bcl_dir\"\nsample_sheet: # please fill in - example: \"bcl_dir\"\ndemultiplexer: \"bcl2fastq\"\n# ignore_missing: true\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/ingestion/demux/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/ingestion/demux.html#argument-group",
    "href": "components/workflows/ingestion/demux.html#argument-group",
    "title": "Demux",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nInput run directory\nfile, required, example: \"bcl_dir\"\n\n\n--sample_sheet\nPointer to the sample sheet\nfile, required, example: \"bcl_dir\"\n\n\n--demultiplexer\nThe multiplexer to use, one of bclconvert or mkfastq\nstring, default: \"bcl2fastq\"\n\n\n--ignore_missing\nShould the demultiplexer ignore missing entities (filter, ‚Ä¶)\nboolean"
  },
  {
    "objectID": "components/workflows/ingestion/demux.html#authors",
    "href": "components/workflows/ingestion/demux.html#authors",
    "title": "Demux",
    "section": "Authors",
    "text": "Authors\n\nToni Verbeiren   (author, maintainer)\nMarijke Van Moerbeke    (author)\nAngela Oliveira Pisco    (author)\nSamuel D‚ÄôSouza   (author)\nRobrecht Cannoodt    (author)"
  },
  {
    "objectID": "components/workflows/ingestion/demux.html#visualisation",
    "href": "components/workflows/ingestion/demux.html#visualisation",
    "title": "Demux",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v5(filter)\n    v10(cellranger_mkfastq)\n    v12(join)\n    v35(mix)\n    v15(filter)\n    v20(bcl_convert)\n    v22(join)\n    v25(filter)\n    v30(bcl2fastq)\n    v32(join)\n    v41(fastqc)\n    v43(join)\n    v46(Output)\n    v48(toSortedList)\n    v54(multiqc)\n    v56(join)\n    v59(Output)\n    v64(Output)\n    v4--&gt;v5\n    v4--&gt;v15\n    v4--&gt;v25\n    v0--&gt;v2\n    v2--&gt;v4\n    v5--&gt;v12\n    v5--&gt;v10\n    v10--&gt;v12\n    v12--&gt;v35\n    v15--&gt;v22\n    v15--&gt;v20\n    v20--&gt;v22\n    v22--&gt;v35\n    v25--&gt;v32\n    v25--&gt;v30\n    v30--&gt;v32\n    v32--&gt;v35\n    v35--&gt;v43\n    v35--&gt;v41\n    v41--&gt;v43\n    v43--&gt;v46\n    v35--&gt;v48\n    v48--&gt;v56\n    v48--&gt;v54\n    v54--&gt;v56\n    v56--&gt;v59\n    v35--&gt;v64"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html",
    "title": "Cell Ranger post-processing",
    "section": "",
    "text": "ID: cellranger_postprocessing\nNamespace: ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html#example-commands",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html#example-commands",
    "title": "Cell Ranger post-processing",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/ingestion/cellranger_postprocessing/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\n\n# Outputs\n# output: \"$id.$key.output.output\"\n\n# Correction arguments\nperform_correction: false\ncellbender_epochs: 150\n\n# Filtering arguments\n# min_genes: 100\n# min_counts: 1000\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/ingestion/cellranger_postprocessing/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html#argument-groups",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html#argument-groups",
    "title": "Cell Ranger post-processing",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nInput h5mu file created by running Cell Ranger and converting its output to h5mu.\nfile, required, example: \"input.h5mu\"\n\n\n\n\n\nOutputs\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe converted h5mu file.\nfile\n\n\n\n\n\nCorrection arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--perform_correction\nWhether or not to run CellBender to perform count correction.\nboolean_true\n\n\n--cellbender_epochs\nNumber of epochs to run CellBender for.\ninteger, default: 150\n\n\n\n\n\nFiltering arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_genes\nMinimum number of counts required for a cell to pass filtering.\ninteger, example: 100\n\n\n--min_counts\nMinimum number of genes expressed required for a cell to pass filtering.\ninteger, example: 1000"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html#authors",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html#authors",
    "title": "Cell Ranger post-processing",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html#visualisation",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html#visualisation",
    "title": "Cell Ranger post-processing",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v6(from_10xh5_to_h5mu)\n    v8(join)\n    v12(toSortedList)\n    v14(flatMap)\n    v15(filter)\n    v21(cellbender_remove_background)\n    v23(join)\n    v27(mix)\n    v26(filter)\n    v28(filter)\n    v34(filter_with_counts)\n    v36(join)\n    v40(mix)\n    v39(filter)\n    v46(publish)\n    v48(join)\n    v54(Output)\n    v14--&gt;v15\n    v14--&gt;v26\n    v26--&gt;v27\n    v27--&gt;v28\n    v27--&gt;v39\n    v39--&gt;v40\n    v0--&gt;v8\n    v0--&gt;v6\n    v6--&gt;v8\n    v8--&gt;v12\n    v12--&gt;v14\n    v15--&gt;v23\n    v15--&gt;v21\n    v21--&gt;v23\n    v23--&gt;v27\n    v28--&gt;v36\n    v28--&gt;v34\n    v34--&gt;v36\n    v36--&gt;v40\n    v40--&gt;v48\n    v40--&gt;v46\n    v46--&gt;v48\n    v48--&gt;v54"
  },
  {
    "objectID": "components/workflows/qc/qc.html",
    "href": "components/workflows/qc/qc.html",
    "title": "Qc",
    "section": "",
    "text": "ID: qc\nNamespace: qc\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/qc/qc.html#example-commands",
    "href": "components/workflows/qc/qc.html#example-commands",
    "title": "Qc",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/qc/qc/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"raw_counts\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Mitochondrial Gene Detection\n# var_name_mitochondrial_genes: \"foo\"\n# obs_name_mitochondrial_fraction: \"foo\"\n# var_gene_names: \"gene_symbol\"\nmitochondrial_gene_regex: \"^[mM][tT]-\"\n\n# QC metrics calculation options\n# var_qc_metrics: [\"ercc\", \"highly_variable\"]\ntop_n_vars: [50, 100, 200, 500]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/qc/qc/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/qc/qc.html#argument-groups",
    "href": "components/workflows/qc/qc.html#argument-groups",
    "title": "Qc",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--layer\nLayer to calculate qc metrics for.\nstring, example: \"raw_counts\"\n\n\n\n\n\nMitochondrial Gene Detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_name_mitochondrial_genes\nIn which .var slot to store a boolean array corresponding the mitochondrial genes.\nstring\n\n\n--obs_name_mitochondrial_fraction\n.Obs slot to store the fraction of reads found to be mitochondrial. Defaults to ‚Äòfraction_‚Äô suffixed by the value of ‚Äìvar_name_mitochondrial_genes\nstring\n\n\n--var_gene_names\n.var column name to be used to detect mitochondrial genes instead of .var_names (default if not set). Gene names matching with the regex value from ‚Äìmitochondrial_gene_regex will be identified as a mitochondrial gene.\nstring, example: \"gene_symbol\"\n\n\n--mitochondrial_gene_regex\nRegex string that identifies mitochondrial genes from ‚Äìvar_gene_names. By default will detect human and mouse mitochondrial genes from a gene symbol.\nstring, default: \"^[mM][tT]-\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‚ÄòTrue‚Äô, compared to the total sum of the values for all genes. Defaults to the value from ‚Äìvar_name_mitochondrial_genes.\nList of string, example: \"ercc,highly_variable\", multiple_sep: \",\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\""
  },
  {
    "objectID": "components/workflows/qc/qc.html#authors",
    "href": "components/workflows/qc/qc.html#authors",
    "title": "Qc",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/qc/qc.html#visualisation",
    "href": "components/workflows/qc/qc.html#visualisation",
    "title": "Qc",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v7(filter)\n    v13(grep_annotation_column)\n    v15(join)\n    v19(mix)\n    v18(filter)\n    v25(calculate_qc_metrics)\n    v27(join)\n    v35(publish)\n    v37(join)\n    v41(toSortedList)\n    v43(Output)\n    v18--&gt;v19\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v7\n    v4--&gt;v18\n    v7--&gt;v15\n    v7--&gt;v13\n    v13--&gt;v15\n    v15--&gt;v19\n    v19--&gt;v27\n    v19--&gt;v25\n    v25--&gt;v27\n    v27--&gt;v37\n    v27--&gt;v35\n    v35--&gt;v37\n    v37--&gt;v41\n    v41--&gt;v43"
  },
  {
    "objectID": "components/workflows/multiomics/rna_singlesample.html",
    "href": "components/workflows/multiomics/rna_singlesample.html",
    "title": "Rna singlesample",
    "section": "",
    "text": "ID: rna_singlesample\nNamespace: multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/rna_singlesample.html#example-commands",
    "href": "components/workflows/multiomics/rna_singlesample.html#example-commands",
    "title": "Rna singlesample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/multiomics/rna_singlesample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\n\n# Filtering options\n# min_counts: 200\n# max_counts: 5000000\n# min_genes_per_cell: 200\n# max_genes_per_cell: 1500000\n# min_cells_per_gene: 3\n# min_fraction_mito: 0\n# max_fraction_mito: 0.2\n\n# Mitochondrial gene detection\n# var_name_mitochondrial_genes: \"foo\"\n# obs_name_mitochondrial_fraction: \"foo\"\n# var_gene_names: \"gene_symbol\"\nmitochondrial_gene_regex: \"^[mM][tT]-\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/rna_singlesample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/rna_singlesample.html#argument-groups",
    "href": "components/workflows/multiomics/rna_singlesample.html#argument-groups",
    "title": "Rna singlesample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nFiltering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--min_genes_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--max_genes_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--min_cells_per_gene\nMinimum of non-zero values per gene.\ninteger, example: 3\n\n\n--min_fraction_mito\nMinimum fraction of UMIs that are mitochondrial. Requires ‚Äìobs_name_mitochondrial_fraction.\ndouble, example: 0\n\n\n--max_fraction_mito\nMaximum fraction of UMIs that are mitochondrial. Requires ‚Äìobs_name_mitochondrial_fraction.\ndouble, example: 0.2\n\n\n\n\n\nMitochondrial gene detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_name_mitochondrial_genes\nIn which .var slot to store a boolean array corresponding the mitochondrial genes.\nstring\n\n\n--obs_name_mitochondrial_fraction\nWhen specified, write the fraction of counts originating from mitochondrial genes (based on ‚Äìmitochondrial_gene_regex) to an .obs column with the specified name. Requires ‚Äìvar_name_mitochondrial_genes.\nstring\n\n\n--var_gene_names\n.var column name to be used to detect mitochondrial genes instead of .var_names (default if not set). Gene names matching with the regex value from ‚Äìmitochondrial_gene_regex will be identified as a mitochondrial gene.\nstring, example: \"gene_symbol\"\n\n\n--mitochondrial_gene_regex\nRegex string that identifies mitochondrial genes from ‚Äìvar_gene_names. By default will detect human and mouse mitochondrial genes from a gene symbol.\nstring, default: \"^[mM][tT]-\""
  },
  {
    "objectID": "components/workflows/multiomics/rna_singlesample.html#authors",
    "href": "components/workflows/multiomics/rna_singlesample.html#authors",
    "title": "Rna singlesample",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (author, maintainer)\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/rna_singlesample.html#visualisation",
    "href": "components/workflows/multiomics/rna_singlesample.html#visualisation",
    "title": "Rna singlesample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v10(filter)\n    v16(grep_annotation_column)\n    v18(join)\n    v22(mix)\n    v21(filter)\n    v28(calculate_qc_metrics)\n    v30(join)\n    v38(publish)\n    v40(join)\n    v44(filter)\n    v51(delimit_fraction)\n    v53(join)\n    v57(mix)\n    v56(filter)\n    v63(filter_with_counts)\n    v65(join)\n    v73(do_filter)\n    v75(join)\n    v83(filter_with_scrublet)\n    v85(join)\n    v92(Output)\n    v21--&gt;v22\n    v56--&gt;v57\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v10\n    v4--&gt;v21\n    v10--&gt;v18\n    v10--&gt;v16\n    v16--&gt;v18\n    v18--&gt;v22\n    v22--&gt;v30\n    v22--&gt;v28\n    v28--&gt;v30\n    v30--&gt;v40\n    v30--&gt;v38\n    v38--&gt;v40\n    v40--&gt;v44\n    v40--&gt;v56\n    v44--&gt;v53\n    v44--&gt;v51\n    v51--&gt;v53\n    v53--&gt;v57\n    v57--&gt;v65\n    v57--&gt;v63\n    v63--&gt;v65\n    v65--&gt;v75\n    v65--&gt;v73\n    v73--&gt;v75\n    v75--&gt;v85\n    v75--&gt;v83\n    v83--&gt;v85\n    v85--&gt;v92"
  },
  {
    "objectID": "components/workflows/multiomics/multisample.html",
    "href": "components/workflows/multiomics/multisample.html",
    "title": "Multisample",
    "section": "",
    "text": "ID: multisample\nNamespace: multiomics\n\n\n\nSource\nAn input .h5mu file will first be split in order to run the multisample processing per modality. Next, the modalities are merged again and the integration setup pipeline is executed. Please note that this workflow assumes that samples from multiple pipelines are already concatenated."
  },
  {
    "objectID": "components/workflows/multiomics/multisample.html#example-commands",
    "href": "components/workflows/multiomics/multisample.html#example-commands",
    "title": "Multisample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/multiomics/multisample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Highly variable gene detection\nfilter_with_hvg_var_output: \"filter_with_hvg\"\nfilter_with_hvg_obs_batch_key: \"sample_id\"\n\n# QC metrics calculation options\nvar_qc_metrics: [\"filter_with_hvg\"]\ntop_n_vars: [50, 100, 200, 500]\n\n# PCA options\npca_overwrite: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/multisample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/multisample.html#argument-groups",
    "href": "components/workflows/multiomics/multisample.html#argument-groups",
    "title": "Multisample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"input.h5mu\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nHighly variable gene detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--filter_with_hvg_var_output\nIn which .var slot to store a boolean array corresponding to the highly variable genes.\nstring, default: \"filter_with_hvg\"\n\n\n--filter_with_hvg_obs_batch_key\nIf specified, highly-variable genes are selected within each batch separately and merged. This simple process avoids the selection of batch-specific genes and acts as a lightweight batch correction method.\nstring, default: \"sample_id\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‚ÄòTrue‚Äô, compared to the total sum of the values for all genes.\nList of string, default: \"filter_with_hvg\", example: \"ercc,highly_variable\", multiple_sep: \",\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pca_overwrite\nAllow overwriting slots for PCA output.\nboolean_true"
  },
  {
    "objectID": "components/workflows/multiomics/multisample.html#authors",
    "href": "components/workflows/multiomics/multisample.html#authors",
    "title": "Multisample",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/multiomics/multisample.html#visualisation",
    "href": "components/workflows/multiomics/multisample.html#visualisation",
    "title": "Multisample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v7(filter)\n    v12(split_modalities)\n    v14(join)\n    v21(concat)\n    v17(filter)\n    v19(test_wf:run_wf:split_modalities_workflow:splitStub)\n    v22(flatMap)\n    v24(filter)\n    v27(toSortedList)\n    v29(flatMap)\n    v31(toSortedList)\n    v33(Output)\n    v39(normalize_total)\n    v41(join)\n    v50(log1p)\n    v52(join)\n    v61(delete_layer)\n    v63(join)\n    v72(filter_with_hvg)\n    v74(join)\n    v83(rna_calculate_qc_metrics)\n    v85(join)\n    v149(concat)\n    v90(filter)\n    v93(toSortedList)\n    v95(flatMap)\n    v96(toSortedList)\n    v98(Output)\n    v104(clr)\n    v106(join)\n    v112(filter)\n    v118(grep_annotation_column)\n    v120(join)\n    v124(mix)\n    v123(filter)\n    v130(calculate_qc_metrics)\n    v132(join)\n    v140(publish)\n    v142(join)\n    v146(filter)\n    v150(groupTuple)\n    v156(merge)\n    v158(join)\n    v162(filter)\n    v166(toSortedList)\n    v168(flatMap)\n    v175(pca)\n    v177(join)\n    v186(find_neighbors)\n    v188(join)\n    v197(umap)\n    v199(join)\n    v205(concat)\n    v204(filter)\n    v206(filter)\n    v210(toSortedList)\n    v212(flatMap)\n    v219(pca)\n    v221(join)\n    v230(find_neighbors)\n    v232(join)\n    v241(test_wf:run_wf:integration_setup_workflow:initialize_integration_prot:umap:umap_process1)\n    v243(join)\n    v249(concat)\n    v248(filter)\n    v257(test_wf:run_wf:publish:publish_process1)\n    v259(join)\n    v264(toSortedList)\n    v266(Output)\n    v21--&gt;v22\n    v95--&gt;v96\n    v123--&gt;v124\n    v149--&gt;v150\n    v204--&gt;v205\n    v205--&gt;v206\n    v205--&gt;v248\n    v248--&gt;v249\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v7\n    v4--&gt;v17\n    v7--&gt;v14\n    v7--&gt;v12\n    v12--&gt;v14\n    v14--&gt;v21\n    v17--&gt;v19\n    v19--&gt;v21\n    v22--&gt;v24\n    v22--&gt;v90\n    v22--&gt;v146\n    v24--&gt;v27\n    v27--&gt;v29\n    v29--&gt;v31\n    v31--&gt;v33\n    v29--&gt;v41\n    v29--&gt;v39\n    v39--&gt;v41\n    v41--&gt;v52\n    v41--&gt;v50\n    v50--&gt;v52\n    v52--&gt;v63\n    v52--&gt;v61\n    v61--&gt;v63\n    v63--&gt;v74\n    v63--&gt;v72\n    v72--&gt;v74\n    v74--&gt;v85\n    v74--&gt;v83\n    v83--&gt;v85\n    v85--&gt;v149\n    v90--&gt;v93\n    v93--&gt;v95\n    v96--&gt;v98\n    v95--&gt;v106\n    v95--&gt;v104\n    v104--&gt;v106\n    v106--&gt;v112\n    v106--&gt;v123\n    v112--&gt;v120\n    v112--&gt;v118\n    v118--&gt;v120\n    v120--&gt;v124\n    v124--&gt;v132\n    v124--&gt;v130\n    v130--&gt;v132\n    v132--&gt;v142\n    v132--&gt;v140\n    v140--&gt;v142\n    v142--&gt;v149\n    v146--&gt;v149\n    v150--&gt;v158\n    v150--&gt;v156\n    v156--&gt;v158\n    v158--&gt;v162\n    v158--&gt;v204\n    v162--&gt;v166\n    v166--&gt;v168\n    v168--&gt;v177\n    v168--&gt;v175\n    v175--&gt;v177\n    v177--&gt;v188\n    v177--&gt;v186\n    v186--&gt;v188\n    v188--&gt;v199\n    v188--&gt;v197\n    v197--&gt;v199\n    v199--&gt;v205\n    v206--&gt;v210\n    v210--&gt;v212\n    v212--&gt;v221\n    v212--&gt;v219\n    v219--&gt;v221\n    v221--&gt;v232\n    v221--&gt;v230\n    v230--&gt;v232\n    v232--&gt;v243\n    v232--&gt;v241\n    v241--&gt;v243\n    v243--&gt;v249\n    v249--&gt;v259\n    v249--&gt;v257\n    v257--&gt;v259\n    v259--&gt;v264\n    v264--&gt;v266"
  },
  {
    "objectID": "components/workflows/multiomics/integration/scvi_leiden.html",
    "href": "components/workflows/multiomics/integration/scvi_leiden.html",
    "title": "Scvi leiden",
    "section": "",
    "text": "ID: scvi_leiden\nNamespace: multiomics/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration/scvi_leiden.html#example-commands",
    "href": "components/workflows/multiomics/integration/scvi_leiden.html#example-commands",
    "title": "Scvi leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/multiomics/integration/scvi_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_model: \"$id.$key.output_model.output_model\"\n\n# Neighbour calculation\nuns_neighbors: \"scvi_integration_neighbors\"\nobsp_neighbor_distances: \"scvi_integration_distances\"\nobsp_neighbor_connectivities: \"scvi_integration_connectivities\"\n\n# Scvi integration options\nobs_batch: # please fill in - example: \"foo\"\nobsm_output: \"X_scvi_integrated\"\n# var_input: \"foo\"\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n# max_epochs: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30\n\n# Clustering options\nobs_cluster: \"scvi_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_scvi_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/integration/scvi_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration/scvi_leiden.html#argument-groups",
    "href": "components/workflows/multiomics/integration/scvi_leiden.html#argument-groups",
    "title": "Scvi leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n--output_model\nFolder where the state of the trained model will be saved to.\nfile, required, example: \"output_dir\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"scvi_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"scvi_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"scvi_integration_connectivities\"\n\n\n\n\n\nScvi integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, required\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_scvi_integrated\"\n\n\n--var_input\n.var column containing highly variable genes. By default, do not subset genes.\nstring\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e.¬†an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‚Äò‚Äìobs_cluster‚Äô suffixed with an underscore and one of the resolutions resolutions specified in ‚Äò‚Äìleiden_resolution‚Äô.\nstring, default: \"scvi_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \":\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_scvi_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration/scvi_leiden.html#authors",
    "href": "components/workflows/multiomics/integration/scvi_leiden.html#authors",
    "title": "Scvi leiden",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration/scvi_leiden.html#visualisation",
    "href": "components/workflows/multiomics/integration/scvi_leiden.html#visualisation",
    "title": "Scvi leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v10(scvi)\n    v12(join)\n    v20(find_neighbors)\n    v22(join)\n    v25(filter)\n    v31(leiden)\n    v33(join)\n    v41(move_obsm_to_obs)\n    v43(join)\n    v47(mix)\n    v46(filter)\n    v53(umap)\n    v55(join)\n    v61(Output)\n    v46--&gt;v47\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v12\n    v4--&gt;v10\n    v10--&gt;v12\n    v12--&gt;v22\n    v12--&gt;v20\n    v20--&gt;v22\n    v22--&gt;v25\n    v22--&gt;v46\n    v25--&gt;v33\n    v25--&gt;v31\n    v31--&gt;v33\n    v33--&gt;v43\n    v33--&gt;v41\n    v41--&gt;v43\n    v43--&gt;v47\n    v47--&gt;v55\n    v47--&gt;v53\n    v53--&gt;v55\n    v55--&gt;v61"
  },
  {
    "objectID": "components/workflows/multiomics/integration/scanorama_leiden.html",
    "href": "components/workflows/multiomics/integration/scanorama_leiden.html",
    "title": "Scanorama leiden",
    "section": "",
    "text": "ID: scanorama_leiden\nNamespace: multiomics/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration/scanorama_leiden.html#example-commands",
    "href": "components/workflows/multiomics/integration/scanorama_leiden.html#example-commands",
    "title": "Scanorama leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/multiomics/integration/scanorama_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Neighbour calculation\nuns_neighbors: \"scanorama_integration_neighbors\"\nobsp_neighbor_distances: \"scanorama_integration_distances\"\nobsp_neighbor_connectivities: \"scanorama_integration_connectivities\"\n\n# Scanorama integration options\nobs_batch: \"sample_id\"\nobsm_input: \"X_pca\"\nobsm_output: \"X_scanorama\"\nknn: 20\nbatch_size: 5000\nsigma: 15\napprox: true\nalpha: 0.1\n\n# Clustering options\nobs_cluster: \"scanorama_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_leiden_scanorama_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/integration/scanorama_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration/scanorama_leiden.html#argument-groups",
    "href": "components/workflows/multiomics/integration/scanorama_leiden.html#argument-groups",
    "title": "Scanorama leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"scanorama_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"scanorama_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"scanorama_integration_connectivities\"\n\n\n\n\n\nScanorama integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--obsm_input\n.obsm slot that points to embedding to run scanorama on.\nstring, default: \"X_pca\"\n\n\n--obsm_output\nThe name of the field in adata.obsm where the integrated embeddings will be stored after running this function. Defaults to X_scanorama.\nstring, default: \"X_scanorama\"\n\n\n--knn\nNumber of nearest neighbors to use for matching.\ninteger, default: 20\n\n\n--batch_size\nThe batch size used in the alignment vector computation. Useful when integrating very large (&gt;100k samples) datasets. Set to large value that runs within available memory.\ninteger, default: 5000\n\n\n--sigma\nCorrection smoothing parameter on Gaussian kernel.\ndouble, default: 15\n\n\n--approx\nUse approximate nearest neighbors with Python annoy; greatly speeds up matching runtime.\nboolean, default: TRUE\n\n\n--alpha\nAlignment score minimum cutoff\ndouble, default: 0.1\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‚Äò‚Äìobs_cluster‚Äô suffixed with an underscore and one of the resolutions specified in ‚Äò‚Äìleiden_resolution‚Äô.\nstring, default: \"scanorama_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \":\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_scanorama_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration/scanorama_leiden.html#authors",
    "href": "components/workflows/multiomics/integration/scanorama_leiden.html#authors",
    "title": "Scanorama leiden",
    "section": "Authors",
    "text": "Authors\n\nMauro Saporita   (author)\nPovilas Gibas   (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration/scanorama_leiden.html#visualisation",
    "href": "components/workflows/multiomics/integration/scanorama_leiden.html#visualisation",
    "title": "Scanorama leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v10(scanorama)\n    v12(join)\n    v20(find_neighbors)\n    v22(join)\n    v25(filter)\n    v31(leiden)\n    v33(join)\n    v41(move_obsm_to_obs)\n    v43(join)\n    v47(mix)\n    v46(filter)\n    v53(umap)\n    v55(join)\n    v61(Output)\n    v46--&gt;v47\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v12\n    v4--&gt;v10\n    v10--&gt;v12\n    v12--&gt;v22\n    v12--&gt;v20\n    v20--&gt;v22\n    v22--&gt;v25\n    v22--&gt;v46\n    v25--&gt;v33\n    v25--&gt;v31\n    v31--&gt;v33\n    v33--&gt;v43\n    v33--&gt;v41\n    v41--&gt;v43\n    v43--&gt;v47\n    v47--&gt;v55\n    v47--&gt;v53\n    v53--&gt;v55\n    v55--&gt;v61"
  },
  {
    "objectID": "components/workflows/multiomics/integration/harmony_leiden.html",
    "href": "components/workflows/multiomics/integration/harmony_leiden.html",
    "title": "Harmony leiden",
    "section": "",
    "text": "ID: harmony_leiden\nNamespace: multiomics/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration/harmony_leiden.html#example-commands",
    "href": "components/workflows/multiomics/integration/harmony_leiden.html#example-commands",
    "title": "Harmony leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/multiomics/integration/harmony_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Neighbour calculation\nuns_neighbors: \"harmonypy_integration_neighbors\"\nobsp_neighbor_distances: \"harmonypy_integration_distances\"\nobsp_neighbor_connectivities: \"harmonypy_integration_connectivities\"\n\n# Harmony integration options\nembedding: \"X_pca\"\nobsm_integrated: \"X_pca_integrated\"\nobs_covariates: # please fill in - example: [\"batch\", \"sample\"]\ntheta: [2]\n\n# Clustering options\nobs_cluster: \"harmony_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_leiden_harmony_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/integration/harmony_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration/harmony_leiden.html#argument-groups",
    "href": "components/workflows/multiomics/integration/harmony_leiden.html#argument-groups",
    "title": "Harmony leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"harmonypy_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"harmonypy_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"harmonypy_integration_connectivities\"\n\n\n\n\n\nHarmony integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--embedding\nEmbedding to use as input\nstring, default: \"X_pca\"\n\n\n--obsm_integrated\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_pca_integrated\"\n\n\n--obs_covariates\nThe .obs field(s) that define the covariate(s) to regress out.\nList of string, required, example: \"batch\", \"sample\", multiple_sep: \":\"\n\n\n--theta\nDiversity clustering penalty parameter. Specify for each variable in group.by.vars. theta=0 does not encourage any diversity. Larger values of theta result in more diverse clusters.‚Äù\nList of double, default: 2, multiple_sep: \":\"\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‚Äò‚Äìobs_cluster‚Äô suffixed with an underscore and one of the resolutions resolutions specified in ‚Äò‚Äìleiden_resolution‚Äô.\nstring, default: \"harmony_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \":\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_harmony_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration/harmony_leiden.html#authors",
    "href": "components/workflows/multiomics/integration/harmony_leiden.html#authors",
    "title": "Harmony leiden",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration/harmony_leiden.html#visualisation",
    "href": "components/workflows/multiomics/integration/harmony_leiden.html#visualisation",
    "title": "Harmony leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v10(harmonypy)\n    v12(join)\n    v20(find_neighbors)\n    v22(join)\n    v25(filter)\n    v31(leiden)\n    v33(join)\n    v41(move_obsm_to_obs)\n    v43(join)\n    v47(mix)\n    v46(filter)\n    v53(umap)\n    v55(join)\n    v61(Output)\n    v46--&gt;v47\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v12\n    v4--&gt;v10\n    v10--&gt;v12\n    v12--&gt;v22\n    v12--&gt;v20\n    v20--&gt;v22\n    v22--&gt;v25\n    v22--&gt;v46\n    v25--&gt;v33\n    v25--&gt;v31\n    v31--&gt;v33\n    v33--&gt;v43\n    v33--&gt;v41\n    v41--&gt;v43\n    v43--&gt;v47\n    v47--&gt;v55\n    v47--&gt;v53\n    v53--&gt;v55\n    v55--&gt;v61"
  },
  {
    "objectID": "components/workflows/multiomics/rna_multisample.html",
    "href": "components/workflows/multiomics/rna_multisample.html",
    "title": "Rna multisample",
    "section": "",
    "text": "ID: rna_multisample\nNamespace: multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/rna_multisample.html#example-commands",
    "href": "components/workflows/multiomics/rna_multisample.html#example-commands",
    "title": "Rna multisample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/multiomics/rna_multisample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"concatenated\"\ninput: # please fill in - example: \"dataset.h5mu\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\n\n# Filtering highly variable genes\nfilter_with_hvg_var_output: \"filter_with_hvg\"\nfilter_with_hvg_obs_batch_key: \"sample_id\"\nfilter_with_hvg_flavor: \"seurat\"\n# filter_with_hvg_n_top_genes: 123\n\n# QC metrics calculation options\nvar_qc_metrics: [\"filter_with_hvg\"]\ntop_n_vars: [50, 100, 200, 500]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/rna_multisample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/rna_multisample.html#argument-groups",
    "href": "components/workflows/multiomics/rna_multisample.html#argument-groups",
    "title": "Rna multisample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the concatenated file\nstring, required, example: \"concatenated\"\n\n\n--input\nPath to the samples.\nfile, required, example: \"dataset.h5mu\"\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nFiltering highly variable genes\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--filter_with_hvg_var_output\nIn which .var slot to store a boolean array corresponding to the highly variable genes.\nstring, default: \"filter_with_hvg\"\n\n\n--filter_with_hvg_obs_batch_key\nIf specified, highly-variable genes are selected within each batch separately and merged. This simple process avoids the selection of batch-specific genes and acts as a lightweight batch correction method. For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If flavor = ‚Äòseurat_v3‚Äô, ties are broken by the median (across batches) rank based on within-batch normalized variance.\nstring, default: \"sample_id\"\n\n\n--filter_with_hvg_flavor\nChoose the flavor for identifying highly variable genes. For the dispersion based methods in their default workflows, Seurat passes the cutoffs whereas Cell Ranger passes n_top_genes.\nstring, default: \"seurat\"\n\n\n--filter_with_hvg_n_top_genes\nNumber of highly-variable genes to keep. Mandatory if filter_with_hvg_flavor is set to ‚Äòseurat_v3‚Äô.\ninteger\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‚ÄòTrue‚Äô, compared to the total sum of the values for all genes.\nList of string, default: \"filter_with_hvg\", example: \"ercc,highly_variable\", multiple_sep: \",\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\""
  },
  {
    "objectID": "components/workflows/multiomics/rna_multisample.html#authors",
    "href": "components/workflows/multiomics/rna_multisample.html#authors",
    "title": "Rna multisample",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (author, maintainer)\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/rna_multisample.html#visualisation",
    "href": "components/workflows/multiomics/rna_multisample.html#visualisation",
    "title": "Rna multisample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v3(toSortedList)\n    v5(flatMap)\n    v7(toSortedList)\n    v9(Output)\n    v15(normalize_total)\n    v17(join)\n    v26(log1p)\n    v28(join)\n    v37(delete_layer)\n    v39(join)\n    v48(filter_with_hvg)\n    v50(join)\n    v59(rna_calculate_qc_metrics)\n    v61(join)\n    v68(Output)\n    v0--&gt;v3\n    v3--&gt;v5\n    v5--&gt;v7\n    v7--&gt;v9\n    v5--&gt;v17\n    v5--&gt;v15\n    v15--&gt;v17\n    v17--&gt;v28\n    v17--&gt;v26\n    v26--&gt;v28\n    v28--&gt;v39\n    v28--&gt;v37\n    v37--&gt;v39\n    v39--&gt;v50\n    v39--&gt;v48\n    v48--&gt;v50\n    v50--&gt;v61\n    v50--&gt;v59\n    v59--&gt;v61\n    v61--&gt;v68"
  },
  {
    "objectID": "components/workflows/multiomics/prot_multisample.html",
    "href": "components/workflows/multiomics/prot_multisample.html",
    "title": "Prot multisample",
    "section": "",
    "text": "ID: prot_multisample\nNamespace: multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/prot_multisample.html#example-commands",
    "href": "components/workflows/multiomics/prot_multisample.html#example-commands",
    "title": "Prot multisample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -main-script ./workflows/multiomics/prot_multisample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"concatenated\"\ninput: # please fill in - example: \"dataset.h5mu\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# QC metrics calculation options\n# var_qc_metrics: [\"ercc\", \"highly_variable\"]\ntop_n_vars: [50, 100, 200, 500]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.6 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/prot_multisample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/prot_multisample.html#argument-groups",
    "href": "components/workflows/multiomics/prot_multisample.html#argument-groups",
    "title": "Prot multisample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the concatenated file\nstring, required, example: \"concatenated\"\n\n\n--input\nPath to the samples.\nfile, required, example: \"dataset.h5mu\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‚ÄòTrue‚Äô, compared to the total sum of the values for all genes. Defaults to the value from ‚Äìvar_name_mitochondrial_genes.\nList of string, example: \"ercc,highly_variable\", multiple_sep: \",\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\""
  },
  {
    "objectID": "components/workflows/multiomics/prot_multisample.html#authors",
    "href": "components/workflows/multiomics/prot_multisample.html#authors",
    "title": "Prot multisample",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/prot_multisample.html#visualisation",
    "href": "components/workflows/multiomics/prot_multisample.html#visualisation",
    "title": "Prot multisample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v3(toSortedList)\n    v5(flatMap)\n    v6(toSortedList)\n    v8(Output)\n    v14(clr)\n    v16(join)\n    v22(filter)\n    v28(grep_annotation_column)\n    v30(join)\n    v34(mix)\n    v33(filter)\n    v40(calculate_qc_metrics)\n    v42(join)\n    v50(publish)\n    v52(join)\n    v58(Output)\n    v5--&gt;v6\n    v33--&gt;v34\n    v0--&gt;v3\n    v3--&gt;v5\n    v6--&gt;v8\n    v5--&gt;v16\n    v5--&gt;v14\n    v14--&gt;v16\n    v16--&gt;v22\n    v16--&gt;v33\n    v22--&gt;v30\n    v22--&gt;v28\n    v28--&gt;v30\n    v30--&gt;v34\n    v34--&gt;v42\n    v34--&gt;v40\n    v40--&gt;v42\n    v42--&gt;v52\n    v42--&gt;v50\n    v50--&gt;v52\n    v52--&gt;v58"
  },
  {
    "objectID": "components/modules/transfer/publish.html",
    "href": "components/modules/transfer/publish.html",
    "title": "Publish",
    "section": "",
    "text": "ID: publish\nNamespace: transfer\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/transfer/publish.html#example-commands",
    "href": "components/modules/transfer/publish.html#example-commands",
    "title": "Publish",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/transfer/publish/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transfer/publish/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transfer/publish.html#argument-group",
    "href": "components/modules/transfer/publish.html#argument-group",
    "title": "Publish",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput filename\nfile, required\n\n\n--output\nOutput filename\nfile, required"
  },
  {
    "objectID": "components/modules/transfer/publish.html#authors",
    "href": "components/modules/transfer/publish.html#authors",
    "title": "Publish",
    "section": "Authors",
    "text": "Authors\n\nToni Verbeiren   (maintainer)"
  },
  {
    "objectID": "components/modules/reference/build_cellranger_reference.html",
    "href": "components/modules/reference/build_cellranger_reference.html",
    "title": "Build cellranger reference",
    "section": "",
    "text": "ID: build_cellranger_reference\nNamespace: reference\n\n\n\nSource\nCreates a new folder named after the genome."
  },
  {
    "objectID": "components/modules/reference/build_cellranger_reference.html#example-commands",
    "href": "components/modules/reference/build_cellranger_reference.html#example-commands",
    "title": "Build cellranger reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/reference/build_cellranger_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ngenome_fasta: # please fill in - example: \"genome_sequence.fa.gz\"\ntranscriptome_gtf: # please fill in - example: \"transcriptome_annotation.gtf.gz\"\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/reference/build_cellranger_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/reference/build_cellranger_reference.html#argument-group",
    "href": "components/modules/reference/build_cellranger_reference.html#argument-group",
    "title": "Build cellranger reference",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genome_fasta\nReference genome fasta.\nfile, required, example: \"genome_sequence.fa.gz\"\n\n\n--transcriptome_gtf\nReference transcriptome annotation.\nfile, required, example: \"transcriptome_annotation.gtf.gz\"\n\n\n--output\nOutput folder\nfile, required, example: \"cellranger_reference\""
  },
  {
    "objectID": "components/modules/reference/build_cellranger_reference.html#authors",
    "href": "components/modules/reference/build_cellranger_reference.html#authors",
    "title": "Build cellranger reference",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/download/download_file.html",
    "href": "components/modules/download/download_file.html",
    "title": "Download file",
    "section": "",
    "text": "ID: download_file\nNamespace: download\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/download/download_file.html#example-commands",
    "href": "components/modules/download/download_file.html#example-commands",
    "title": "Download file",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/download/download_file/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"https://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_protein_v3/pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n# output: \"$id.$key.output.h5\"\nverbose: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/download/download_file/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/download/download_file.html#argument-group",
    "href": "components/modules/download/download_file.html#argument-group",
    "title": "Download file",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nURL to a file to download.\nstring, required, example: \"https://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_protein_v3/pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n\n\n--output\nPath where to store output.\nfile, required, example: \"pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n\n\n--verbose\nIncrease verbosity\nboolean_true"
  },
  {
    "objectID": "components/modules/download/download_file.html#authors",
    "href": "components/modules/download/download_file.html#authors",
    "title": "Download file",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/annotate/popv.html",
    "href": "components/modules/annotate/popv.html",
    "title": "Popv",
    "section": "",
    "text": "ID: popv\nNamespace: annotate\n\n\n\nSource\nNote that this is a one-shot version of PopV."
  },
  {
    "objectID": "components/modules/annotate/popv.html#example-commands",
    "href": "components/modules/annotate/popv.html#example-commands",
    "title": "Popv",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/annotate/popv/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# input_obs_batch: \"foo\"\n# input_var_subset: \"foo\"\n# input_obs_label: \"foo\"\nunknown_celltype_label: \"unknown\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Arguments\nmethods: # please fill in - example: [\"knn_on_scvi\", \"scanvi\"]\n\n# Reference\nreference: # please fill in - example: \"TS_Bladder_filtered.h5ad\"\n# reference_layer: \"foo\"\nreference_obs_label: \"cell_ontology_class\"\nreference_obs_batch: \"donor_assay\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/annotate/popv/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/annotate/popv.html#argument-groups",
    "href": "components/modules/annotate/popv.html#argument-groups",
    "title": "Popv",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\nArguments related to the input (aka query) dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--input_layer\nWhich layer to use. If no value is provided, the counts are assumed to be in the .X slot. Otherwise, count data is expected to be in .layers[input_layer].\nstring\n\n\n--input_obs_batch\nKey in obs field of input adata for batch information. If no value is provided, batch label is assumed to be unknown.\nstring\n\n\n--input_var_subset\nSubset the input object with this column.\nstring\n\n\n--input_obs_label\nKey in obs field of input adata for label information. This is only used for training scANVI. Unlabelled cells should be set to \"unknown_celltype_label\".\nstring\n\n\n--unknown_celltype_label\nIf input_obs_label is specified, cells with this value will be treated as unknown and will be predicted by the model.\nstring, default: \"unknown\"\n\n\n\n\n\nReference\nArguments related to the reference dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nUser-provided reference tissue. The data that will be used as reference to call cell types.\nfile, required, example: \"TS_Bladder_filtered.h5ad\"\n\n\n--reference_layer\nWhich layer to use. If no value is provided, the counts are assumed to be in the .X slot. Otherwise, count data is expected to be in .layers[reference_layer].\nstring\n\n\n--reference_obs_label\nKey in obs field of reference AnnData with cell-type information.\nstring, default: \"cell_ontology_class\"\n\n\n--reference_obs_batch\nKey in obs field of input adata for batch information.\nstring, default: \"donor_assay\"\n\n\n\n\n\nOutputs\nOutput arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n\n\n\nArguments\nOther arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--methods\nMethods to call cell types. By default, runs to knn_on_scvi and scanvi.\nList of string, required, example: \"knn_on_scvi\", \"scanvi\", multiple_sep: \";\""
  },
  {
    "objectID": "components/modules/annotate/popv.html#authors",
    "href": "components/modules/annotate/popv.html#authors",
    "title": "Popv",
    "section": "Authors",
    "text": "Authors\n\nMatthias Beyens    (author)\nRobrecht Cannoodt    (author)"
  },
  {
    "objectID": "components/modules/genetic_demux/souporcell.html",
    "href": "components/modules/genetic_demux/souporcell.html",
    "title": "Souporcell",
    "section": "",
    "text": "ID: souporcell\nNamespace: genetic_demux\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/genetic_demux/souporcell.html#example-commands",
    "href": "components/modules/genetic_demux/souporcell.html#example-commands",
    "title": "Souporcell",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/genetic_demux/souporcell/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# fasta: \"path/to/file\"\n# bam: \"path/to/file\"\n# bam_index: \"path/to/file\"\n# barcodes: \"path/to/file\"\n# clusters: 123\nploidy: 2\nmin_alt: 10\nmin_ref: 10\nmax_loci: 2048\n# restarts: 123\n# common_variants: \"path/to/file\"\n# known_genotypes: \"path/to/file\"\n# known_genotypes_sample_names: \"foo\"\nskip_remap: false\nignore: false\n\n# Output\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/souporcell/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/genetic_demux/souporcell.html#argument-groups",
    "href": "components/modules/genetic_demux/souporcell.html#argument-groups",
    "title": "Souporcell",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--fasta\nreference fasta file\nfile\n\n\n--bam\ncellranger bam\nfile\n\n\n--bam_index\ncellranger bam index\nfile\n\n\n--barcodes\nbarcodes.tsv from cellranger\nfile\n\n\n--clusters\nnumber cluster, tbd add easy way to run on a range of k\ninteger\n\n\n--ploidy\nploidy, must be 1 or 2\ninteger, default: 2\n\n\n--min_alt\nmin alt to use locus\ninteger, default: 10\n\n\n--min_ref\nmin ref to use locus\ninteger, default: 10\n\n\n--max_loci\nmax loci per cell, affects speed\ninteger, default: 2048\n\n\n--restarts\nnumber of restarts in clustering, when there are &gt; 12 clusters we recommend increasing this to avoid local minima\ninteger\n\n\n--common_variants\ncommon variant loci or known variant loci vcf, must be vs same reference fasta\nfile\n\n\n--known_genotypes\nknown variants per clone in population vcf mode, must be .vcf right now we dont accept gzip or bcf sorry\nfile\n\n\n--known_genotypes_sample_names\nwhich samples in population vcf from known genotypes option represent the donors in your sample\nstring\n\n\n--skip_remap\ndont remap with minimap2 (not recommended unless in conjunction with ‚Äìcommon_variants\nboolean_true\n\n\n--ignore\nset to True to ignore data error assertions\nboolean_true\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nname of directory to place souporcell files\nfile, example: \"souporcell_out\""
  },
  {
    "objectID": "components/modules/genetic_demux/souporcell.html#authors",
    "href": "components/modules/genetic_demux/souporcell.html#authors",
    "title": "Souporcell",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)"
  },
  {
    "objectID": "components/modules/genetic_demux/dsc_pileup.html",
    "href": "components/modules/genetic_demux/dsc_pileup.html",
    "title": "Dsc pileup",
    "section": "",
    "text": "ID: dsc_pileup\nNamespace: genetic_demux\n\n\n\nSource\nBy using pileup files, it would allow us to run demuxlet/freemuxlet pretty fast multiple times without going over the BAM file again"
  },
  {
    "objectID": "components/modules/genetic_demux/dsc_pileup.html#example-commands",
    "href": "components/modules/genetic_demux/dsc_pileup.html#example-commands",
    "title": "Dsc pileup",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/genetic_demux/dsc_pileup/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# sam: \"path/to/file\"\ntag_group: \"CB\"\ntag_umi: \"UB\"\nexclude_flag: 1796\n# vcf: \"path/to/file\"\n# sm: \"foo\"\n# sm_list: \"foo\"\nsam_verbose: 1000000\nvcf_verbose: 1000\nskip_umi: false\ncap_bq: 40\nmin_bq: 13\nmin_mq: 20\nmin_td: 0\nexcl_flag: 3844\n# group_list: \"foo\"\nmin_total: 0\nmin_uniq: 0\nmin_snp: 0\n\n# Output\n# output: \"$id.$key.output.output\"\n# out: \"demuxlet_dsc\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/dsc_pileup/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/genetic_demux/dsc_pileup.html#argument-groups",
    "href": "components/modules/genetic_demux/dsc_pileup.html#argument-groups",
    "title": "Dsc pileup",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sam\nInput SAM/BAM/CRAM file. Must be sorted by coordinates and indexed.\nfile\n\n\n--tag_group\nTag representing readgroup or cell barcodes, in the case to partition the BAM file into multiple groups. For 10x genomics, use CB.\nstring, default: \"CB\"\n\n\n--tag_umi\nTag representing UMIs. For 10x genomiucs, use UB.\nstring, default: \"UB\"\n\n\n--exclude_flag\nSAM/BAM FLAGs to be excluded.\ninteger, default: 1796\n\n\n--vcf\nInput VCF/BCF file for dsc-pileup, containing the AC and AN field.\nfile\n\n\n--sm\nList of sample IDs to compare to (default: use all).\nstring\n\n\n--sm_list\nFile containing the list of sample IDs to compare.\nstring\n\n\n--sam_verbose\nVerbose message frequency for SAM/BAM/CRAM.\ninteger, default: 1000000\n\n\n--vcf_verbose\nVerbose message frequency for VCF/BCF.\ninteger, default: 1000\n\n\n--skip_umi\nDo not generate [prefix].umi.gz file, which stores the regions covered by each barcode/UMI pair.\nboolean_true\n\n\n--cap_bq\nMaximum base quality (higher BQ will be capped).\ninteger, default: 40\n\n\n--min_bq\nMinimum base quality to consider (lower BQ will be skipped).\ninteger, default: 13\n\n\n--min_mq\nMinimum mapping quality to consider (lower MQ will be ignored).\ninteger, default: 20\n\n\n--min_td\nMinimum distance to the tail (lower will be ignored).\ninteger, default: 0\n\n\n--excl_flag\nSAM/BAM FLAGs to be excluded for SNP overlapping Read filtering Options.\ninteger, default: 3844\n\n\n--group_list\nList of tag readgroup/cell barcode to consider in this run. All other barcodes will be ignored. This is useful for parallelized run.\nstring\n\n\n--min_total\nMinimum number of total reads for a droplet/cell to be considered.\ninteger, default: 0\n\n\n--min_uniq\nMinimum number of unique reads (determined by UMI/SNP pair) for a droplet/cell to be considered.\ninteger, default: 0\n\n\n--min_snp\nMinimum number of SNPs with coverage for a droplet/cell to be considered.\ninteger, default: 0\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory\nfile, example: \"demux\"\n\n\n--out\ndsc-pileup output file prefix\nstring, example: \"demuxlet_dsc\""
  },
  {
    "objectID": "components/modules/genetic_demux/dsc_pileup.html#authors",
    "href": "components/modules/genetic_demux/dsc_pileup.html#authors",
    "title": "Dsc pileup",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)"
  },
  {
    "objectID": "components/modules/genetic_demux/samtools.html",
    "href": "components/modules/genetic_demux/samtools.html",
    "title": "Samtools",
    "section": "",
    "text": "ID: samtools\nNamespace: genetic_demux\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/genetic_demux/samtools.html#example-commands",
    "href": "components/modules/genetic_demux/samtools.html#example-commands",
    "title": "Samtools",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/genetic_demux/samtools/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nbam: # please fill in - example: \"path/to/file\"\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/samtools/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/genetic_demux/samtools.html#argument-group",
    "href": "components/modules/genetic_demux/samtools.html#argument-group",
    "title": "Samtools",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--bam\nInput bam file for filtering.\nfile, required\n\n\n--output\nSamtools output directory.\nfile, example: \"samtools_out\""
  },
  {
    "objectID": "components/modules/genetic_demux/samtools.html#authors",
    "href": "components/modules/genetic_demux/samtools.html#authors",
    "title": "Samtools",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)"
  },
  {
    "objectID": "components/modules/genetic_demux/cellsnp.html",
    "href": "components/modules/genetic_demux/cellsnp.html",
    "title": "Cellsnp",
    "section": "",
    "text": "ID: cellsnp\nNamespace: genetic_demux\n\n\n\nSource\nIt can be directly used for donor deconvolution in multiplexed single-cell RNA-seq data, particularly with vireo."
  },
  {
    "objectID": "components/modules/genetic_demux/cellsnp.html#example-commands",
    "href": "components/modules/genetic_demux/cellsnp.html#example-commands",
    "title": "Cellsnp",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/genetic_demux/cellsnp/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# sam_file: \"path/to/file\"\n# sam_index_file: \"path/to/file\"\n# sam_fileList: \"path/to/file\"\n# regions_vcf: \"path/to/file\"\n# targets_vcf: \"path/to/file\"\n# barcode_file: \"path/to/file\"\n# sample_list: \"path/to/file\"\n# sample_ids: \"foo\"\ngenotype: false\ngzip: false\nprint_skip_snps: false\n# chrom: \"foo\"\ncell_tag: \"CB\"\numi_tag: \"Auto\"\nmin_count: 20\nmin_maf: 0.0\ndoublet_gl: false\n# incl_flag: \"foo\"\n# excl_flag: \"foo\"\ncount_orphan: false\nmin_mapq: 20\nmin_len: 30\n\n# Output\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/cellsnp/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/genetic_demux/cellsnp.html#argument-groups",
    "href": "components/modules/genetic_demux/cellsnp.html#argument-groups",
    "title": "Cellsnp",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sam_file\nIndexed sam/bam file(s), comma separated multiple samples. Mode 1a & 2a: one sam/bam file with single cell. Mode 1b & 2b: one or multiple bulk sam/bam files, no barcodes needed, but sample ids and regionsVCF.\nfile\n\n\n--sam_index_file\nInput SAM/BAM Index file, problem with samFileList.\nfile\n\n\n--sam_fileList\nA list file containing bam files, each per line, for Mode 1b & 2b.\nfile\n\n\n--regions_vcf\nA vcf file listing all candidate SNPs, for fetch each variants. If None, pileup the genome. Needed for bulk samples.\nfile\n\n\n--targets_vcf\nSimilar as ‚Äìregions_vcf, but the next position is accessed by streaming rather than indexing/jumping (like -T in samtools/bcftools mpileup).\nfile\n\n\n--barcode_file\nA plain file listing all effective cell barcode.\nfile\n\n\n--sample_list\nA list file containing sample IDs, each per line.\nfile\n\n\n--sample_ids\nComma separated sample ids.\nstring\n\n\n--genotype\nIf use, do genotyping in addition to counting.\nboolean_true\n\n\n--gzip\nIf use, the output files will be zipped into BGZF format.\nboolean_true\n\n\n--print_skip_snps\nIf use, the SNPs skipped when loading VCF will be printed.\nboolean_true\n\n\n--chrom\nThe chromosomes to use in integer format 1-22, comma separated\nstring\n\n\n--cell_tag\nTag for cell barcodes, turn off with None.\nstring, default: \"CB\"\n\n\n--umi_tag\nTag for UMI: UR, Auto, None. For Auto mode, use UR if barcodes is inputted, otherwise use None. None mode means no UMI but read counts.\nstring, default: \"Auto\"\n\n\n--min_count\nMinimum aggragated count.\ninteger, default: 20\n\n\n--min_maf\nMinimum minor allele frequency.\ndouble, default: 0\n\n\n--doublet_gl\nIf use, keep doublet GT likelihood, i.e., GT=0.5 and GT=1.5.\nboolean_true\n\n\n--incl_flag\nRequired flags: skip reads with all mask bits unset.\nstring\n\n\n--excl_flag\nFilter flags: skip reads with any mask bits set [UNMAP,SECONDARY,QCFAIL (when use UMI) or UNMAP,SECONDARY,QCFAIL,DUP (otherwise)]\nstring\n\n\n--count_orphan\nIf use, do not skip anomalous read pairs.\nboolean_true\n\n\n--min_mapq\nMinimum MAPQ for read filtering.\ninteger, default: 20\n\n\n--min_len\nMinimum mapped length for read filtering.\ninteger, default: 30\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory for VCF and sparse matrices.\nfile, example: \"cellsnp_out\""
  },
  {
    "objectID": "components/modules/genetic_demux/cellsnp.html#authors",
    "href": "components/modules/genetic_demux/cellsnp.html#authors",
    "title": "Cellsnp",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)"
  },
  {
    "objectID": "components/modules/genetic_demux/freebayes.html",
    "href": "components/modules/genetic_demux/freebayes.html",
    "title": "Freebayes",
    "section": "",
    "text": "ID: freebayes\nNamespace: genetic_demux\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/genetic_demux/freebayes.html#example-commands",
    "href": "components/modules/genetic_demux/freebayes.html#example-commands",
    "title": "Freebayes",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/genetic_demux/freebayes/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\n# bam: \"path/to/file\"\n# bam_list: \"path/to/file\"\nstdin: false\n# fasta_reference: \"path/to/file\"\n# fasta_reference_index: \"path/to/file\"\n# targets: \"path/to/file\"\n# region: \"foo\"\n# samples: \"path/to/file\"\n# populations: \"path/to/file\"\n# cnv_map: \"path/to/file\"\ngvcf: false\n# gvcf_chunk: 123\n# variant_input: \"path/to/file\"\nonly_use_input_alleles: false\n# haplotype_basis_alleles: \"path/to/file\"\nreport_all_haplotype_alleles: false\nreport_monomorphic: false\npvar: 0.0\nstrict_vcf: false\ntheta: 0.001\nploidy: 2\npooled_discrete: false\npooled_continuous: false\nuse_reference_allele: false\nreference_quality: \"100,60\"\nthrow_away_snp_obs: false\nthrow_away_mnps_obs: true\nthrow_away_indel_obs: true\nthrow_away_complex_obs: true\nuse_best_n_alleles: 0\nmax_complex_gap: 3\nmin_repeat_size: 5\nmin_repeat_entropy: 1\nno_partial_observations: false\ndont_left_align_indels: false\nuse_duplicate_reads: false\nmin_mapping_quality: 1\nmin_base_quality: 1\nmin_supporting_allele_qsum: 0\nmin_supporting_mapping_qsum: 0\nmismatch_base_quality_threshold: 10\nread_max_mismatch_fraction: 1.0\n# read_mismatch_limit: 123\n# read_snp_limit: 123\n# read_indel_limit: 123\nstandard_filters: false\nmin_alternate_fraction: 0.05\nmin_alternate_count: 2\nmin_alternate_qsum: 0\nmin_alternate_total: 1\nmin_coverage: 0\n# max_coverage: 123\nno_population_priors: false\nhwe_priors_off: false\nbinomial_obs_priors_off: false\nallele_balance_priors_off: false\n# observation_bias: \"path/to/file\"\n# base_quality_cap: 123\nprob_contamination: 1.0E-8\nlegacy_gls: false\n# contamination_estimates: \"path/to/file\"\nreport_genotype_likelihood_max: false\ngenotyping_max_iterations: 1000\ngenotyping_max_banddepth: 6\nposterior_integration_limits: \"1,3\"\nexclude_unobserved_genotypes: false\n# genotype_variant_threshold: 123\nuse_mapping_quality: false\nharmonic_indel_quality: false\nread_dependence_factor: 0.9\ngenotype_qualities: false\ndebug: false\ndd: false\n\n# Output\n# output: \"$id.$key.output.output\"\n# vcf: \"snp.vcf\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/genetic_demux/freebayes/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/genetic_demux/freebayes.html#argument-groups",
    "href": "components/modules/genetic_demux/freebayes.html#argument-groups",
    "title": "Freebayes",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--bam\nAdd FILE to the set of BAM files to be analyzed.\nfile\n\n\n--bam_list\nA file containing a list of BAM files to be analyzed.\nfile\n\n\n--stdin\nRead BAM input on stdin.\nboolean_true\n\n\n--fasta_reference\nUse FILE as the reference sequence for analysis. An index file (FILE.fai) will be created if none exists. If neither ‚Äìtargets nor ‚Äìregion are specified, FreeBayes will analyze every position in this reference.\nfile\n\n\n--fasta_reference_index\nUse FILE.fai as the index of reference sequence for analysis.\nfile\n\n\n--targets\nLimit analysis to targets listed in the BED-format FILE.\nfile\n\n\n--region\nLimit analysis to the specified region, 0-base coordinates, end_position not included (same as BED format).\nstring\n\n\n--samples\nLimit analysis to samples listed (one per line) in the FILE. By default FreeBayes will analyze all samples in its input BAM files.\nfile\n\n\n--populations\nEach line of FILE should list a sample and a population which it is part of. The population-based bayesian inference model will then be partitioned on the basis of the populations.\nfile\n\n\n--cnv_map\nRead a copy number map from the BED file FILE, which has either a sample-level ploidy or a region-specific format.\nfile\n\n\n--gvcf\nWrite gVCF output, which indicates coverage in uncalled regions.\nboolean_true\n\n\n--gvcf_chunk\nWhen writing gVCF output emit a record for every NUM bases.\ninteger\n\n\n--variant_input\nUse variants reported in VCF file as input to the algorithm. Variants in this file will included in the output even if there is not enough support in the data to pass input filters.\nfile\n\n\n--only_use_input_alleles\nOnly provide variant calls and genotype likelihoods for sites and alleles which are provided in the VCF input, and provide output in the VCF for all input alleles, not just those which have support in the data.\nboolean_true\n\n\n--haplotype_basis_alleles\nWhen specified, only variant alleles provided in this input VCF will be used for the construction of complex or haplotype alleles.\nfile\n\n\n--report_all_haplotype_alleles\nAt sites where genotypes are made over haplotype alleles, provide information about all alleles in output, not only those which are called.\nboolean_true\n\n\n--report_monomorphic\nReport even loci which appear to be monomorphic, and report all considered alleles, even those which are not in called genotypes.\nboolean_true\n\n\n--pvar\nReport sites if the probability that there is a polymorphism at the site is greater than N. Note that post-filtering is generally recommended over the use of this parameter.\ndouble, default: 0\n\n\n--strict_vcf\nGenerate strict VCF format (FORMAT/GQ will be an int).\nboolean_true\n\n\n--theta\nThe expected mutation rate or pairwise nucleotide diversity among the population under analysis. This serves as the single parameter to the Ewens Sampling Formula prior model.\ndouble, default: 0.001\n\n\n--ploidy\nSets the default ploidy for the analysis to N.\ninteger, default: 2\n\n\n--pooled_discrete\nAssume that samples result from pooled sequencing. Model pooled samples using discrete genotypes across pools.\nboolean_true\n\n\n--pooled_continuous\nOutput all alleles which pass input filters, regardles of genotyping outcome or model.\nboolean_true\n\n\n--use_reference_allele\nThis flag includes the reference allele in the analysis as if it is another sample from the same population.\nboolean_true\n\n\n--reference_quality\nAssign mapping quality of MQ to the reference allele at each site and base quality of BQ.\nstring, default: \"100,60\"\n\n\n--throw_away_snp_obs\nIgnore SNP alleles.\nboolean_true\n\n\n--throw_away_mnps_obs\nIgnore multi-nuceotide polymorphisms, MNPs. MNPs are excluded as default.\nboolean_false\n\n\n--throw_away_indel_obs\nIgnore insertion and deletion alleles. Indels are excluded as default.\nboolean_false\n\n\n--throw_away_complex_obs\nIgnore complex events (composites of other classes). Complex are excluded as default\nboolean_false\n\n\n--use_best_n_alleles\nEvaluate only the best N SNP alleles, ranked by sum of supporting quality scores.\ninteger, default: 0\n\n\n--max_complex_gap\nAllow haplotype calls with contiguous embedded matches of up to this length.\ninteger, default: 3\n\n\n--min_repeat_size\nWhen assembling observations across repeats, require the total repeat length at least this many bp.\ninteger, default: 5\n\n\n--min_repeat_entropy\nTo detect interrupted repeats, build across sequence until it has entropy &gt; N bits per bp. Set to 0 to turn off.\ninteger, default: 1\n\n\n--no_partial_observations\nExclude observations which do not fully span the dynamically-determined detection window. (default, use all observations, dividing partial support across matching haplotypes when generating haplotypes.)\nboolean_true\n\n\n--dont_left_align_indels\nTurn off left-alignment of indels, which is enabled by default.\nboolean_true\n\n\n--use_duplicate_reads\nInclude duplicate-marked alignments in the analysis. default: exclude duplicates marked as such in alignments\nboolean_true\n\n\n--min_mapping_quality\nExclude alignments from analysis if they have a mapping quality less than Q.\ninteger, default: 1\n\n\n--min_base_quality\nExclude alleles from analysis if their supporting base quality is less than Q. Default value is changed according to the instruction of scSplit.\ninteger, default: 1\n\n\n--min_supporting_allele_qsum\nConsider any allele in which the sum of qualities of supporting observations is at least Q.\ninteger, default: 0\n\n\n--min_supporting_mapping_qsum\nConsider any allele in which and the sum of mapping qualities of supporting reads is at least.\ninteger, default: 0\n\n\n--mismatch_base_quality_threshold\nCount mismatches toward ‚Äìread-mismatch-limit if the base quality of the mismatch is &gt;= Q.\ninteger, default: 10\n\n\n--read_max_mismatch_fraction\nExclude reads with more than N mismatches where each mismatch has base quality &gt;= mismatch-base-quality-threshold.\ndouble, default: 1\n\n\n--read_mismatch_limit\nExclude reads with more than N [0,1] fraction of mismatches where each mismatch has base quality &gt;= mismatch-base-quality-threshold.\ninteger\n\n\n--read_snp_limit\nExclude reads with more than N base mismatches, ignoring gaps with quality &gt;= mismatch-base-quality-threshold.\ninteger\n\n\n--read_indel_limit\nExclude reads with more than N separate gaps.\ninteger\n\n\n--standard_filters\nUse stringent input base and mapping quality filters, equivalent to -m 30 -q 20 -R 0 -S 0\nboolean_true\n\n\n--min_alternate_fraction\nRequire at least this fraction of observations supporting an alternate allele within a single individual in order to evaluate the position.\ndouble, default: 0.05\n\n\n--min_alternate_count\nRequire at least this count of observations supporting an alternate allele within a single individual in order to evaluate the position.\ninteger, default: 2\n\n\n--min_alternate_qsum\nRequire at least this sum of quality of observations supporting an alternate allele within a single individual in order to evaluate the position.\ninteger, default: 0\n\n\n--min_alternate_total\nRequire at least this count of observations supporting an alternate allele within the total population in order to use the allele in analysis.\ninteger, default: 1\n\n\n--min_coverage\nRequire at least this coverage to process a site.\ninteger, default: 0\n\n\n--max_coverage\nDo not process sites with greater than this coverage.\ninteger\n\n\n--no_population_priors\nEquivalent to ‚Äìpooled-discrete ‚Äìhwe-priors-off and removal of Ewens Sampling Formula component of priors.\nboolean_true\n\n\n--hwe_priors_off\nDisable estimation of the probability of the combination arising under HWE given the allele frequency as estimated by observation frequency.\nboolean_true\n\n\n--binomial_obs_priors_off\nDisable incorporation of prior expectations about observations. Uses read placement probability, strand balance probability, and read position probability.\nboolean_true\n\n\n--allele_balance_priors_off\nDisable use of aggregate probability of observation balance between alleles as a component of the priors.\nboolean_true\n\n\n--observation_bias\nRead length-dependent allele observation biases from FILE. The format is [length] [alignment efficiency relative to reference] where the efficiency is 1 if there is no relative observation bias.\nfile\n\n\n--base_quality_cap\nLimit estimated observation quality by capping base quality at Q.\ninteger\n\n\n--prob_contamination\nAn estimate of contamination to use for all samples.\ndouble, default: 1e-08\n\n\n--legacy_gls\nUse legacy (polybayes equivalent) genotype likelihood calculations\nboolean_true\n\n\n--contamination_estimates\nA file containing per-sample estimates of contamination, such as those generated by VerifyBamID.\nfile\n\n\n--report_genotype_likelihood_max\nReport genotypes using the maximum-likelihood estimate provided from genotype likelihoods.\nboolean_true\n\n\n--genotyping_max_iterations\nIterate no more than N times during genotyping step.\ninteger, default: 1000\n\n\n--genotyping_max_banddepth\nIntegrate no deeper than the Nth best genotype by likelihood when genotyping.\ninteger, default: 6\n\n\n--posterior_integration_limits\nIntegrate all genotype combinations in our posterior space which include no more than N samples with their Mth best data likelihood.\nstring, default: \"1,3\"\n\n\n--exclude_unobserved_genotypes\nSkip sample genotypings for which the sample has no supporting reads.\nboolean_true\n\n\n--genotype_variant_threshold\nLimit posterior integration to samples where the second-best genotype likelihood is no more than log(N) from the highest genotype likelihood for the sample.\ninteger\n\n\n--use_mapping_quality\nUse mapping quality of alleles when calculating data likelihoods.\nboolean_true\n\n\n--harmonic_indel_quality\nUse a weighted sum of base qualities around an indel, scaled by the distance from the indel. By default use a minimum BQ in flanking sequence.\nboolean_true\n\n\n--read_dependence_factor\nIncorporate non-independence of reads by scaling successive observations by this factor during data likelihood calculations.\ndouble, default: 0.9\n\n\n--genotype_qualities\nCalculate the marginal probability of genotypes and report as GQ in each sample field in the VCF output.\nboolean_true\n\n\n--debug\nPrint debugging output.\nboolean_true\n\n\n--dd\nPrint more verbose debugging output\nboolean_true\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory\nfile, example: \"freebayes_out\"\n\n\n--vcf\nOutput VCF-format results to FILE.\nstring, example: \"snp.vcf\""
  },
  {
    "objectID": "components/modules/genetic_demux/freebayes.html#authors",
    "href": "components/modules/genetic_demux/freebayes.html#authors",
    "title": "Freebayes",
    "section": "Authors",
    "text": "Authors\n\nXichen Wu    (author)"
  },
  {
    "objectID": "components/modules/dataflow/split_modalities.html",
    "href": "components/modules/dataflow/split_modalities.html",
    "title": "Split modalities",
    "section": "",
    "text": "ID: split_modalities\nNamespace: dataflow\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/dataflow/split_modalities.html#example-commands",
    "href": "components/modules/dataflow/split_modalities.html#example-commands",
    "title": "Split modalities",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/dataflow/split_modalities/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"sample_path\"\n# output: \"$id.$key.output.output\"\n# output_compression: \"gzip\"\n# output_types: \"$id.$key.output_types.csv\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dataflow/split_modalities/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/dataflow/split_modalities.html#argument-group",
    "href": "components/modules/dataflow/split_modalities.html#argument-group",
    "title": "Split modalities",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to a single .h5mu file.\nfile, required, default: \"sample_path\"\n\n\n--output\nOutput directory containing multiple h5mu files.\nfile, required, example: \"/path/to/output\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--output_types\nA csv containing the base filename and modality type per output file.\nfile, required, example: \"types.csv\""
  },
  {
    "objectID": "components/modules/dataflow/split_modalities.html#authors",
    "href": "components/modules/dataflow/split_modalities.html#authors",
    "title": "Split modalities",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)\nRobrecht Cannoodt    (contributor)"
  },
  {
    "objectID": "components/modules/dataflow/concat.html",
    "href": "components/modules/dataflow/concat.html",
    "title": "Concat",
    "section": "",
    "text": "ID: concat\nNamespace: dataflow\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/dataflow/concat.html#example-commands",
    "href": "components/modules/dataflow/concat.html#example-commands",
    "title": "Concat",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/dataflow/concat/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: [\"sample_paths\"]\n# input_id: [\"foo\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobs_sample_name: \"sample_id\"\nother_axis_mode: \"move\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dataflow/concat/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/dataflow/concat.html#argument-group",
    "href": "components/modules/dataflow/concat.html#argument-group",
    "title": "Concat",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPaths to the different samples to be concatenated.\nList of file, required, example: \"sample_paths\", multiple_sep: \";\"\n\n\n--input_id\nNames of the different samples that have to be concatenated. Must be specified when using ‚Äò‚Äìmode move‚Äô. In this case, the ids will be used for the columns names of the dataframes registring the conflicts. If specified, must be of same length as --input.\nList of string, multiple_sep: \";\"\n\n\n--output\n\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obs_sample_name\nName of the .obs key under which to add the sample names.\nstring, default: \"sample_id\"\n\n\n--other_axis_mode\nHow to handle the merging of other axis (var, obs, ‚Ä¶). - None: keep no data - same: only keep elements of the matrices which are the same in each of the samples - unique: only keep elements for which there is only 1 possible value (1 value that can occur in multiple samples) - first: keep the annotation from the first sample - only: keep elements that show up in only one of the objects (1 unique element in only 1 sample) - move: identical to ‚Äòsame‚Äô, but moving the conflicting values to .varm or .obsm\nstring, default: \"move\""
  },
  {
    "objectID": "components/modules/dataflow/concat.html#authors",
    "href": "components/modules/dataflow/concat.html#authors",
    "title": "Concat",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/demux/bcl2fastq.html",
    "href": "components/modules/demux/bcl2fastq.html",
    "title": "Bcl2fastq",
    "section": "",
    "text": "ID: bcl2fastq\nNamespace: demux\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/demux/bcl2fastq.html#example-commands",
    "href": "components/modules/demux/bcl2fastq.html#example-commands",
    "title": "Bcl2fastq",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/demux/bcl2fastq/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"bcl_dir\"\nsample_sheet: # please fill in - example: \"SampleSheet.csv\"\n# output: \"$id.$key.output.output\"\n# reports: \"$id.$key.reports.reports\"\nignore_missing: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/demux/bcl2fastq/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/demux/bcl2fastq.html#argument-group",
    "href": "components/modules/demux/bcl2fastq.html#argument-group",
    "title": "Bcl2fastq",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput run directory\nfile, required, example: \"bcl_dir\"\n\n\n--sample_sheet\nPointer to the sample sheet\nfile, required, example: \"SampleSheet.csv\"\n\n\n--output\nOutput directory containig fastq files\nfile, required, example: \"fastq_dir\"\n\n\n--reports\nReports directory\nfile, example: \"reports_dir\"\n\n\n--ignore_missing\n\nboolean_true"
  },
  {
    "objectID": "components/modules/demux/bcl2fastq.html#authors",
    "href": "components/modules/demux/bcl2fastq.html#authors",
    "title": "Bcl2fastq",
    "section": "Authors",
    "text": "Authors\n\nToni Verbeiren   (author, maintainer)"
  },
  {
    "objectID": "components/modules/demux/bcl_convert.html",
    "href": "components/modules/demux/bcl_convert.html",
    "title": "Bcl convert",
    "section": "",
    "text": "ID: bcl_convert\nNamespace: demux\n\n\n\nSource\nInformation about upgrading from bcl2fastq via https://emea.support.illumina.com/bulletins/2020/10/upgrading-from-bcl2fastq-to-bcl-convert.html and https://support.illumina.com/sequencing/sequencing_software/bcl-convert/compatibility.html"
  },
  {
    "objectID": "components/modules/demux/bcl_convert.html#example-commands",
    "href": "components/modules/demux/bcl_convert.html#example-commands",
    "title": "Bcl convert",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/demux/bcl_convert/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"bcl_dir\"\nsample_sheet: # please fill in - example: \"bcl_dir\"\n# output: \"$id.$key.output.output\"\n# reports: \"$id.$key.reports.reports\"\ntest_mode: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/demux/bcl_convert/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/demux/bcl_convert.html#argument-group",
    "href": "components/modules/demux/bcl_convert.html#argument-group",
    "title": "Bcl convert",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput run directory\nfile, required, example: \"bcl_dir\"\n\n\n--sample_sheet\nPointer to the sample sheet\nfile, required, example: \"bcl_dir\"\n\n\n--output\nOutput directory containig fastq files\nfile, required, example: \"fastq_dir\"\n\n\n--reports\nReports directory\nfile, example: \"reports_dir\"\n\n\n--test_mode\nShould bcl-convert be run in test mode (using ‚Äìfirst-tile-only)?\nboolean, default: FALSE"
  },
  {
    "objectID": "components/modules/demux/bcl_convert.html#authors",
    "href": "components/modules/demux/bcl_convert.html#authors",
    "title": "Bcl convert",
    "section": "Authors",
    "text": "Authors\n\nToni Verbeiren   (author, maintainer)\nMarijke Van Moerbeke    (author)"
  },
  {
    "objectID": "components/modules/transform/scale.html",
    "href": "components/modules/transform/scale.html",
    "title": "Scale",
    "section": "",
    "text": "ID: scale\nNamespace: transform\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/transform/scale.html#example-commands",
    "href": "components/modules/transform/scale.html#example-commands",
    "title": "Scale",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/transform/scale/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# max_value: 123.0\nzero_center: true\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/scale/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transform/scale.html#argument-group",
    "href": "components/modules/transform/scale.html#argument-group",
    "title": "Scale",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nList of modalities to process.\nstring, default: \"rna\"\n\n\n--max_value\nClip (truncate) to this value after scaling. Does not clip by default.\ndouble\n\n\n--zero_center\nIf False, omit zero-centering variables, which allows to handle sparse input efficiently.\nboolean, default: TRUE\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/transform/scale.html#authors",
    "href": "components/modules/transform/scale.html#authors",
    "title": "Scale",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/transform/clr.html",
    "href": "components/modules/transform/clr.html",
    "title": "Clr",
    "section": "",
    "text": "ID: clr\nNamespace: transform\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/transform/clr.html#example-commands",
    "href": "components/modules/transform/clr.html#example-commands",
    "title": "Clr",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/transform/clr/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"prot\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n# input_layer: \"foo\"\n# output_layer: \"foo\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/clr/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transform/clr.html#argument-group",
    "href": "components/modules/transform/clr.html#argument-group",
    "title": "Clr",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"prot\"\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--input_layer\nInput layer to use. By default, .X is used.\nstring\n\n\n--output_layer\nOutput layer to use. By default, use X.\nstring"
  },
  {
    "objectID": "components/modules/transform/clr.html#authors",
    "href": "components/modules/transform/clr.html#authors",
    "title": "Clr",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/transform/log1p.html",
    "href": "components/modules/transform/log1p.html",
    "title": "Log1p",
    "section": "",
    "text": "ID: log1p\nNamespace: transform\n\n\n\nSource\nComputes X = log(X + 1), where log denotes the natural logarithm unless a different base is given"
  },
  {
    "objectID": "components/modules/transform/log1p.html#example-commands",
    "href": "components/modules/transform/log1p.html#example-commands",
    "title": "Log1p",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/transform/log1p/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# output_layer: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n# base: 2\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/log1p/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transform/log1p.html#argument-group",
    "href": "components/modules/transform/log1p.html#argument-group",
    "title": "Log1p",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\nInput layer to use. If None, X is normalized\nstring\n\n\n--output_layer\nOutput layer to use. By default, use X.\nstring\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--base\n\ndouble, example: 2"
  },
  {
    "objectID": "components/modules/transform/log1p.html#authors",
    "href": "components/modules/transform/log1p.html#authors",
    "title": "Log1p",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)\nRobrecht Cannoodt    (contributor)"
  },
  {
    "objectID": "components/modules/transform/delete_layer.html",
    "href": "components/modules/transform/delete_layer.html",
    "title": "Delete layer",
    "section": "",
    "text": "ID: delete_layer\nNamespace: transform\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/transform/delete_layer.html#example-commands",
    "href": "components/modules/transform/delete_layer.html#example-commands",
    "title": "Delete layer",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/transform/delete_layer/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nlayer: # please fill in - example: [\"foo\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nmissing_ok: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/delete_layer/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transform/delete_layer.html#argument-group",
    "href": "components/modules/transform/delete_layer.html#argument-group",
    "title": "Delete layer",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nInput layer to remove\nList of string, required, multiple_sep: \";\"\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--missing_ok\nDo not raise an error if the layer does not exist for all modalities.\nboolean_true"
  },
  {
    "objectID": "components/modules/transform/delete_layer.html#authors",
    "href": "components/modules/transform/delete_layer.html#authors",
    "title": "Delete layer",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/labels_transfer/xgboost.html",
    "href": "components/modules/labels_transfer/xgboost.html",
    "title": "Xgboost",
    "section": "",
    "text": "ID: xgboost\nNamespace: labels_transfer\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/labels_transfer/xgboost.html#example-commands",
    "href": "components/modules/labels_transfer/xgboost.html#example-commands",
    "title": "Xgboost",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/labels_transfer/xgboost/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Execution arguments\nforce_retrain: false\nuse_gpu: false\nverbosity: 1\n# model_output: \"$id.$key.model_output.model_output\"\n\n# Learning parameters\nlearning_rate: 0.3\nmin_split_loss: 0\nmax_depth: 6\nmin_child_weight: 1\nmax_delta_step: 0\nsubsample: 1\nsampling_method: \"uniform\"\ncolsample_bytree: 1\ncolsample_bylevel: 1\ncolsample_bynode: 1\nreg_lambda: 1\nreg_alpha: 0\nscale_pos_weight: 1\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/labels_transfer/xgboost/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/labels_transfer/xgboost.html#argument-groups",
    "href": "components/modules/labels_transfer/xgboost.html#argument-groups",
    "title": "Xgboost",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput dataset (query) arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe query data to transfer the labels to. Should be a .h5mu file.\nfile, required\n\n\n--modality\nWhich modality to use.\nstring, default: \"rna\"\n\n\n--input_obsm_features\nThe .obsm key of the embedding to use for the classifier‚Äôs inference. If not provided, the .X slot will be used instead. Make sure that embedding was obtained in the same way as the reference embedding (e.g.¬†by the same model or preprocessing).\nstring, example: \"X_integrated_scanvi\"\n\n\n\n\n\nReference dataset arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nThe reference data to train classifiers on.\nfile, example: \"https:/zenodo.org/record/6337966/files/HLCA_emb_and_metadata.h5ad\"\n\n\n--reference_obsm_features\nThe .obsm key of the embedding to use for the classifier‚Äôs training. Make sure that embedding was obtained in the same way as the query embedding (e.g.¬†by the same model or preprocessing).\nstring, required, default: \"X_integrated_scanvi\"\n\n\n--reference_obs_targets\nThe .obs key of the target labels to tranfer.\nList of string, default: \"ann_level_1\", \"ann_level_2\", \"ann_level_3\", \"ann_level_4\", \"ann_level_5\", \"ann_finest_level\", multiple_sep: \";\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe query data in .h5mu format with predicted labels transfered from the reference.\nfile, required\n\n\n--output_obs_predictions\nIn which .obs slots to store the predicted information. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_pred\" suffix.\nList of string, multiple_sep: \";\"\n\n\n--output_obs_uncertainty\nIn which .obs slots to store the uncertainty of the predictions. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_uncertainty\" suffix.\nList of string, multiple_sep: \";\"\n\n\n--output_uns_parameters\nThe .uns key to store additional information about the parameters used for the label transfer.\nstring, default: \"labels_transfer\"\n\n\n\n\n\nExecution arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--force_retrain\nRetrain models on the reference even if model_output directory already has trained classifiers. WARNING! It will rewrite existing classifiers for targets in the model_output directory!\nboolean_true\n\n\n--use_gpu\nUse GPU during models training and inference (recommended).\nboolean, default: FALSE\n\n\n--verbosity\nThe verbosity level for evaluation of the classifier from the range [0,2]\ninteger, default: 1\n\n\n--model_output\nOutput directory for model\nfile, default: \"model\"\n\n\n\n\n\nLearning parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--learning_rate\nStep size shrinkage used in update to prevents overfitting. Range: [0,1]. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 0.3\n\n\n--min_split_loss\nMinimum loss reduction required to make a further partition on a leaf node of the tree. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 0\n\n\n--max_depth\nMaximum depth of a tree. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ninteger, default: 6\n\n\n--min_child_weight\nMinimum sum of instance weight (hessian) needed in a child. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ninteger, default: 1\n\n\n--max_delta_step\nMaximum delta step we allow each leaf output to be. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 0\n\n\n--subsample\nSubsample ratio of the training instances. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--sampling_method\nThe method to use to sample the training instances. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\nstring, default: \"uniform\"\n\n\n--colsample_bytree\nFraction of columns to be subsampled. Range (0, 1]. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--colsample_bylevel\nSubsample ratio of columns for each level. Range (0, 1]. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--colsample_bynode\nSubsample ratio of columns for each node (split). Range (0, 1]. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--reg_lambda\nL2 regularization term on weights. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--reg_alpha\nL1 regularization term on weights. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 0\n\n\n--scale_pos_weight\nControl the balance of positive and negative weights, useful for unbalanced classes. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1"
  },
  {
    "objectID": "components/modules/labels_transfer/xgboost.html#authors",
    "href": "components/modules/labels_transfer/xgboost.html#authors",
    "title": "Xgboost",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov    (author)"
  },
  {
    "objectID": "components/modules/mapping/htseq_count_to_h5mu.html",
    "href": "components/modules/mapping/htseq_count_to_h5mu.html",
    "title": "Htseq count to h5mu",
    "section": "",
    "text": "ID: htseq_count_to_h5mu\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/htseq_count_to_h5mu.html#example-commands",
    "href": "components/modules/mapping/htseq_count_to_h5mu.html#example-commands",
    "title": "Htseq count to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/mapping/htseq_count_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Input\ninput_id: # please fill in - example: [\"foo\"]\ninput_counts: # please fill in - example: [\"counts.tsv\"]\nreference: # please fill in - example: \"gencode_v41_star\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/htseq_count_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/htseq_count_to_h5mu.html#argument-groups",
    "href": "components/modules/mapping/htseq_count_to_h5mu.html#argument-groups",
    "title": "Htseq count to h5mu",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_id\nThe obs index for the counts\nList of string, required, example: \"foo\", multiple_sep: \";\"\n\n\n--input_counts\nThe counts as a TSV file as output by HTSeq.\nList of file, required, example: \"counts.tsv\", multiple_sep: \";\"\n\n\n--reference\nThe GTF file.\nfile, required, example: \"gencode_v41_star\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/mapping/htseq_count_to_h5mu.html#authors",
    "href": "components/modules/mapping/htseq_count_to_h5mu.html#authors",
    "title": "Htseq count to h5mu",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)\nAngela Oliveira Pisco    (author)"
  },
  {
    "objectID": "components/modules/mapping/cellranger_count_split.html",
    "href": "components/modules/mapping/cellranger_count_split.html",
    "title": "Cellranger count split",
    "section": "",
    "text": "ID: cellranger_count_split\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/cellranger_count_split.html#example-commands",
    "href": "components/modules/mapping/cellranger_count_split.html#example-commands",
    "title": "Cellranger count split",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/mapping/cellranger_count_split/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input_dir\"\n# filtered_h5: \"$id.$key.filtered_h5.h5\"\n# metrics_summary: \"$id.$key.metrics_summary.csv\"\n# molecule_info: \"$id.$key.molecule_info.h5\"\n# bam: \"$id.$key.bam.bam\"\n# bai: \"$id.$key.bai.bai\"\n# raw_h5: \"$id.$key.raw_h5.h5\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/cellranger_count_split/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/cellranger_count_split.html#argument-group",
    "href": "components/modules/mapping/cellranger_count_split.html#argument-group",
    "title": "Cellranger count split",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nOutput directory from a Cell Ranger count run.\nfile, required, example: \"input_dir\"\n\n\n--filtered_h5\n\nfile, example: \"filtered_feature_bc_matrix.h5\"\n\n\n--metrics_summary\n\nfile, example: \"metrics_summary.csv\"\n\n\n--molecule_info\n\nfile, example: \"molecule_info.h5\"\n\n\n--bam\n\nfile, example: \"possorted_genome_bam.bam\"\n\n\n--bai\n\nfile, example: \"possorted_genome_bam.bam.bai\"\n\n\n--raw_h5\n\nfile, example: \"raw_feature_bc_matrix.h5\""
  },
  {
    "objectID": "components/modules/mapping/cellranger_count_split.html#authors",
    "href": "components/modules/mapping/cellranger_count_split.html#authors",
    "title": "Cellranger count split",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nSamuel D‚ÄôSouza   (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/mapping/samtools_sort.html",
    "href": "components/modules/mapping/samtools_sort.html",
    "title": "Samtools sort",
    "section": "",
    "text": "ID: samtools_sort\nNamespace: mapping\n\n\n\nSource\nReads are sorted by leftmost coordinates, or by read name when --sort_by_read_names is used.\nAn appropriate @HD-SO sort order header tag will be added or an existing one updated if necessary.\nNote that to generate an index file (by specifying --output_bai), the default coordinate sort must be used. Thus the --sort_by_read_names and --sort_by &lt;TAG&gt; options are incompatible with --output_bai."
  },
  {
    "objectID": "components/modules/mapping/samtools_sort.html#example-commands",
    "href": "components/modules/mapping/samtools_sort.html#example-commands",
    "title": "Samtools sort",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/mapping/samtools_sort/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nminimizer_cluster: false\n# minimizer_kmer: 20\nsort_by_read_names: false\n# sort_by: \"foo\"\nno_pg: false\n\n# Input\ninput: # please fill in - example: \"input.bam\"\n\n# Output\n# output_bam: \"$id.$key.output_bam.bam\"\n# output_bai: \"$id.$key.output_bai.bai\"\n# output_format: \"bam\"\n# compression: 5\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/samtools_sort/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/samtools_sort.html#argument-groups",
    "href": "components/modules/mapping/samtools_sort.html#argument-groups",
    "title": "Samtools sort",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the SAM/BAM/CRAM files containing the mapped reads.\nfile, required, example: \"input.bam\"\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_bam\nFilename to output the counts to.\nfile, required, example: \"output.bam\"\n\n\n--output_bai\nBAI-format index for BAM file.\nfile, example: \"output.bam.bai\"\n\n\n--output_format\nThe output format. By default, samtools tries to select a format based on the -o filename extension; if output is to standard output or no format can be deduced, bam is selected.\nstring, example: \"bam\"\n\n\n--compression\nCompression level, from 0 (uncompressed) to 9 (best\ninteger, example: 5\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--minimizer_cluster\nSort unmapped reads (those in chromosome ‚Äú*‚Äú) by their sequence minimiser (Schleimer et al., 2003; Roberts et al., 2004), also reverse complementing as appropriate. This has the effect of collating some similar data together, improving the compressibility of the unmapped sequence. The minimiser kmer size is adjusted using the -K option. Note data compressed in this manner may need to be name collated prior to conversion back to fastq. Mapped sequences are sorted by chromosome and position.\nboolean_true\n\n\n--minimizer_kmer\nSets the kmer size to be used in the -M option.\ninteger, example: 20\n\n\n--sort_by_read_names\nSort by read names (i.e., the QNAME field) rather than by chromosomal coordinates.\nboolean_true\n\n\n--sort_by\nSort first by this value in the alignment tag, then by position or name (if also using -n).\nstring\n\n\n--no_pg\nDo not add a @PG line to the header of the output file.\nboolean_true"
  },
  {
    "objectID": "components/modules/mapping/samtools_sort.html#authors",
    "href": "components/modules/mapping/samtools_sort.html#authors",
    "title": "Samtools sort",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)\nAngela Oliveira Pisco    (author)"
  },
  {
    "objectID": "components/modules/mapping/htseq_count.html",
    "href": "components/modules/mapping/htseq_count.html",
    "title": "Htseq count",
    "section": "",
    "text": "ID: htseq_count\nNamespace: mapping\n\n\n\nSource\nThis script takes one or more alignment files in SAM/BAM format and a feature file in GFF format and calculates for each feature the number of reads mapping to it.\nSee http://htseq.readthedocs.io/en/master/count.html for details."
  },
  {
    "objectID": "components/modules/mapping/htseq_count.html#example-commands",
    "href": "components/modules/mapping/htseq_count.html#example-commands",
    "title": "Htseq count",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/mapping/htseq_count/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\norder: \"name\"\nstranded: \"yes\"\nminimum_alignment_quality: 10\n# type: \"exon\"\n# id_attribute: [\"gene_id\"]\n# additional_attributes: [\"gene_name\"]\nadd_chromosome_info: false\nmode: \"union\"\nnon_unique: \"none\"\n# secondary_alignments: \"foo\"\n# supplementary_alignments: \"foo\"\ncounts_output_sparse: false\n\n# Input\ninput: # please fill in - example: [\"mysample1.BAM\", \"mysample2.BAM\"]\nreference: # please fill in - example: \"reference.gtf\"\n\n# Output\n# output: \"$id.$key.output.tsv\"\n# output_delimiter: \"   \"\n# output_sam: [\"$id.$key.output_sam_*.BAM\"]\n# output_sam_format: \"foo\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/htseq_count/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/htseq_count.html#argument-groups",
    "href": "components/modules/mapping/htseq_count.html#argument-groups",
    "title": "Htseq count",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the SAM/BAM files containing the mapped reads.\nList of file, required, example: \"mysample1.BAM\", \"mysample2.BAM\", multiple_sep: \";\"\n\n\n--reference\nPath to the GTF file containing the features.\nfile, required, example: \"reference.gtf\"\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nFilename to output the counts to.\nfile, required, example: \"htseq-count.tsv\"\n\n\n--output_delimiter\nColumn delimiter in output.\nstring, example: \"    \"\n\n\n--output_sam\nWrite out all SAM alignment records into SAM/BAM files (one per input file needed), annotating each line with its feature assignment (as an optional field with tag ‚ÄòXF‚Äô). See the -p option to use BAM instead of SAM.\nList of file, example: \"mysample1_out.BAM\", \"mysample2_out.BAM\", multiple_sep: \";\"\n\n\n--output_sam_format\nFormat to use with the ‚Äìoutput_sam argument.\nstring\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--order\nSorting order of . Paired-end sequencing data must be sorted either by position or by read name, and the sorting order must be specified. Ignored for single-end data.\nstring, default: \"name\"\n\n\n--stranded\nWhether the data is from a strand-specific assay. ‚Äòreverse‚Äô means ‚Äòyes‚Äô with reversed strand interpretation.\nstring, default: \"yes\"\n\n\n--minimum_alignment_quality\nSkip all reads with MAPQ alignment quality lower than the given minimum value. MAPQ is the 5th column of a SAM/BAM file and its usage depends on the software used to map the reads.\ninteger, default: 10\n\n\n--type\nFeature type (3rd column in GTF file) to be used, all features of other type are ignored (default, suitable for Ensembl GTF files: exon)\nstring, example: \"exon\"\n\n\n--id_attribute\nGTF attribute to be used as feature ID (default, suitable for Ensembl GTF files: gene_id). All feature of the right type (see -t option) within the same GTF attribute will be added together. The typical way of using this option is to count all exonic reads from each gene and add the exons but other uses are possible as well. You can call this option multiple times: in that case, the combination of all attributes separated by colons (:) will be used as a unique identifier, e.g.¬†for exons you might use -i gene_id -i exon_number.\nList of string, example: \"gene_id\", multiple_sep: \";\"\n\n\n--additional_attributes\nAdditional feature attributes (suitable for Ensembl GTF files: gene_name). Use multiple times for more than one additional attribute. These attributes are only used as annotations in the output, while the determination of how the counts are added together is done based on option -i.\nList of string, example: \"gene_name\", multiple_sep: \";\"\n\n\n--add_chromosome_info\nStore information about the chromosome of each feature as an additional attribute (e.g.¬†colunm in the TSV output file).\nboolean_true\n\n\n--mode\nMode to handle reads overlapping more than one feature.\nstring, default: \"union\"\n\n\n--non_unique\nWhether and how to score reads that are not uniquely aligned or ambiguously assigned to features.\nstring, default: \"none\"\n\n\n--secondary_alignments\nWhether to score secondary alignments (0x100 flag).\nstring\n\n\n--supplementary_alignments\nWhether to score supplementary alignments (0x800 flag).\nstring\n\n\n--counts_output_sparse\nStore the counts as a sparse matrix (mtx, h5ad, loom).\nboolean_true"
  },
  {
    "objectID": "components/modules/mapping/htseq_count.html#authors",
    "href": "components/modules/mapping/htseq_count.html#authors",
    "title": "Htseq count",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)\nAngela Oliveira Pisco    (author)"
  },
  {
    "objectID": "components/modules/mapping/cellranger_count.html",
    "href": "components/modules/mapping/cellranger_count.html",
    "title": "Cellranger count",
    "section": "",
    "text": "ID: cellranger_count\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/cellranger_count.html#example-commands",
    "href": "components/modules/mapping/cellranger_count.html#example-commands",
    "title": "Cellranger count",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/mapping/cellranger_count/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: [\"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\"]\nreference: # please fill in - example: \"reference.tar.gz\"\n\n# Outputs\n# output: \"$id.$key.output.output\"\n\n# Arguments\n# expect_cells: 3000\nchemistry: \"auto\"\nsecondary_analysis: false\ngenerate_bam: true\ninclude_introns: true\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/cellranger_count/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/cellranger_count.html#argument-groups",
    "href": "components/modules/mapping/cellranger_count.html#argument-groups",
    "title": "Cellranger count",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe fastq.gz files to align. Can also be a single directory containing fastq.gz files.\nList of file, required, example: \"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nThe path to Cell Ranger reference tar.gz file. Can also be a directory.\nfile, required, example: \"reference.tar.gz\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe folder to store the alignment results.\nfile, required, example: \"/path/to/output\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\ninteger, example: 3000\n\n\n--chemistry\nAssay configuration. - auto: autodetect mode - threeprime: Single Cell 3‚Äô - fiveprime: Single Cell 5‚Äô - SC3Pv1: Single Cell 3‚Äô v1 - SC3Pv2: Single Cell 3‚Äô v2 - SC3Pv3: Single Cell 3‚Äô v3 - SC3Pv3LT: Single Cell 3‚Äô v3 LT - SC3Pv3HT: Single Cell 3‚Äô v3 HT - SC5P-PE: Single Cell 5‚Äô paired-end - SC5P-R2: Single Cell 5‚Äô R2-only - SC-FB: Single Cell Antibody-only 3‚Äô v2 or 5‚Äô See https://kb.10xgenomics.com/hc/en-us/articles/115003764132-How-does-Cell-Ranger-auto-detect-chemistry- for more information.\nstring, default: \"auto\"\n\n\n--secondary_analysis\nWhether or not to run the secondary analysis e.g.¬†clustering.\nboolean, default: FALSE\n\n\n--generate_bam\nWhether to generate a BAM file.\nboolean, default: TRUE\n\n\n--include_introns\nInclude intronic reads in count (default=true unless ‚Äìtarget-panel is specified in which case default=false)\nboolean, default: TRUE"
  },
  {
    "objectID": "components/modules/mapping/cellranger_count.html#authors",
    "href": "components/modules/mapping/cellranger_count.html#authors",
    "title": "Cellranger count",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nSamuel D‚ÄôSouza   (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/mapping/star_build_reference.html",
    "href": "components/modules/mapping/star_build_reference.html",
    "title": "Star build reference",
    "section": "",
    "text": "ID: star_build_reference\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/star_build_reference.html#example-commands",
    "href": "components/modules/mapping/star_build_reference.html#example-commands",
    "title": "Star build reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/mapping/star_build_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input/Output\ngenome_fasta: # please fill in - example: [\"chr1.fasta\", \"chr2.fasta\"]\n# transcriptome_gtf: \"path/to/file\"\n# output: \"$id.$key.output.output\"\n\n# Genome indexing arguments\ngenomeSAindexNbases: 14\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/star_build_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/star_build_reference.html#argument-groups",
    "href": "components/modules/mapping/star_build_reference.html#argument-groups",
    "title": "Star build reference",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput/Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genome_fasta\nThe fasta files to be included in the reference. Corresponds to the ‚ÄìgenomeFastaFiles argument in the STAR command.\nList of file, required, example: \"chr1.fasta\", \"chr2.fasta\", multiple_sep: \";\"\n\n\n--transcriptome_gtf\nSpecifies the path to the file with annotated transcripts in the standard GTF format. STAR will extract splice junctions from this file and use them to greatly improve accuracy of the mapping. Corresponds to the ‚ÄìsjdbGTFfile argument in the STAR command.\nfile\n\n\n--output\nPath to output directory. Corresponds to the ‚ÄìgenomeDir argument in the STAR command.\nfile, required, example: \"/path/to/foo\"\n\n\n\n\n\nGenome indexing arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genomeSAindexNbases\nLength (bases) of the SA pre-indexing string. Typically between 10 and 15. Longer strings will use much more memory, but allow faster searches. For small genomes, the parameter {genomeSAindexNbases must be scaled down to min(14, log2(GenomeLength)/2 - 1).\ninteger, default: 14"
  },
  {
    "objectID": "components/modules/mapping/star_build_reference.html#authors",
    "href": "components/modules/mapping/star_build_reference.html#authors",
    "title": "Star build reference",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/modules/metadata/grep_annotation_column.html",
    "href": "components/modules/metadata/grep_annotation_column.html",
    "title": "Grep annotation column",
    "section": "",
    "text": "ID: grep_annotation_column\nNamespace: metadata\n\n\n\nSource\nThe annotation matrix can originate from either a modality, or all modalities (global .var or .obs)"
  },
  {
    "objectID": "components/modules/metadata/grep_annotation_column.html#example-commands",
    "href": "components/modules/metadata/grep_annotation_column.html#example-commands",
    "title": "Grep annotation column",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/metadata/grep_annotation_column/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"sample_path\"\n# input_column: \"foo\"\n# input_layer: \"foo\"\nmodality: # please fill in - example: \"rna\"\n# matrix: \"var\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\noutput_match_column: # please fill in - example: \"foo\"\n# output_fraction_column: \"foo\"\n\n# Query options\nregex_pattern: # please fill in - example: \"^[mM][tT]-\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/grep_annotation_column/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/metadata/grep_annotation_column.html#argument-groups",
    "href": "components/modules/metadata/grep_annotation_column.html#argument-groups",
    "title": "Grep annotation column",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\nArguments related to the input dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the input .h5mu.\nfile, required, example: \"sample_path\"\n\n\n--input_column\nColumn to query. If not specified, use .var_names or .obs_names, depending on the value of ‚Äìmatrix\nstring\n\n\n--input_layer\nInput data to use when calculating fraction of observations that match with the query. Only used when ‚Äìoutput_fraction_column is provided. If not specified, .X is used.\nstring\n\n\n--modality\nWhich modality to get the annotation matrix from.\nstring, required, example: \"rna\"\n\n\n--matrix\nMatrix to fetch the column from that will be searched.\nstring, example: \"var\"\n\n\n\n\n\nOutputs\nArguments related to how the output will be written.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\n\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--output_match_column\nName of the column to write the result to.\nstring, required\n\n\n--output_fraction_column\nFor the opposite axis, name of the column to write the fraction of observations that matches to the pattern.\nstring\n\n\n\n\n\nQuery options\nOptions related to the query\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--regex_pattern\nRegex to use to match with the input column.\nstring, required, example: \"^[mM][tT]-\""
  },
  {
    "objectID": "components/modules/metadata/grep_annotation_column.html#authors",
    "href": "components/modules/metadata/grep_annotation_column.html#authors",
    "title": "Grep annotation column",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/metadata/join_csv.html",
    "href": "components/modules/metadata/join_csv.html",
    "title": "Join csv",
    "section": "",
    "text": "ID: join_csv\nNamespace: metadata\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/metadata/join_csv.html#example-commands",
    "href": "components/modules/metadata/join_csv.html#example-commands",
    "title": "Join csv",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/metadata/join_csv/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# MuData Input\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# obs_key: \"foo\"\n# var_key: \"foo\"\n\n# MuData Output\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Metadata Input\ninput_csv: # please fill in - example: \"metadata.csv\"\ncsv_key: \"id\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/join_csv/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/metadata/join_csv.html#argument-groups",
    "href": "components/modules/metadata/join_csv.html#argument-groups",
    "title": "Join csv",
    "section": "Argument groups",
    "text": "Argument groups\n\nMuData Input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obs_key\nObs column name where the sample id can be found for each observation to join on. Useful when adding metadata to concatenated samples. Mutually exclusive with --var_key.‚Äù\nstring\n\n\n--var_key\nVar column name where the sample id can be found for each variable to join on. Mutually exclusive with --obs_key.‚Äù\nstring\n\n\n\n\n\nMuData Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n\n\n\nMetadata Input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_csv\n.csv file containing metadata\nfile, required, example: \"metadata.csv\"\n\n\n--csv_key\ncolumn of the the csv that corresponds to the sample id.\nstring, default: \"id\""
  },
  {
    "objectID": "components/modules/metadata/join_csv.html#authors",
    "href": "components/modules/metadata/join_csv.html#authors",
    "title": "Join csv",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/modules/metadata/add_id.html",
    "href": "components/modules/metadata/add_id.html",
    "title": "Add id",
    "section": "",
    "text": "ID: add_id\nNamespace: metadata\n\n\n\nSource\nAlso allows to make .obs_names (the .obs index) unique by prefixing the values with an unique id per .h5mu file"
  },
  {
    "objectID": "components/modules/metadata/add_id.html#example-commands",
    "href": "components/modules/metadata/add_id.html#example-commands",
    "title": "Add id",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/metadata/add_id/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"sample_path\"\ninput_id: # please fill in - example: \"foo\"\nobs_output: \"sample_id\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nmake_observation_keys_unique: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/add_id/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/metadata/add_id.html#argument-group",
    "href": "components/modules/metadata/add_id.html#argument-group",
    "title": "Add id",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the input .h5mu.\nfile, required, example: \"sample_path\"\n\n\n--input_id\nThe input id.\nstring, required\n\n\n--obs_output\nName of the .obs column where to store the id.\nstring, default: \"sample_id\"\n\n\n--output\n\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--make_observation_keys_unique\nJoin the id to the .obs index (.obs_names).\nboolean_true"
  },
  {
    "objectID": "components/modules/metadata/add_id.html#authors",
    "href": "components/modules/metadata/add_id.html#authors",
    "title": "Add id",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background.html",
    "href": "components/modules/correction/cellbender_remove_background.html",
    "title": "Cellbender remove background",
    "section": "",
    "text": "ID: cellbender_remove_background\nNamespace: correction\n\n\n\nSource\nThis module removes counts due to ambient RNA molecules and random barcode swapping from (raw) UMI-based scRNA-seq count matrices. At the moment, only the count matrices produced by the CellRanger count pipeline is supported. Support for additional tools and protocols will be added in the future. A quick start tutorial can be found here.\nFleming et al.¬†2022, bioRxiv."
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background.html#example-commands",
    "href": "components/modules/correction/cellbender_remove_background.html#example-commands",
    "title": "Cellbender remove background",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/correction/cellbender_remove_background/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nlayer_output: \"cellbender_corrected\"\nobs_background_fraction: \"cellbender_background_fraction\"\nobs_cell_probability: \"cellbender_cell_probability\"\nobs_cell_size: \"cellbender_cell_size\"\nobs_droplet_efficiency: \"cellbender_droplet_efficiency\"\nobs_latent_scale: \"cellbender_latent_scale\"\nvar_ambient_expression: \"cellbender_ambient_expression\"\nobsm_gene_expression_encoding: \"cellbender_gene_expression_encoding\"\n\n# Arguments\nexpected_cells_from_qc: false\n# expected_cells: 1000\n# total_droplets_included: 25000\n# force_cell_umi_prior: 123\n# force_empty_umi_prior: 123\nmodel: \"full\"\nepochs: 150\nlow_count_threshold: 5\nz_dim: 64\nz_layers: [512]\ntraining_fraction: 0.9\nempty_drop_training_fraction: 0.2\n# ignore_features: [123]\nfpr: [0.01]\n# exclude_feature_types: [\"foo\"]\nprojected_ambient_count_threshold: 0.1\nlearning_rate: 1.0E-4\n# final_elbo_fail_fraction: 123.0\n# epoch_elbo_fail_fraction: 123.0\nnum_training_tries: 1\nlearning_rate_retry_mult: 0.2\nposterior_batch_size: 128\n# posterior_regulation: \"foo\"\n# alpha: 123.0\n# q: 123.0\nestimator: \"mckp\"\nestimator_multiple_cpu: false\n# constant_learning_rate: true\ndebug: false\ncuda: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/correction/cellbender_remove_background/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background.html#argument-groups",
    "href": "components/modules/correction/cellbender_remove_background.html#argument-groups",
    "title": "Cellbender remove background",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file. Data file on which to run tool. Data must be un-filtered: it should include empty droplets.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nList of modalities to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nFull count matrix as an h5mu file, with background RNA removed. This file contains all the original droplet barcodes.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--layer_output\nOutput layer\nstring, default: \"cellbender_corrected\"\n\n\n--obs_background_fraction\n\nstring, default: \"cellbender_background_fraction\"\n\n\n--obs_cell_probability\n\nstring, default: \"cellbender_cell_probability\"\n\n\n--obs_cell_size\n\nstring, default: \"cellbender_cell_size\"\n\n\n--obs_droplet_efficiency\n\nstring, default: \"cellbender_droplet_efficiency\"\n\n\n--obs_latent_scale\n\nstring, default: \"cellbender_latent_scale\"\n\n\n--var_ambient_expression\n\nstring, default: \"cellbender_ambient_expression\"\n\n\n--obsm_gene_expression_encoding\n\nstring, default: \"cellbender_gene_expression_encoding\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--expected_cells_from_qc\nWill use the Cell Ranger QC to determine the estimated number of cells\nboolean, default: FALSE\n\n\n--expected_cells\nNumber of cells expected in the dataset (a rough estimate within a factor of 2 is sufficient).\ninteger, example: 1000\n\n\n--total_droplets_included\nThe number of droplets from the rank-ordered UMI plot that will have their cell probabilities inferred as an output. Include the droplets which might contain cells. Droplets beyond TOTAL_DROPLETS_INCLUDED should be ‚Äòsurely empty‚Äô droplets.\ninteger, example: 25000\n\n\n--force_cell_umi_prior\nIgnore CellBender‚Äôs heuristic prior estimation, and use this prior for UMI counts in cells.\ninteger\n\n\n--force_empty_umi_prior\nIgnore CellBender‚Äôs heuristic prior estimation, and use this prior for UMI counts in empty droplets.\ninteger\n\n\n--model\nWhich model is being used for count data. * ‚Äònaive‚Äô subtracts the estimated ambient profile. * ‚Äòsimple‚Äô does not model either ambient RNA or random barcode swapping (for debugging purposes ‚Äì not recommended). * ‚Äòambient‚Äô assumes background RNA is incorporated into droplets. * ‚Äòswapping‚Äô assumes background RNA comes from random barcode swapping (via PCR chimeras). * ‚Äòfull‚Äô uses a combined ambient and swapping model.\nstring, default: \"full\"\n\n\n--epochs\nNumber of epochs to train.\ninteger, default: 150\n\n\n--low_count_threshold\nDroplets with UMI counts below this number are completely excluded from the analysis. This can help identify the correct prior for empty droplet counts in the rare case where empty counts are extremely high (over 200).\ninteger, default: 5\n\n\n--z_dim\nDimension of latent variable z.\ninteger, default: 64\n\n\n--z_layers\nDimension of hidden layers in the encoder for z.\nList of integer, default: 512, multiple_sep: \";\"\n\n\n--training_fraction\nTraining detail: the fraction of the data used for training. The rest is never seen by the inference algorithm. Speeds up learning.\ndouble, default: 0.9\n\n\n--empty_drop_training_fraction\nTraining detail: the fraction of the training data each epoch that is drawn (randomly sampled) from surely empty droplets.\ndouble, default: 0.2\n\n\n--ignore_features\nInteger indices of features to ignore entirely. In the output count matrix, the counts for these features will be unchanged.\nList of integer, multiple_sep: \";\"\n\n\n--fpr\nTarget ‚Äòdelta‚Äô false positive rate in [0, 1). Use 0 for a cohort of samples which will be jointly analyzed for differential expression. A false positive is a true signal count that is erroneously removed. More background removal is accompanied by more signal removal at high values of FPR. You can specify multiple values, which will create multiple output files.\nList of double, default: 0.01, multiple_sep: \";\"\n\n\n--exclude_feature_types\nFeature types to ignore during the analysis. These features will be left unchanged in the output file.\nList of string, multiple_sep: \";\"\n\n\n--projected_ambient_count_threshold\nControls how many features are included in the analysis, which can lead to a large speedup. If a feature is expected to have less than PROJECTED_AMBIENT_COUNT_THRESHOLD counts total in all cells (summed), then that gene is excluded, and it will be unchanged in the output count matrix. For example, PROJECTED_AMBIENT_COUNT_THRESHOLD = 0 will include all features which have even a single count in any empty droplet.\ndouble, default: 0.1\n\n\n--learning_rate\nTraining detail: lower learning rate for inference. A OneCycle learning rate schedule is used, where the upper learning rate is ten times this value. (For this value, probably do not exceed 1e-3).\ndouble, default: 1e-04\n\n\n--final_elbo_fail_fraction\nTraining is considered to have failed if (best_test_ELBO - final_test_ELBO)/(best_test_ELBO - initial_test_ELBO) &gt; FINAL_ELBO_FAIL_FRACTION. Training will automatically re-run if ‚Äìnum-training-tries &gt; 1. By default, will not fail training based on final_training_ELBO.\ndouble\n\n\n--epoch_elbo_fail_fraction\nTraining is considered to have failed if (previous_epoch_test_ELBO - current_epoch_test_ELBO)/(previous_epoch_test_ELBO - initial_train_ELBO) &gt; EPOCH_ELBO_FAIL_FRACTION. Training will automatically re-run if ‚Äìnum-training-tries &gt; 1. By default, will not fail training based on epoch_training_ELBO.\ndouble\n\n\n--num_training_tries\nNumber of times to attempt to train the model. At each subsequent attempt, the learning rate is multiplied by LEARNING_RATE_RETRY_MULT.\ninteger, default: 1\n\n\n--learning_rate_retry_mult\nLearning rate is multiplied by this amount each time a new training attempt is made. (This parameter is only used if training fails based on EPOCH_ELBO_FAIL_FRACTION or FINAL_ELBO_FAIL_FRACTION and NUM_TRAINING_TRIES is &gt; 1.)\ndouble, default: 0.2\n\n\n--posterior_batch_size\nTraining detail: size of batches when creating the posterior. Reduce this to avoid running out of GPU memory creating the posterior (will be slower).\ninteger, default: 128\n\n\n--posterior_regulation\nPosterior regularization method. (For experts: not required for normal usage, see documentation). * PRq is approximate quantile-targeting. * PRmu is approximate mean-targeting aggregated over genes (behavior of v0.2.0). * PRmu_gene is approximate mean-targeting per gene.\nstring\n\n\n--alpha\nTunable parameter alpha for the PRq posterior regularization method (not normally used: see documentation).\ndouble\n\n\n--q\nTunable parameter q for the CDF threshold estimation method (not normally used: see documentation).\ndouble\n\n\n--estimator\nOutput denoised count estimation method. (For experts: not required for normal usage, see documentation).\nstring, default: \"mckp\"\n\n\n--estimator_multiple_cpu\nIncluding the flag ‚Äìestimator-multiple-cpu will use more than one CPU to compute the MCKP output count estimator in parallel (does nothing for other estimators).\nboolean_true\n\n\n--constant_learning_rate\nIncluding the flag ‚Äìconstant-learning-rate will use the ClippedAdam optimizer instead of the OneCycleLR learning rate schedule, which is the default. Learning is faster with the OneCycleLR schedule. However, training can easily be continued from a checkpoint for more epochs than the initial command specified when using ClippedAdam. On the other hand, if using the OneCycleLR schedule with 150 epochs specified, it is not possible to pick up from that final checkpoint and continue training until 250 epochs.\nboolean\n\n\n--debug\nIncluding the flag ‚Äìdebug will log extra messages useful for debugging.\nboolean_true\n\n\n--cuda\nIncluding the flag ‚Äìcuda will run the inference on a GPU.\nboolean_true"
  },
  {
    "objectID": "components/modules/neighbors/bbknn.html",
    "href": "components/modules/neighbors/bbknn.html",
    "title": "Bbknn",
    "section": "",
    "text": "ID: bbknn\nNamespace: neighbors\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/neighbors/bbknn.html#example-commands",
    "href": "components/modules/neighbors/bbknn.html#example-commands",
    "title": "Bbknn",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/neighbors/bbknn/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\nobsm_input: \"X_pca\"\nobs_batch: \"batch\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nuns_output: \"neighbors\"\nobsp_distances: \"distances\"\nobsp_connectivities: \"connectivities\"\nn_neighbors_within_batch: 3\nn_pcs: 50\n# n_trim: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/neighbors/bbknn/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/neighbors/bbknn.html#argument-group",
    "href": "components/modules/neighbors/bbknn.html#argument-group",
    "title": "Bbknn",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsm_input\nThe dimensionality reduction in .obsm to use for neighbour detection. Defaults to X_pca.\nstring, default: \"X_pca\"\n\n\n--obs_batch\n.obs column name discriminating between your batches.\nstring, default: \"batch\"\n\n\n--output\nOutput .h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--uns_output\nMandatory .uns slot to store various neighbor output objects.\nstring, default: \"neighbors\"\n\n\n--obsp_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"distances\"\n\n\n--obsp_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"connectivities\"\n\n\n--n_neighbors_within_batch\nHow many top neighbours to report for each batch; total number of neighbours in the initial k-nearest-neighbours computation will be this number times the number of batches.\ninteger, default: 3\n\n\n--n_pcs\nHow many dimensions (in case of PCA, principal components) to use in the analysis.\ninteger, default: 50\n\n\n--n_trim\nTrim the neighbours of each cell to these many top connectivities. May help with population independence and improve the tidiness of clustering. The lower the value the more independent the individual populations, at the cost of more conserved batch effect. If None (default), sets the parameter value automatically to 10 times neighbors_within_batch times the number of batches. Set to 0 to skip.\ninteger"
  },
  {
    "objectID": "components/modules/neighbors/bbknn.html#authors",
    "href": "components/modules/neighbors/bbknn.html#authors",
    "title": "Bbknn",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_seurat.html",
    "href": "components/modules/convert/from_h5mu_to_seurat.html",
    "title": "From h5mu to seurat",
    "section": "",
    "text": "ID: from_h5mu_to_seurat\nNamespace: convert\n\n\n\nSource\nRestrictions: - Only the intersection of cells is currently loaded into the Seurat object due to the object structure limitation. - Multimodal embeddings (global .obsm slot) are loaded with the assay.used field set to the default assay. - Embeddings names are changed in order to comply with R & Seurat requirements and conventions. - Feature names with underscores (‚Äô_‚Äò) are automatically replaced with dashes (‚Äô-‚Äô) - Seurat does not support global variables metadata /var."
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_seurat.html#example-commands",
    "href": "components/modules/convert/from_h5mu_to_seurat.html#example-commands",
    "title": "From h5mu to seurat",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/convert/from_h5mu_to_seurat/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\n# output: \"$id.$key.output.rds\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_h5mu_to_seurat/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_seurat.html#argument-group",
    "href": "components/modules/convert/from_h5mu_to_seurat.html#argument-group",
    "title": "From h5mu to seurat",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--output\nOutput Seurat file\nfile, required, example: \"output.rds\""
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_seurat.html#authors",
    "href": "components/modules/convert/from_h5mu_to_seurat.html#authors",
    "title": "From h5mu to seurat",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/convert/from_10xh5_to_h5mu.html",
    "href": "components/modules/convert/from_10xh5_to_h5mu.html",
    "title": "From 10xh5 to h5mu",
    "section": "",
    "text": "ID: from_10xh5_to_h5mu\nNamespace: convert\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/convert/from_10xh5_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_10xh5_to_h5mu.html#example-commands",
    "title": "From 10xh5 to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/convert/from_10xh5_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"raw_feature_bc_matrix.h5\"\n# input_metrics_summary: \"metrics_cellranger.h5\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nuns_metrics: \"metrics_cellranger\"\n\n# Arguments\n# min_genes: 100\n# min_counts: 1000\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_10xh5_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_10xh5_to_h5mu.html#argument-groups",
    "href": "components/modules/convert/from_10xh5_to_h5mu.html#argument-groups",
    "title": "From 10xh5 to h5mu",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nA 10x h5 file as generated by Cell Ranger.\nfile, required, example: \"raw_feature_bc_matrix.h5\"\n\n\n--input_metrics_summary\nA metrics summary csv file as generated by Cell Ranger.\nfile, example: \"metrics_cellranger.h5\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--uns_metrics\nName of the .uns slot under which to QC metrics (if any).\nstring, default: \"metrics_cellranger\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_genes\nMinimum number of counts required for a cell to pass filtering.\ninteger, example: 100\n\n\n--min_counts\nMinimum number of genes expressed required for a cell to pass filtering.\ninteger, example: 1000"
  },
  {
    "objectID": "components/modules/convert/from_10xh5_to_h5mu.html#authors",
    "href": "components/modules/convert/from_10xh5_to_h5mu.html#authors",
    "title": "From 10xh5 to h5mu",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_h5ad.html",
    "href": "components/modules/convert/from_h5mu_to_h5ad.html",
    "title": "From h5mu to h5ad",
    "section": "",
    "text": "ID: from_h5mu_to_h5ad\nNamespace: convert\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_h5ad.html#example-commands",
    "href": "components/modules/convert/from_h5mu_to_h5ad.html#example-commands",
    "title": "From h5mu to h5ad",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/convert/from_h5mu_to_h5ad/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# output: \"$id.$key.output.h5ad\"\noutput_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_h5mu_to_h5ad/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_h5ad.html#argument-group",
    "href": "components/modules/convert/from_h5mu_to_h5ad.html#argument-group",
    "title": "From h5mu to h5ad",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput MuData file\nfile, required, default: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--output\nOutput AnnData file.\nfile, default: \"output.h5ad\"\n\n\n--output_compression\nThe compression format to be used on the final h5ad object.\nstring, default: \"gzip\""
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_h5ad.html#authors",
    "href": "components/modules/convert/from_h5mu_to_h5ad.html#authors",
    "title": "From h5mu to h5ad",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/convert/velocyto_to_h5mu.html",
    "href": "components/modules/convert/velocyto_to_h5mu.html",
    "title": "Velocyto to h5mu",
    "section": "",
    "text": "ID: velocyto_to_h5mu\nNamespace: convert\n\n\n\nSource\nIf an input h5mu file is also provided, the velocity h5ad object will get added to that h5mu instead."
  },
  {
    "objectID": "components/modules/convert/velocyto_to_h5mu.html#example-commands",
    "href": "components/modules/convert/velocyto_to_h5mu.html#example-commands",
    "title": "Velocyto to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/convert/velocyto_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput_loom: # please fill in - example: \"input.loom\"\n# input_h5mu: \"input.h5mu\"\nmodality: \"rna_velocity\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nlayer_spliced: \"velo_spliced\"\nlayer_unspliced: \"velo_unspliced\"\nlayer_ambiguous: \"velo_ambiguous\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/velocyto_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/velocyto_to_h5mu.html#argument-groups",
    "href": "components/modules/convert/velocyto_to_h5mu.html#argument-groups",
    "title": "Velocyto to h5mu",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_loom\nPath to the input loom file.\nfile, required, example: \"input.loom\"\n\n\n--input_h5mu\nIf a MuData file is provided,\nfile, example: \"input.h5mu\"\n\n\n--modality\nThe name of the modality to operate on.\nstring, default: \"rna_velocity\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nPath to the output MuData file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--layer_spliced\nOutput layer for the spliced reads.\nstring, default: \"velo_spliced\"\n\n\n--layer_unspliced\nOutput layer for the unspliced reads.\nstring, default: \"velo_unspliced\"\n\n\n--layer_ambiguous\nOutput layer for the ambiguous reads.\nstring, default: \"velo_ambiguous\""
  },
  {
    "objectID": "components/modules/convert/velocyto_to_h5mu.html#authors",
    "href": "components/modules/convert/velocyto_to_h5mu.html#authors",
    "title": "Velocyto to h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer, author)\nRobrecht Cannoodt    (author)\nAngela Oliveira Pisco    (contributor)"
  },
  {
    "objectID": "components/modules/convert/from_10xmtx_to_h5mu.html",
    "href": "components/modules/convert/from_10xmtx_to_h5mu.html",
    "title": "From 10xmtx to h5mu",
    "section": "",
    "text": "ID: from_10xmtx_to_h5mu\nNamespace: convert\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/convert/from_10xmtx_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_10xmtx_to_h5mu.html#example-commands",
    "title": "From 10xmtx to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/convert/from_10xmtx_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input_dir_containing_gz_files\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_10xmtx_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_10xmtx_to_h5mu.html#argument-group",
    "href": "components/modules/convert/from_10xmtx_to_h5mu.html#argument-group",
    "title": "From 10xmtx to h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput mtx folder\nfile, required, example: \"input_dir_containing_gz_files\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/convert/from_10xmtx_to_h5mu.html#authors",
    "href": "components/modules/convert/from_10xmtx_to_h5mu.html#authors",
    "title": "From 10xmtx to h5mu",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/qc/calculate_qc_metrics.html",
    "href": "components/modules/qc/calculate_qc_metrics.html",
    "title": "Calculate qc metrics",
    "section": "",
    "text": "ID: calculate_qc_metrics\nNamespace: qc\n\n\n\nSource\nThe metrics are comparable to what scanpy.pp.calculate_qc_metrics output, although they have slightly different names:\nVar metrics (name in this component -&gt; name in scanpy): - pct_dropout -&gt; pct_dropout_by_{expr_type} - num_nonzero_obs -&gt; n_cells_by_{expr_type} - obs_mean -&gt; mean_{expr_type} - total_counts -&gt; total_{expr_type}\nObs metrics: - num_nonzero_vars -&gt; n_genes_by_{expr_type} - pct_{var_qc_metrics} -&gt; pct_{expr_type}{qc_var} - total_counts{var_qc_metrics} -&gt; total_{expr_type}{qc_var} - pct_of_counts_in_top{top_n_vars}vars -&gt; pct{expr_type}in_top{n}{var_type} - total_counts -&gt; total{expr_type}"
  },
  {
    "objectID": "components/modules/qc/calculate_qc_metrics.html#example-commands",
    "href": "components/modules/qc/calculate_qc_metrics.html#example-commands",
    "title": "Calculate qc metrics",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/qc/calculate_qc_metrics/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"raw_counts\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Metrics added to .obs\n# var_qc_metrics: [\"ercc,highly_variable,mitochondrial\"]\n# var_qc_metrics_fill_na_value: true\n# top_n_vars: [123]\noutput_obs_num_nonzero_vars: \"num_nonzero_vars\"\noutput_obs_total_counts_vars: \"total_counts\"\n\n# Metrics added to .var\noutput_var_num_nonzero_obs: \"num_nonzero_obs\"\noutput_var_total_counts_obs: \"total_counts\"\noutput_var_obs_mean: \"obs_mean\"\noutput_var_pct_dropout: \"pct_dropout\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/qc/calculate_qc_metrics/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/qc/calculate_qc_metrics.html#argument-groups",
    "href": "components/modules/qc/calculate_qc_metrics.html#argument-groups",
    "title": "Calculate qc metrics",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\n\nstring, example: \"raw_counts\"\n\n\n\n\n\nMetrics added to .obs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‚ÄòTrue‚Äô, compared to the total sum of the values for all genes.\nList of string, example: \"ercc,highly_variable,mitochondrial\", multiple_sep: \";\"\n\n\n--var_qc_metrics_fill_na_value\nFill any ‚ÄòNA‚Äô values found in the columns specified with ‚Äìvar_qc_metrics to ‚ÄòTrue‚Äô or ‚ÄòFalse‚Äô. as False.\nboolean\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20;50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, multiple_sep: \";\"\n\n\n--output_obs_num_nonzero_vars\nName of column in .obs describing, for each observation, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each row the number of columns that contain data.\nstring, default: \"num_nonzero_vars\"\n\n\n--output_obs_total_counts_vars\nName of the column for .obs describing, for each observation (row), the sum of the stored values in the columns.\nstring, default: \"total_counts\"\n\n\n\n\n\nMetrics added to .var\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_var_num_nonzero_obs\nName of column describing, for each feature, the number of stored values (including explicit zeroes). In other words, the name of the column that counts for each column the number of rows that contain data.\nstring, default: \"num_nonzero_obs\"\n\n\n--output_var_total_counts_obs\nName of the column in .var describing, for each feature (column), the sum of the stored values in the rows.\nstring, default: \"total_counts\"\n\n\n--output_var_obs_mean\nName of the column in .obs providing the mean of the values in each row.\nstring, default: \"obs_mean\"\n\n\n--output_var_pct_dropout\nName of the column in .obs providing for each feature the percentage of observations the feature does not appear on (i.e.¬†is missing). Same as --num_nonzero_obs but percentage based.\nstring, default: \"pct_dropout\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/qc/calculate_qc_metrics.html#authors",
    "href": "components/modules/qc/calculate_qc_metrics.html#authors",
    "title": "Calculate qc metrics",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/modules/filter/filter_with_counts.html",
    "href": "components/modules/filter/filter_with_counts.html",
    "title": "Filter with counts",
    "section": "",
    "text": "ID: filter_with_counts\nNamespace: filter\n\n\n\nSource\nThis is based on both the UMI counts, the gene counts and the mitochondrial genes (genes starting with mt/MT)"
  },
  {
    "objectID": "components/modules/filter/filter_with_counts.html#example-commands",
    "href": "components/modules/filter/filter_with_counts.html#example-commands",
    "title": "Filter with counts",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/filter/filter_with_counts/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"raw_counts\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\ndo_subset: false\nobs_name_filter: \"filter_with_counts\"\nvar_name_filter: \"filter_with_counts\"\n\n# Arguments\n# min_counts: 200\n# max_counts: 5000000\n# min_genes_per_cell: 200\n# max_genes_per_cell: 1500000\n# min_cells_per_gene: 3\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/filter_with_counts/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/filter_with_counts.html#argument-groups",
    "href": "components/modules/filter/filter_with_counts.html#argument-groups",
    "title": "Filter with counts",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\n\nstring, example: \"raw_counts\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--do_subset\nWhether to subset before storing the output.\nboolean_true\n\n\n--obs_name_filter\nIn which .obs slot to store a boolean array corresponding to which observations should be removed.\nstring, default: \"filter_with_counts\"\n\n\n--var_name_filter\nIn which .var slot to store a boolean array corresponding to which variables should be removed.\nstring, default: \"filter_with_counts\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--min_genes_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--max_genes_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--min_cells_per_gene\nMinimum of non-zero values per gene.\ninteger, example: 3"
  },
  {
    "objectID": "components/modules/filter/filter_with_counts.html#authors",
    "href": "components/modules/filter/filter_with_counts.html#authors",
    "title": "Filter with counts",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (maintainer, author)"
  },
  {
    "objectID": "components/modules/filter/filter_with_hvg.html",
    "href": "components/modules/filter/filter_with_hvg.html",
    "title": "Filter with hvg",
    "section": "",
    "text": "ID: filter_with_hvg\nNamespace: filter\n\n\n\nSource\nExpects logarithmized data, except when flavor=‚Äòseurat_v3‚Äô in which count data is expected.\nDepending on flavor, this reproduces the R-implementations of Seurat [Satija15], Cell Ranger [Zheng17], and Seurat v3 [Stuart19].\nFor the dispersion-based methods ([Satija15] and [Zheng17]), the normalized dispersion is obtained by scaling with the mean and standard deviation of the dispersions for genes falling into a given bin for mean expression of genes. This means that for each bin of mean expression, highly variable genes are selected.\nFor [Stuart19], a normalized variance for each gene is computed. First, the data are standardized (i.e., z-score normalization per feature) with a regularized standard deviation. Next, the normalized variance is computed as the variance of each gene after the transformation. Genes are ranked by the normalized variance."
  },
  {
    "objectID": "components/modules/filter/filter_with_hvg.html#example-commands",
    "href": "components/modules/filter/filter_with_hvg.html#example-commands",
    "title": "Filter with hvg",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/filter/filter_with_hvg/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nvar_name_filter: \"filter_with_hvg\"\nvarm_name: \"hvg\"\ndo_subset: false\nflavor: \"seurat\"\n# n_top_genes: 123\nmin_mean: 0.0125\nmax_mean: 3\nmin_disp: 0.5\n# max_disp: 123.0\nspan: 0.3\nn_bins: 20\n# obs_batch_key: \"foo\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/filter_with_hvg/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/filter_with_hvg.html#argument-group",
    "href": "components/modules/filter/filter_with_hvg.html#argument-group",
    "title": "Filter with hvg",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nuse adata.layers[layer] for expression values instead of adata.X.\nstring\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--var_name_filter\nIn which .var slot to store a boolean array corresponding to which observations should be filtered out.\nstring, default: \"filter_with_hvg\"\n\n\n--varm_name\nIn which .varm slot to store additional metadata.\nstring, default: \"hvg\"\n\n\n--do_subset\nWhether to subset before storing the output.\nboolean_true\n\n\n--flavor\nChoose the flavor for identifying highly variable genes. For the dispersion based methods in their default workflows, Seurat passes the cutoffs whereas Cell Ranger passes n_top_genes.\nstring, default: \"seurat\"\n\n\n--n_top_genes\nNumber of highly-variable genes to keep. Mandatory if flavor=‚Äòseurat_v3‚Äô.\ninteger\n\n\n--min_mean\nIf n_top_genes is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‚Äòseurat_v3‚Äô.\ndouble, default: 0.0125\n\n\n--max_mean\nIf n_top_genes is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‚Äòseurat_v3‚Äô.\ndouble, default: 3\n\n\n--min_disp\nIf n_top_genes is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‚Äòseurat_v3‚Äô.\ndouble, default: 0.5\n\n\n--max_disp\nIf n_top_genes is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‚Äòseurat_v3‚Äô. Default is +inf.\ndouble\n\n\n--span\nThe fraction of the data (cells) used when estimating the variance in the loess model fit if flavor=‚Äòseurat_v3‚Äô.\ndouble, default: 0.3\n\n\n--n_bins\nNumber of bins for binning the mean gene expression. Normalization is done with respect to each bin. If just a single gene falls into a bin, the normalized dispersion is artificially set to 1.\ninteger, default: 20\n\n\n--obs_batch_key\nIf specified, highly-variable genes are selected within each batch separately and merged. This simple process avoids the selection of batch-specific genes and acts as a lightweight batch correction method. For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If flavor = ‚Äòseurat_v3‚Äô, ties are broken by the median (across batches) rank based on within-batch normalized variance.\nstring"
  },
  {
    "objectID": "components/modules/filter/filter_with_hvg.html#authors",
    "href": "components/modules/filter/filter_with_hvg.html#authors",
    "title": "Filter with hvg",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (contributor)\nRobrecht Cannoodt    (maintainer, contributor)"
  },
  {
    "objectID": "components/modules/filter/delimit_fraction.html",
    "href": "components/modules/filter/delimit_fraction.html",
    "title": "Delimit fraction",
    "section": "",
    "text": "ID: delimit_fraction\nNamespace: filter\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/filter/delimit_fraction.html#example-commands",
    "href": "components/modules/filter/delimit_fraction.html#example-commands",
    "title": "Delimit fraction",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/filter/delimit_fraction/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"raw_counts\"\nobs_fraction_column: # please fill in - example: \"fraction_mitochondrial\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobs_name_filter: # please fill in - example: \"foo\"\n\n# Arguments\nmin_fraction: 0\nmax_fraction: 1\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/delimit_fraction/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/delimit_fraction.html#argument-groups",
    "href": "components/modules/filter/delimit_fraction.html#argument-groups",
    "title": "Delimit fraction",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\n\nstring, example: \"raw_counts\"\n\n\n--obs_fraction_column\nName of column from .var dataframe selecting a column that contains floating point values between 0 and 1.\nstring, required, example: \"fraction_mitochondrial\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obs_name_filter\nIn which .obs slot to store a boolean array corresponding to which observations should be removed.\nstring, required\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_fraction\nMin fraction for an observation to be retained (True in output).\ndouble, default: 0\n\n\n--max_fraction\nMax fraction for an observation to be retained (True in output).\ndouble, default: 1"
  },
  {
    "objectID": "components/modules/filter/delimit_fraction.html#authors",
    "href": "components/modules/filter/delimit_fraction.html#authors",
    "title": "Delimit fraction",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)"
  },
  {
    "objectID": "components/modules/filter/filter_with_scrublet.html",
    "href": "components/modules/filter/filter_with_scrublet.html",
    "title": "Filter with scrublet",
    "section": "",
    "text": "ID: filter_with_scrublet\nNamespace: filter\n\n\n\nSource\nThe method tests for potential doublets by using the expression profiles of cells to generate synthetic potential doubles which are tested against cells. The method returns a ‚Äúdoublet score‚Äù on which it calls for potential doublets.\nFor the source code please visit https://github.com/AllonKleinLab/scrublet.\nFor 10x we expect the doublet rates to be: Multiplet Rate (%) - # of Cells Loaded - # of Cells Recovered ~0.4% ~800 ~500 ~0.8% ~1,600 ~1,000 ~1.6% ~3,200 ~2,000 ~2.3% ~4,800 ~3,000 ~3.1% ~6,400 ~4,000 ~3.9% ~8,000 ~5,000 ~4.6% ~9,600 ~6,000 ~5.4% ~11,200 ~7,000 ~6.1% ~12,800 ~8,000 ~6.9% ~14,400 ~9,000 ~7.6% ~16,000 ~10,000"
  },
  {
    "objectID": "components/modules/filter/filter_with_scrublet.html#example-commands",
    "href": "components/modules/filter/filter_with_scrublet.html#example-commands",
    "title": "Filter with scrublet",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/filter/filter_with_scrublet/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobs_name_filter: \"filter_with_scrublet\"\ndo_subset: false\nobs_name_doublet_score: \"scrublet_doublet_score\"\nmin_counts: 2\nmin_cells: 3\nmin_gene_variablity_percent: 85\nnum_pca_components: 30\ndistance_metric: \"euclidean\"\nallow_automatic_threshold_detection_fail: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/filter_with_scrublet/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/filter_with_scrublet.html#argument-group",
    "href": "components/modules/filter/filter_with_scrublet.html#argument-group",
    "title": "Filter with scrublet",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nInput layer to use as data for calculating doublets. .X is used not specified.\nstring\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obs_name_filter\nIn which .obs slot to store a boolean array corresponding to which observations should be filtered out.\nstring, default: \"filter_with_scrublet\"\n\n\n--do_subset\nWhether to subset before storing the output.\nboolean_true\n\n\n--obs_name_doublet_score\nName of the doublet scores column in the obs slot of the returned object.\nstring, default: \"scrublet_doublet_score\"\n\n\n--min_counts\nThe number of minimal UMI counts per cell that have to be present for initial cell detection.\ninteger, default: 2\n\n\n--min_cells\nThe number of cells in which UMIs for a gene were detected.\ninteger, default: 3\n\n\n--min_gene_variablity_percent\nUsed for gene filtering prior to PCA. Keep the most highly variable genes (in the top min_gene_variability_pctl percentile), as measured by the v-statistic [Klein et al., Cell 2015].\ndouble, default: 85\n\n\n--num_pca_components\nNumber of principal components to use during PCA dimensionality reduction.\ninteger, default: 30\n\n\n--distance_metric\nThe distance metric used for computing similarities.\nstring, default: \"euclidean\"\n\n\n--allow_automatic_threshold_detection_fail\nWhen scrublet fails to automatically determine the double score threshold, allow the component to continue and set the output columns to NA.\nboolean_true"
  },
  {
    "objectID": "components/modules/filter/filter_with_scrublet.html#authors",
    "href": "components/modules/filter/filter_with_scrublet.html#authors",
    "title": "Filter with scrublet",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (contributor)\nRobrecht Cannoodt    (maintainer, contributor)"
  },
  {
    "objectID": "components/modules/report/mermaid.html",
    "href": "components/modules/report/mermaid.html",
    "title": "Mermaid",
    "section": "",
    "text": "ID: mermaid\nNamespace: report\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/report/mermaid.html#example-commands",
    "href": "components/modules/report/mermaid.html#example-commands",
    "title": "Mermaid",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/report/mermaid/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\n# output: \"$id.$key.output.output\"\n# output_format: \"foo\"\nwidth: 800\nheight: 600\nbackground_color: \"white\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/report/mermaid/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/report/mermaid.html#argument-group",
    "href": "components/modules/report/mermaid.html#argument-group",
    "title": "Mermaid",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput directory\nfile, required\n\n\n--output\nGenerated network as output.\nfile, required\n\n\n--output_format\nOutput format for the generated image. By default will be inferred from the extension of the file specified with ‚Äìoutput.\nstring\n\n\n--width\nWidth of the page\ninteger, default: 800\n\n\n--height\nHeight of the page\ninteger, default: 600\n\n\n--background_color\nBackground color for pngs/svgs (not pdfs)\nstring, default: \"white\", example: \"#F0F0F0\""
  },
  {
    "objectID": "components/modules/report/mermaid.html#authors",
    "href": "components/modules/report/mermaid.html#authors",
    "title": "Mermaid",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)"
  },
  {
    "objectID": "components/modules/integrate/totalvi.html",
    "href": "components/modules/integrate/totalvi.html",
    "title": "Totalvi",
    "section": "",
    "text": "ID: totalvi\nNamespace: integrate\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/integrate/totalvi.html#example-commands",
    "href": "components/modules/integrate/totalvi.html#example-commands",
    "title": "Totalvi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/integrate/totalvi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"path/to/file\"\nreference: # please fill in - example: \"path/to/file\"\nforce_retrain: false\nquery_modality: \"rna\"\n# query_proteins_modality: \"foo\"\nreference_modality: \"rna\"\nreference_proteins_modality: \"prot\"\n# input_layer: \"foo\"\nobs_batch: \"sample_id\"\n# var_input: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.output\"\nobsm_output: \"X_integrated_totalvi\"\nobsm_normalized_rna_output: \"X_totalvi_normalized_rna\"\nobsm_normalized_protein_output: \"X_totalvi_normalized_protein\"\n# reference_model_path: \"$id.$key.reference_model_path.reference_model_path\"\n# query_model_path: \"$id.$key.query_model_path.query_model_path\"\n\n# Learning parameters\nmax_epochs: 400\nmax_query_epochs: 200\nweight_decay: 0.0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/totalvi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/integrate/totalvi.html#argument-groups",
    "href": "components/modules/integrate/totalvi.html#argument-groups",
    "title": "Totalvi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file with query data to integrate with reference.\nfile, required\n\n\n--reference\nInput h5mu file with reference data to train the TOTALVI model.\nfile, required\n\n\n--force_retrain\nIf true, retrain the model and save it to reference_model_path\nboolean_true\n\n\n--query_modality\n\nstring, default: \"rna\"\n\n\n--query_proteins_modality\nName of the modality in the input (query) h5mu file containing protein data\nstring\n\n\n--reference_modality\n\nstring, default: \"rna\"\n\n\n--reference_proteins_modality\nName of the modality containing proteins in the reference\nstring, default: \"prot\"\n\n\n--input_layer\nInput layer to use. If None, X is used\nstring\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--var_input\n.var column containing highly variable genes. By default, do not subset genes.\nstring\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_integrated_totalvi\"\n\n\n--obsm_normalized_rna_output\nIn which .obsm slot to store the normalized RNA from TOTALVI.\nstring, default: \"X_totalvi_normalized_rna\"\n\n\n--obsm_normalized_protein_output\nIn which .obsm slot to store the normalized protein data from TOTALVI.\nstring, default: \"X_totalvi_normalized_protein\"\n\n\n--reference_model_path\nDirectory with the reference model. If not exists, trained model will be saved there\nfile, default: \"totalvi_model_reference\"\n\n\n--query_model_path\nDirectory, where the query model will be saved\nfile, default: \"totalvi_model_query\"\n\n\n\n\n\nLearning parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--max_epochs\nNumber of passes through the dataset\ninteger, default: 400\n\n\n--max_query_epochs\nNumber of passes through the dataset, when fine-tuning model for query\ninteger, default: 200\n\n\n--weight_decay\nWeight decay, when fine-tuning model for query\ndouble, default: 0"
  },
  {
    "objectID": "components/modules/integrate/totalvi.html#authors",
    "href": "components/modules/integrate/totalvi.html#authors",
    "title": "Totalvi",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov"
  },
  {
    "objectID": "components/modules/integrate/scarches.html",
    "href": "components/modules/integrate/scarches.html",
    "title": "Scarches",
    "section": "",
    "text": "ID: scarches\nNamespace: integrate\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/integrate/scarches.html#example-commands",
    "href": "components/modules/integrate/scarches.html#example-commands",
    "title": "Scarches",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/integrate/scarches/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\nreference: # please fill in - example: \"path/to/file\"\ndataset_name: \"test_dataset\"\n\n# Outputs\n# output: \"$id.$key.output.output\"\n# output_compression: \"gzip\"\n# model_output: \"$id.$key.model_output.model_output\"\nobsm_output: \"X_integrated_scanvi\"\n\n# Early stopping arguments\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n\n# Learning parameters\nmax_epochs: # please fill in - example: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/scarches/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/integrate/scarches.html#argument-groups",
    "href": "components/modules/integrate/scarches.html#argument-groups",
    "title": "Scarches",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file to use as a query\nfile, required\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--reference\nPath to the directory with reference model or a web link. For HLCA use https://zenodo.org/record/6337966/files/HLCA_reference_model.zip\nfile, required\n\n\n--dataset_name\nName of query dataset to use as a batch name. If not set, name of the input file is used\nstring, default: \"test_dataset\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--model_output\nOutput directory for model\nfile, default: \"model\"\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_integrated_scanvi\"\n\n\n\n\n\nEarly stopping arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e.¬†an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n\n\n\nLearning parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger, required\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30"
  },
  {
    "objectID": "components/modules/integrate/scarches.html#authors",
    "href": "components/modules/integrate/scarches.html#authors",
    "title": "Scarches",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov"
  },
  {
    "objectID": "components/modules/query/cellxgene_census.html",
    "href": "components/modules/query/cellxgene_census.html",
    "title": "Cellxgene census",
    "section": "",
    "text": "ID: cellxgene_census\nNamespace: query\n\n\n\nSource\nAside from fetching the cells‚Äô RNA counts (.X), cell metadata (.obs) and gene metadata (.var), this component also fetches the dataset metadata and joins it into the cell metadata"
  },
  {
    "objectID": "components/modules/query/cellxgene_census.html#example-commands",
    "href": "components/modules/query/cellxgene_census.html#example-commands",
    "title": "Cellxgene census",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/query/cellxgene_census/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\noutput_modality: \"rna\"\n\n# Input database\n# input_uri: \"s3://bucket/path\"\n# census_version: \"stable\"\nadd_dataset_metadata: false\n\n# Cell query\nspecies: # please fill in - example: \"homo_sapiens\"\nobs_value_filter: # please fill in - example: \"is_primary_data == True and cell_type_ontology_term_id in ['CL:0000136', 'CL:1000311', 'CL:0002616'] and suspension_type == 'cell'\"\n\n# Filter cells by grouping\n# cell_filter_grouping: [\"dataset_id\", \"tissue\", \"assay\", \"disease\", \"cell_type\"]\n# cell_filter_minimum_count: 100\n\n# Count filtering\ncell_filter_min_genes: 50\ncell_filter_min_counts: 0\ngene_filter_min_cells: 5\ngene_filter_min_counts: 0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/query/cellxgene_census/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/query/cellxgene_census.html#argument-groups",
    "href": "components/modules/query/cellxgene_census.html#argument-groups",
    "title": "Cellxgene census",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput database\nOpen CellxGene Census by version or URI.\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_uri\nIf specified, a URI containing the Census SOMA objects. If specified, will take precedence over the --census_version argument.\nstring, example: \"s3://bucket/path\"\n\n\n--census_version\nWhich release of CellxGene census to use. Possible values are ‚Äúlatest‚Äù, ‚Äústable‚Äù, or the date of one of the releases (e.g.¬†‚Äú2023-07-25‚Äù). For more information, check the documentation on Census data releases.\nstring, example: \"stable\"\n\n\n--add_dataset_metadata\nIf true, the experiment metadata will be added to the cell metadata. More specifically: collection_id, collection_name, collection_doi, dataset_title.\nboolean_true\n\n\n\n\n\nCell query\nArguments related to the query.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--species\nThe organism to query, usually one of Homo sapiens or Mus musculus.\nstring, required, example: \"homo_sapiens\"\n\n\n--obs_value_filter\nFilter for selecting the obs metadata (i.e.¬†cells). Value is a filter query written in the SOMA value_filter syntax.\nstring, required, example: \"is_primary_data == True and cell_type_ontology_term_id in ['CL:0000136', 'CL:1000311', 'CL:0002616'] and suspension_type == 'cell'\"\n\n\n\n\n\nFilter cells by grouping\nFilter groups with fewer than X number of cells.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_filter_grouping\nA subset of ‚Äòobs‚Äô columns by which to group the cells for filtering. Only groups surpassing or equal to the --cell_filter_minimum_count threshold will be retained. Take care not to introduce a selection bias against cells with more fine-grained ontology annotations.\nList of string, example: \"dataset_id\", \"tissue\", \"assay\", \"disease\", \"cell_type\", multiple_sep: \";\"\n\n\n--cell_filter_minimum_count\nA minimum number of cells per group to retain. If --cell_filter_grouping is defined, this parameter should also be provided and vice versa.\ninteger, example: 100\n\n\n\n\n\nCount filtering\nArguments related to filtering cells and genes by counts.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_filter_min_genes\nRemove cells with less than this number of genes.\ninteger, default: 50\n\n\n--cell_filter_min_counts\nRemove cells with less than this number of counts.\ninteger, default: 0\n\n\n--gene_filter_min_cells\nRemove genes expressed in less than this number of cells.\ninteger, default: 5\n\n\n--gene_filter_min_counts\nRemove genes with less than this number of counts.\ninteger, default: 0\n\n\n\n\n\nOutputs\nOutput arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--output_modality\nWhich modality to store the output in.\nstring, default: \"rna\""
  },
  {
    "objectID": "components/modules/query/cellxgene_census.html#authors",
    "href": "components/modules/query/cellxgene_census.html#authors",
    "title": "Cellxgene census",
    "section": "Authors",
    "text": "Authors\n\nMatthias Beyens    (maintainer, author)\nDries De Maeyer   (author)\nRobrecht Cannoodt    (author)\nKai Waldrant   (contributor)"
  },
  {
    "objectID": "components/modules/velocity/velocyto.html",
    "href": "components/modules/velocity/velocyto.html",
    "title": "Velocyto",
    "section": "",
    "text": "ID: velocyto\nNamespace: velocity\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/velocity/velocyto.html#example-commands",
    "href": "components/modules/velocity/velocyto.html#example-commands",
    "title": "Velocyto",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/velocity/velocyto/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\ntranscriptome: # please fill in - example: \"path/to/file\"\n# barcode: \"path/to/file\"\nwithout_umi: false\n# output: \"$id.$key.output.output\"\nlogic: \"Default\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/velocity/velocyto/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/velocity/velocyto.html#argument-group",
    "href": "components/modules/velocity/velocyto.html#argument-group",
    "title": "Velocyto",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to BAM file\nfile, required\n\n\n--transcriptome\nPath to GTF file\nfile, required\n\n\n--barcode\nValid barcodes file, to filter the bam. If ‚Äìbcfile is not specified all the cell barcodes will be included. Cell barcodes should be specified in the bcfile as the ‚ÄòCB‚Äô tag for each read\nfile\n\n\n--without_umi\nfoo\nboolean_true\n\n\n--output\nVelocyto loom file\nfile, required\n\n\n--logic\nThe logic to use for the filtering.\nstring, default: \"Default\""
  },
  {
    "objectID": "components/modules/velocity/velocyto.html#authors",
    "href": "components/modules/velocity/velocyto.html#authors",
    "title": "Velocyto",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/dimred/pca.html",
    "href": "components/modules/dimred/pca.html",
    "title": "Pca",
    "section": "",
    "text": "ID: pca\nNamespace: dimred\n\n\n\nSource\nUses the implementation of scikit-learn [Pedregosa11]"
  },
  {
    "objectID": "components/modules/dimred/pca.html#example-commands",
    "href": "components/modules/dimred/pca.html#example-commands",
    "title": "Pca",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/dimred/pca/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"foo\"\n# var_input: \"filter_with_hvg\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobsm_output: \"X_pca\"\nvarm_output: \"pca_loadings\"\nuns_output: \"pca_variance\"\n# num_components: 25\noverwrite: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dimred/pca/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/dimred/pca.html#argument-group",
    "href": "components/modules/dimred/pca.html#argument-group",
    "title": "Pca",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nUse specified layer for expression values instead of the .X object from the modality.\nstring\n\n\n--var_input\nColumn name in .var matrix that will be used to select which genes to run the PCA on.\nstring, example: \"filter_with_hvg\"\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obsm_output\nIn which .obsm slot to store the resulting embedding.\nstring, default: \"X_pca\"\n\n\n--varm_output\nIn which .varm slot to store the resulting loadings matrix.\nstring, default: \"pca_loadings\"\n\n\n--uns_output\nIn which .uns slot to store the resulting variance objects.\nstring, default: \"pca_variance\"\n\n\n--num_components\nNumber of principal components to compute. Defaults to 50, or 1 - minimum dimension size of selected representation.\ninteger, example: 25\n\n\n--overwrite\nAllow overwriting .obsm, .varm and .uns slots.\nboolean_true"
  },
  {
    "objectID": "components/modules/dimred/pca.html#authors",
    "href": "components/modules/dimred/pca.html#authors",
    "title": "Pca",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)"
  },
  {
    "objectID": "components/modules/interpret/lianapy.html",
    "href": "components/modules/interpret/lianapy.html",
    "title": "Lianapy",
    "section": "",
    "text": "ID: lianapy\nNamespace: interpret\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/interpret/lianapy.html#example-commands",
    "href": "components/modules/interpret/lianapy.html#example-commands",
    "title": "Lianapy",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -main-script target/nextflow/interpret/lianapy/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\n# output: \"$id.$key.output.output\"\noutput_compression: \"gzip\"\nmodality: \"rna\"\n# layer: \"foo\"\ngroupby: \"bulk_labels\"\nresource_name: \"consensus\"\ngene_symbol: \"gene_symbol\"\nexpr_prop: 0.1\nmin_cells: 5\naggregate_method: \"rra\"\nreturn_all_lrs: false\nn_perms: 100\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 1.0.0-rc5 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/interpret/lianapy/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/interpret/lianapy.html#argument-group",
    "href": "components/modules/interpret/lianapy.html#argument-group",
    "title": "Lianapy",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--output_compression\n\nstring, default: \"gzip\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nLayer in anndata.AnnData.layers to use. If None, use mudata.mod[modality].X.\nstring\n\n\n--groupby\nThe key of the observations grouping to consider.\nstring, default: \"bulk_labels\"\n\n\n--resource_name\nName of the resource to be loaded and use for ligand-receptor inference.\nstring, default: \"consensus\"\n\n\n--gene_symbol\nColumn name in var DataFrame in which gene symbol are stored.\nstring, default: \"gene_symbol\"\n\n\n--expr_prop\nMinimum expression proportion for the ligands/receptors (and their subunits) in the corresponding cell identities. Set to ‚Äò0‚Äô, to return unfiltered results.\ndouble, default: 0.1\n\n\n--min_cells\nMinimum cells per cell identity (‚Äògroupby‚Äô) to be considered for downstream analysis.\ninteger, default: 5\n\n\n--aggregate_method\nMethod aggregation approach, one of [‚Äòmean‚Äô, ‚Äòrra‚Äô], where ‚Äòmean‚Äô represents the mean rank, while ‚Äòrra‚Äô is the RobustRankAggregate (Kolde et al., 2014) of the interactions.\nstring, default: \"rra\"\n\n\n--return_all_lrs\nBool whether to return all LRs, or only those that surpass the ‚Äòexpr_prop‚Äô threshold. Those interactions that do not pass the ‚Äòexpr_prop‚Äô threshold will be assigned to the worst score of the ones that do. ‚ÄòFalse‚Äô by default.\nboolean, default: FALSE\n\n\n--n_perms\nNumber of permutations for the permutation test. Note that this is relevant only for permutation-based methods - e.g.¬†‚ÄôCellPhoneDB\ninteger, default: 100"
  },
  {
    "objectID": "components/modules/interpret/lianapy.html#authors",
    "href": "components/modules/interpret/lianapy.html#authors",
    "title": "Lianapy",
    "section": "Authors",
    "text": "Authors\n\nMauro Saporita   (author)\nPovilas Gibas   (author)"
  },
  {
    "objectID": "team/index.html",
    "href": "team/index.html",
    "title": "Team",
    "section": "",
    "text": "Angela Oliveira Pisco\n      Contributor\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Director of Computational Biology \n           at \n              \n              Insitro\n              \n        \n      \n      \n        \n          Core Member \n           at \n              \n              Open Problems\n              \n        \n      \n    \n  \n  \n    \n    \n      Dries De Maeyer\n      Core Team Member\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Principal Scientist \n           at \n              \n              Janssen Pharmaceuticals\n              \n        \n      \n    \n  \n  \n    \n    \n      Dries Schaumont\n      Core Team Member\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Data Scientist \n           at \n              \n              Data Intuitive\n              \n        \n      \n    \n  \n  \n    \n    \n      Malte D. Luecken\n      Core Team Member\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Group Leader \n           at \n              \n              Helmholtz Munich\n              \n        \n      \n      \n        \n          Core Member \n           at \n              \n              Open Problems\n              \n        \n      \n    \n  \n  \n    \n    \n      Marijke Van Moerbeke\n      Contributor\n      \n        \n      \n      \n        \n      \n      \n        \n          Statistical Consultant \n           at \n              \n              OpenAnalytics\n              \n        \n      \n    \n  \n  \n    \n    \n      Matthias Beyens\n      Contributor\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Principal Scientist \n           at \n              \n              Janssen Pharmaceuticals\n              \n        \n      \n    \n  \n  \n    \n    \n      Mauro Saporita\n      Contributor\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Lead Nextflow Developer \n           at \n              \n              Ardigen\n              \n        \n      \n    \n  \n  \n    \n    \n      Povilas Gibas\n      Contributor\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Bioinformatician \n           at \n              \n              Ardigen\n              \n        \n      \n    \n  \n  \n    \n    \n      Robrecht Cannoodt\n      Core Team Member\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Data Science Engineer \n           at \n              \n              Data Intuitive\n              \n        \n      \n      \n        \n          Core Member \n           at \n              \n              Open Problems\n              \n        \n      \n    \n  \n  \n    \n    \n      Samuel D'Souza\n      Contributor\n      \n        \n      \n      \n        \n      \n      \n        \n          Data Engineer \n           at \n              \n              Chan Zuckerberg Biohub\n              \n        \n      \n    \n  \n  \n    \n    \n      Toni Verbeiren\n      Core Team Member\n      \n        \n      \n      \n        \n      \n      \n        \n          Data Scientist and CEO \n           at \n              \n              Data Intuitive\n              \n        \n      \n    \n  \n  \n    \n    \n      Vladimir Shitov\n      Contributor\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          PhD Candidate \n           at \n              \n              Helmholtz Munich\n              \n        \n      \n    \n  \n\n\nNo matching items"
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "OpenPipelines.bio next release",
    "section": "",
    "text": "Add descriptions to all pages and add listings to index pages.\nUpdate documentation on creating components for developers.\nUpdate getting started page for developers\nUpdate project structure.\nUpdate information on running tests.\nUpdate ‚ÄúMore information‚Äù pages\nWrite getting started page for user guide\nDocument how to run workflows\nDocument parameter lists"
  },
  {
    "objectID": "CHANGELOG.html#major-changes",
    "href": "CHANGELOG.html#major-changes",
    "title": "OpenPipelines.bio next release",
    "section": "",
    "text": "Add descriptions to all pages and add listings to index pages.\nUpdate documentation on creating components for developers.\nUpdate getting started page for developers\nUpdate project structure.\nUpdate information on running tests.\nUpdate ‚ÄúMore information‚Äù pages\nWrite getting started page for user guide\nDocument how to run workflows\nDocument parameter lists"
  },
  {
    "objectID": "CHANGELOG.html#major-changes-1",
    "href": "CHANGELOG.html#major-changes-1",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.12.1 release."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-2",
    "href": "CHANGELOG.html#major-changes-2",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.12.0 release."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-3",
    "href": "CHANGELOG.html#major-changes-3",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.11.0 release."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-4",
    "href": "CHANGELOG.html#major-changes-4",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.10.0 release.\nAdd documentation for OpenPipelines architecture."
  },
  {
    "objectID": "CHANGELOG.html#minor-changes",
    "href": "CHANGELOG.html#minor-changes",
    "title": "OpenPipelines.bio next release",
    "section": "MINOR CHANGES",
    "text": "MINOR CHANGES\n\nAlso generate documentation for the multiple_sep values of component arguments."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-5",
    "href": "CHANGELOG.html#major-changes-5",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.9.0 release."
  },
  {
    "objectID": "CHANGELOG.html#minor-changes-1",
    "href": "CHANGELOG.html#minor-changes-1",
    "title": "OpenPipelines.bio next release",
    "section": "MINOR CHANGES",
    "text": "MINOR CHANGES\n\nUpdate to Viash actions 0.4.0."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-6",
    "href": "CHANGELOG.html#major-changes-6",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.8.0 release.\nUse git submodule to access openpipeline repo.\nPropose new website structure.\nUpdate author page."
  },
  {
    "objectID": "contributing/running_tests.html",
    "href": "contributing/running_tests.html",
    "title": "Running tests",
    "section": "",
    "text": "The input data that is needed to run the tests will need to be downloaded from the openpipelines Amazon AWS s3 bucket first. To do so, the download/sync_test_resource component can be used, which will download the data to the correct location (resources_test) by default.\nviash run src/download/sync_test_resources/config.vsh.yaml"
  },
  {
    "objectID": "contributing/running_tests.html#fetch-the-test-data",
    "href": "contributing/running_tests.html#fetch-the-test-data",
    "title": "Running tests",
    "section": "",
    "text": "The input data that is needed to run the tests will need to be downloaded from the openpipelines Amazon AWS s3 bucket first. To do so, the download/sync_test_resource component can be used, which will download the data to the correct location (resources_test) by default.\nviash run src/download/sync_test_resources/config.vsh.yaml"
  },
  {
    "objectID": "contributing/running_tests.html#run-component-tests",
    "href": "contributing/running_tests.html#run-component-tests",
    "title": "Running tests",
    "section": "Run component tests",
    "text": "Run component tests\nTo build and run tests for individual component that you are working on, use viash test with the config.vsh.yaml of the component you would like to test. For example:\nviash test src/convert/from_10xh5_to_h5mu/config.vsh.yaml\nKeep in mind that when no platform is passed to viash test, it will use the first platform that is specified in the config, which is docker for most of the components in openpipelines. Use -p native for example if you do not want to use docker.\nIt is also possible to execute the tests for all components in each namespace using:\nviash ns test --parallel -q convert"
  },
  {
    "objectID": "contributing/running_tests.html#run-integration-tests",
    "href": "contributing/running_tests.html#run-integration-tests",
    "title": "Running tests",
    "section": "Run integration tests",
    "text": "Run integration tests\nIndividual integration tests can be run by using the integration_test.sh scripts for a pipeline, located next to the main.nf in the src/workflows folder.\nsrc/workflows/ingestion/cellranger_demux/integration_test.sh"
  },
  {
    "objectID": "contributing/getting_started.html",
    "href": "contributing/getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "The OpenPipelines code is hosted on GitHub. To start working on OpenPipelines, you should create your own copy of the repository by forking it. Visit the OpenPipelines repository here and use the ‚ÄòFork‚Äô button on the top right hand side of the page. After you are done forking, you can clone the repository to a local directory on your computer using git clone. You can choose between using an SSH key to log in to GitHub or username and password (HTTPS) to connect to github.\n\nHTTPSSSH\n\n\ngit clone https://github.com/&lt;YOUR USERNAME&gt;/openpipeline.git\ncd openpipeline\ngit remote add upstream https://github.com/openpipeline-bio/openpipeline.git\n\n\ngit clone git@github.com:&lt;YOUR USERNAME&gt;/openpipeline.git\ncd openpipeline\ngit remote add upstream https://github.com/openpipeline-bio/openpipeline.git"
  },
  {
    "objectID": "contributing/getting_started.html#forking-the-code-and-cloning-the-repository",
    "href": "contributing/getting_started.html#forking-the-code-and-cloning-the-repository",
    "title": "Getting started",
    "section": "",
    "text": "The OpenPipelines code is hosted on GitHub. To start working on OpenPipelines, you should create your own copy of the repository by forking it. Visit the OpenPipelines repository here and use the ‚ÄòFork‚Äô button on the top right hand side of the page. After you are done forking, you can clone the repository to a local directory on your computer using git clone. You can choose between using an SSH key to log in to GitHub or username and password (HTTPS) to connect to github.\n\nHTTPSSSH\n\n\ngit clone https://github.com/&lt;YOUR USERNAME&gt;/openpipeline.git\ncd openpipeline\ngit remote add upstream https://github.com/openpipeline-bio/openpipeline.git\n\n\ngit clone git@github.com:&lt;YOUR USERNAME&gt;/openpipeline.git\ncd openpipeline\ngit remote add upstream https://github.com/openpipeline-bio/openpipeline.git"
  },
  {
    "objectID": "contributing/getting_started.html#sec-install-viash-nextflow",
    "href": "contributing/getting_started.html#sec-install-viash-nextflow",
    "title": "Getting started",
    "section": "Install viash and nextflow",
    "text": "Install viash and nextflow\nTo start contributing to OpenPipelines, you will need at Java 11 (or higher) and Docker installed on your system.\nOpenPipelines is being developed in Viash and Nextflow. If you are unfamiliar with either one of these platforms, you can check out their respective documentation pages.\nYou can check if is installed correctly by running the following commands.\nnextflow run hello -with-docker\nviash --version"
  },
  {
    "objectID": "contributing/getting_started.html#fetch-test-resources",
    "href": "contributing/getting_started.html#fetch-test-resources",
    "title": "Getting started",
    "section": "Fetch test resources",
    "text": "Fetch test resources\nOpenPipelines uses a number of test resources to test the pipelines. If everything is installed correctly, you should be able to fetch these resources by running the following command.\nviash run src/download/sync_test_resources/config.vsh.yaml"
  },
  {
    "objectID": "contributing/project_structure.html",
    "href": "contributing/project_structure.html",
    "title": "Project structure",
    "section": "",
    "text": "The root of the repository contains two main folders:\n\nsrc, which contains the source code for components and workflows.\n(optionally) the target folder\n\nEach subfolder from src contains a Viash namespace, a logical grouping of pipeline components that perform a similar function. Within each namespace, subfolders designate individual pipeline components. For example ./src/convert/from_bdrhap_to_h5ad contains the implementation for a component from_bdrhap_to_h5ad which is grouped together with other components such as from_10xmtx_to_h5mu into a namespace convert. In a similar manner as grouping components into namespaces, pipelines are grouped together into folders. However, these are not component namespaces and as such do not interact with viash ns commands.\nAs will become apparent later on, Viash not only provides commands to perform operations on individual components, but also on groups of components in a namespace and all components in a project. As a rule of thumb, the basic Viash commands (like viash test) are designated for running commands on individual components, while ns commands are (viash ns test) are for namespaces. When cloning a fresh repository, there will be no target folder present. This is because the target folder will only be created after components have been build."
  },
  {
    "objectID": "contributing/project_structure.html#sec-project-structure",
    "href": "contributing/project_structure.html#sec-project-structure",
    "title": "Project structure",
    "section": "",
    "text": "The root of the repository contains two main folders:\n\nsrc, which contains the source code for components and workflows.\n(optionally) the target folder\n\nEach subfolder from src contains a Viash namespace, a logical grouping of pipeline components that perform a similar function. Within each namespace, subfolders designate individual pipeline components. For example ./src/convert/from_bdrhap_to_h5ad contains the implementation for a component from_bdrhap_to_h5ad which is grouped together with other components such as from_10xmtx_to_h5mu into a namespace convert. In a similar manner as grouping components into namespaces, pipelines are grouped together into folders. However, these are not component namespaces and as such do not interact with viash ns commands.\nAs will become apparent later on, Viash not only provides commands to perform operations on individual components, but also on groups of components in a namespace and all components in a project. As a rule of thumb, the basic Viash commands (like viash test) are designated for running commands on individual components, while ns commands are (viash ns test) are for namespaces. When cloning a fresh repository, there will be no target folder present. This is because the target folder will only be created after components have been build."
  },
  {
    "objectID": "contributing/project_structure.html#sec-versioning",
    "href": "contributing/project_structure.html#sec-versioning",
    "title": "Project structure",
    "section": "Versioning and branching strategy",
    "text": "Versioning and branching strategy\nOpenPipeline tries to use of semantic versioning to govern changes between versions. An release of openpipelines uses a version number in the format MAJOR.MINOR.PATCH. Currenly, openpipelines is still at major version 0.x.y, meaning that public-facing breaking changes are possible on MINOR releases. These breaking changes will be documented in a dedicated section of the CHANGELOG that is published with each release. A PATCH release (i.e.¬†a release where the MAJOR and MINOR version number stay the same), is used to resolve bugs with the pipeline but should not introduce breaking changes. Keep in mind that patches might introduce behavioral changes that may look breaking but are actually rectifying changes that were inadvertently introduced previously (and were in fact also ‚Äòbreaking changes‚Äô). In this case, a bug can also be released without changing the MINOR version, in a PATH release.\nBetween releases, development progress is tracked on Git branches. A git branch represents a snapshot of a codebase in time, to which changes can be added (i.e.¬†committed). Eventually, all new feature or bugfixes must be reconsiled into a single branch so that a new release can be created. This process is called merging and the process of requesting the merging of two branches is called a pull request. Openpipelines follows the convention that the target branch for all pull requests is the main branch. Thus, the main branch contains the latest changes for the code and it can be considered the development branch.\nOnce a pull request has been approved and merged, Github Actions CI will automatically build all components (creating the target directory) and push the result to the main_build branch. In essence, the main_build branch is a copy of the main branch, but also containing the build components. Once it is time to create a openpipelines release, the Github CI release workflow is manually triggered, the components on the main branch will be build and tested. Then, the result will be pushed to the release branch and the integration tests will be run. If all tests succeeded, a new github tag and release can be created manually from the release branch.\n\n\n\n\n%%{init: { 'logLevel': 'debug', 'theme': 'default'} } }%%\ngitGraph\n  commit id: \"initial commit\"\n  branch main_build\n  commit id: \"CI build\"\n  checkout main\n  commit\n  checkout main_build\n  merge main\n  checkout main\n  branch feature_a\n  branch feature_b\n  checkout feature_a\n  commit\n  commit\n  checkout main\n  commit id: \"#release 0.1\" type: HIGHLIGHT\n  checkout main_build\n  merge main\n  checkout main\n  branch release\n  commit tag: \"0.1\"\n  checkout main\n  commit\n  checkout feature_b\n  commit\n  commit\n  checkout feature_a\n  commit\n  checkout main\n  merge feature_a\n  checkout main_build\n  merge main\n  checkout main\n  checkout feature_b\n  commit\n  checkout main\n  merge feature_b\n  checkout main_build\n  merge main\n  checkout release\n  merge main tag: \"0.2\""
  },
  {
    "objectID": "user_guide/parameter_lists.html",
    "href": "user_guide/parameter_lists.html",
    "title": "Passing parameter lists",
    "section": "",
    "text": "Using Viash‚Äôs VDSL3 nextflow platform, an optional --param_list argument can be used to pass a large number of inputs to a workflow. A param_list can either be a csv file, a json file, a yaml file, a yaml blob, or be passed as a nextflow config file."
  },
  {
    "objectID": "user_guide/parameter_lists.html#csv-file",
    "href": "user_guide/parameter_lists.html#csv-file",
    "title": "Passing parameter lists",
    "section": "CSV file",
    "text": "CSV file\nThe following example shows how to use a csv file as a parameter list. The csv file has two columns, id and input. The id column is used to name the output file, and the input column is used as the input file. The input column is relativized to the location of the csv file.\n$ cat param_list.csv\nid,input\nfoo,foo.txt\nbar,bar.txt\nnextflow run ... --param_list param_list.csv"
  },
  {
    "objectID": "user_guide/parameter_lists.html#yaml-file",
    "href": "user_guide/parameter_lists.html#yaml-file",
    "title": "Passing parameter lists",
    "section": "YAML file",
    "text": "YAML file\nThe following example shows how to use a yaml file as a parameter list.\n$ cat param_list.yaml\n- id: foo\n  input: foo.txt\n- id: bar\n  input: bar.txt\nnextflow run ... --param_list param_list.yaml"
  },
  {
    "objectID": "user_guide/parameter_lists.html#yaml-blob",
    "href": "user_guide/parameter_lists.html#yaml-blob",
    "title": "Passing parameter lists",
    "section": "YAML blob",
    "text": "YAML blob\nThe following example shows how to use a yaml blob as a parameter list.\nnextflow run ... --param_list \"[ {'id': 'foo', 'input': 'foo.txt'}, {'id': 'bar', 'input': 'bar.txt'} ]\""
  },
  {
    "objectID": "user_guide/parameter_lists.html#as-a-nextflow-config",
    "href": "user_guide/parameter_lists.html#as-a-nextflow-config",
    "title": "Passing parameter lists",
    "section": "As a Nextflow config",
    "text": "As a Nextflow config\nThe following example shows how to use a nextflow.config file as a parameter list.\n$ cat params.config\nparams {\n  param_list: [\n    ['id': 'foo', 'input': 'foo.txt'],\n    ['id': 'bar', 'input': 'bar.txt']\n  ]\n}\nnextflow run ... -params-file params.config"
  },
  {
    "objectID": "user_guide/parameter_lists.html#global-parameters",
    "href": "user_guide/parameter_lists.html#global-parameters",
    "title": "Passing parameter lists",
    "section": "Global parameters",
    "text": "Global parameters\nNote that a param_list can be combined with setting parameters that are set for all parameter sets. These ‚Äòglobal‚Äô parameters will always be overwritten with their counterpart that was specified in a more specific manner for a single parameter set.\nFor example, using --param_list param_list.yaml --ref global.txt with the following param_list.yaml:\n- id: foo\n  input: foo.txt\n- id: bar\n  input: bar.txt\n  ref: custom_bar_ref.txt\nWill result in the following parameter sets being processed:\n\nid: foo, input: foo.txt, ref: global.txt\nid: bar, input: bar.txt, ref: custom_bar_ref.txt"
  },
  {
    "objectID": "user_guide/parameter_lists.html#resolving-paths",
    "href": "user_guide/parameter_lists.html#resolving-paths",
    "title": "Passing parameter lists",
    "section": "Resolving paths",
    "text": "Resolving paths\nIf the --param_list is a file (CSV, YAML, or JSON), all files in the param_list are relativized to the location of the param_list file. If the --param_list is a YAML blob or a Nextflow config, all files in the param_list are relativized to the current working directory.\nFor example, with a param_list.yaml file located in the data directory:\n$ cat /data/param_list.yaml\n- id: foo\n  input: foo.txt\n- id: bar\n  input: /path/to/bar.txt\nThis will result in the following parameter sets being processed:\n\nid: foo, input: /data/foo.txt\nid: bar, input: /path/to/bar.txt\n\nNote that this also works when the param list is located on a remote location, such as an S3 bucket. In that case, the files in the param list are relativized to the location of the param list on the remote location."
  },
  {
    "objectID": "user_guide/running_pipelines.html",
    "href": "user_guide/running_pipelines.html",
    "title": "Running pipelines",
    "section": "",
    "text": "Dependening on whether you want to run a workflow locally or on cloud infrastructure, using Nextflow Tower or not, you will need to use different commands."
  },
  {
    "objectID": "user_guide/running_pipelines.html#run-locally-from-the-cli",
    "href": "user_guide/running_pipelines.html#run-locally-from-the-cli",
    "title": "Running pipelines",
    "section": "Run locally from the CLI",
    "text": "Run locally from the CLI\nYou can run a workflow from the command line using the following command:\nnextflow run openpipelines-bio/openpipeline \\\n  -main-script target/nextflow/workflows/integration/multimodal_integration/main.nf \\\n  -revision 0.12.1 \\\n  -latest \\\n  -profile docker \\\n  --publish_dir foo/ \\\n  --input \"bar\" \\\n  --output \"test.txt\"\nDoing so will run the workflow locally using a Docker container."
  },
  {
    "objectID": "user_guide/running_pipelines.html#on-cloud-infrastructure",
    "href": "user_guide/running_pipelines.html#on-cloud-infrastructure",
    "title": "Running pipelines",
    "section": "On cloud infrastructure",
    "text": "On cloud infrastructure\nYou can use a similar command to run the workflow on cloud infrastructure, such as AWS Batch or Google Cloud Platform. However, this requires you to create a separate Nextflow config file for each cloud provider. See the Nextflow documentation for more information.\nnextflow run openpipelines-bio/openpipeline \\\n  -main-script target/nextflow/workflows/integration/multimodal_integration/main.nf \\\n  -revision 0.12.1 \\\n  -latest \\\n  --publish_dir foo/ \\\n  --input \"bar\" \\\n  --output \"test.txt\" \\\n  -c configs/my_hpc.config"
  },
  {
    "objectID": "user_guide/running_pipelines.html#using-the-nextflow-tower-cli",
    "href": "user_guide/running_pipelines.html#using-the-nextflow-tower-cli",
    "title": "Running pipelines",
    "section": "Using the Nextflow Tower CLI",
    "text": "Using the Nextflow Tower CLI\nIf you have access to a Nextflow Tower instance in which a Compute Environment has already been set up, you can run a workflow from the Tower CLI. The command is very similar to the command to run a workflow from the CLI, but you need to: * Use tw launch instead of nextflow run * Specify the workspace ID and compute environment ID * Rename arguments: -revision to --revision, -latest to --pull-latest, -main-script to --main-script, -c to --config * Store workflow arguments in a separate yaml file (if this was not already the case).\nExample:\ntw launch openpipelines-bio/openpipeline \\\n  --revision 0.12.1 \\\n  --pull-latest \\\n  --main-script target/nextflow/workflows/integration/multimodal_integration/main.nf \\\n  --workspace &lt;your workspace id&gt; \\\n  --compute-env &lt;your compute environment id&gt; \\\n  --params-file params.yaml \\\n  --config configs/my_hpc.config"
  },
  {
    "objectID": "user_guide/running_pipelines.html#using-the-nextflow-tower-web-ui",
    "href": "user_guide/running_pipelines.html#using-the-nextflow-tower-web-ui",
    "title": "Running pipelines",
    "section": "Using the Nextflow Tower Web UI",
    "text": "Using the Nextflow Tower Web UI\nIf you have access to a Nextflow Tower instance in which a Compute Environment has already been set up, you can run a workflow from the Tower UI. To do so, go to the ‚ÄúLaunchpad‚Äù and click on the button ‚Äúlaunch a run without configuration‚Äù.\n\nNext, fill in the required fields and click on ‚ÄúLaunch run‚Äù.\n\nCompute environment: Select the compute environment you want to run the workflow on.\nPipeline to launch: Fill in openpipelines-bio/openpipeline.\nRevision number: The release number of the pipeline you want to run, e.g.¬†0.12.1. You can find the release number on the GitHub releases page.\nWork directory: The bucket path where the scratch data is stored.\nPipeline parameters: The YAML or JSON of the parameters that are passed to the pipeline. See the Components page for more information about the parameters of each pipeline."
  },
  {
    "objectID": "user_guide/getting_started.html",
    "href": "user_guide/getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "Depending on whether you plan to run the OpenPipelines workflows locally or in the cloud"
  },
  {
    "objectID": "user_guide/getting_started.html#starting-workflows-locally",
    "href": "user_guide/getting_started.html#starting-workflows-locally",
    "title": "Getting started",
    "section": "Starting workflows locally",
    "text": "Starting workflows locally\nIf you want to start workflows locally, you will need to install Nextflow.\n\nInstall Docker (optional)\nDocker is a containerization platform that allows you to package your application and all its dependencies into a single image. It is used to run the analysis pipelines.\nIf you are planning on running the workflows locally, you will need to install Docker. You do not need to install Docker if the workflows will be run in the cloud using AWS Batch, Azure Batch, Google Cloud Batch, or other cloud-based compute environments.\nTo install Docker, follow the instructions here.\n\n\nInstall Java\nNextflow requires Java 11 or later. To check if Java is installed on your system, run:\njava -version\nIf Java is not installed, you can download it from here.\n\n\nInstall Nextflow\nNextflow is distributed as a single executable file. To install it, run:\ncurl -s https://get.nextflow.io | bash\nThis command will download the latest version of Nextflow and store it in the current directory.\nTo install Nextflow system-wide, move the downloaded file to a directory in your $PATH, e.g.:\nmv nextflow /usr/local/bin\n\n\nTest the installation\nTo test the installation, run:\nnextflow run hello -with-docker"
  },
  {
    "objectID": "user_guide/getting_started.html#using-nextflow-tower",
    "href": "user_guide/getting_started.html#using-nextflow-tower",
    "title": "Getting started",
    "section": "Using Nextflow Tower",
    "text": "Using Nextflow Tower\nNextflow Tower is a web-based user interface for running and monitoring Nextflow pipelines. If you are planning on using Nextflow Tower, a compute environment will need to be set up."
  },
  {
    "objectID": "user_guide/bug_reports.html",
    "href": "user_guide/bug_reports.html",
    "title": "Bug reports",
    "section": "",
    "text": "Issues with Openpipelines are being tracked on Github. In order for an issue to be fixed in a timely manner, creating a complete and reproducable is essential."
  },
  {
    "objectID": "more_information/cheat_sheets.html",
    "href": "more_information/cheat_sheets.html",
    "title": "Cheat sheets",
    "section": "",
    "text": "Figure¬†1: Cheat sheet for developing modular pipeline components with Viash, including a sample Viash component (left) and common commands used throughout the various stages of a development cycle (right)."
  },
  {
    "objectID": "more_information/cheat_sheets.html#viash",
    "href": "more_information/cheat_sheets.html#viash",
    "title": "Cheat sheets",
    "section": "",
    "text": "Figure¬†1: Cheat sheet for developing modular pipeline components with Viash, including a sample Viash component (left) and common commands used throughout the various stages of a development cycle (right)."
  },
  {
    "objectID": "more_information/code_of_conduct.html",
    "href": "more_information/code_of_conduct.html",
    "title": "Code of conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\nOur full Code of Conduct is adapted from the Contributor Covenant, version 2.1."
  },
  {
    "objectID": "fundamentals/index.html",
    "href": "fundamentals/index.html",
    "title": "Fundamentals",
    "section": "",
    "text": "Philosophy: Our approach and mission\n  \n  \n    Concepts: The core concepts behind this project\n  \n  \n    Architecture: Structure of the project\n  \n  \n    Roadmap: Development roadmap\n  \n\n\nNo matching items"
  },
  {
    "objectID": "fundamentals/architecture.html",
    "href": "fundamentals/architecture.html",
    "title": "Architecture",
    "section": "",
    "text": "OpenPipeline is a pipeline for the processing of multimodal single-cell data that scales to a great many of samples. Covering the architecture requires us to explain many angles, including: what the expected inputs and outputs are for each workflow are, how do the workflows relate to each other, and what the state of the data is at each step of the pipeline. Here is an overview of the general steps involved in processing sequencing data into a single integrated object. We will discuss each of the steps further below.\nflowchart TD  \n  ingest[\"Ingestion\"] --&gt; split --&gt; unimodalsinglesample[\"Unimodal Single Sample Processing\"] --&gt; concat --&gt; unimodalmultisample[\"Unimodal Multi Sample Processing\"] --&gt; merging --&gt; integation_setup[\"Integration Setup\"] --&gt; integration[\"Integration\"]  --&gt; downstreamprocessing[\"Downstream Processing\"]\n\n\nFigure¬†1: Overview of the steps included in OpenPipeline for the analysis of single cell multiomics data."
  },
  {
    "objectID": "fundamentals/architecture.html#ingestion-workflows",
    "href": "fundamentals/architecture.html#ingestion-workflows",
    "title": "Architecture",
    "section": "Ingestion workflows",
    "text": "Ingestion workflows\nAll of the following workflows from the ingestion namespace have been discussed in more detail in the ingestion section:\n\ningestion/bd_rhapsody\ningestion/cellranger_mapping\ningestion/cellranger_multi\ningestion/demux\ningestion/make_reference"
  },
  {
    "objectID": "fundamentals/architecture.html#multiomics-workflows",
    "href": "fundamentals/architecture.html#multiomics-workflows",
    "title": "Architecture",
    "section": "Multiomics workflows",
    "text": "Multiomics workflows\nThere exists no singlesample workflow. However, the prot_singlesample and rna_singlesample pipelines do exist and they map identically to the functionality described in the single-sample antibody capture processing and single-sample gene expression processing sections respectively. If you would like to process your samples as described in the unimodal single sample processing section, you can execute both workflows in tandem for the two modalities.\nContrary to the workflows for single sample processing, there exists a multiomics/multisample workflow. However this workflow is not just the multiomics/prot_multisample and multiomics/rna_multisample workflows that have been combined. Instead, it combines the multiomics/prot_multisample, multiomics/rna_multisample and multiomics/integration/initialize_integration workflows. The purpose of this pipeline is to provide an extra ‚Äòentrypoint‚Äô into the full pipeline that skips the singlesample processing, allowing reprocessing samples that have already been processed before. A popular usecase is to manually select one or more celltypes which need to be processed again or the integration of observations from multiple experiments into a single dataset. Keep in mind that concatenation is not included in the multisample pipeline, so when multiple input files are specified they are processed in parallel. If you would like to integrate multiple experiments, you need to first concatenate them in a seperate step:"
  },
  {
    "objectID": "fundamentals/architecture.html#the-full-pipeline",
    "href": "fundamentals/architecture.html#the-full-pipeline",
    "title": "Architecture",
    "section": "The ‚Äúfull‚Äù pipeline",
    "text": "The ‚Äúfull‚Äù pipeline\nThe name of this pipeline is a bit of a misnomer, because it does not include all the steps from ingestion to integration. As will be discussed in the ingestion section, which ingestion strategy you need is dependant on your technology provider and the chosen platform. For integration, there exist many methods and combination of methods, and you may wish to choose which integration methods are applicable for your usecase. As a consequence, these two stages in the analysis of single-cell need to be executed seperatly and not as part of a single unified pipeline. All other steps outlined below on the other hand are included into the ‚Äúfull‚Äù pipeline, which can therefore be summarized in the following figure:\n\n\n\n\n\nflowchart TD  \n  split --&gt; unimodalsinglesample[\"Unimodal Single Sample Processing\"] --&gt; concat --&gt; unimodalmultisample[\"Unimodal Multi Sample Processing\"] --&gt; merging --&gt; integation_setup\n\n\nFigure¬†2: Overview of the steps included in the full pipelines from OpenPipeline."
  },
  {
    "objectID": "fundamentals/architecture.html#integration-workflows",
    "href": "fundamentals/architecture.html#integration-workflows",
    "title": "Architecture",
    "section": "Integration workflows",
    "text": "Integration workflows\nFor each of the integration methods (and their optional combination with other tools), a seperate pipeline is defined. More information for each of the pipelines is available in the integration methods section.\n\nmultiomics/integration/bbknn_leiden\nmultiomics/integration/harmony_leiden\nmultiomics/integration/scanorama_leiden\nmultiomics/integration/scvi_leiden\nmultiomics/integration/totalvi_leiden\nmultiomics/integration/initialize_integration"
  },
  {
    "objectID": "fundamentals/architecture.html#sec-splitting",
    "href": "fundamentals/architecture.html#sec-splitting",
    "title": "Architecture",
    "section": "Splitting modalities",
    "text": "Splitting modalities\nWe refer to splitting modalities when multimodal MuData file is split into several unimodal MuData files. The number of output files is equal to the number of modalities present in the input file. Splitting the modalities works on MuData files containing data for multiple samples or for single-sample files."
  },
  {
    "objectID": "fundamentals/architecture.html#sec-merging",
    "href": "fundamentals/architecture.html#sec-merging",
    "title": "Architecture",
    "section": "Merging of modalities",
    "text": "Merging of modalities\nMerging refers to combining multiple files with data for one modality into a single output file that contains all input modalities. It is the inverse operation of splitting the modalities."
  },
  {
    "objectID": "fundamentals/architecture.html#concatenation-of-samples",
    "href": "fundamentals/architecture.html#concatenation-of-samples",
    "title": "Architecture",
    "section": "Concatenation of samples",
    "text": "Concatenation of samples\nJoining of observations for different samples, stored in their respective MuData file, into a single MuData file for all samples together is called sample concatenation. In practice, this operation is performed for each modality separately. An extra column (with default name sample_id) is added to the annotation of the observations (.obs) to indicate where each observation originated from.\n\nSpecial care must be taken when considering annotations for observations and features while concatenating the samples. Indeed, the data from different samples can contain conflicting information. Openpipeline‚Äôs concat component provides an argument other_axis_mode that allows a user to specify what happens when conflicting information is found. The move option for this argument is the default behavior. In this mode, each annotation column (from .obs and .var) is compared across samples. When no conflicts are found or the column is unique for a sample, the column is added output object. When a conflict does occur, all of the columns are gathered from the samples and stored into a dataframe. This dataframe is then stored into .obsm for annotations for the observations and .varm for feature annotations. This way, a user can have a look at the conflicts and decide what to do with them."
  },
  {
    "objectID": "fundamentals/architecture.html#creating-a-transcriptomics-reference",
    "href": "fundamentals/architecture.html#creating-a-transcriptomics-reference",
    "title": "Architecture",
    "section": "Creating a transcriptomics reference",
    "text": "Creating a transcriptomics reference\nMapping reads from the FASTQ files to features requires a reference that needs to be provided to the mapping component. Depending on the usecase, you might even need to provide references specific for the modalities that you are trying to analyze. For gene expression data, the reference is a reference genome, together with its appropriate gene annotation. A genome reference is often indexed in order to improve the mapping speed. Additionally, some mapping frameworks provided by the single-cell technology providers require extra preprocessing of the reference before they can be used with their worklow. OpenPipelines provides a make_reference that allows you to create references in many formats which can be used to map your reads to."
  },
  {
    "objectID": "fundamentals/architecture.html#sec-single-sample-gex",
    "href": "fundamentals/architecture.html#sec-single-sample-gex",
    "title": "Architecture",
    "section": "Single-sample Gene Expression Processing",
    "text": "Single-sample Gene Expression Processing\nSingle-sample gene expression processing involves two steps: removing cells based on count statistics and flagging observations originating from doublets.\nThe removal of cells based on basic count statistics is split up into two parts: first, cells are flagged for removal by filter_with_counts. It flags observations based on several thresholds:\n\nThe number of genes that have a least a single count. Both a maximum and minimum number of genes for a cell to be removed can be specified.\nThe percentage of read counts that originated from a mitochodrial genes. Cells can be filtered based on both a maximum or minimum fraction of mitochondrial genes.\nThe minimum or maximum total number of counts captured per cell. Cells with 0 total counts are always removed.\n\nFlagging cells for removal involved adding a boolean column to the .obs dataframe. After the cells have been flagged for removal, the cells are actually filtered using do_filter, which reads the values in .obs and removed the cells labeled True. This applies the general phylosophy of ‚Äúseparation of concerns‚Äù: one component is responsible for labeling the cells, another for removing them. This keeps the codebase for a single component small and its functionality testable.\nThe next and final step in the single-sample gene expression processing is doublet detection using filter_with_scrublet. Like filter_with_counts, it will not remove cells but add a column to .obs (which have the name filter_with_scrublet by default). The single-sample GEX workflow will not remove not be removed during the processing (hence no do_filter). However, you can choose to remove them yourself before doing your analyses by applying a filter with the column in .obs yourself."
  },
  {
    "objectID": "fundamentals/architecture.html#sec-single-sample-adt",
    "href": "fundamentals/architecture.html#sec-single-sample-adt",
    "title": "Architecture",
    "section": "Single-sample Antibody Capture Processing",
    "text": "Single-sample Antibody Capture Processing\nThe process of filtering antibody capture data is similar to the filtering in the single-sample gene-expression processing, but without doublet detection. In some particular cases you can use your ADT data to perform doublet detection using for example cell-type maskers. More information can be found in the single-cell best practices book."
  },
  {
    "objectID": "fundamentals/architecture.html#multisample-gene-expression-processing",
    "href": "fundamentals/architecture.html#multisample-gene-expression-processing",
    "title": "Architecture",
    "section": "Multisample Gene Expression Processing",
    "text": "Multisample Gene Expression Processing\nProcessing multisample gene expression involved the following steps:\n\nNormalization: Normalization aims to adjust the raw counts in the dataset for variable sampling effects by scaling the observable variance to a specified range. There are different ways to transform the data, but the normalization method is to make sure each observation (cell) has a total count equal to the median of total counts over all genes for observations (cells) before normalization.\nLog transformation: Calculates \\(X = ln(X + 1)\\), which converts multiplicative relative changes to additive differences. This allows for interpreting the gene expression in terms of relative, rather than absolute, abundances of genes.\nHighly variable gene detection: Detects genes that have a large change in expression between samples. By default, OpenPipeline uses the method from Seurat (Satija et al.). As with other ‚Äúfiltering‚Äù components, the filter_with_hvg component does not remove features, but rather annotates genes of interest by adding a boolean column to .var.\nQC metric calculations"
  },
  {
    "objectID": "fundamentals/architecture.html#multisample-antibody-capture-processing",
    "href": "fundamentals/architecture.html#multisample-antibody-capture-processing",
    "title": "Architecture",
    "section": "Multisample Antibody Capture Processing",
    "text": "Multisample Antibody Capture Processing\nProcessing the ADT modality for multiple samples"
  },
  {
    "objectID": "fundamentals/architecture.html#sec-dimensionality-reduction",
    "href": "fundamentals/architecture.html#sec-dimensionality-reduction",
    "title": "Architecture",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\nscRNA-seq is a high-throughput sequencing technology that produces datasets with high dimensions in the number of cells and genes. It is true that the data should provide more information, but it also contains more noise and redudant information, making it harder to distill the usefull information. The number of genes and cells can already reduced by gene filtering, but further reduction is a necessity for downstream analysis. Dimensionality reduction projects high-dimensional data into a lower dimensional space (like taking a photo (2D) of some 3D structure). The lower dimensional representation still captures the underlying information of the data, while having fewer dimensions.\nSeveral dimensionality reduction methods have been developed and applied to single-cell data analysis. Two of which are being applied in OpenPipeline:\n\nPrincipal Component Analysis (PCA): PCA reduces the dimension of a dataset by creating a new set of variables (principal components, PCs) from a linear combination of the original features in such a way that they are as uncorrelated as possible. The PCs can be ranked in the order by which they explain the largest variability in the original dataset. By keeping the top n PCs, the PCs with the lowest variance are discarded to effectively reduce the dimensionality of the data without losing information.\nUniform manifold approximation and projection (UMAP): a non-linear dimensionality technique. It constructs a high dimensional graph representation of the dataset and optimizes the low-dimensional graph representation to be structurally as similar as possible to the original graph. In a review by Xiang et al., 2021 it showed the highest stability and separates best the original cell populations.\nt-SNE is another popular non-linear, graph based dimensionality technique which is very similar to UMAP, but it has not yet been implemented in OpenPipeline."
  },
  {
    "objectID": "fundamentals/architecture.html#sec-initializing-integration",
    "href": "fundamentals/architecture.html#sec-initializing-integration",
    "title": "Architecture",
    "section": "Initializing integration",
    "text": "Initializing integration\nAs will be descibed in more details later on, many integration methods exist and therefore there is no single integration which is executed by default. However, there are common tasks which are run before integration either because they provide required input for many downstream integration methods or because they popular steps that would otherwise be done manually. These operations are executed by default when using the ‚Äúfull pipeline‚Äù as part of the initialize_integration subworkflow.\nPCA is used to reduce the dimensionality of the dataset as described previously. Find Neighbors and Leiden Clustering are useful for the identification of cell types or states in the data. Here we apply a popular method to accomplish this is to first calculate a neighborhood graph on a low dimensinonal representation of the data and then cluster the data based on similarity between data points. Finally, UMAP allows us to visualise the clusters by reducing the dimensionality of the data while still providing an accurate representation of the underlying cell population structure."
  },
  {
    "objectID": "fundamentals/architecture.html#sec-integration-methods",
    "href": "fundamentals/architecture.html#sec-integration-methods",
    "title": "Architecture",
    "section": "Integration Methods",
    "text": "Integration Methods\nIntegration is the alignment of cell types across samples. There exist three different types of integration methods, based on the degree of integration across modalities:\n\nUnimodal integration across batches. For example: scVI, scanorama, harmony\nMultimodal integration across batches and modalities. Can be used to integrate joint-profiling data where multiple modalities are measured. For example: totalVI\nMosaic integration: data integration across batches and modalities where not all cells are profiled in all modalities and it may be the case that no cells contain profiles in all integrated modalities. Mosaic integration methods have not been made available in OpenPipeline yet. An example of a tool that performs mosaic integration is StabMap.\n\nIn either of the three cases, concatenated samples are required, and merged modalities preferred. A plethora of integration methods exist, which in turn interact with other functionality (like clustering and dimensionality reduction methods) to generate a large number of possible usecases which one pipeline cannot cover in an easy manner. Therefore, there is no single integration step that is part of a global pipeline which is executed by default. Instead, a user can choose from the integration workflows provided, and ‚Äòstack‚Äô integration methods by adding the outputs to different output slots of the MuData object. The following sections will descibe the integration workflows that are available in OpenPipeline.\n\nUnimodal integration\nFor unimodal integration, scVI, scanorama and harmony have been added to the scvi_leiden, scanorama_leiden, and harmony_leiden workflows respectively. After executing the integration methods themselves, Find Neighbors and Leiden Clustering are run the results of the integration as wel as UMAP in order to be able to visualise the results. The functioning of these components has already been described here.\n\n\n\nMultimodal Integration\nA single multimodal integration method is currently avaiable in OpenPipeline: totalVI. It allows using information from both the gene-expression data and the antibody-capture data together to integrate the cell types. As with the other integration workflows, after running totalVI, Find Neighbors, Leiden Clustering and UMAP are run on the result. However in this case the three components are executed on both of the integrated modalities."
  }
]