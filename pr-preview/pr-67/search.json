[
  {
    "objectID": "components/modules/process_10xh5/filter_10xh5.html",
    "href": "components/modules/process_10xh5/filter_10xh5.html",
    "title": "Filter 10xh5",
    "section": "",
    "text": "ID: filter_10xh5\nNamespace: process_10xh5\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/process_10xh5/filter_10xh5.html#example-commands",
    "href": "components/modules/process_10xh5/filter_10xh5.html#example-commands",
    "title": "Filter 10xh5",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/process_10xh5/filter_10xh5/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n# output: \"$id.$key.output.h5\"\nmin_library_size: 0\nmin_cells_per_gene: 0\n# keep_feature_types: [\"Antibody Capture\"]\nverbose: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/process_10xh5/filter_10xh5/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/process_10xh5/filter_10xh5.html#argument-group",
    "href": "components/modules/process_10xh5/filter_10xh5.html#argument-group",
    "title": "Filter 10xh5",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nAn h5 file from the 10x genomics website.\nfile, required, example: \"pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n\n\n--output\nOutput h5 file.\nfile, required, example: \"pbmc_1k_protein_v3_raw_feature_bc_matrix_filtered.h5\"\n\n\n--min_library_size\nMinimum library size.\ninteger, default: 0\n\n\n--min_cells_per_gene\nMinimum number of cells per gene.\ninteger, default: 0\n\n\n--keep_feature_types\nSpecify which feature types will never be filtered out\nList of string, example: \"Antibody Capture\", multiple_sep: \":\"\n\n\n--verbose\nIncrease verbosity\nboolean_true"
  },
  {
    "objectID": "components/modules/process_10xh5/filter_10xh5.html#authors",
    "href": "components/modules/process_10xh5/filter_10xh5.html#authors",
    "title": "Filter 10xh5",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background_v0_2.html",
    "href": "components/modules/correction/cellbender_remove_background_v0_2.html",
    "title": "Cellbender remove background v0 2",
    "section": "",
    "text": "ID: cellbender_remove_background_v0_2\nNamespace: correction\n\n\n\nSource\nThis module removes counts due to ambient RNA molecules and random barcode swapping from (raw) UMI-based scRNA-seq count matrices. At the moment, only the count matrices produced by the CellRanger count pipeline is supported. Support for additional tools and protocols will be added in the future. A quick start tutorial can be found here.\nFleming et al. 2022, bioRxiv."
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background_v0_2.html#example-commands",
    "href": "components/modules/correction/cellbender_remove_background_v0_2.html#example-commands",
    "title": "Cellbender remove background v0 2",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/correction/cellbender_remove_background_v0_2/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nlayer_output: \"corrected\"\nobs_latent_rt_efficiency: \"latent_rt_efficiency\"\nobs_latent_cell_probability: \"latent_cell_probability\"\nobs_latent_scale: \"latent_scale\"\nvar_ambient_expression: \"ambient_expression\"\nobsm_latent_gene_encoding: \"cellbender_latent_gene_encoding\"\n\n# Arguments\n# expected_cells: 1000\n# total_droplets_included: 25000\nexpected_cells_from_qc: true\nmodel: \"full\"\nepochs: 150\nlow_count_threshold: 15\nz_dim: 100\nz_layers: [500]\ntraining_fraction: 0.9\nempty_drop_training_fraction: 0.5\nfpr: [0.01]\nexclude_antibody_capture: false\n# learning_rate: 1.0E-4\ncuda: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/correction/cellbender_remove_background_v0_2/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background_v0_2.html#argument-groups",
    "href": "components/modules/correction/cellbender_remove_background_v0_2.html#argument-groups",
    "title": "Cellbender remove background v0 2",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nList of modalities to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nFull count matrix as an h5mu file, with background RNA removed. This file contains all the original droplet barcodes.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--layer_output\nOutput layer\nstring, default: \"corrected\"\n\n\n--obs_latent_rt_efficiency\n\nstring, default: \"latent_rt_efficiency\"\n\n\n--obs_latent_cell_probability\n\nstring, default: \"latent_cell_probability\"\n\n\n--obs_latent_scale\n\nstring, default: \"latent_scale\"\n\n\n--var_ambient_expression\n\nstring, default: \"ambient_expression\"\n\n\n--obsm_latent_gene_encoding\n\nstring, default: \"cellbender_latent_gene_encoding\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--expected_cells\nNumber of cells expected in the dataset (a rough estimate within a factor of 2 is sufficient).\ninteger, example: 1000\n\n\n--total_droplets_included\nThe number of droplets from the rank-ordered UMI plot that will be analyzed. The largest ‘total_droplets’ droplets will have their cell probabilities inferred as an output.\ninteger, example: 25000\n\n\n--expected_cells_from_qc\nWill use the Cell Ranger QC to determine the estimated number of cells\nboolean, default: TRUE\n\n\n--model\nWhich model is being used for count data. ‘simple’ does not model either ambient RNA or random barcode swapping (for debugging purposes – not recommended). ‘ambient’ assumes background RNA is incorporated into droplets. ‘swapping’ assumes background RNA comes from random barcode swapping. ‘full’ uses a combined ambient and swapping model.\nstring, default: \"full\"\n\n\n--epochs\nNumber of epochs to train.\ninteger, default: 150\n\n\n--low_count_threshold\nDroplets with UMI counts below this number are completely excluded from the analysis. This can help identify the correct prior for empty droplet counts in the rare case where empty counts are extremely high (over 200).\ninteger, default: 15\n\n\n--z_dim\nDimension of latent variable z.\ninteger, default: 100\n\n\n--z_layers\nDimension of hidden layers in the encoder for z.\nList of integer, default: 500, multiple_sep: \":\"\n\n\n--training_fraction\nTraining detail: the fraction of the data used for training. The rest is never seen by the inference algorithm. Speeds up learning.\ndouble, default: 0.9\n\n\n--empty_drop_training_fraction\nTraining detail: the fraction of the training data each epoch that is drawn (randomly sampled) from surely empty droplets.\ndouble, default: 0.5\n\n\n--fpr\nTarget false positive rate in (0, 1). A false positive is a true signal count that is erroneously removed. More background removal is accompanied by more signal removal at high values of FPR. You can specify multiple values, which will create multiple output files.\nList of double, default: 0.01, multiple_sep: \":\"\n\n\n--exclude_antibody_capture\nIncluding the flag –exclude-antibody-capture will cause remove-background to operate on gene counts only, ignoring other features.\nboolean_true\n\n\n--learning_rate\nTraining detail: lower learning rate for inference. A OneCycle learning rate schedule is used, where the upper learning rate is ten times this value. (For this value, probably do not exceed 1e-3).\ndouble, example: 1e-04\n\n\n--cuda\nIncluding the flag –cuda will run the inference on a GPU.\nboolean_true"
  },
  {
    "objectID": "components/modules/reference/make_reference.html",
    "href": "components/modules/reference/make_reference.html",
    "title": "Make reference",
    "section": "",
    "text": "ID: make_reference\nNamespace: reference\n\n\n\nSource\nExample input files are: - genome_fasta: https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/GRCh38.primary_assembly.genome.fa.gz - transcriptome_gtf: https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/gencode.v41.annotation.gtf.gz - ercc: https://assets.thermofisher.com/TFS-Assets/LSG/manuals/ERCC92.zip"
  },
  {
    "objectID": "components/modules/reference/make_reference.html#example-commands",
    "href": "components/modules/reference/make_reference.html#example-commands",
    "title": "Make reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/reference/make_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ngenome_fasta: # please fill in - example: \"genome_fasta.fa.gz\"\ntranscriptome_gtf: # please fill in - example: \"transcriptome.gtf.gz\"\n# ercc: \"ercc.zip\"\n# subset_regex: \"(ERCC-00002|chr1)\"\n# output_fasta: \"$id.$key.output_fasta.gz\"\n# output_gtf: \"$id.$key.output_gtf.gz\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/reference/make_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/reference/make_reference.html#argument-group",
    "href": "components/modules/reference/make_reference.html#argument-group",
    "title": "Make reference",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genome_fasta\nReference genome fasta. Example:\nfile, required, example: \"genome_fasta.fa.gz\"\n\n\n--transcriptome_gtf\nReference transcriptome annotation.\nfile, required, example: \"transcriptome.gtf.gz\"\n\n\n--ercc\nERCC sequence and annotation file.\nfile, example: \"ercc.zip\"\n\n\n--subset_regex\nWill subset the reference chromosomes using the given regex.\nstring, example: \"(ERCC-00002&#124;chr1)\"\n\n\n--output_fasta\nOutput genome sequence fasta.\nfile, required, example: \"genome_sequence.fa.gz\"\n\n\n--output_gtf\nOutput transcriptome annotation gtf.\nfile, required, example: \"transcriptome_annotation.gtf.gz\""
  },
  {
    "objectID": "components/modules/reference/make_reference.html#authors",
    "href": "components/modules/reference/make_reference.html#authors",
    "title": "Make reference",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/reference/build_cellranger_reference.html",
    "href": "components/modules/reference/build_cellranger_reference.html",
    "title": "Build cellranger reference",
    "section": "",
    "text": "ID: build_cellranger_reference\nNamespace: reference\n\n\n\nSource\nCreates a new folder named after the genome."
  },
  {
    "objectID": "components/modules/reference/build_cellranger_reference.html#example-commands",
    "href": "components/modules/reference/build_cellranger_reference.html#example-commands",
    "title": "Build cellranger reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/reference/build_cellranger_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ngenome_fasta: # please fill in - example: \"genome_sequence.fa.gz\"\ntranscriptome_gtf: # please fill in - example: \"transcriptome_annotation.gtf.gz\"\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/reference/build_cellranger_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/reference/build_cellranger_reference.html#argument-group",
    "href": "components/modules/reference/build_cellranger_reference.html#argument-group",
    "title": "Build cellranger reference",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genome_fasta\nReference genome fasta.\nfile, required, example: \"genome_sequence.fa.gz\"\n\n\n--transcriptome_gtf\nReference transcriptome annotation.\nfile, required, example: \"transcriptome_annotation.gtf.gz\"\n\n\n--output\nOutput folder\nfile, required, example: \"cellranger_reference\""
  },
  {
    "objectID": "components/modules/reference/build_cellranger_reference.html#authors",
    "href": "components/modules/reference/build_cellranger_reference.html#authors",
    "title": "Build cellranger reference",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/transform/delete_layer.html",
    "href": "components/modules/transform/delete_layer.html",
    "title": "Delete layer",
    "section": "",
    "text": "ID: delete_layer\nNamespace: transform\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/transform/delete_layer.html#example-commands",
    "href": "components/modules/transform/delete_layer.html#example-commands",
    "title": "Delete layer",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/transform/delete_layer/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nlayer: # please fill in - example: [\"foo\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nmissing_ok: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/delete_layer/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transform/delete_layer.html#argument-group",
    "href": "components/modules/transform/delete_layer.html#argument-group",
    "title": "Delete layer",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nInput layer to remove\nList of string, required, multiple_sep: \":\"\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--missing_ok\nDo not raise an error if the layer does not exist for all modalities.\nboolean_true"
  },
  {
    "objectID": "components/modules/transform/delete_layer.html#authors",
    "href": "components/modules/transform/delete_layer.html#authors",
    "title": "Delete layer",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/transform/log1p.html",
    "href": "components/modules/transform/log1p.html",
    "title": "Log1p",
    "section": "",
    "text": "ID: log1p\nNamespace: transform\n\n\n\nSource\nComputes X = log(X + 1), where log denotes the natural logarithm unless a different base is given"
  },
  {
    "objectID": "components/modules/transform/log1p.html#example-commands",
    "href": "components/modules/transform/log1p.html#example-commands",
    "title": "Log1p",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/transform/log1p/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# output_layer: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n# base: 2\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/log1p/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transform/log1p.html#argument-group",
    "href": "components/modules/transform/log1p.html#argument-group",
    "title": "Log1p",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\nInput layer to use. If None, X is normalized\nstring\n\n\n--output_layer\nOutput layer to use. By default, use X.\nstring\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--base\n\ndouble, example: 2"
  },
  {
    "objectID": "components/modules/transform/log1p.html#authors",
    "href": "components/modules/transform/log1p.html#authors",
    "title": "Log1p",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)\nRobrecht Cannoodt    (contributor)"
  },
  {
    "objectID": "components/modules/transform/scale.html",
    "href": "components/modules/transform/scale.html",
    "title": "Scale",
    "section": "",
    "text": "ID: scale\nNamespace: transform\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/transform/scale.html#example-commands",
    "href": "components/modules/transform/scale.html#example-commands",
    "title": "Scale",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/transform/scale/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# max_value: 123.0\nzero_center: true\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/scale/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transform/scale.html#argument-group",
    "href": "components/modules/transform/scale.html#argument-group",
    "title": "Scale",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nList of modalities to process.\nstring, default: \"rna\"\n\n\n--max_value\nClip (truncate) to this value after scaling. Does not clip by default.\ndouble\n\n\n--zero_center\nIf False, omit zero-centering variables, which allows to handle sparse input efficiently.\nboolean, default: TRUE\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/transform/scale.html#authors",
    "href": "components/modules/transform/scale.html#authors",
    "title": "Scale",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/cluster/leiden.html",
    "href": "components/modules/cluster/leiden.html",
    "title": "Leiden",
    "section": "",
    "text": "ID: leiden\nNamespace: cluster\n\n\n\nSource\nLeiden is an improved version of the Louvain algorithm [Blondel08]. It has been proposed for single-cell analysis by [Levine15]. This requires having ran neighbors/find_neighbors or neighbors/bbknn first.\nBlondel08: Blondel et al. (2008), Fast unfolding of communities in large networks, J. Stat. Mech.\nLevine15: Levine et al. (2015), Data-Driven Phenotypic Dissection of AML Reveals Progenitor-like Cells that Correlate with Prognosis, Cell.\nTraag18: Traag et al. (2018), From Louvain to Leiden: guaranteeing well-connected communities arXiv.\nWolf18: Wolf et al. (2018), Scanpy: large-scale single-cell gene expression data analysis, Genome Biology."
  },
  {
    "objectID": "components/modules/cluster/leiden.html#example-commands",
    "href": "components/modules/cluster/leiden.html#example-commands",
    "title": "Leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/cluster/leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nobsp_connectivities: \"connectivities\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobsm_name: \"leiden\"\nresolution: [1]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/cluster/leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/cluster/leiden.html#argument-group",
    "href": "components/modules/cluster/leiden.html#argument-group",
    "title": "Leiden",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsp_connectivities\nIn which .obsp slot the neighbor connectivities can be found.\nstring, default: \"connectivities\"\n\n\n--output\nOutput file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--obsm_name\nName of the .obsm key under which to add the cluster labels. The name of the columns in the matrix will correspond to the resolutions.\nstring, default: \"leiden\"\n\n\n--resolution\nA parameter value controlling the coarseness of the clustering. Higher values lead to more clusters. Multiple values will result in clustering being performed multiple times.\nList of double, default: 1, multiple_sep: \":\""
  },
  {
    "objectID": "components/modules/cluster/leiden.html#authors",
    "href": "components/modules/cluster/leiden.html#authors",
    "title": "Leiden",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)"
  },
  {
    "objectID": "components/modules/dataflow/split_modalities.html",
    "href": "components/modules/dataflow/split_modalities.html",
    "title": "Split modalities",
    "section": "",
    "text": "ID: split_modalities\nNamespace: dataflow\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/dataflow/split_modalities.html#example-commands",
    "href": "components/modules/dataflow/split_modalities.html#example-commands",
    "title": "Split modalities",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/dataflow/split_modalities/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"sample_path\"\n# output: \"$id.$key.output.output\"\n# output_compression: \"gzip\"\n# output_types: \"$id.$key.output_types.csv\"\ncompression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dataflow/split_modalities/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/dataflow/split_modalities.html#argument-group",
    "href": "components/modules/dataflow/split_modalities.html#argument-group",
    "title": "Split modalities",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to a single .h5mu file.\nfile, required, default: \"sample_path\"\n\n\n--output\nOutput directory containing multiple h5mu files.\nfile, required, example: \"/path/to/output\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--output_types\nA csv containing the base filename and modality type per output file.\nfile, required, example: \"types.csv\"\n\n\n--compression\nThe compression format to be used on the final h5mu object.\nstring, default: \"gzip\""
  },
  {
    "objectID": "components/modules/dataflow/split_modalities.html#authors",
    "href": "components/modules/dataflow/split_modalities.html#authors",
    "title": "Split modalities",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)\nRobrecht Cannoodt    (contributor)"
  },
  {
    "objectID": "components/modules/filter/delimit_fraction.html",
    "href": "components/modules/filter/delimit_fraction.html",
    "title": "Delimit fraction",
    "section": "",
    "text": "ID: delimit_fraction\nNamespace: filter\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/filter/delimit_fraction.html#example-commands",
    "href": "components/modules/filter/delimit_fraction.html#example-commands",
    "title": "Delimit fraction",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.2 -latest \\\n  -main-script target/nextflow/filter/delimit_fraction/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"raw_counts\"\nobs_fraction_column: # please fill in - example: \"fraction_mitochondrial\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobs_name_filter: # please fill in - example: \"foo\"\n\n# Arguments\nmin_fraction: 0\nmax_fraction: 1\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.2 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/delimit_fraction/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/delimit_fraction.html#argument-groups",
    "href": "components/modules/filter/delimit_fraction.html#argument-groups",
    "title": "Delimit fraction",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\n\nstring, example: \"raw_counts\"\n\n\n--obs_fraction_column\nName of column from .var dataframe selecting a column that contains floating point values between 0 and 1.\nstring, required, example: \"fraction_mitochondrial\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obs_name_filter\nIn which .obs slot to store a boolean array corresponding to which observations should be removed.\nstring, required\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_fraction\nMin fraction for an observation to be retained (True in output).\ndouble, default: 0\n\n\n--max_fraction\nMax fraction for an observation to be retained (True in output).\ndouble, default: 1"
  },
  {
    "objectID": "components/modules/filter/delimit_fraction.html#authors",
    "href": "components/modules/filter/delimit_fraction.html#authors",
    "title": "Delimit fraction",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)"
  },
  {
    "objectID": "components/modules/filter/remove_modality.html",
    "href": "components/modules/filter/remove_modality.html",
    "title": "Remove modality",
    "section": "",
    "text": "ID: remove_modality\nNamespace: filter\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/filter/remove_modality.html#example-commands",
    "href": "components/modules/filter/remove_modality.html#example-commands",
    "title": "Remove modality",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/filter/remove_modality/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: # please fill in - example: [\"foo\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/remove_modality/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/remove_modality.html#argument-group",
    "href": "components/modules/filter/remove_modality.html#argument-group",
    "title": "Remove modality",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nList of string, required, multiple_sep: \":\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/filter/remove_modality.html#authors",
    "href": "components/modules/filter/remove_modality.html#authors",
    "title": "Remove modality",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/filter/filter_with_hvg.html",
    "href": "components/modules/filter/filter_with_hvg.html",
    "title": "Filter with hvg",
    "section": "",
    "text": "ID: filter_with_hvg\nNamespace: filter\n\n\n\nSource\nExpects logarithmized data, except when flavor=‘seurat_v3’ in which count data is expected.\nDepending on flavor, this reproduces the R-implementations of Seurat [Satija15], Cell Ranger [Zheng17], and Seurat v3 [Stuart19].\nFor the dispersion-based methods ([Satija15] and [Zheng17]), the normalized dispersion is obtained by scaling with the mean and standard deviation of the dispersions for genes falling into a given bin for mean expression of genes. This means that for each bin of mean expression, highly variable genes are selected.\nFor [Stuart19], a normalized variance for each gene is computed. First, the data are standardized (i.e., z-score normalization per feature) with a regularized standard deviation. Next, the normalized variance is computed as the variance of each gene after the transformation. Genes are ranked by the normalized variance."
  },
  {
    "objectID": "components/modules/filter/filter_with_hvg.html#example-commands",
    "href": "components/modules/filter/filter_with_hvg.html#example-commands",
    "title": "Filter with hvg",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/filter/filter_with_hvg/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nvar_name_filter: \"filter_with_hvg\"\nvarm_name: \"hvg\"\ndo_subset: false\nflavor: \"seurat\"\n# n_top_genes: 123\nmin_mean: 0.0125\nmax_mean: 3\nmin_disp: 0.5\n# max_disp: 123.0\nspan: 0.3\nn_bins: 20\n# obs_batch_key: \"foo\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/filter_with_hvg/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/filter_with_hvg.html#argument-group",
    "href": "components/modules/filter/filter_with_hvg.html#argument-group",
    "title": "Filter with hvg",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nuse adata.layers[layer] for expression values instead of adata.X.\nstring\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--var_name_filter\nIn which .var slot to store a boolean array corresponding to which observations should be filtered out.\nstring, default: \"filter_with_hvg\"\n\n\n--varm_name\nIn which .varm slot to store additional metadata.\nstring, default: \"hvg\"\n\n\n--do_subset\nWhether to subset before storing the output.\nboolean_true\n\n\n--flavor\nChoose the flavor for identifying highly variable genes. For the dispersion based methods in their default workflows, Seurat passes the cutoffs whereas Cell Ranger passes n_top_genes.\nstring, default: \"seurat\"\n\n\n--n_top_genes\nNumber of highly-variable genes to keep. Mandatory if flavor=‘seurat_v3’.\ninteger\n\n\n--min_mean\nIf n_top_genes is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‘seurat_v3’.\ndouble, default: 0.0125\n\n\n--max_mean\nIf n_top_genes is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‘seurat_v3’.\ndouble, default: 3\n\n\n--min_disp\nIf n_top_genes is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‘seurat_v3’.\ndouble, default: 0.5\n\n\n--max_disp\nIf n_top_genes is defined, this and all other cutoffs for the means and the normalized dispersions are ignored. Ignored if flavor=‘seurat_v3’. Default is +inf.\ndouble\n\n\n--span\nThe fraction of the data (cells) used when estimating the variance in the loess model fit if flavor=‘seurat_v3’.\ndouble, default: 0.3\n\n\n--n_bins\nNumber of bins for binning the mean gene expression. Normalization is done with respect to each bin. If just a single gene falls into a bin, the normalized dispersion is artificially set to 1.\ninteger, default: 20\n\n\n--obs_batch_key\nIf specified, highly-variable genes are selected within each batch separately and merged. This simple process avoids the selection of batch-specific genes and acts as a lightweight batch correction method. For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If flavor = ‘seurat_v3’, ties are broken by the median (across batches) rank based on within-batch normalized variance.\nstring"
  },
  {
    "objectID": "components/modules/filter/filter_with_hvg.html#authors",
    "href": "components/modules/filter/filter_with_hvg.html#authors",
    "title": "Filter with hvg",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (contributor)\nRobrecht Cannoodt    (maintainer, contributor)"
  },
  {
    "objectID": "components/modules/filter/filter_with_counts.html",
    "href": "components/modules/filter/filter_with_counts.html",
    "title": "Filter with counts",
    "section": "",
    "text": "ID: filter_with_counts\nNamespace: filter\n\n\n\nSource\nThis is based on both the UMI counts, the gene counts and the mitochondrial genes (genes starting with mt/MT)"
  },
  {
    "objectID": "components/modules/filter/filter_with_counts.html#example-commands",
    "href": "components/modules/filter/filter_with_counts.html#example-commands",
    "title": "Filter with counts",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/filter/filter_with_counts/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"raw_counts\"\n# var_gene_names: \"gene_symbol\"\nmitochondrial_gene_regex: \"^[mM][tT]-\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\ndo_subset: false\nobs_name_filter: \"filter_with_counts\"\nvar_name_filter: \"filter_with_counts\"\n# var_name_mitochondrial_genes: \"foo\"\n\n# Arguments\n# min_counts: 200\n# max_counts: 5000000\n# min_genes_per_cell: 200\n# max_genes_per_cell: 1500000\n# min_cells_per_gene: 3\n# min_fraction_mito: 0\n# max_fraction_mito: 0.2\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/filter_with_counts/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/filter_with_counts.html#argument-groups",
    "href": "components/modules/filter/filter_with_counts.html#argument-groups",
    "title": "Filter with counts",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\n\nstring, example: \"raw_counts\"\n\n\n--var_gene_names\n.var column name to be used to detect mitochondrial genes instead of .var_names (default if not set). Gene names matching with the regex value from –mitochondrial_gene_regex will be identified as a mitochondrial gene.\nstring, example: \"gene_symbol\"\n\n\n--mitochondrial_gene_regex\nRegex string that identifies mitochondrial genes from –var_gene_names. By default will detect human and mouse mitochondrial genes from a gene symbol.\nstring, default: \"^[mM][tT]-\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--do_subset\nWhether to subset before storing the output.\nboolean_true\n\n\n--obs_name_filter\nIn which .obs slot to store a boolean array corresponding to which observations should be removed.\nstring, default: \"filter_with_counts\"\n\n\n--var_name_filter\nIn which .var slot to store a boolean array corresponding to which variables should be removed.\nstring, default: \"filter_with_counts\"\n\n\n--var_name_mitochondrial_genes\nIn which .var slot to store a boolean array corresponding the mitochondrial genes. Will only be used if –min_fraction_mito or –max_fraction_mito are specified.\nstring\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--min_genes_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--max_genes_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--min_cells_per_gene\nMinimum of non-zero values per gene.\ninteger, example: 3\n\n\n--min_fraction_mito\nMinimum fraction of UMIs that are mitochondrial.\ndouble, example: 0\n\n\n--max_fraction_mito\nMaximum fraction of UMIs that are mitochondrial.\ndouble, example: 0.2"
  },
  {
    "objectID": "components/modules/filter/filter_with_counts.html#authors",
    "href": "components/modules/filter/filter_with_counts.html#authors",
    "title": "Filter with counts",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (maintainer, author)"
  },
  {
    "objectID": "components/modules/labels_transfer/knn.html",
    "href": "components/modules/labels_transfer/knn.html",
    "title": "Knn",
    "section": "",
    "text": "ID: knn\nNamespace: labels_transfer\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/labels_transfer/knn.html#example-commands",
    "href": "components/modules/labels_transfer/knn.html#example-commands",
    "title": "Knn",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/labels_transfer/knn/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Learning parameters\nn_neighbors: # please fill in - example: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/labels_transfer/knn/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/labels_transfer/knn.html#argument-groups",
    "href": "components/modules/labels_transfer/knn.html#argument-groups",
    "title": "Knn",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput dataset (query) arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe query data to transfer the labels to. Should be a .h5mu file.\nfile, required\n\n\n--modality\nWhich modality to use.\nstring, default: \"rna\"\n\n\n--input_obsm_features\nThe .obsm key of the embedding to use for the classifier’s inference. If not provided, the .X slot will be used instead. Make sure that embedding was obtained in the same way as the reference embedding (e.g. by the same model or preprocessing).\nstring, example: \"X_integrated_scanvi\"\n\n\n\n\n\nReference dataset arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nThe reference data to train classifiers on.\nfile, example: \"https:/zenodo.org/record/6337966/files/HLCA_emb_and_metadata.h5ad\"\n\n\n--reference_obsm_features\nThe .obsm key of the embedding to use for the classifier’s training. Make sure that embedding was obtained in the same way as the query embedding (e.g. by the same model or preprocessing).\nstring, required, default: \"X_integrated_scanvi\"\n\n\n--reference_obs_targets\nThe .obs key of the target labels to tranfer.\nList of string, default: \"ann_level_1\", \"ann_level_2\", \"ann_level_3\", \"ann_level_4\", \"ann_level_5\", \"ann_finest_level\", multiple_sep: \",\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe query data in .h5mu format with predicted labels transfered from the reference.\nfile, required\n\n\n--output_obs_predictions\nIn which .obs slots to store the predicted information. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_pred\" suffix.\nList of string, multiple_sep: \":\"\n\n\n--output_obs_uncertainty\nIn which .obs slots to store the uncertainty of the predictions. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_uncertainty\" suffix.\nList of string, multiple_sep: \":\"\n\n\n--output_uns_parameters\nThe .uns key to store additional information about the parameters used for the label transfer.\nstring, default: \"labels_transfer\"\n\n\n\n\n\nLearning parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_neighbors\nNumber of nearest neighbors to use for classification\ninteger, required"
  },
  {
    "objectID": "components/modules/labels_transfer/knn.html#authors",
    "href": "components/modules/labels_transfer/knn.html#authors",
    "title": "Knn",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov    (author)"
  },
  {
    "objectID": "components/modules/neighbors/bbknn.html",
    "href": "components/modules/neighbors/bbknn.html",
    "title": "Bbknn",
    "section": "",
    "text": "ID: bbknn\nNamespace: neighbors\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/neighbors/bbknn.html#example-commands",
    "href": "components/modules/neighbors/bbknn.html#example-commands",
    "title": "Bbknn",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/neighbors/bbknn/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\nobsm_input: \"X_pca\"\nobs_batch: \"batch\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nuns_output: \"neighbors\"\nobsp_distances: \"distances\"\nobsp_connectivities: \"connectivities\"\nn_neighbors_within_batch: 3\nn_pcs: 50\n# n_trim: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/neighbors/bbknn/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/neighbors/bbknn.html#argument-group",
    "href": "components/modules/neighbors/bbknn.html#argument-group",
    "title": "Bbknn",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsm_input\nThe dimensionality reduction in .obsm to use for neighbour detection. Defaults to X_pca.\nstring, default: \"X_pca\"\n\n\n--obs_batch\n.obs column name discriminating between your batches.\nstring, default: \"batch\"\n\n\n--output\nOutput .h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--uns_output\nMandatory .uns slot to store various neighbor output objects.\nstring, default: \"neighbors\"\n\n\n--obsp_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"distances\"\n\n\n--obsp_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"connectivities\"\n\n\n--n_neighbors_within_batch\nHow many top neighbours to report for each batch; total number of neighbours in the initial k-nearest-neighbours computation will be this number times the number of batches.\ninteger, default: 3\n\n\n--n_pcs\nHow many dimensions (in case of PCA, principal components) to use in the analysis.\ninteger, default: 50\n\n\n--n_trim\nTrim the neighbours of each cell to these many top connectivities. May help with population independence and improve the tidiness of clustering. The lower the value the more independent the individual populations, at the cost of more conserved batch effect. If None (default), sets the parameter value automatically to 10 times neighbors_within_batch times the number of batches. Set to 0 to skip.\ninteger"
  },
  {
    "objectID": "components/modules/neighbors/bbknn.html#authors",
    "href": "components/modules/neighbors/bbknn.html#authors",
    "title": "Bbknn",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/demux/cellranger_mkfastq.html",
    "href": "components/modules/demux/cellranger_mkfastq.html",
    "title": "Cellranger mkfastq",
    "section": "",
    "text": "ID: cellranger_mkfastq\nNamespace: demux\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/demux/cellranger_mkfastq.html#example-commands",
    "href": "components/modules/demux/cellranger_mkfastq.html#example-commands",
    "title": "Cellranger mkfastq",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/demux/cellranger_mkfastq/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"/path/to/bcl\"\nsample_sheet: # please fill in - example: \"SampleSheet.csv\"\n# output: \"$id.$key.output.output\"\n# reports: \"$id.$key.reports.reports\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/demux/cellranger_mkfastq/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/demux/cellranger_mkfastq.html#argument-group",
    "href": "components/modules/demux/cellranger_mkfastq.html#argument-group",
    "title": "Cellranger mkfastq",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the (untarred) BCL files. Expects ‘RunParameters.xml’ at ‘./’.\nfile, required, example: \"/path/to/bcl\"\n\n\n--sample_sheet\nThe path to the sample sheet.\nfile, required, example: \"SampleSheet.csv\"\n\n\n--output\nThe folder to store the demux results\nfile, required, default: \"fastqs\", example: \"/path/to/output\"\n\n\n--reports\nReports directory\nfile, example: \"reports_dir\""
  },
  {
    "objectID": "components/modules/demux/cellranger_mkfastq.html#authors",
    "href": "components/modules/demux/cellranger_mkfastq.html#authors",
    "title": "Cellranger mkfastq",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nSamuel D’Souza   (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/demux/bcl_convert.html",
    "href": "components/modules/demux/bcl_convert.html",
    "title": "Bcl convert",
    "section": "",
    "text": "ID: bcl_convert\nNamespace: demux\n\n\n\nSource\nInformation about upgrading from bcl2fastq via https://emea.support.illumina.com/bulletins/2020/10/upgrading-from-bcl2fastq-to-bcl-convert.html and https://support.illumina.com/sequencing/sequencing_software/bcl-convert/compatibility.html"
  },
  {
    "objectID": "components/modules/demux/bcl_convert.html#example-commands",
    "href": "components/modules/demux/bcl_convert.html#example-commands",
    "title": "Bcl convert",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/demux/bcl_convert/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"bcl_dir\"\nsample_sheet: # please fill in - example: \"bcl_dir\"\n# output: \"$id.$key.output.output\"\n# reports: \"$id.$key.reports.reports\"\ntest_mode: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/demux/bcl_convert/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/demux/bcl_convert.html#argument-group",
    "href": "components/modules/demux/bcl_convert.html#argument-group",
    "title": "Bcl convert",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput run directory\nfile, required, example: \"bcl_dir\"\n\n\n--sample_sheet\nPointer to the sample sheet\nfile, required, example: \"bcl_dir\"\n\n\n--output\nOutput directory containig fastq files\nfile, required, example: \"fastq_dir\"\n\n\n--reports\nReports directory\nfile, example: \"reports_dir\"\n\n\n--test_mode\nShould bcl-convert be run in test mode (using –first-tile-only)?\nboolean, default: FALSE"
  },
  {
    "objectID": "components/modules/demux/bcl_convert.html#authors",
    "href": "components/modules/demux/bcl_convert.html#authors",
    "title": "Bcl convert",
    "section": "Authors",
    "text": "Authors\n\nToni Verbeiren   (author, maintainer)\nMarijke Van Moerbeke    (author)"
  },
  {
    "objectID": "components/modules/qc/multiqc.html",
    "href": "components/modules/qc/multiqc.html",
    "title": "Multiqc",
    "section": "",
    "text": "ID: multiqc\nNamespace: qc\n\n\n\nSource\nIt searches a given directory for analysis logs and compiles a HTML report. It’s a general use tool, perfect for summarising the output from numerous bioinformatics tools"
  },
  {
    "objectID": "components/modules/qc/multiqc.html#example-commands",
    "href": "components/modules/qc/multiqc.html#example-commands",
    "title": "Multiqc",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/qc/multiqc/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: [\"input.txt\"]\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/qc/multiqc/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/qc/multiqc.html#argument-group",
    "href": "components/modules/qc/multiqc.html#argument-group",
    "title": "Multiqc",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInputs for MultiQC.\nList of file, required, example: \"input.txt\", multiple_sep: \":\"\n\n\n--output\nCreate report in the specified output directory.\nfile, required, example: \"report\""
  },
  {
    "objectID": "components/modules/integrate/harmonypy.html",
    "href": "components/modules/integrate/harmonypy.html",
    "title": "Harmonypy",
    "section": "",
    "text": "ID: harmonypy\nNamespace: integrate\n\n\n\nSource\nBased on an implementation in python from https://github.com/slowkow/harmonypy"
  },
  {
    "objectID": "components/modules/integrate/harmonypy.html#example-commands",
    "href": "components/modules/integrate/harmonypy.html#example-commands",
    "title": "Harmonypy",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/integrate/harmonypy/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\n# output: \"$id.$key.output.output\"\n# output_compression: \"gzip\"\nmodality: \"rna\"\nobsm_input: \"X_pca\"\nobsm_output: \"X_pca_integrated\"\ntheta: [2]\nobs_covariates: # please fill in - example: [\"batch\", \"sample\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/harmonypy/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/integrate/harmonypy.html#argument-group",
    "href": "components/modules/integrate/harmonypy.html#argument-group",
    "title": "Harmonypy",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsm_input\nWhich .obsm slot to use as a starting PCA embedding.\nstring, default: \"X_pca\"\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_pca_integrated\"\n\n\n--theta\nDiversity clustering penalty parameter. Specify for each variable in group.by.vars. theta=0 does not encourage any diversity. Larger values of theta result in more diverse clusters.\nList of double, default: 2, multiple_sep: \":\"\n\n\n--obs_covariates\nThe .obs field(s) that define the covariate(s) to regress out.\nList of string, required, example: \"batch\", \"sample\", multiple_sep: \":\""
  },
  {
    "objectID": "components/modules/integrate/harmonypy.html#authors",
    "href": "components/modules/integrate/harmonypy.html#authors",
    "title": "Harmonypy",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)\nRobrecht Cannoodt    (contributor)"
  },
  {
    "objectID": "components/modules/integrate/scvi.html",
    "href": "components/modules/integrate/scvi.html",
    "title": "Scvi",
    "section": "",
    "text": "ID: scvi\nNamespace: integrate\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/integrate/scvi.html#example-commands",
    "href": "components/modules/integrate/scvi.html#example-commands",
    "title": "Scvi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/integrate/scvi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\n# input_layer: \"foo\"\nobs_batch: \"sample_id\"\n# var_input: \"foo\"\n# obs_labels: \"foo\"\n# obs_size_factor: \"foo\"\n# obs_categorical_covariate: [\"foo\"]\n# obs_continuous_covariate: [\"foo\"]\n\n# Outputs\n# output: \"$id.$key.output.output\"\n# model_output: \"$id.$key.model_output.model_output\"\n# output_compression: \"gzip\"\nobsm_output: \"X_scvi_integrated\"\n\n# SCVI options\nn_hidden_nodes: 128\nn_dimensions_latent_space: 30\nn_hidden_layers: 2\ndropout_rate: 0.1\ndispersion: \"gene\"\ngene_likelihood: \"nb\"\n\n# Variational auto-encoder model options\nuse_layer_normalization: \"both\"\nuse_batch_normalization: \"none\"\nencode_covariates: true\ndeeply_inject_covariates: false\nuse_observed_lib_size: false\n\n# Early stopping arguments\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n\n# Learning parameters\n# max_epochs: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30\n\n# Data validition\nn_obs_min_count: 0\nn_var_min_count: 0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/scvi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/integrate/scvi.html#argument-groups",
    "href": "components/modules/integrate/scvi.html#argument-groups",
    "title": "Scvi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\nInput layer to use. If None, X is used\nstring\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--var_input\n.var column containing highly variable genes. By default, do not subset genes.\nstring\n\n\n--obs_labels\nKey in adata.obs for label information. Categories will automatically be converted into integer categories and saved to adata.obs[’_scvi_labels’]. If None, assigns the same label to all the data.\nstring\n\n\n--obs_size_factor\nKey in adata.obs for size factor information. Instead of using library size as a size factor, the provided size factor column will be used as offset in the mean of the likelihood. Assumed to be on linear scale.\nstring\n\n\n--obs_categorical_covariate\nKeys in adata.obs that correspond to categorical data. These covariates can be added in addition to the batch covariate and are also treated as nuisance factors (i.e., the model tries to minimize their effects on the latent space). Thus, these should not be used for biologically-relevant factors that you do not want to correct for.\nList of string, multiple_sep: \":\"\n\n\n--obs_continuous_covariate\nKeys in adata.obs that correspond to continuous data. These covariates can be added in addition to the batch covariate and are also treated as nuisance factors (i.e., the model tries to minimize their effects on the latent space). Thus, these should not be used for biologically-relevant factors that you do not want to correct for.\nList of string, multiple_sep: \":\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--model_output\nFolder where the state of the trained model will be saved to.\nfile\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_scvi_integrated\"\n\n\n\n\n\nSCVI options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_hidden_nodes\nNumber of nodes per hidden layer.\ninteger, default: 128\n\n\n--n_dimensions_latent_space\nDimensionality of the latent space.\ninteger, default: 30\n\n\n--n_hidden_layers\nNumber of hidden layers used for encoder and decoder neural-networks.\ninteger, default: 2\n\n\n--dropout_rate\nDropout rate for the neural networks.\ndouble, default: 0.1\n\n\n--dispersion\nSet the behavior for the dispersion for negative binomial distributions: - gene: dispersion parameter of negative binomial is constant per gene across cells - gene-batch: dispersion can differ between different batches - gene-label: dispersion can differ between different labels - gene-cell: dispersion can differ for every gene in every cell\nstring, default: \"gene\"\n\n\n--gene_likelihood\nModel used to generate the expression data from a count-based likelihood distribution. - nb: Negative binomial distribution - zinb: Zero-inflated negative binomial distribution - poisson: Poisson distribution\nstring, default: \"nb\"\n\n\n\n\n\nVariational auto-encoder model options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--use_layer_normalization\nNeural networks for which to enable layer normalization.\nstring, default: \"both\"\n\n\n--use_batch_normalization\nNeural networks for which to enable batch normalization.\nstring, default: \"none\"\n\n\n--encode_covariates\nWhether to concatenate covariates to expression in encoder\nboolean_false\n\n\n--deeply_inject_covariates\nWhether to concatenate covariates into output of hidden layers in encoder/decoder. This option only applies when n_layers &gt; 1. The covariates are concatenated to the input of subsequent hidden layers.\nboolean_true\n\n\n--use_observed_lib_size\nUse observed library size for RNA as scaling factor in mean of conditional distribution.\nboolean_true\n\n\n\n\n\nEarly stopping arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n\n\n\nLearning parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30\n\n\n\n\n\nData validition\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_obs_min_count\nMinimum number of cells threshold ensuring that every obs_batch category has sufficient observations (cells) for model training.\ninteger, default: 0\n\n\n--n_var_min_count\nMinimum number of genes threshold ensuring that every var_input filter has sufficient observations (genes) for model training.\ninteger, default: 0"
  },
  {
    "objectID": "components/modules/integrate/scvi.html#authors",
    "href": "components/modules/integrate/scvi.html#authors",
    "title": "Scvi",
    "section": "Authors",
    "text": "Authors\n\nMalte D. Luecken    (author)\nDries Schaumont    (maintainer)\nMatthias Beyens    (contributor)"
  },
  {
    "objectID": "components/modules/integrate/scarches.html",
    "href": "components/modules/integrate/scarches.html",
    "title": "Scarches",
    "section": "",
    "text": "ID: scarches\nNamespace: integrate\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/integrate/scarches.html#example-commands",
    "href": "components/modules/integrate/scarches.html#example-commands",
    "title": "Scarches",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/integrate/scarches/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\nreference: # please fill in - example: \"path/to/file\"\ndataset_name: \"test_dataset\"\n\n# Outputs\n# output: \"$id.$key.output.output\"\n# output_compression: \"gzip\"\n# model_output: \"$id.$key.model_output.model_output\"\nobsm_output: \"X_integrated_scanvi\"\n\n# Early stopping arguments\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n\n# Learning parameters\nmax_epochs: # please fill in - example: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/scarches/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/integrate/scarches.html#argument-groups",
    "href": "components/modules/integrate/scarches.html#argument-groups",
    "title": "Scarches",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file to use as a query\nfile, required\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--reference\nPath to the directory with reference model or a web link. For HLCA use https://zenodo.org/record/6337966/files/HLCA_reference_model.zip\nfile, required\n\n\n--dataset_name\nName of query dataset to use as a batch name. If not set, name of the input file is used\nstring, default: \"test_dataset\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--model_output\nOutput directory for model\nfile, default: \"model\"\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_integrated_scanvi\"\n\n\n\n\n\nEarly stopping arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n\n\n\nLearning parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger, required\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30"
  },
  {
    "objectID": "components/modules/integrate/scarches.html#authors",
    "href": "components/modules/integrate/scarches.html#authors",
    "title": "Scarches",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov"
  },
  {
    "objectID": "components/modules/report/mermaid.html",
    "href": "components/modules/report/mermaid.html",
    "title": "Mermaid",
    "section": "",
    "text": "ID: mermaid\nNamespace: report\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/report/mermaid.html#example-commands",
    "href": "components/modules/report/mermaid.html#example-commands",
    "title": "Mermaid",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/report/mermaid/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\n# output: \"$id.$key.output.output\"\n# output_format: \"foo\"\nwidth: 800\nheight: 600\nbackground_color: \"white\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/report/mermaid/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/report/mermaid.html#argument-group",
    "href": "components/modules/report/mermaid.html#argument-group",
    "title": "Mermaid",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput directory\nfile, required\n\n\n--output\nGenerated network as output.\nfile, required\n\n\n--output_format\nOutput format for the generated image. By default will be inferred from the extension of the file specified with –output.\nstring\n\n\n--width\nWidth of the page\ninteger, default: 800\n\n\n--height\nHeight of the page\ninteger, default: 600\n\n\n--background_color\nBackground color for pngs/svgs (not pdfs)\nstring, default: \"white\", example: \"#F0F0F0\""
  },
  {
    "objectID": "components/modules/report/mermaid.html#authors",
    "href": "components/modules/report/mermaid.html#authors",
    "title": "Mermaid",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)"
  },
  {
    "objectID": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html",
    "href": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html",
    "title": "From bd to 10x molecular barcode tags",
    "section": "",
    "text": "ID: from_bd_to_10x_molecular_barcode_tags\nNamespace: convert\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#example-commands",
    "href": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#example-commands",
    "title": "From bd to 10x molecular barcode tags",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/convert/from_bd_to_10x_molecular_barcode_tags/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.bam\"\n# output: \"$id.$key.output.sam\"\nbam: false\n# threads: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_bd_to_10x_molecular_barcode_tags/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#argument-group",
    "href": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#argument-group",
    "title": "From bd to 10x molecular barcode tags",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput SAM or BAM file.\nfile, required, example: \"input.bam\"\n\n\n--output\nOutput alignment file.\nfile, example: \"output.sam\"\n\n\n--bam\nOutput a BAM file.\nboolean_true\n\n\n--threads\nNumber of threads\ninteger"
  },
  {
    "objectID": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#authors",
    "href": "components/modules/convert/from_bd_to_10x_molecular_barcode_tags.html#authors",
    "title": "From bd to 10x molecular barcode tags",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/convert/from_10xh5_to_h5mu.html",
    "href": "components/modules/convert/from_10xh5_to_h5mu.html",
    "title": "From 10xh5 to h5mu",
    "section": "",
    "text": "ID: from_10xh5_to_h5mu\nNamespace: convert\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/convert/from_10xh5_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_10xh5_to_h5mu.html#example-commands",
    "title": "From 10xh5 to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/convert/from_10xh5_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"raw_feature_bc_matrix.h5\"\n# input_metrics_summary: \"metrics_cellranger.h5\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nuns_metrics: \"metrics_cellranger\"\n\n# Arguments\n# min_genes: 100\n# min_counts: 1000\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_10xh5_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_10xh5_to_h5mu.html#argument-groups",
    "href": "components/modules/convert/from_10xh5_to_h5mu.html#argument-groups",
    "title": "From 10xh5 to h5mu",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nA 10x h5 file as generated by Cell Ranger.\nfile, required, example: \"raw_feature_bc_matrix.h5\"\n\n\n--input_metrics_summary\nA metrics summary csv file as generated by Cell Ranger.\nfile, example: \"metrics_cellranger.h5\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--uns_metrics\nName of the .uns slot under which to QC metrics (if any).\nstring, default: \"metrics_cellranger\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_genes\nMinimum number of counts required for a cell to pass filtering.\ninteger, example: 100\n\n\n--min_counts\nMinimum number of genes expressed required for a cell to pass filtering.\ninteger, example: 1000"
  },
  {
    "objectID": "components/modules/convert/from_10xh5_to_h5mu.html#authors",
    "href": "components/modules/convert/from_10xh5_to_h5mu.html#authors",
    "title": "From 10xh5 to h5mu",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/convert/from_cellranger_multi_to_h5mu.html",
    "href": "components/modules/convert/from_cellranger_multi_to_h5mu.html",
    "title": "From cellranger multi to h5mu",
    "section": "",
    "text": "ID: from_cellranger_multi_to_h5mu\nNamespace: convert\n\n\n\nSource\nBy default, will map the following library type names to modality names: - Gene Expression: rna - Peaks: atac - Antibody Capture: prot - VDJ: vdj - VDJ-T: vdj_t - VDJ-B: vdj_b - CRISPR Guide Capture: crispr - Multiplexing Capture: hashing\nOther library types have their whitepace removed and dashes replaced by underscores to generate the modality name.\nCurrently does not allow parsing the output from cell barcode demultiplexing."
  },
  {
    "objectID": "components/modules/convert/from_cellranger_multi_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_cellranger_multi_to_h5mu.html#example-commands",
    "title": "From cellranger multi to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/convert/from_cellranger_multi_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input_dir_containing_modalities\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nuns_metrics: \"metrics_cellranger\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_cellranger_multi_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_cellranger_multi_to_h5mu.html#argument-group",
    "href": "components/modules/convert/from_cellranger_multi_to_h5mu.html#argument-group",
    "title": "From cellranger multi to h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput folder. Must contain the output from a cellranger multi run.\nfile, required, example: \"input_dir_containing_modalities\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--uns_metrics\nName of the .uns slot under which to QC metrics (if any).\nstring, default: \"metrics_cellranger\""
  },
  {
    "objectID": "components/modules/convert/from_cellranger_multi_to_h5mu.html#authors",
    "href": "components/modules/convert/from_cellranger_multi_to_h5mu.html#authors",
    "title": "From cellranger multi to h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_h5mu.html",
    "href": "components/modules/convert/from_h5ad_to_h5mu.html",
    "title": "From h5ad to h5mu",
    "section": "",
    "text": "ID: from_h5ad_to_h5mu\nNamespace: convert\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_h5ad_to_h5mu.html#example-commands",
    "title": "From h5ad to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/convert/from_h5ad_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: [\"input.h5ad\"]\nmodality: [\"rna\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_h5ad_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_h5mu.html#argument-group",
    "href": "components/modules/convert/from_h5ad_to_h5mu.html#argument-group",
    "title": "From h5ad to h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5ad files\nList of file, required, default: \"input.h5ad\", multiple_sep: \":\"\n\n\n--modality\n\nList of string, default: \"rna\", multiple_sep: \":\"\n\n\n--output\nOutput MuData file.\nfile, default: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/convert/from_h5ad_to_h5mu.html#authors",
    "href": "components/modules/convert/from_h5ad_to_h5mu.html#authors",
    "title": "From h5ad to h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)"
  },
  {
    "objectID": "components/modules/mapping/cellranger_count_split.html",
    "href": "components/modules/mapping/cellranger_count_split.html",
    "title": "Cellranger count split",
    "section": "",
    "text": "ID: cellranger_count_split\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/cellranger_count_split.html#example-commands",
    "href": "components/modules/mapping/cellranger_count_split.html#example-commands",
    "title": "Cellranger count split",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/mapping/cellranger_count_split/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input_dir\"\n# filtered_h5: \"$id.$key.filtered_h5.h5\"\n# metrics_summary: \"$id.$key.metrics_summary.csv\"\n# molecule_info: \"$id.$key.molecule_info.h5\"\n# bam: \"$id.$key.bam.bam\"\n# bai: \"$id.$key.bai.bai\"\n# raw_h5: \"$id.$key.raw_h5.h5\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/cellranger_count_split/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/cellranger_count_split.html#argument-group",
    "href": "components/modules/mapping/cellranger_count_split.html#argument-group",
    "title": "Cellranger count split",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nOutput directory from a Cell Ranger count run.\nfile, required, example: \"input_dir\"\n\n\n--filtered_h5\n\nfile, example: \"filtered_feature_bc_matrix.h5\"\n\n\n--metrics_summary\n\nfile, example: \"metrics_summary.csv\"\n\n\n--molecule_info\n\nfile, example: \"molecule_info.h5\"\n\n\n--bam\n\nfile, example: \"possorted_genome_bam.bam\"\n\n\n--bai\n\nfile, example: \"possorted_genome_bam.bam.bai\"\n\n\n--raw_h5\n\nfile, example: \"raw_feature_bc_matrix.h5\""
  },
  {
    "objectID": "components/modules/mapping/cellranger_count_split.html#authors",
    "href": "components/modules/mapping/cellranger_count_split.html#authors",
    "title": "Cellranger count split",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nSamuel D’Souza   (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/mapping/multi_star.html",
    "href": "components/modules/mapping/multi_star.html",
    "title": "Multi star",
    "section": "",
    "text": "ID: multi_star\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/multi_star.html#example-commands",
    "href": "components/modules/mapping/multi_star.html#example-commands",
    "title": "Multi star",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/mapping/multi_star/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input/Output\ninput_id: # please fill in - example: [\"mysample\", \"mysample\"]\ninput_r1: # please fill in - example: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L002_R1_001.fastq.gz\"]\n# input_r2: [\"mysample_S1_L001_R2_001.fastq.gz\", \"mysample_S1_L002_R2_001.fastq.gz\"]\nreference_index: # please fill in - example: \"/path/to/reference\"\nreference_gtf: # please fill in - example: \"genes.gtf\"\n# output: \"$id.$key.output.output\"\n\n# Processing arguments\nrun_htseq_count: true\nrun_multiqc: true\nmin_success_rate: 0.5\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/multi_star/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/multi_star.html#argument-groups",
    "href": "components/modules/mapping/multi_star.html#argument-groups",
    "title": "Multi star",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput/Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_id\nThe ID of the sample being processed. This vector should have the same length as the --input_r1 argument.\nList of string, required, example: \"mysample\", \"mysample\", multiple_sep: \";\"\n\n\n--input_r1\nPaths to the sequences to be mapped. If using Illumina paired-end reads, only the R1 files should be passed.\nList of file, required, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L002_R1_001.fastq.gz\", multiple_sep: \";\"\n\n\n--input_r2\nPaths to the sequences to be mapped. If using Illumina paired-end reads, only the R2 files should be passed.\nList of file, example: \"mysample_S1_L001_R2_001.fastq.gz\", \"mysample_S1_L002_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference_index\nPath to the reference built by star_build_reference. Corresponds to the –genomeDir argument in the STAR command.\nfile, required, example: \"/path/to/reference\"\n\n\n--reference_gtf\nPath to the gtf reference file.\nfile, required, example: \"genes.gtf\"\n\n\n--output\nPath to output directory. Corresponds to the –outFileNamePrefix argument in the STAR command.\nfile, required, example: \"/path/to/foo\"\n\n\n\n\n\nProcessing arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--run_htseq_count\nWhether or not to also run htseq-count after STAR.\nboolean, default: TRUE\n\n\n--run_multiqc\nWhether or not to also run MultiQC at the end.\nboolean, default: TRUE\n\n\n--min_success_rate\nFail when the success rate is below this threshold.\ndouble, default: 0.5\n\n\n\n\n\nRun Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--runRNGseed\nrandom number generator seed.\ninteger, example: 777\n\n\n\n\n\nGenome Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genomeFastaFiles\npath(s) to the fasta files with the genome sequences, separated by spaces. These files should be plain text FASTA files, they cannot be zipped. Required for the genome generation (–runMode genomeGenerate). Can also be used in the mapping (–runMode alignReads) to add extra (new) sequences to the genome (e.g. spike-ins).\nList of file, multiple_sep: \";\"\n\n\n\n\n\nSplice Junctions Database\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sjdbFileChrStartEnd\npath to the files with genomic coordinates (chr  start  end  strand) for the splice junction introns. Multiple files can be supplied and will be concatenated.\nList of string, multiple_sep: \";\"\n\n\n--sjdbGTFfile\npath to the GTF file with annotations\nfile\n\n\n--sjdbGTFchrPrefix\nprefix for chromosome names in a GTF file (e.g. ‘chr’ for using ENSMEBL annotations with UCSC genomes)\nstring\n\n\n--sjdbGTFfeatureExon\nfeature type in GTF file to be used as exons for building transcripts\nstring, example: \"exon\"\n\n\n--sjdbGTFtagExonParentTranscript\nGTF attribute name for parent transcript ID (default “transcript_id” works for GTF files)\nstring, example: \"transcript_id\"\n\n\n--sjdbGTFtagExonParentGene\nGTF attribute name for parent gene ID (default “gene_id” works for GTF files)\nstring, example: \"gene_id\"\n\n\n--sjdbGTFtagExonParentGeneName\nGTF attribute name for parent gene name\nList of string, example: \"gene_name\", multiple_sep: \";\"\n\n\n--sjdbGTFtagExonParentGeneType\nGTF attribute name for parent gene type\nList of string, example: \"gene_type\", \"gene_biotype\", multiple_sep: \";\"\n\n\n--sjdbOverhang\nlength of the donor/acceptor sequence on each side of the junctions, ideally = (mate_length - 1)\ninteger, example: 100\n\n\n--sjdbScore\nextra alignment score for alignments that cross database junctions\ninteger, example: 2\n\n\n--sjdbInsertSave\nwhich files to save when sjdb junctions are inserted on the fly at the mapping step - Basic … only small junction / transcript files - All … all files including big Genome, SA and SAindex - this will create a complete genome directory\nstring, example: \"Basic\"\n\n\n\n\n\nVariation parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--varVCFfile\npath to the VCF file that contains variation data. The 10th column should contain the genotype information, e.g. 0/1\nstring\n\n\n\n\n\nRead Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--readFilesType\nformat of input read files - Fastx … FASTA or FASTQ - SAM SE … SAM or BAM single-end reads; for BAM use –readFilesCommand samtools view - SAM PE … SAM or BAM paired-end reads; for BAM use –readFilesCommand samtools view\nstring, example: \"Fastx\"\n\n\n--readFilesSAMattrKeep\nfor –readFilesType SAM SE/PE, which SAM tags to keep in the output BAM, e.g.: –readFilesSAMtagsKeep RG PL - All … keep all tags - None … do not keep any tags\nList of string, example: \"All\", multiple_sep: \";\"\n\n\n--readFilesManifest\npath to the “manifest” file with the names of read files. The manifest file should contain 3 tab-separated columns: paired-end reads: read1_file_name \\(tab\\) read2_file_name \\(tab\\) read_group_line. single-end reads: read1_file_name \\(tab\\) - \\(tab\\) read_group_line. Spaces, but not tabs are allowed in file names. If read_group_line does not start with ID:, it can only contain one ID field, and ID: will be added to it. If read_group_line starts with ID:, it can contain several fields separated by \\(tab\\), and all fields will be be copied verbatim into SAM @RG header line.\nfile\n\n\n--readFilesPrefix\nprefix for the read files names, i.e. it will be added in front of the strings in –readFilesIn\nstring\n\n\n--readFilesCommand\ncommand line to execute for each of the input file. This command should generate FASTA or FASTQ text and send it to stdout For example: zcat - to uncompress .gz files, bzcat - to uncompress .bz2 files, etc.\nList of string, multiple_sep: \";\"\n\n\n--readMapNumber\nnumber of reads to map from the beginning of the file -1: map all reads\ninteger, example: -1\n\n\n--readMatesLengthsIn\nEqual/NotEqual - lengths of names,sequences,qualities for both mates are the same / not the same. NotEqual is safe in all situations.\nstring, example: \"NotEqual\"\n\n\n--readNameSeparator\ncharacter(s) separating the part of the read names that will be trimmed in output (read name after space is always trimmed)\nList of string, example: \"/\", multiple_sep: \";\"\n\n\n--readQualityScoreBase\nnumber to be subtracted from the ASCII code to get Phred quality score\ninteger, example: 33\n\n\n\n\n\nRead Clipping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--clipAdapterType\nadapter clipping type - Hamming … adapter clipping based on Hamming distance, with the number of mismatches controlled by –clip5pAdapterMMp - CellRanger4 … 5p and 3p adapter clipping similar to CellRanger4. Utilizes Opal package by Martin Sosic: https://github.com/Martinsos/opal - None … no adapter clipping, all other clip* parameters are disregarded\nstring, example: \"Hamming\"\n\n\n--clip3pNbases\nnumber(s) of bases to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip3pAdapterSeq\nadapter sequences to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates. - polyA … polyA sequence with the length equal to read length\nList of string, multiple_sep: \";\"\n\n\n--clip3pAdapterMMp\nmax proportion of mismatches for 3p adapter clipping for each mate. If one value is given, it will be assumed the same for both mates.\nList of double, example: 0.1, multiple_sep: \";\"\n\n\n--clip3pAfterAdapterNbases\nnumber of bases to clip from 3p of each mate after the adapter clipping. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip5pNbases\nnumber(s) of bases to clip from 5p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n\n\n\nLimits\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--limitGenomeGenerateRAM\nmaximum available RAM (bytes) for genome generation\nlong, example: NA\n\n\n--limitIObufferSize\nmax available buffers size (bytes) for input/output, per thread\nList of long, example: 30000000, 50000000, multiple_sep: \";\"\n\n\n--limitOutSAMoneReadBytes\nmax size of the SAM record (bytes) for one read. Recommended value: &gt;(2(LengthMate1+LengthMate2+100)outFilterMultimapNmax\nlong, example: 100000\n\n\n--limitOutSJoneRead\nmax number of junctions for one read (including all multi-mappers)\ninteger, example: 1000\n\n\n--limitOutSJcollapsed\nmax number of collapsed junctions\ninteger, example: 1000000\n\n\n--limitBAMsortRAM\nmaximum available RAM (bytes) for sorting BAM. If =0, it will be set to the genome index size. 0 value can only be used with –genomeLoad NoSharedMemory option.\nlong, example: 0\n\n\n--limitSjdbInsertNsj\nmaximum number of junctions to be inserted to the genome on the fly at the mapping stage, including those from annotations and those detected in the 1st step of the 2-pass run\ninteger, example: 1000000\n\n\n--limitNreadsSoft\nsoft limit on the number of reads\ninteger, example: -1\n\n\n\n\n\nOutput: general\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outTmpKeep\nwhether to keep the temporary files after STAR runs is finished - None … remove all temporary files - All … keep all files\nstring\n\n\n--outStd\nwhich output will be directed to stdout (standard out) - Log … log messages - SAM … alignments in SAM format (which normally are output to Aligned.out.sam file), normal standard output will go into Log.std.out - BAM_Unsorted … alignments in BAM format, unsorted. Requires –outSAMtype BAM Unsorted - BAM_SortedByCoordinate … alignments in BAM format, sorted by coordinate. Requires –outSAMtype BAM SortedByCoordinate - BAM_Quant … alignments to transcriptome in BAM format, unsorted. Requires –quantMode TranscriptomeSAM\nstring, example: \"Log\"\n\n\n--outReadsUnmapped\noutput of unmapped and partially mapped (i.e. mapped only one mate of a paired end read) reads in separate file(s). - None … no output - Fastx … output in separate fasta/fastq files, Unmapped.out.mate1/2\nstring\n\n\n--outQSconversionAdd\nadd this number to the quality score (e.g. to convert from Illumina to Sanger, use -31)\ninteger, example: 0\n\n\n--outMultimapperOrder\norder of multimapping alignments in the output files - Old_2.4 … quasi-random order used before 2.5.0 - Random … random order of alignments for each multi-mapper. Read mates (pairs) are always adjacent, all alignment for each read stay together. This option will become default in the future releases.\nstring, example: \"Old_2.4\"\n\n\n\n\n\nOutput: SAM and BAM\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSAMmode\nmode of SAM output - None … no SAM output - Full … full SAM output - NoQS … full SAM but without quality scores\nstring, example: \"Full\"\n\n\n--outSAMstrandField\nCufflinks-like strand field flag - None … not used - intronMotif … strand derived from the intron motif. This option changes the output alignments: reads with inconsistent and/or non-canonical introns are filtered out.\nstring\n\n\n--outSAMattributes\na string of desired SAM attributes, in the order desired for the output SAM. Tags can be listed in any combination/order. Presets: - None … no attributes - Standard … NH HI AS nM - All … NH HI AS nM NM MD jM jI MC ch Alignment: - NH … number of loci the reads maps to: =1 for unique mappers, &gt;1 for multimappers. Standard SAM tag. - HI … multiple alignment index, starts with –outSAMattrIHstart (=1 by default). Standard SAM tag. - AS … local alignment score, +1/-1 for matches/mismateches, score* penalties for indels and gaps. For PE reads, total score for two mates. Stadnard SAM tag. - nM … number of mismatches. For PE reads, sum over two mates. - NM … edit distance to the reference (number of mismatched + inserted + deleted bases) for each mate. Standard SAM tag. - MD … string encoding mismatched and deleted reference bases (see standard SAM specifications). Standard SAM tag. - jM … intron motifs for all junctions (i.e. N in CIGAR): 0: non-canonical; 1: GT/AG, 2: CT/AC, 3: GC/AG, 4: CT/GC, 5: AT/AC, 6: GT/AT. If splice junctions database is used, and a junction is annotated, 20 is added to its motif value. - jI … start and end of introns for all junctions (1-based). - XS … alignment strand according to –outSAMstrandField. - MC … mate’s CIGAR string. Standard SAM tag. - ch … marks all segment of all chimeric alingments for –chimOutType WithinBAM output. - cN … number of bases clipped from the read ends: 5’ and 3’ Variation: - vA … variant allele - vG … genomic coordinate of the variant overlapped by the read. - vW … 1 - alignment passes WASP filtering; 2,3,4,5,6,7 - alignment does not pass WASP filtering. Requires –waspOutputMode SAMtag. STARsolo: - CR CY UR UY … sequences and quality scores of cell barcodes and UMIs for the solo* demultiplexing. - GX GN … gene ID and gene name for unique-gene reads. - gx gn … gene IDs and gene names for unique- and multi-gene reads. - CB UB … error-corrected cell barcodes and UMIs for solo* demultiplexing. Requires –outSAMtype BAM SortedByCoordinate. - sM … assessment of CB and UMI. - sS … sequence of the entire barcode (CB,UMI,adapter). - sQ … quality of the entire barcode. ***Unsupported/undocumented: - ha … haplotype (1/2) when mapping to the diploid genome. Requires genome generated with –genomeTransformType Diploid . - rB … alignment block read/genomic coordinates. - vR … read coordinate of the variant.\nList of string, example: \"Standard\", multiple_sep: \";\"\n\n\n--outSAMattrIHstart\nstart value for the IH attribute. 0 may be required by some downstream software, such as Cufflinks or StringTie.\ninteger, example: 1\n\n\n--outSAMunmapped\noutput of unmapped reads in the SAM format 1st word: - None … no output - Within … output unmapped reads within the main SAM file (i.e. Aligned.out.sam) 2nd word: - KeepPairs … record unmapped mate for each alignment, and, in case of unsorted output, keep it adjacent to its mapped mate. Only affects multi-mapping reads.\nList of string, multiple_sep: \";\"\n\n\n--outSAMorder\ntype of sorting for the SAM output Paired: one mate after the other for all paired alignments PairedKeepInputOrder: one mate after the other for all paired alignments, the order is kept the same as in the input FASTQ files\nstring, example: \"Paired\"\n\n\n--outSAMprimaryFlag\nwhich alignments are considered primary - all others will be marked with 0x100 bit in the FLAG - OneBestScore … only one alignment with the best score is primary - AllBestScore … all alignments with the best score are primary\nstring, example: \"OneBestScore\"\n\n\n--outSAMreadID\nread ID record type - Standard … first word (until space) from the FASTx read ID line, removing /1,/2 from the end - Number … read number (index) in the FASTx file\nstring, example: \"Standard\"\n\n\n--outSAMmapqUnique\n0 to 255: the MAPQ value for unique mappers\ninteger, example: 255\n\n\n--outSAMflagOR\n0 to 65535: sam FLAG will be bitwise OR’d with this value, i.e. FLAG=FLAG | outSAMflagOR. This is applied after all flags have been set by STAR, and after outSAMflagAND. Can be used to set specific bits that are not set otherwise.\ninteger, example: 0\n\n\n--outSAMflagAND\n0 to 65535: sam FLAG will be bitwise AND’d with this value, i.e. FLAG=FLAG & outSAMflagOR. This is applied after all flags have been set by STAR, but before outSAMflagOR. Can be used to unset specific bits that are not set otherwise.\ninteger, example: 65535\n\n\n--outSAMattrRGline\nSAM/BAM read group line. The first word contains the read group identifier and must start with “ID:”, e.g. –outSAMattrRGline ID:xxx CN:yy “DS:z z z”. xxx will be added as RG tag to each output alignment. Any spaces in the tag values have to be double quoted. Comma separated RG lines correspons to different (comma separated) input files in –readFilesIn. Commas have to be surrounded by spaces, e.g. –outSAMattrRGline ID:xxx , ID:zzz “DS:z z” , ID:yyy DS:yyyy\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderHD\n@HD (header) line of the SAM header\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderPG\nextra @PG (software) line of the SAM header (in addition to STAR)\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderCommentFile\npath to the file with @CO (comment) lines of the SAM header\nstring\n\n\n--outSAMfilter\nfilter the output into main SAM/BAM files - KeepOnlyAddedReferences … only keep the reads for which all alignments are to the extra reference sequences added with –genomeFastaFiles at the mapping stage. - KeepAllAddedReferences … keep all alignments to the extra reference sequences added with –genomeFastaFiles at the mapping stage.\nList of string, multiple_sep: \";\"\n\n\n--outSAMmultNmax\nmax number of multiple alignments for a read that will be output to the SAM/BAM files. Note that if this value is not equal to -1, the top scoring alignment will be output first - -1 … all alignments (up to –outFilterMultimapNmax) will be output\ninteger, example: -1\n\n\n--outSAMtlen\ncalculation method for the TLEN field in the SAM/BAM files - 1 … leftmost base of the (+)strand mate to rightmost base of the (-)mate. (+)sign for the (+)strand mate - 2 … leftmost base of any mate to rightmost base of any mate. (+)sign for the mate with the leftmost base. This is different from 1 for overlapping mates with protruding ends\ninteger, example: 1\n\n\n--outBAMcompression\n-1 to 10 BAM compression level, -1=default compression (6?), 0=no compression, 10=maximum compression\ninteger, example: 1\n\n\n--outBAMsortingThreadN\n&gt;=0: number of threads for BAM sorting. 0 will default to min(6,–runThreadN).\ninteger, example: 0\n\n\n--outBAMsortingBinsN\n&gt;0: number of genome bins for coordinate-sorting\ninteger, example: 50\n\n\n\n\n\nBAM processing\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--bamRemoveDuplicatesType\nmark duplicates in the BAM file, for now only works with (i) sorted BAM fed with inputBAMfile, and (ii) for paired-end alignments only - - … no duplicate removal/marking - UniqueIdentical … mark all multimappers, and duplicate unique mappers. The coordinates, FLAG, CIGAR must be identical - UniqueIdenticalNotMulti … mark duplicate unique mappers but not multimappers.\nstring\n\n\n--bamRemoveDuplicatesMate2basesN\nnumber of bases from the 5’ of mate 2 to use in collapsing (e.g. for RAMPAGE)\ninteger, example: 0\n\n\n\n\n\nOutput Wiggle\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outWigType\ntype of signal output, e.g. “bedGraph” OR “bedGraph read1_5p”. Requires sorted BAM: –outSAMtype BAM SortedByCoordinate . 1st word: - None … no signal output - bedGraph … bedGraph format - wiggle … wiggle format 2nd word: - read1_5p … signal from only 5’ of the 1st read, useful for CAGE/RAMPAGE etc - read2 … signal from only 2nd read\nList of string, multiple_sep: \";\"\n\n\n--outWigStrand\nstrandedness of wiggle/bedGraph output - Stranded … separate strands, str1 and str2 - Unstranded … collapsed strands\nstring, example: \"Stranded\"\n\n\n--outWigReferencesPrefix\nprefix matching reference names to include in the output wiggle file, e.g. “chr”, default “-” - include all references\nstring\n\n\n--outWigNorm\ntype of normalization for the signal - RPM … reads per million of mapped reads - None … no normalization, “raw” counts\nstring, example: \"RPM\"\n\n\n\n\n\nOutput Filtering\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outFilterType\ntype of filtering - Normal … standard filtering using only current alignment - BySJout … keep only those reads that contain junctions that passed filtering into SJ.out.tab\nstring, example: \"Normal\"\n\n\n--outFilterMultimapScoreRange\nthe score range below the maximum score for multimapping alignments\ninteger, example: 1\n\n\n--outFilterMultimapNmax\nmaximum number of loci the read is allowed to map to. Alignments (all of them) will be output only if the read maps to no more loci than this value. Otherwise no alignments will be output, and the read will be counted as “mapped to too many loci” in the Log.final.out .\ninteger, example: 10\n\n\n--outFilterMismatchNmax\nalignment will be output only if it has no more mismatches than this value.\ninteger, example: 10\n\n\n--outFilterMismatchNoverLmax\nalignment will be output only if its ratio of mismatches to mapped length is less than or equal to this value.\ndouble, example: 0.3\n\n\n--outFilterMismatchNoverReadLmax\nalignment will be output only if its ratio of mismatches to read length is less than or equal to this value.\ndouble, example: 1\n\n\n--outFilterScoreMin\nalignment will be output only if its score is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterScoreMinOverLread\nsame as outFilterScoreMin, but normalized to read length (sum of mates’ lengths for paired-end reads)\ndouble, example: 0.66\n\n\n--outFilterMatchNmin\nalignment will be output only if the number of matched bases is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterMatchNminOverLread\nsam as outFilterMatchNmin, but normalized to the read length (sum of mates’ lengths for paired-end reads).\ndouble, example: 0.66\n\n\n--outFilterIntronMotifs\nfilter alignment using their motifs - None … no filtering - RemoveNoncanonical … filter out alignments that contain non-canonical junctions - RemoveNoncanonicalUnannotated … filter out alignments that contain non-canonical unannotated junctions when using annotated splice junctions database. The annotated non-canonical junctions will be kept.\nstring\n\n\n--outFilterIntronStrands\nfilter alignments - RemoveInconsistentStrands … remove alignments that have junctions with inconsistent strands - None … no filtering\nstring, example: \"RemoveInconsistentStrands\"\n\n\n\n\n\nOutput splice junctions (SJ.out.tab)\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJtype\ntype of splice junction output - Standard … standard SJ.out.tab output - None … no splice junction output\nstring, example: \"Standard\"\n\n\n\n\n\nOutput Filtering: Splice Junctions\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJfilterReads\nwhich reads to consider for collapsed splice junctions output - All … all reads, unique- and multi-mappers - Unique … uniquely mapping reads only\nstring, example: \"All\"\n\n\n--outSJfilterOverhangMin\nminimum overhang length for splice junctions on both sides for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif does not apply to annotated junctions\nList of integer, example: 30, 12, 12, 12, multiple_sep: \";\"\n\n\n--outSJfilterCountUniqueMin\nminimum uniquely mapping read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterCountTotalMin\nminimum total (multi-mapping+unique) read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterDistToOtherSJmin\nminimum allowed distance to other junctions’ donor/acceptor does not apply to annotated junctions\nList of integer, example: 10, 0, 5, 10, multiple_sep: \";\"\n\n\n--outSJfilterIntronMaxVsReadN\nmaximum gap allowed for junctions supported by 1,2,3,,,N reads i.e. by default junctions supported by 1 read can have gaps &lt;=50000b, by 2 reads: &lt;=100000b, by 3 reads: &lt;=200000. by &gt;=4 reads any gap &lt;=alignIntronMax does not apply to annotated junctions\nList of integer, example: 50000, 100000, 200000, multiple_sep: \";\"\n\n\n\n\n\nScoring\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--scoreGap\nsplice junction penalty (independent on intron motif)\ninteger, example: 0\n\n\n--scoreGapNoncan\nnon-canonical junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGapGCAG\nGC/AG and CT/GC junction penalty (in addition to scoreGap)\ninteger, example: -4\n\n\n--scoreGapATAC\nAT/AC and GT/AT junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGenomicLengthLog2scale\nextra score logarithmically scaled with genomic length of the alignment: scoreGenomicLengthLog2scale*log2(genomicLength)\ninteger, example: 0\n\n\n--scoreDelOpen\ndeletion open penalty\ninteger, example: -2\n\n\n--scoreDelBase\ndeletion extension penalty per base (in addition to scoreDelOpen)\ninteger, example: -2\n\n\n--scoreInsOpen\ninsertion open penalty\ninteger, example: -2\n\n\n--scoreInsBase\ninsertion extension penalty per base (in addition to scoreInsOpen)\ninteger, example: -2\n\n\n--scoreStitchSJshift\nmaximum score reduction while searching for SJ boundaries in the stitching step\ninteger, example: 1\n\n\n\n\n\nAlignments and Seeding\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--seedSearchStartLmax\ndefines the search start point through the read - the read is split into pieces no longer than this value\ninteger, example: 50\n\n\n--seedSearchStartLmaxOverLread\nseedSearchStartLmax normalized to read length (sum of mates’ lengths for paired-end reads)\ndouble, example: 1\n\n\n--seedSearchLmax\ndefines the maximum length of the seeds, if =0 seed length is not limited\ninteger, example: 0\n\n\n--seedMultimapNmax\nonly pieces that map fewer than this value are utilized in the stitching procedure\ninteger, example: 10000\n\n\n--seedPerReadNmax\nmax number of seeds per read\ninteger, example: 1000\n\n\n--seedPerWindowNmax\nmax number of seeds per window\ninteger, example: 50\n\n\n--seedNoneLociPerWindow\nmax number of one seed loci per window\ninteger, example: 10\n\n\n--seedSplitMin\nmin length of the seed sequences split by Ns or mate gap\ninteger, example: 12\n\n\n--seedMapMin\nmin length of seeds to be mapped\ninteger, example: 5\n\n\n--alignIntronMin\nminimum intron size, genomic gap is considered intron if its length&gt;=alignIntronMin, otherwise it is considered Deletion\ninteger, example: 21\n\n\n--alignIntronMax\nmaximum intron size, if 0, max intron size will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignMatesGapMax\nmaximum gap between two mates, if 0, max intron gap will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignSJoverhangMin\nminimum overhang (i.e. block size) for spliced alignments\ninteger, example: 5\n\n\n--alignSJstitchMismatchNmax\nmaximum number of mismatches for stitching of the splice junctions (-1: no limit). (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif.\nList of integer, example: 0, -1, 0, 0, multiple_sep: \";\"\n\n\n--alignSJDBoverhangMin\nminimum overhang (i.e. block size) for annotated (sjdb) spliced alignments\ninteger, example: 3\n\n\n--alignSplicedMateMapLmin\nminimum mapped length for a read mate that is spliced\ninteger, example: 0\n\n\n--alignSplicedMateMapLminOverLmate\nalignSplicedMateMapLmin normalized to mate length\ndouble, example: 0.66\n\n\n--alignWindowsPerReadNmax\nmax number of windows per read\ninteger, example: 10000\n\n\n--alignTranscriptsPerWindowNmax\nmax number of transcripts per window\ninteger, example: 100\n\n\n--alignTranscriptsPerReadNmax\nmax number of different alignments per read to consider\ninteger, example: 10000\n\n\n--alignEndsType\ntype of read ends alignment - Local … standard local alignment with soft-clipping allowed - EndToEnd … force end-to-end read alignment, do not soft-clip - Extend5pOfRead1 … fully extend only the 5p of the read1, all other ends: local alignment - Extend5pOfReads12 … fully extend only the 5p of the both read1 and read2, all other ends: local alignment\nstring, example: \"Local\"\n\n\n--alignEndsProtrude\nallow protrusion of alignment ends, i.e. start (end) of the +strand mate downstream of the start (end) of the -strand mate 1st word: int: maximum number of protrusion bases allowed 2nd word: string: - ConcordantPair … report alignments with non-zero protrusion as concordant pairs - DiscordantPair … report alignments with non-zero protrusion as discordant pairs\nstring, example: \"0    ConcordantPair\"\n\n\n--alignSoftClipAtReferenceEnds\nallow the soft-clipping of the alignments past the end of the chromosomes - Yes … allow - No … prohibit, useful for compatibility with Cufflinks\nstring, example: \"Yes\"\n\n\n--alignInsertionFlush\nhow to flush ambiguous insertion positions - None … insertions are not flushed - Right … insertions are flushed to the right\nstring\n\n\n\n\n\nPaired-End reads\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--peOverlapNbasesMin\nminimum number of overlapping bases to trigger mates merging and realignment. Specify &gt;0 value to switch on the “merginf of overlapping mates” algorithm.\ninteger, example: 0\n\n\n--peOverlapMMp\nmaximum proportion of mismatched bases in the overlap area\ndouble, example: 0.01\n\n\n\n\n\nWindows, Anchors, Binning\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--winAnchorMultimapNmax\nmax number of loci anchors are allowed to map to\ninteger, example: 50\n\n\n--winBinNbits\n=log2(winBin), where winBin is the size of the bin for the windows/clustering, each window will occupy an integer number of bins.\ninteger, example: 16\n\n\n--winAnchorDistNbins\nmax number of bins between two anchors that allows aggregation of anchors into one window\ninteger, example: 9\n\n\n--winFlankNbins\nlog2(winFlank), where win Flank is the size of the left and right flanking regions for each window\ninteger, example: 4\n\n\n--winReadCoverageRelativeMin\nminimum relative coverage of the read sequence by the seeds in a window, for STARlong algorithm only.\ndouble, example: 0.5\n\n\n--winReadCoverageBasesMin\nminimum number of bases covered by the seeds in a window , for STARlong algorithm only.\ninteger, example: 0\n\n\n\n\n\nChimeric Alignments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--chimOutType\ntype of chimeric output - Junctions … Chimeric.out.junction - SeparateSAMold … output old SAM into separate Chimeric.out.sam file - WithinBAM … output into main aligned BAM files (Aligned.*.bam) - WithinBAM HardClip … (default) hard-clipping in the CIGAR for supplemental chimeric alignments (default if no 2nd word is present) - WithinBAM SoftClip … soft-clipping in the CIGAR for supplemental chimeric alignments\nList of string, example: \"Junctions\", multiple_sep: \";\"\n\n\n--chimSegmentMin\nminimum length of chimeric segment length, if ==0, no chimeric output\ninteger, example: 0\n\n\n--chimScoreMin\nminimum total (summed) score of the chimeric segments\ninteger, example: 0\n\n\n--chimScoreDropMax\nmax drop (difference) of chimeric score (the sum of scores of all chimeric segments) from the read length\ninteger, example: 20\n\n\n--chimScoreSeparation\nminimum difference (separation) between the best chimeric score and the next one\ninteger, example: 10\n\n\n--chimScoreJunctionNonGTAG\npenalty for a non-GT/AG chimeric junction\ninteger, example: -1\n\n\n--chimJunctionOverhangMin\nminimum overhang for a chimeric junction\ninteger, example: 20\n\n\n--chimSegmentReadGapMax\nmaximum gap in the read sequence between chimeric segments\ninteger, example: 0\n\n\n--chimFilter\ndifferent filters for chimeric alignments - None … no filtering - banGenomicN … Ns are not allowed in the genome sequence around the chimeric junction\nList of string, example: \"banGenomicN\", multiple_sep: \";\"\n\n\n--chimMainSegmentMultNmax\nmaximum number of multi-alignments for the main chimeric segment. =1 will prohibit multimapping main segments.\ninteger, example: 10\n\n\n--chimMultimapNmax\nmaximum number of chimeric multi-alignments - 0 … use the old scheme for chimeric detection which only considered unique alignments\ninteger, example: 0\n\n\n--chimMultimapScoreRange\nthe score range for multi-mapping chimeras below the best chimeric score. Only works with –chimMultimapNmax &gt; 1\ninteger, example: 1\n\n\n--chimNonchimScoreDropMin\nto trigger chimeric detection, the drop in the best non-chimeric alignment score with respect to the read length has to be greater than this value\ninteger, example: 20\n\n\n--chimOutJunctionFormat\nformatting type for the Chimeric.out.junction file - 0 … no comment lines/headers - 1 … comment lines at the end of the file: command line and Nreads: total, unique/multi-mapping\ninteger, example: 0\n\n\n\n\n\nQuantification of Annotations\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--quantMode\ntypes of quantification requested - - … none - TranscriptomeSAM … output SAM/BAM alignments to transcriptome into a separate file - GeneCounts … count reads per gene\nList of string, multiple_sep: \";\"\n\n\n--quantTranscriptomeBAMcompression\n-2 to 10 transcriptome BAM compression level - -2 … no BAM output - -1 … default compression (6?) - 0 … no compression - 10 … maximum compression\ninteger, example: 1\n\n\n--quantTranscriptomeBan\nprohibit various alignment type - IndelSoftclipSingleend … prohibit indels, soft clipping and single-end alignments - compatible with RSEM - Singleend … prohibit single-end alignments\nstring, example: \"IndelSoftclipSingleend\"\n\n\n\n\n\n2-pass Mapping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--twopassMode\n2-pass mapping mode. - None … 1-pass mapping - Basic … basic 2-pass mapping, with all 1st pass junctions inserted into the genome indices on the fly\nstring\n\n\n--twopass1readsN\nnumber of reads to process for the 1st step. Use very large number (or default -1) to map all reads in the first step.\ninteger, example: -1\n\n\n\n\n\nWASP parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--waspOutputMode\nWASP allele-specific output type. This is re-implementation of the original WASP mappability filtering by Bryce van de Geijn, Graham McVicker, Yoav Gilad & Jonathan K Pritchard. Please cite the original WASP paper: Nature Methods 12, 1061-1063 (2015), https://www.nature.com/articles/nmeth.3582 . - SAMtag … add WASP tags to the alignments that pass WASP filtering\nstring\n\n\n\n\n\nSTARsolo (single cell RNA-seq) parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--soloType\ntype of single-cell RNA-seq - CB_UMI_Simple … (a.k.a. Droplet) one UMI and one Cell Barcode of fixed length in read2, e.g. Drop-seq and 10X Chromium. - CB_UMI_Complex … multiple Cell Barcodes of varying length, one UMI of fixed length and one adapter sequence of fixed length are allowed in read2 only (e.g. inDrop, ddSeq). - CB_samTagOut … output Cell Barcode as CR and/or CB SAm tag. No UMI counting. –readFilesIn cDNA_read1 [cDNA_read2 if paired-end] CellBarcode_read . Requires –outSAMtype BAM Unsorted [and/or SortedByCoordinate] - SmartSeq … Smart-seq: each cell in a separate FASTQ (paired- or single-end), barcodes are corresponding read-groups, no UMI sequences, alignments deduplicated according to alignment start and end (after extending soft-clipped bases)\nList of string, multiple_sep: \";\"\n\n\n--soloCBwhitelist\nfile(s) with whitelist(s) of cell barcodes. Only –soloType CB_UMI_Complex allows more than one whitelist file. - None … no whitelist: all cell barcodes are allowed\nList of string, multiple_sep: \";\"\n\n\n--soloCBstart\ncell barcode start base\ninteger, example: 1\n\n\n--soloCBlen\ncell barcode length\ninteger, example: 16\n\n\n--soloUMIstart\nUMI start base\ninteger, example: 17\n\n\n--soloUMIlen\nUMI length\ninteger, example: 10\n\n\n--soloBarcodeReadLength\nlength of the barcode read - 1 … equal to sum of soloCBlen+soloUMIlen - 0 … not defined, do not check\ninteger, example: 1\n\n\n--soloBarcodeMate\nidentifies which read mate contains the barcode (CB+UMI) sequence - 0 … barcode sequence is on separate read, which should always be the last file in the –readFilesIn listed - 1 … barcode sequence is a part of mate 1 - 2 … barcode sequence is a part of mate 2\ninteger, example: 0\n\n\n--soloCBposition\nposition of Cell Barcode(s) on the barcode read. Presently only works with –soloType CB_UMI_Complex, and barcodes are assumed to be on Read2. Format for each barcode: startAnchor_startPosition_endAnchor_endPosition start(end)Anchor defines the Anchor Base for the CB: 0: read start; 1: read end; 2: adapter start; 3: adapter end start(end)Position is the 0-based position with of the CB start(end) with respect to the Anchor Base String for different barcodes are separated by space. Example: inDrop (Zilionis et al, Nat. Protocols, 2017): –soloCBposition 0_0_2_-1 3_1_3_8\nList of string, multiple_sep: \";\"\n\n\n--soloUMIposition\nposition of the UMI on the barcode read, same as soloCBposition Example: inDrop (Zilionis et al, Nat. Protocols, 2017): –soloCBposition 3_9_3_14\nstring\n\n\n--soloAdapterSequence\nadapter sequence to anchor barcodes. Only one adapter sequence is allowed.\nstring\n\n\n--soloAdapterMismatchesNmax\nmaximum number of mismatches allowed in adapter sequence.\ninteger, example: 1\n\n\n--soloCBmatchWLtype\nmatching the Cell Barcodes to the WhiteList - Exact … only exact matches allowed - 1MM … only one match in whitelist with 1 mismatched base allowed. Allowed CBs have to have at least one read with exact match. - 1MM_multi … multiple matches in whitelist with 1 mismatched base allowed, posterior probability calculation is used choose one of the matches. Allowed CBs have to have at least one read with exact match. This option matches best with CellRanger 2.2.0 - 1MM_multi_pseudocounts … same as 1MM_Multi, but pseudocounts of 1 are added to all whitelist barcodes. - 1MM_multi_Nbase_pseudocounts … same as 1MM_multi_pseudocounts, multimatching to WL is allowed for CBs with N-bases. This option matches best with CellRanger &gt;= 3.0.0 - EditDist_2 … allow up to edit distance of 3 fpr each of the barcodes. May include one deletion + one insertion. Only works with –soloType CB_UMI_Complex. Matches to multiple passlist barcdoes are not allowed. Similar to ParseBio Split-seq pipeline.\nstring, example: \"1MM_multi\"\n\n\n--soloInputSAMattrBarcodeSeq\nwhen inputting reads from a SAM file (–readsFileType SAM SE/PE), these SAM attributes mark the barcode sequence (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use –soloInputSAMattrBarcodeSeq CR UR . This parameter is required when running STARsolo with input from SAM.\nList of string, multiple_sep: \";\"\n\n\n--soloInputSAMattrBarcodeQual\nwhen inputting reads from a SAM file (–readsFileType SAM SE/PE), these SAM attributes mark the barcode qualities (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use –soloInputSAMattrBarcodeQual CY UY . If this parameter is ‘-’ (default), the quality ‘H’ will be assigned to all bases.\nList of string, multiple_sep: \";\"\n\n\n--soloStrand\nstrandedness of the solo libraries: - Unstranded … no strand information - Forward … read strand same as the original RNA molecule - Reverse … read strand opposite to the original RNA molecule\nstring, example: \"Forward\"\n\n\n--soloFeatures\ngenomic features for which the UMI counts per Cell Barcode are collected - Gene … genes: reads match the gene transcript - SJ … splice junctions: reported in SJ.out.tab - GeneFull … full gene (pre-mRNA): count all reads overlapping genes’ exons and introns - GeneFull_ExonOverIntron … full gene (pre-mRNA): count all reads overlapping genes’ exons and introns: prioritize 100% overlap with exons - GeneFull_Ex50pAS … full gene (pre-RNA): count all reads overlapping genes’ exons and introns: prioritize &gt;50% overlap with exons. Do not count reads with 100% exonic overlap in the antisense direction.\nList of string, example: \"Gene\", multiple_sep: \";\"\n\n\n--soloMultiMappers\ncounting method for reads mapping to multiple genes - Unique … count only reads that map to unique genes - Uniform … uniformly distribute multi-genic UMIs to all genes - Rescue … distribute UMIs proportionally to unique+uniform counts (~ first iteration of EM) - PropUnique … distribute UMIs proportionally to unique mappers, if present, and uniformly if not. - EM … multi-gene UMIs are distributed using Expectation Maximization algorithm\nList of string, example: \"Unique\", multiple_sep: \";\"\n\n\n--soloUMIdedup\ntype of UMI deduplication (collapsing) algorithm - 1MM_All … all UMIs with 1 mismatch distance to each other are collapsed (i.e. counted once). - 1MM_Directional_UMItools … follows the “directional” method from the UMI-tools by Smith, Heger and Sudbery (Genome Research 2017). - 1MM_Directional … same as 1MM_Directional_UMItools, but with more stringent criteria for duplicate UMIs - Exact … only exactly matching UMIs are collapsed. - NoDedup … no deduplication of UMIs, count all reads. - 1MM_CR … CellRanger2-4 algorithm for 1MM UMI collapsing.\nList of string, example: \"1MM_All\", multiple_sep: \";\"\n\n\n--soloUMIfiltering\ntype of UMI filtering (for reads uniquely mapping to genes) - - … basic filtering: remove UMIs with N and homopolymers (similar to CellRanger 2.2.0). - MultiGeneUMI … basic + remove lower-count UMIs that map to more than one gene. - MultiGeneUMI_All … basic + remove all UMIs that map to more than one gene. - MultiGeneUMI_CR … basic + remove lower-count UMIs that map to more than one gene, matching CellRanger &gt; 3.0.0 . Only works with –soloUMIdedup 1MM_CR\nList of string, multiple_sep: \";\"\n\n\n--soloOutFileNames\nfile names for STARsolo output: file_name_prefix gene_names barcode_sequences cell_feature_count_matrix\nList of string, example: \"Solo.out/\", \"features.tsv\", \"barcodes.tsv\", \"matrix.mtx\", multiple_sep: \";\"\n\n\n--soloCellFilter\ncell filtering type and parameters - None … do not output filtered cells - TopCells … only report top cells by UMI count, followed by the exact number of cells - CellRanger2.2 … simple filtering of CellRanger 2.2. Can be followed by numbers: number of expected cells, robust maximum percentile for UMI count, maximum to minimum ratio for UMI count The harcoded values are from CellRanger: nExpectedCells=3000; maxPercentile=0.99; maxMinRatio=10 - EmptyDrops_CR … EmptyDrops filtering in CellRanger flavor. Please cite the original EmptyDrops paper: A.T.L Lun et al, Genome Biology, 20, 63 (2019): https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1662-y Can be followed by 10 numeric parameters: nExpectedCells maxPercentile maxMinRatio indMin indMax umiMin umiMinFracMedian candMaxN FDR simN The harcoded values are from CellRanger: 3000 0.99 10 45000 90000 500 0.01 20000 0.01 10000\nList of string, example: \"CellRanger2.2\", \"3000\", \"0.99\", \"10\", multiple_sep: \";\"\n\n\n--soloOutFormatFeaturesGeneField3\nfield 3 in the Gene features.tsv file. If “-”, then no 3rd field is output.\nList of string, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--soloCellReadStats\nOutput reads statistics for each CB - Standard … standard output\nstring\n\n\n\n\n\nHTSeq arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--stranded\nWhether the data is from a strand-specific assay. ‘reverse’ means ‘yes’ with reversed strand interpretation.\nstring, default: \"yes\"\n\n\n--minimum_alignment_quality\nSkip all reads with MAPQ alignment quality lower than the given minimum value. MAPQ is the 5th column of a SAM/BAM file and its usage depends on the software used to map the reads.\ninteger, default: 10\n\n\n--type\nFeature type (3rd column in GTF file) to be used, all features of other type are ignored (default, suitable for Ensembl GTF files: exon)\nstring, example: \"exon\"\n\n\n--id_attribute\nGTF attribute to be used as feature ID (default, suitable for Ensembl GTF files: gene_id). All feature of the right type (see -t option) within the same GTF attribute will be added together. The typical way of using this option is to count all exonic reads from each gene and add the exons but other uses are possible as well. You can call this option multiple times: in that case, the combination of all attributes separated by colons (:) will be used as a unique identifier, e.g. for exons you might use -i gene_id -i exon_number.\nList of string, example: \"gene_id\", multiple_sep: \":\"\n\n\n--additional_attributes\nAdditional feature attributes (suitable for Ensembl GTF files: gene_name). Use multiple times for more than one additional attribute. These attributes are only used as annotations in the output, while the determination of how the counts are added together is done based on option -i.\nList of string, example: \"gene_name\", multiple_sep: \":\"\n\n\n--add_chromosome_info\nStore information about the chromosome of each feature as an additional attribute (e.g. colunm in the TSV output file).\nboolean_true\n\n\n--mode\nMode to handle reads overlapping more than one feature.\nstring, default: \"union\"\n\n\n--non_unique\nWhether and how to score reads that are not uniquely aligned or ambiguously assigned to features.\nstring, default: \"none\"\n\n\n--secondary_alignments\nWhether to score secondary alignments (0x100 flag).\nstring\n\n\n--supplementary_alignments\nWhether to score supplementary alignments (0x800 flag).\nstring\n\n\n--counts_output_sparse\nStore the counts as a sparse matrix (mtx, h5ad, loom).\nboolean_true"
  },
  {
    "objectID": "components/modules/mapping/multi_star.html#authors",
    "href": "components/modules/mapping/multi_star.html#authors",
    "title": "Multi star",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/mapping/htseq_count.html",
    "href": "components/modules/mapping/htseq_count.html",
    "title": "Htseq count",
    "section": "",
    "text": "ID: htseq_count\nNamespace: mapping\n\n\n\nSource\nThis script takes one or more alignment files in SAM/BAM format and a feature file in GFF format and calculates for each feature the number of reads mapping to it.\nSee http://htseq.readthedocs.io/en/master/count.html for details."
  },
  {
    "objectID": "components/modules/mapping/htseq_count.html#example-commands",
    "href": "components/modules/mapping/htseq_count.html#example-commands",
    "title": "Htseq count",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/mapping/htseq_count/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\norder: \"name\"\nstranded: \"yes\"\nminimum_alignment_quality: 10\n# type: \"exon\"\n# id_attribute: [\"gene_id\"]\n# additional_attributes: [\"gene_name\"]\nadd_chromosome_info: false\nmode: \"union\"\nnon_unique: \"none\"\n# secondary_alignments: \"foo\"\n# supplementary_alignments: \"foo\"\ncounts_output_sparse: false\n\n# Input\ninput: # please fill in - example: [\"mysample1.BAM\", \"mysample2.BAM\"]\nreference: # please fill in - example: \"reference.gtf\"\n\n# Output\n# output: \"$id.$key.output.tsv\"\n# output_delimiter: \"   \"\n# output_sam: [\"$id.$key.output_sam_*.BAM\"]\n# output_sam_format: \"foo\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/htseq_count/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/htseq_count.html#argument-groups",
    "href": "components/modules/mapping/htseq_count.html#argument-groups",
    "title": "Htseq count",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the SAM/BAM files containing the mapped reads.\nList of file, required, example: \"mysample1.BAM\", \"mysample2.BAM\", multiple_sep: \";\"\n\n\n--reference\nPath to the GTF file containing the features.\nfile, required, example: \"reference.gtf\"\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nFilename to output the counts to.\nfile, required, example: \"htseq-count.tsv\"\n\n\n--output_delimiter\nColumn delimiter in output.\nstring, example: \"    \"\n\n\n--output_sam\nWrite out all SAM alignment records into SAM/BAM files (one per input file needed), annotating each line with its feature assignment (as an optional field with tag ‘XF’). See the -p option to use BAM instead of SAM.\nList of file, example: \"mysample1_out.BAM\", \"mysample2_out.BAM\", multiple_sep: \";\"\n\n\n--output_sam_format\nFormat to use with the –output_sam argument.\nstring\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--order\nSorting order of . Paired-end sequencing data must be sorted either by position or by read name, and the sorting order must be specified. Ignored for single-end data.\nstring, default: \"name\"\n\n\n--stranded\nWhether the data is from a strand-specific assay. ‘reverse’ means ‘yes’ with reversed strand interpretation.\nstring, default: \"yes\"\n\n\n--minimum_alignment_quality\nSkip all reads with MAPQ alignment quality lower than the given minimum value. MAPQ is the 5th column of a SAM/BAM file and its usage depends on the software used to map the reads.\ninteger, default: 10\n\n\n--type\nFeature type (3rd column in GTF file) to be used, all features of other type are ignored (default, suitable for Ensembl GTF files: exon)\nstring, example: \"exon\"\n\n\n--id_attribute\nGTF attribute to be used as feature ID (default, suitable for Ensembl GTF files: gene_id). All feature of the right type (see -t option) within the same GTF attribute will be added together. The typical way of using this option is to count all exonic reads from each gene and add the exons but other uses are possible as well. You can call this option multiple times: in that case, the combination of all attributes separated by colons (:) will be used as a unique identifier, e.g. for exons you might use -i gene_id -i exon_number.\nList of string, example: \"gene_id\", multiple_sep: \":\"\n\n\n--additional_attributes\nAdditional feature attributes (suitable for Ensembl GTF files: gene_name). Use multiple times for more than one additional attribute. These attributes are only used as annotations in the output, while the determination of how the counts are added together is done based on option -i.\nList of string, example: \"gene_name\", multiple_sep: \":\"\n\n\n--add_chromosome_info\nStore information about the chromosome of each feature as an additional attribute (e.g. colunm in the TSV output file).\nboolean_true\n\n\n--mode\nMode to handle reads overlapping more than one feature.\nstring, default: \"union\"\n\n\n--non_unique\nWhether and how to score reads that are not uniquely aligned or ambiguously assigned to features.\nstring, default: \"none\"\n\n\n--secondary_alignments\nWhether to score secondary alignments (0x100 flag).\nstring\n\n\n--supplementary_alignments\nWhether to score supplementary alignments (0x800 flag).\nstring\n\n\n--counts_output_sparse\nStore the counts as a sparse matrix (mtx, h5ad, loom).\nboolean_true"
  },
  {
    "objectID": "components/modules/mapping/htseq_count.html#authors",
    "href": "components/modules/mapping/htseq_count.html#authors",
    "title": "Htseq count",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)\nAngela Oliveira Pisco    (author)"
  },
  {
    "objectID": "components/modules/mapping/htseq_count_to_h5mu.html",
    "href": "components/modules/mapping/htseq_count_to_h5mu.html",
    "title": "Htseq count to h5mu",
    "section": "",
    "text": "ID: htseq_count_to_h5mu\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/htseq_count_to_h5mu.html#example-commands",
    "href": "components/modules/mapping/htseq_count_to_h5mu.html#example-commands",
    "title": "Htseq count to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/mapping/htseq_count_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Input\ninput_id: # please fill in - example: [\"foo\"]\ninput_counts: # please fill in - example: [\"counts.tsv\"]\nreference: # please fill in - example: \"gencode_v41_star\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/htseq_count_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/htseq_count_to_h5mu.html#argument-groups",
    "href": "components/modules/mapping/htseq_count_to_h5mu.html#argument-groups",
    "title": "Htseq count to h5mu",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_id\nThe obs index for the counts\nList of string, required, example: \"foo\", multiple_sep: \";\"\n\n\n--input_counts\nThe counts as a TSV file as output by HTSeq.\nList of file, required, example: \"counts.tsv\", multiple_sep: \";\"\n\n\n--reference\nThe GTF file.\nfile, required, example: \"gencode_v41_star\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/mapping/htseq_count_to_h5mu.html#authors",
    "href": "components/modules/mapping/htseq_count_to_h5mu.html#authors",
    "title": "Htseq count to h5mu",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)\nAngela Oliveira Pisco    (author)"
  },
  {
    "objectID": "components/modules/mapping/samtools_sort.html",
    "href": "components/modules/mapping/samtools_sort.html",
    "title": "Samtools sort",
    "section": "",
    "text": "ID: samtools_sort\nNamespace: mapping\n\n\n\nSource\nReads are sorted by leftmost coordinates, or by read name when --sort_by_read_names is used.\nAn appropriate @HD-SO sort order header tag will be added or an existing one updated if necessary.\nNote that to generate an index file (by specifying --output_bai), the default coordinate sort must be used. Thus the --sort_by_read_names and --sort_by &lt;TAG&gt; options are incompatible with --output_bai."
  },
  {
    "objectID": "components/modules/mapping/samtools_sort.html#example-commands",
    "href": "components/modules/mapping/samtools_sort.html#example-commands",
    "title": "Samtools sort",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/mapping/samtools_sort/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nminimizer_cluster: false\n# minimizer_kmer: 20\nsort_by_read_names: false\n# sort_by: \"foo\"\nno_pg: false\n\n# Input\ninput: # please fill in - example: \"input.bam\"\n\n# Output\n# output_bam: \"$id.$key.output_bam.bam\"\n# output_bai: \"$id.$key.output_bai.bai\"\n# output_format: \"bam\"\n# compression: 5\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/samtools_sort/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/samtools_sort.html#argument-groups",
    "href": "components/modules/mapping/samtools_sort.html#argument-groups",
    "title": "Samtools sort",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the SAM/BAM/CRAM files containing the mapped reads.\nfile, required, example: \"input.bam\"\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_bam\nFilename to output the counts to.\nfile, required, example: \"output.bam\"\n\n\n--output_bai\nBAI-format index for BAM file.\nfile, example: \"output.bam.bai\"\n\n\n--output_format\nThe output format. By default, samtools tries to select a format based on the -o filename extension; if output is to standard output or no format can be deduced, bam is selected.\nstring, example: \"bam\"\n\n\n--compression\nCompression level, from 0 (uncompressed) to 9 (best\ninteger, example: 5\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--minimizer_cluster\nSort unmapped reads (those in chromosome “*“) by their sequence minimiser (Schleimer et al., 2003; Roberts et al., 2004), also reverse complementing as appropriate. This has the effect of collating some similar data together, improving the compressibility of the unmapped sequence. The minimiser kmer size is adjusted using the -K option. Note data compressed in this manner may need to be name collated prior to conversion back to fastq. Mapped sequences are sorted by chromosome and position.\nboolean_true\n\n\n--minimizer_kmer\nSets the kmer size to be used in the -M option.\ninteger, example: 20\n\n\n--sort_by_read_names\nSort by read names (i.e., the QNAME field) rather than by chromosomal coordinates.\nboolean_true\n\n\n--sort_by\nSort first by this value in the alignment tag, then by position or name (if also using -n).\nstring\n\n\n--no_pg\nDo not add a @PG line to the header of the output file.\nboolean_true"
  },
  {
    "objectID": "components/modules/mapping/samtools_sort.html#authors",
    "href": "components/modules/mapping/samtools_sort.html#authors",
    "title": "Samtools sort",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)\nAngela Oliveira Pisco    (author)"
  },
  {
    "objectID": "components/modules/mapping/multi_star_to_h5mu.html",
    "href": "components/modules/mapping/multi_star_to_h5mu.html",
    "title": "Multi star to h5mu",
    "section": "",
    "text": "ID: multi_star_to_h5mu\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/multi_star_to_h5mu.html#example-commands",
    "href": "components/modules/mapping/multi_star_to_h5mu.html#example-commands",
    "title": "Multi star to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/mapping/multi_star_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"/path/to/foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/multi_star_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/multi_star_to_h5mu.html#argument-group",
    "href": "components/modules/mapping/multi_star_to_h5mu.html#argument-group",
    "title": "Multi star to h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe directory created by multi_star\nfile, required, example: \"/path/to/foo\"\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/mapping/multi_star_to_h5mu.html#authors",
    "href": "components/modules/mapping/multi_star_to_h5mu.html#authors",
    "title": "Multi star to h5mu",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (author, maintainer)\nAngela Oliveira Pisco    (author)"
  },
  {
    "objectID": "components/modules/download/download_file.html",
    "href": "components/modules/download/download_file.html",
    "title": "Download file",
    "section": "",
    "text": "ID: download_file\nNamespace: download\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/download/download_file.html#example-commands",
    "href": "components/modules/download/download_file.html#example-commands",
    "title": "Download file",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/download/download_file/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"https://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_protein_v3/pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n# output: \"$id.$key.output.h5\"\nverbose: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/download/download_file/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/download/download_file.html#argument-group",
    "href": "components/modules/download/download_file.html#argument-group",
    "title": "Download file",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nURL to a file to download.\nstring, required, example: \"https://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_protein_v3/pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n\n\n--output\nPath where to store output.\nfile, required, example: \"pbmc_1k_protein_v3_raw_feature_bc_matrix.h5\"\n\n\n--verbose\nIncrease verbosity\nboolean_true"
  },
  {
    "objectID": "components/modules/download/download_file.html#authors",
    "href": "components/modules/download/download_file.html#authors",
    "title": "Download file",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/velocity/velocyto.html",
    "href": "components/modules/velocity/velocyto.html",
    "title": "Velocyto",
    "section": "",
    "text": "ID: velocyto\nNamespace: velocity\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/velocity/velocyto.html#example-commands",
    "href": "components/modules/velocity/velocyto.html#example-commands",
    "title": "Velocyto",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/velocity/velocyto/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\ntranscriptome: # please fill in - example: \"path/to/file\"\n# barcode: \"path/to/file\"\nwithout_umi: false\n# output: \"$id.$key.output.output\"\nlogic: \"Default\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/velocity/velocyto/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/velocity/velocyto.html#argument-group",
    "href": "components/modules/velocity/velocyto.html#argument-group",
    "title": "Velocyto",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to BAM file\nfile, required\n\n\n--transcriptome\nPath to GTF file\nfile, required\n\n\n--barcode\nValid barcodes file, to filter the bam. If –bcfile is not specified all the cell barcodes will be included. Cell barcodes should be specified in the bcfile as the ‘CB’ tag for each read\nfile\n\n\n--without_umi\nfoo\nboolean_true\n\n\n--output\nVelocyto loom file\nfile, required\n\n\n--logic\nThe logic to use for the filtering.\nstring, default: \"Default\""
  },
  {
    "objectID": "components/modules/velocity/velocyto.html#authors",
    "href": "components/modules/velocity/velocyto.html#authors",
    "title": "Velocyto",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/interpret/lianapy.html",
    "href": "components/modules/interpret/lianapy.html",
    "title": "Lianapy",
    "section": "",
    "text": "ID: lianapy\nNamespace: interpret\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/interpret/lianapy.html#example-commands",
    "href": "components/modules/interpret/lianapy.html#example-commands",
    "title": "Lianapy",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/interpret/lianapy/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\n# output: \"$id.$key.output.output\"\noutput_compression: \"gzip\"\nmodality: \"rna\"\n# layer: \"foo\"\ngroupby: \"bulk_labels\"\nresource_name: \"consensus\"\ngene_symbol: \"gene_symbol\"\nexpr_prop: 0.1\nmin_cells: 5\naggregate_method: \"rra\"\nreturn_all_lrs: false\nn_perms: 100\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/interpret/lianapy/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/interpret/lianapy.html#argument-group",
    "href": "components/modules/interpret/lianapy.html#argument-group",
    "title": "Lianapy",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--output_compression\n\nstring, default: \"gzip\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nLayer in anndata.AnnData.layers to use. If None, use mudata.mod[modality].X.\nstring\n\n\n--groupby\nThe key of the observations grouping to consider.\nstring, default: \"bulk_labels\"\n\n\n--resource_name\nName of the resource to be loaded and use for ligand-receptor inference.\nstring, default: \"consensus\"\n\n\n--gene_symbol\nColumn name in var DataFrame in which gene symbol are stored.\nstring, default: \"gene_symbol\"\n\n\n--expr_prop\nMinimum expression proportion for the ligands/receptors (and their subunits) in the corresponding cell identities. Set to ‘0’, to return unfiltered results.\ndouble, default: 0.1\n\n\n--min_cells\nMinimum cells per cell identity (‘groupby’) to be considered for downstream analysis.\ninteger, default: 5\n\n\n--aggregate_method\nMethod aggregation approach, one of [‘mean’, ‘rra’], where ‘mean’ represents the mean rank, while ‘rra’ is the RobustRankAggregate (Kolde et al., 2014) of the interactions.\nstring, default: \"rra\"\n\n\n--return_all_lrs\nBool whether to return all LRs, or only those that surpass the ‘expr_prop’ threshold. Those interactions that do not pass the ‘expr_prop’ threshold will be assigned to the worst score of the ones that do. ‘False’ by default.\nboolean, default: FALSE\n\n\n--n_perms\nNumber of permutations for the permutation test. Note that this is relevant only for permutation-based methods - e.g. ’CellPhoneDB\ninteger, default: 100"
  },
  {
    "objectID": "components/modules/interpret/lianapy.html#authors",
    "href": "components/modules/interpret/lianapy.html#authors",
    "title": "Lianapy",
    "section": "Authors",
    "text": "Authors\n\nMauro Saporita   (author)\nPovilas Gibas   (author)"
  },
  {
    "objectID": "components/modules/metadata/move_obsm_to_obs.html",
    "href": "components/modules/metadata/move_obsm_to_obs.html",
    "title": "Move obsm to obs",
    "section": "",
    "text": "ID: move_obsm_to_obs\nNamespace: metadata\n\n\n\nSource\nNewly created columns in .obs will be created from the .obsm key suffixed with an underscore and the name of the columns of the specified .obsm matrix"
  },
  {
    "objectID": "components/modules/metadata/move_obsm_to_obs.html#example-commands",
    "href": "components/modules/metadata/move_obsm_to_obs.html#example-commands",
    "title": "Move obsm to obs",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/metadata/move_obsm_to_obs/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# MuData Input\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nobsm_key: # please fill in - example: \"foo\"\n\n# MuData Output\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/move_obsm_to_obs/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/metadata/move_obsm_to_obs.html#argument-groups",
    "href": "components/modules/metadata/move_obsm_to_obs.html#argument-groups",
    "title": "Move obsm to obs",
    "section": "Argument groups",
    "text": "Argument groups\n\nMuData Input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsm_key\nKey of a data structure to move from .obsm to .obs.\nstring, required\n\n\n\n\n\nMuData Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/metadata/move_obsm_to_obs.html#authors",
    "href": "components/modules/metadata/move_obsm_to_obs.html#authors",
    "title": "Move obsm to obs",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/modules/metadata/grep_annotation_column.html",
    "href": "components/modules/metadata/grep_annotation_column.html",
    "title": "Grep annotation column",
    "section": "",
    "text": "ID: grep_annotation_column\nNamespace: metadata\n\n\n\nSource\nThe annotation matrix can originate from either a modality, or all modalities (global .var or .obs)"
  },
  {
    "objectID": "components/modules/metadata/grep_annotation_column.html#example-commands",
    "href": "components/modules/metadata/grep_annotation_column.html#example-commands",
    "title": "Grep annotation column",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.2 -latest \\\n  -main-script target/nextflow/metadata/grep_annotation_column/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"sample_path\"\n# input_column: \"foo\"\nmodality: # please fill in - example: \"rna\"\n# matrix: \"var\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\noutput_match_column: # please fill in - example: \"foo\"\n# output_fraction_column: \"foo\"\n\n# Query options\nregex_pattern: # please fill in - example: \"^[mM][tT]-\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.2 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/grep_annotation_column/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/metadata/grep_annotation_column.html#argument-groups",
    "href": "components/modules/metadata/grep_annotation_column.html#argument-groups",
    "title": "Grep annotation column",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\nArguments related to the input dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the input .h5mu.\nfile, required, example: \"sample_path\"\n\n\n--input_column\nColumn to query. If not specified, use .var_names or .obs_names, depending on the value of –matrix\nstring\n\n\n--modality\nWhich modality to get the annotation matrix from.\nstring, required, example: \"rna\"\n\n\n--matrix\nMatrix to fetch the column from that will be searched.\nstring, example: \"var\"\n\n\n\n\n\nOutputs\nArguments related to how the output will be written.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\n\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--output_match_column\nName of the column to write the result to.\nstring, required\n\n\n--output_fraction_column\nFor the opposite axis, name of the column to write the fraction of observations that matches to the pattern.\nstring\n\n\n\n\n\nQuery options\nOptions related to the query\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--regex_pattern\nRegex to use to match with the input column.\nstring, required, example: \"^[mM][tT]-\""
  },
  {
    "objectID": "components/modules/metadata/grep_annotation_column.html#authors",
    "href": "components/modules/metadata/grep_annotation_column.html#authors",
    "title": "Grep annotation column",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/dimred/umap.html",
    "href": "components/modules/dimred/umap.html",
    "title": "Umap",
    "section": "",
    "text": "ID: umap\nNamespace: dimred\n\n\n\nSource\nBesides tending to be faster than tSNE, it optimizes the embedding such that it best reflects the topology of the data, which we represent throughout Scanpy using a neighborhood graph. tSNE, by contrast, optimizes the distribution of nearest-neighbor distances in the embedding such that these best match the distribution of distances in the high-dimensional space. We use the implementation of umap-learn [McInnes18]. For a few comparisons of UMAP with tSNE, see this preprint"
  },
  {
    "objectID": "components/modules/dimred/umap.html#example-commands",
    "href": "components/modules/dimred/umap.html#example-commands",
    "title": "Umap",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/dimred/umap/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nuns_neighbors: \"neighbors\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobsm_output: \"umap\"\n\n# Arguments\nmin_dist: 0.5\nspread: 1.0\nnum_components: 2\n# max_iter: 123\nalpha: 1.0\ngamma: 1.0\nnegative_sample_rate: 5\ninit_pos: \"spectral\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dimred/umap/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/dimred/umap.html#argument-groups",
    "href": "components/modules/dimred/umap.html#argument-groups",
    "title": "Umap",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--uns_neighbors\nThe .uns neighbors slot as output by the find_neighbors component.\nstring, default: \"neighbors\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obsm_output\nThe pre/postfix under which to store the UMAP results.\nstring, default: \"umap\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_dist\nThe effective minimum distance between embedded points. Smaller values will result in a more clustered/clumped embedding where nearby points on the manifold are drawn closer together, while larger values will result on a more even dispersal of points. The value should be set relative to the spread value, which determines the scale at which embedded points will be spread out.\ndouble, default: 0.5\n\n\n--spread\nThe effective scale of embedded points. In combination with min_dist this determines how clustered/clumped the embedded points are.\ndouble, default: 1\n\n\n--num_components\nThe number of dimensions of the embedding.\ninteger, default: 2\n\n\n--max_iter\nThe number of iterations (epochs) of the optimization. Called n_epochs in the original UMAP. Default is set to 500 if neighbors[‘connectivities’].shape[0] &lt;= 10000, else 200.\ninteger\n\n\n--alpha\nThe initial learning rate for the embedding optimization.\ndouble, default: 1\n\n\n--gamma\nWeighting applied to negative samples in low dimensional embedding optimization. Values higher than one will result in greater weight being given to negative samples.\ndouble, default: 1\n\n\n--negative_sample_rate\nThe number of negative edge/1-simplex samples to use per positive edge/1-simplex sample in optimizing the low dimensional embedding.\ninteger, default: 5\n\n\n--init_pos\nHow to initialize the low dimensional embedding. Called init in the original UMAP. Options are: * Any key from .obsm * 'paga': positions from paga() * 'spectral': use a spectral embedding of the graph * 'random': assign initial embedding positions at random.\nstring, default: \"spectral\""
  },
  {
    "objectID": "components/modules/dimred/umap.html#authors",
    "href": "components/modules/dimred/umap.html#authors",
    "title": "Umap",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)"
  },
  {
    "objectID": "components/workflows/integration/scvi/scvi.html",
    "href": "components/workflows/integration/scvi/scvi.html",
    "title": "Scvi",
    "section": "",
    "text": "ID: scvi\nNamespace: integration/scvi\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/integration/scvi/scvi.html#example-commands",
    "href": "components/workflows/integration/scvi/scvi.html#example-commands",
    "title": "Scvi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -main-script workflows/multiomics/integration/scvi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_model: \"$id.$key.output_model.output_model\"\n\n# Neighbour calculation\nuns_neighbors: \"scvi_integration_neighbors\"\nobsp_neighbor_distances: \"scvi_integration_distances\"\nobsp_neighbor_connectivities: \"scvi_integration_connectivities\"\n\n# Scvi integration options\nobs_batch: # please fill in - example: \"foo\"\nobsm_output: \"X_scvi_integrated\"\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n# max_epochs: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30\n\n# Umap options\nobsm_umap: \"X_scvi_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -profile docker \\\n  -main-script workflows/multiomics/integration/scvi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/integration/scvi/scvi.html#argument-groups",
    "href": "components/workflows/integration/scvi/scvi.html#argument-groups",
    "title": "Scvi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n--output_model\nFolder where the state of the trained model will be saved to.\nfile, required, example: \"output_dir\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"scvi_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"scvi_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"scvi_integration_connectivities\"\n\n\n\n\n\nScvi integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, required\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_scvi_integrated\"\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_scvi_umap\""
  },
  {
    "objectID": "components/workflows/integration/scvi/scvi.html#authors",
    "href": "components/workflows/integration/scvi/scvi.html#authors",
    "title": "Scvi",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/integration/scvi/scvi.html#visualisation",
    "href": "components/workflows/integration/scvi/scvi.html#visualisation",
    "title": "Scvi",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    p0(Input)\n    p3(toSortedList)\n    p5(flatMap)\n    p13(scvi)\n    p24(find_neighbors)\n    p34(umap)\n    p42(Output)\n    p0--&gt;p3\n    p3--&gt;p5\n    p5--&gt;p13\n    p13--&gt;p24\n    p24--&gt;p34\n    p34--&gt;p42"
  },
  {
    "objectID": "components/workflows/integration/common/harmony_leiden.html",
    "href": "components/workflows/integration/common/harmony_leiden.html",
    "title": "Harmony leiden",
    "section": "",
    "text": "ID: harmony_leiden\nNamespace: integration/common\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/integration/common/harmony_leiden.html#example-commands",
    "href": "components/workflows/integration/common/harmony_leiden.html#example-commands",
    "title": "Harmony leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -main-script workflows/multiomics/integration/harmony_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Neighbour calculation\nuns_neighbors: \"harmonypy_integration_neighbors\"\nobsp_neighbor_distances: \"harmonypy_integration_distances\"\nobsp_neighbor_connectivities: \"harmonypy_integration_connectivities\"\n\n# Harmony integration options\nembedding: \"X_pca\"\nobsm_integrated: \"X_pca_integrated\"\nobs_covariates: # please fill in - example: [\"batch\", \"sample\"]\ntheta: [2]\n\n# Clustering options\nobs_cluster: \"harmony_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_leiden_harmony_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -profile docker \\\n  -main-script workflows/multiomics/integration/harmony_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/integration/common/harmony_leiden.html#argument-groups",
    "href": "components/workflows/integration/common/harmony_leiden.html#argument-groups",
    "title": "Harmony leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"harmonypy_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"harmonypy_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"harmonypy_integration_connectivities\"\n\n\n\n\n\nHarmony integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--embedding\nEmbedding to use as input\nstring, default: \"X_pca\"\n\n\n--obsm_integrated\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_pca_integrated\"\n\n\n--obs_covariates\nThe .obs field(s) that define the covariate(s) to regress out.\nstring, required, example: \"batch\", example: \"sample\"\n\n\n--theta\nDiversity clustering penalty parameter. Specify for each variable in group.by.vars. theta=0 does not encourage any diversity. Larger values of theta result in more diverse clusters.”\ndouble, default: 2\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nName of the .obs key under which to add the cluster labels.\nstring, default: \"harmony_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\ndouble, default: 1\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_harmony_umap\""
  },
  {
    "objectID": "components/workflows/integration/common/harmony_leiden.html#authors",
    "href": "components/workflows/integration/common/harmony_leiden.html#authors",
    "title": "Harmony leiden",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/integration/common/harmony_leiden.html#visualisation",
    "href": "components/workflows/integration/common/harmony_leiden.html#visualisation",
    "title": "Harmony leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    p0(Input)\n    p2(toSortedList)\n    p4(flatMap)\n    p12(harmonypy)\n    p22(find_neighbors)\n    p32(leiden)\n    p42(umap)\n    p52(move_obsm_to_obs)\n    p60(Output)\n    p0--&gt;p2\n    p2--&gt;p4\n    p4--&gt;p12\n    p12--&gt;p22\n    p22--&gt;p32\n    p32--&gt;p42\n    p42--&gt;p52\n    p52--&gt;p60"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html",
    "title": "Cell Ranger post-processing",
    "section": "",
    "text": "ID: cellranger_postprocessing\nNamespace: ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html#example-commands",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html#example-commands",
    "title": "Cell Ranger post-processing",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/ingestion/cellranger_postprocessing/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\n\n# Outputs\n# output: \"$id.$key.output.output\"\n\n# Correction arguments\nperform_correction: false\ncellbender_epochs: 150\n\n# Filtering arguments\n# min_genes: 100\n# min_counts: 1000\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/ingestion/cellranger_postprocessing/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html#argument-groups",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html#argument-groups",
    "title": "Cell Ranger post-processing",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nInput h5mu file created by running Cell Ranger and converting its output to h5mu.\nfile, required, example: \"input.h5mu\"\n\n\n\n\n\nOutputs\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe converted h5mu file.\nfile\n\n\n\n\n\nCorrection arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--perform_correction\nWhether or not to run CellBender to perform count correction.\nboolean_true\n\n\n--cellbender_epochs\nNumber of epochs to run CellBender for.\ninteger, default: 150\n\n\n\n\n\nFiltering arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_genes\nMinimum number of counts required for a cell to pass filtering.\ninteger, example: 100\n\n\n--min_counts\nMinimum number of genes expressed required for a cell to pass filtering.\ninteger, example: 1000"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html#authors",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html#authors",
    "title": "Cell Ranger post-processing",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_postprocessing.html#visualisation",
    "href": "components/workflows/ingestion/cellranger_postprocessing.html#visualisation",
    "title": "Cell Ranger post-processing",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v6(from_10xh5_to_h5mu)\n    v8(join)\n    v12(toSortedList)\n    v14(flatMap)\n    v15(filter)\n    v21(cellbender_remove_background)\n    v23(join)\n    v27(mix)\n    v26(filter)\n    v28(filter)\n    v34(filter_with_counts)\n    v36(join)\n    v40(mix)\n    v39(filter)\n    v46(publish)\n    v48(join)\n    v54(Output)\n    v14--&gt;v15\n    v14--&gt;v26\n    v26--&gt;v27\n    v27--&gt;v28\n    v27--&gt;v39\n    v39--&gt;v40\n    v0--&gt;v8\n    v0--&gt;v6\n    v6--&gt;v8\n    v8--&gt;v12\n    v12--&gt;v14\n    v15--&gt;v23\n    v15--&gt;v21\n    v21--&gt;v23\n    v23--&gt;v27\n    v28--&gt;v36\n    v28--&gt;v34\n    v34--&gt;v36\n    v36--&gt;v40\n    v40--&gt;v48\n    v40--&gt;v46\n    v46--&gt;v48\n    v48--&gt;v54"
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html",
    "href": "components/workflows/ingestion/make_reference.html",
    "title": "Make reference",
    "section": "",
    "text": "ID: make_reference\nNamespace: ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html#example-commands",
    "href": "components/workflows/ingestion/make_reference.html#example-commands",
    "title": "Make reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/ingestion/make_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ngenome_fasta: # please fill in - example: \"https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/GRCh38.primary_assembly.genome.fa.gz\"\ntranscriptome_gtf: # please fill in - example: \"https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/gencode.v41.annotation.gtf.gz\"\n# ercc: \"https://assets.thermofisher.com/TFS-Assets/LSG/manuals/ERCC92.zip\"\n\n# Outputs\ntarget: [\"star\"]\n# output_fasta: \"$id.$key.output_fasta.gz\"\n# output_gtf: \"$id.$key.output_gtf.gz\"\n# output_cellranger: \"$id.$key.output_cellranger.gz\"\n# output_bd_rhapsody: \"$id.$key.output_bd_rhapsody.gz\"\n# output_star: \"$id.$key.output_star.gz\"\n\n# Arguments\n# subset_regex: \"(ERCC-00002|chr1)\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/ingestion/make_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html#argument-groups",
    "href": "components/workflows/ingestion/make_reference.html#argument-groups",
    "title": "Make reference",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the reference.\nstring, required, example: \"foo\"\n\n\n--genome_fasta\nReference genome fasta.\nfile, required, example: \"https:/ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/GRCh38.primary_assembly.genome.fa.gz\"\n\n\n--transcriptome_gtf\nReference transcriptome annotation.\nfile, required, example: \"https:/ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/gencode.v41.annotation.gtf.gz\"\n\n\n--ercc\nERCC sequence and annotation file.\nfile, example: \"https:/assets.thermofisher.com/TFS-Assets/LSG/manuals/ERCC92.zip\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--target\nWhich reference indices to generate.\nList of string, default: \"star\", multiple_sep: \":\"\n\n\n--output_fasta\nOutput genome sequence fasta.\nfile, example: \"genome_sequence.fa.gz\"\n\n\n--output_gtf\nOutput transcriptome annotation gtf.\nfile, example: \"transcriptome_annotation.gtf.gz\"\n\n\n--output_cellranger\nOutput index\nfile, example: \"cellranger_index.tar.gz\"\n\n\n--output_bd_rhapsody\nOutput index\nfile, example: \"bdrhap_index.tar.gz\"\n\n\n--output_star\nOutput index\nfile, example: \"star_index.tar.gz\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--subset_regex\nWill subset the reference chromosomes using the given regex.\nstring, example: \"(ERCC-00002&#124;chr1)\""
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html#authors",
    "href": "components/workflows/ingestion/make_reference.html#authors",
    "title": "Make reference",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/ingestion/make_reference.html#visualisation",
    "href": "components/workflows/ingestion/make_reference.html#visualisation",
    "title": "Make reference",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v11(make_reference)\n    v13(join)\n    v17(filter)\n    v22(build_cellranger_reference)\n    v24(join)\n    v54(join)\n    v29(filter)\n    v34(build_bdrhap_reference)\n    v36(join)\n    v55(join)\n    v41(filter)\n    v46(star_build_reference)\n    v48(join)\n    v56(join)\n    v57(join)\n    v62(Output)\n    v54--&gt;v55\n    v55--&gt;v56\n    v56--&gt;v57\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v13\n    v4--&gt;v11\n    v11--&gt;v13\n    v13--&gt;v17\n    v17--&gt;v24\n    v17--&gt;v22\n    v22--&gt;v24\n    v24--&gt;v54\n    v13--&gt;v29\n    v29--&gt;v36\n    v29--&gt;v34\n    v34--&gt;v36\n    v36--&gt;v55\n    v13--&gt;v41\n    v41--&gt;v48\n    v41--&gt;v46\n    v46--&gt;v48\n    v48--&gt;v56\n    v0--&gt;v57\n    v13--&gt;v54\n    v57--&gt;v62"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html",
    "href": "components/workflows/ingestion/cellranger_multi.html",
    "title": "Cell Ranger multi",
    "section": "",
    "text": "ID: cellranger_multi\nNamespace: ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html#example-commands",
    "href": "components/workflows/ingestion/cellranger_multi.html#example-commands",
    "title": "Cell Ranger multi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/ingestion/cellranger_multi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: [\"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\"]\ngex_reference: # please fill in - example: \"reference_genome.tar.gz\"\n# vdj_reference: \"reference_vdj.tar.gz\"\n# feature_reference: \"feature_reference.csv\"\n# vdj_inner_enrichment_primers: \"enrichment_primers.txt\"\n\n# Outputs\n# output_raw: \"$id.$key.output_raw.output_raw\"\n# output_h5mu: \"$id.$key.output_h5mu.h5mu\"\nuns_metrics: \"metrics_cellranger\"\n\n# Cell multiplexing parameters\n# cell_multiplex_sample_id: \"foo\"\n# cell_multiplex_oligo_ids: \"foo\"\n# cell_multiplex_description: \"foo\"\n\n# Gene expression arguments\n# gex_expect_cells: 3000\ngex_chemistry: \"auto\"\ngex_secondary_analysis: false\ngex_generate_bam: true\ngex_include_introns: true\n\n# Library arguments\nlibrary_id: # please fill in - example: [\"mysample1\"]\nlibrary_type: # please fill in - example: [\"Gene Expression\"]\n# library_subsample: [\"0.5\"]\n# library_lanes: [\"1-4\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/ingestion/cellranger_multi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html#argument-groups",
    "href": "components/workflows/ingestion/cellranger_multi.html#argument-groups",
    "title": "Cell Ranger multi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nThe fastq.gz files to align. Can also be a single directory containing fastq.gz files.\nList of file, required, example: \"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--gex_reference\nGenome refence index built by Cell Ranger mkref.\nfile, required, example: \"reference_genome.tar.gz\"\n\n\n--vdj_reference\nVDJ refence index built by Cell Ranger mkref.\nfile, example: \"reference_vdj.tar.gz\"\n\n\n--feature_reference\nPath to the Feature reference CSV file, declaring Feature Barcode constructs and associated barcodes. Required only for Antibody Capture or CRISPR Guide Capture libraries. See https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/using/feature-bc-analysis#feature-ref for more information.\nfile, example: \"feature_reference.csv\"\n\n\n--vdj_inner_enrichment_primers\nV(D)J Immune Profiling libraries: if inner enrichment primers other than those provided in the 10x Genomics kits are used, they need to be specified here as a text file with one primer per line.\nfile, example: \"enrichment_primers.txt\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_raw\nThe raw output folder.\nfile, required, example: \"output_dir\"\n\n\n--output_h5mu\nThe converted h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--uns_metrics\nName of the .uns slot under which to QC metrics (if any).\nstring, default: \"metrics_cellranger\"\n\n\n\n\n\nCell multiplexing parameters\nArguments related to cell multiplexing.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_multiplex_sample_id\nA name to identify a multiplexed sample. Must be alphanumeric with hyphens and/or underscores, and less than 64 characters. Required for Cell Multiplexing libraries.\nstring\n\n\n--cell_multiplex_oligo_ids\nThe Cell Multiplexing oligo IDs used to multiplex this sample. If multiple CMOs were used for a sample, separate IDs with a pipe (e.g., CMO301|CMO302). Required for Cell Multiplexing libraries.\nstring\n\n\n--cell_multiplex_description\nA description for the sample.\nstring\n\n\n\n\n\nGene expression arguments\nArguments relevant to the analysis of gene expression data.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--gex_expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\ninteger, example: 3000\n\n\n--gex_chemistry\nAssay configuration. - auto: autodetect mode - threeprime: Single Cell 3’ - fiveprime: Single Cell 5’ - SC3Pv1: Single Cell 3’ v1 - SC3Pv2: Single Cell 3’ v2 - SC3Pv3: Single Cell 3’ v3 - SC3Pv3LT: Single Cell 3’ v3 LT - SC3Pv3HT: Single Cell 3’ v3 HT - SC5P-PE: Single Cell 5’ paired-end - SC5P-R2: Single Cell 5’ R2-only - SC-FB: Single Cell Antibody-only 3’ v2 or 5’ See https://kb.10xgenomics.com/hc/en-us/articles/115003764132-How-does-Cell-Ranger-auto-detect-chemistry- for more information.\nstring, default: \"auto\"\n\n\n--gex_secondary_analysis\nWhether or not to run the secondary analysis e.g. clustering.\nboolean, default: FALSE\n\n\n--gex_generate_bam\nWhether to generate a BAM file.\nboolean, default: TRUE\n\n\n--gex_include_introns\nInclude intronic reads in count (default=true unless –target-panel is specified in which case default=false)\nboolean, default: TRUE\n\n\n\n\n\nLibrary arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--library_id\nThe Illumina sample name to analyze. This must exactly match the ‘Sample Name’ part of the FASTQ files specified in the --input argument.\nList of string, required, example: \"mysample1\", multiple_sep: \";\"\n\n\n--library_type\nThe underlying feature type of the library. Possible values: “Gene Expression”, “VDJ”, “VDJ-T”, “VDJ-B”, “Antibody Capture”, “CRISPR Guide Capture”, “Multiplexing Capture”\nList of string, required, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--library_subsample\nOptional. The rate at which reads from the provided FASTQ files are sampled. Must be strictly greater than 0 and less than or equal to 1.\nList of string, example: \"0.5\", multiple_sep: \";\"\n\n\n--library_lanes\nLanes associated with this sample. Defaults to using all lanes.\nList of string, example: \"1-4\", multiple_sep: \";\""
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html#authors",
    "href": "components/workflows/ingestion/cellranger_multi.html#authors",
    "title": "Cell Ranger multi",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_multi.html#visualisation",
    "href": "components/workflows/ingestion/cellranger_multi.html#visualisation",
    "title": "Cell Ranger multi",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v11(cellranger_multi)\n    v13(join)\n    v20(from_cellranger_multi_to_h5mu)\n    v22(join)\n    v29(Output)\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v13\n    v4--&gt;v11\n    v11--&gt;v13\n    v13--&gt;v22\n    v13--&gt;v20\n    v20--&gt;v22\n    v22--&gt;v29"
  },
  {
    "objectID": "components/workflows/qc/qc.html",
    "href": "components/workflows/qc/qc.html",
    "title": "Qc",
    "section": "",
    "text": "ID: qc\nNamespace: qc\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/qc/qc.html#example-commands",
    "href": "components/workflows/qc/qc.html#example-commands",
    "title": "Qc",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.2 -latest \\\n  -main-script ./workflows/qc/qc/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"raw_counts\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Mitochondrial Gene Detection\n# var_name_mitochondrial_genes: \"foo\"\n# obs_name_mitochondrial_fraction: \"foo\"\n# var_gene_names: \"gene_symbol\"\nmitochondrial_gene_regex: \"^[mM][tT]-\"\n\n# QC metrics calculation options\n# var_qc_metrics: [\"ercc\", \"highly_variable\"]\ntop_n_vars: [50, 100, 200, 500]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.12.2 -latest \\\n  -profile docker \\\n  -main-script ./workflows/qc/qc/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/qc/qc.html#argument-groups",
    "href": "components/workflows/qc/qc.html#argument-groups",
    "title": "Qc",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--layer\nLayer to calculate qc metrics for.\nstring, example: \"raw_counts\"\n\n\n\n\n\nMitochondrial Gene Detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_name_mitochondrial_genes\nIn which .var slot to store a boolean array corresponding the mitochondrial genes.\nstring\n\n\n--obs_name_mitochondrial_fraction\n.Obs slot to store the fraction of reads found to be mitochondrial. Defaults to ‘fraction_’ suffixed by the value of –var_name_mitochondrial_genes\nstring\n\n\n--var_gene_names\n.var column name to be used to detect mitochondrial genes instead of .var_names (default if not set). Gene names matching with the regex value from –mitochondrial_gene_regex will be identified as a mitochondrial gene.\nstring, example: \"gene_symbol\"\n\n\n--mitochondrial_gene_regex\nRegex string that identifies mitochondrial genes from –var_gene_names. By default will detect human and mouse mitochondrial genes from a gene symbol.\nstring, default: \"^[mM][tT]-\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‘True’, compared to the total sum of the values for all genes. Defaults to the value from –var_name_mitochondrial_genes.\nList of string, example: \"ercc,highly_variable\", multiple_sep: \",\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\""
  },
  {
    "objectID": "components/workflows/qc/qc.html#authors",
    "href": "components/workflows/qc/qc.html#authors",
    "title": "Qc",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/qc/qc.html#visualisation",
    "href": "components/workflows/qc/qc.html#visualisation",
    "title": "Qc",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v7(filter)\n    v13(grep_annotation_column)\n    v15(join)\n    v19(mix)\n    v18(filter)\n    v25(calculate_qc_metrics)\n    v27(join)\n    v35(publish)\n    v37(join)\n    v41(toSortedList)\n    v43(Output)\n    v18--&gt;v19\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v7\n    v4--&gt;v18\n    v7--&gt;v15\n    v7--&gt;v13\n    v13--&gt;v15\n    v15--&gt;v19\n    v19--&gt;v27\n    v19--&gt;v25\n    v25--&gt;v27\n    v27--&gt;v37\n    v27--&gt;v35\n    v35--&gt;v37\n    v37--&gt;v41\n    v41--&gt;v43"
  },
  {
    "objectID": "components/workflows/multiomics/prot_multisample.html",
    "href": "components/workflows/multiomics/prot_multisample.html",
    "title": "Prot multisample",
    "section": "",
    "text": "ID: prot_multisample\nNamespace: multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/prot_multisample.html#example-commands",
    "href": "components/workflows/multiomics/prot_multisample.html#example-commands",
    "title": "Prot multisample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/multiomics/prot_multisample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"concatenated\"\ninput: # please fill in - example: \"dataset.h5mu\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# QC metrics calculation options\ntop_n_vars: [50, 100, 200, 500]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/prot_multisample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/prot_multisample.html#argument-groups",
    "href": "components/workflows/multiomics/prot_multisample.html#argument-groups",
    "title": "Prot multisample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the concatenated file\nstring, required, example: \"concatenated\"\n\n\n--input\nPath to the samples.\nfile, required, example: \"dataset.h5mu\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\""
  },
  {
    "objectID": "components/workflows/multiomics/prot_multisample.html#authors",
    "href": "components/workflows/multiomics/prot_multisample.html#authors",
    "title": "Prot multisample",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/prot_multisample.html#visualisation",
    "href": "components/workflows/multiomics/prot_multisample.html#visualisation",
    "title": "Prot multisample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v3(toSortedList)\n    v5(flatMap)\n    v7(toSortedList)\n    v9(Output)\n    v15(clr)\n    v17(join)\n    v25(prot_calculate_qc_metrics)\n    v27(join)\n    v34(Output)\n    v0--&gt;v3\n    v3--&gt;v5\n    v5--&gt;v7\n    v7--&gt;v9\n    v5--&gt;v17\n    v5--&gt;v15\n    v15--&gt;v17\n    v17--&gt;v27\n    v17--&gt;v25\n    v25--&gt;v27\n    v27--&gt;v34"
  },
  {
    "objectID": "components/workflows/multiomics/integration.html",
    "href": "components/workflows/multiomics/integration.html",
    "title": "Integration",
    "section": "",
    "text": "ID: integration\nNamespace: multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration.html#example-commands",
    "href": "components/workflows/multiomics/integration.html#example-commands",
    "title": "Integration",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.8.0 -latest \\\n  -main-script workflows/multiomics/integration/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# PCA options\nobsm_pca: \"X_pca\"\n# var_pca_feature_selection: \"foo\"\n\n# Harmony integration options\nobsm_integrated: \"X_pca_integrated\"\nobs_covariates: # please fill in - example: [\"batch\", \"sample\"]\nrna_theta: [2]\n\n# Neighbour calculation\nuns_neighbors: \"neighbors\"\nobsp_neighbor_distances: \"distances\"\nobsp_neighbor_connectivities: \"connectivities\"\n\n# Clustering options\nobs_cluster: \"leiden\"\nleiden_resolution: 1\n\n# Umap options\nobsm_umap: \"X_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.8.0 -latest \\\n  -profile docker \\\n  -main-script workflows/multiomics/integration/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration.html#argument-groups",
    "href": "components/workflows/multiomics/integration.html#argument-groups",
    "title": "Integration",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_pca\nIn which .obsm slot to store the resulting PCA embedding.\nstring, default: \"X_pca\"\n\n\n--var_pca_feature_selection\nColumn name in .var matrix that will be used to select which genes to run the PCA on.\nstring\n\n\n\n\n\nHarmony integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_integrated\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_pca_integrated\"\n\n\n--obs_covariates\nThe .obs field(s) that define the covariate(s) to regress out.\nstring, required, example: \"batch\", example: \"sample\"\n\n\n--rna_theta\nDiversity clustering penalty parameter. Specify for each variable in group.by.vars. theta=0 does not encourage any diversity. Larger values of theta result in more diverse clusters.”\ndouble, default: 2\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"connectivities\"\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nName of the .obs key under which to add the cluster labels.\nstring, default: \"leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\ndouble, default: 1\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration.html#authors",
    "href": "components/workflows/multiomics/integration.html#authors",
    "title": "Integration",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer  (author)\nRobrecht Cannoodt   (author, maintainer)\nDries Schaumont   (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration.html#visualisation",
    "href": "components/workflows/multiomics/integration.html#visualisation",
    "title": "Integration",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    p0(Input)\n    p2(toSortedList)\n    p4(flatMap)\n    p15(join)\n    p13(pca)\n    p18(filter)\n    p29(concat)\n    p19(filter)\n    p27(join)\n    p25(harmonypy)\n    p38(join)\n    p36(find_neighbors)\n    p48(join)\n    p46(leiden)\n    p58(join)\n    p56(umap)\n    p64(Output)\n    p18--&gt;p29\n    p0--&gt;p2\n    p2--&gt;p4\n    p4--&gt;p15\n    p4--&gt;p13\n    p13--&gt;p15\n    p15--&gt;p18\n    p15--&gt;p19\n    p19--&gt;p27\n    p19--&gt;p25\n    p25--&gt;p27\n    p27--&gt;p29\n    p29--&gt;p38\n    p29--&gt;p36\n    p36--&gt;p38\n    p38--&gt;p48\n    p38--&gt;p46\n    p46--&gt;p48\n    p48--&gt;p58\n    p48--&gt;p56\n    p56--&gt;p58\n    p58--&gt;p64"
  },
  {
    "objectID": "components/workflows/multiomics/integration/scanorama_leiden.html",
    "href": "components/workflows/multiomics/integration/scanorama_leiden.html",
    "title": "Scanorama leiden",
    "section": "",
    "text": "ID: scanorama_leiden\nNamespace: multiomics/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration/scanorama_leiden.html#example-commands",
    "href": "components/workflows/multiomics/integration/scanorama_leiden.html#example-commands",
    "title": "Scanorama leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/multiomics/integration/scanorama_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Neighbour calculation\nuns_neighbors: \"scanorama_integration_neighbors\"\nobsp_neighbor_distances: \"scanorama_integration_distances\"\nobsp_neighbor_connectivities: \"scanorama_integration_connectivities\"\n\n# Scanorama integration options\nobs_batch: \"sample_id\"\nobsm_input: \"X_pca\"\nobsm_output: \"X_scanorama\"\nknn: 20\nbatch_size: 5000\nsigma: 15\napprox: true\nalpha: 0.1\n\n# Clustering options\nobs_cluster: \"scanorama_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_leiden_scanorama_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/integration/scanorama_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration/scanorama_leiden.html#argument-groups",
    "href": "components/workflows/multiomics/integration/scanorama_leiden.html#argument-groups",
    "title": "Scanorama leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"scanorama_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"scanorama_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"scanorama_integration_connectivities\"\n\n\n\n\n\nScanorama integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--obsm_input\n.obsm slot that points to embedding to run scanorama on.\nstring, default: \"X_pca\"\n\n\n--obsm_output\nThe name of the field in adata.obsm where the integrated embeddings will be stored after running this function. Defaults to X_scanorama.\nstring, default: \"X_scanorama\"\n\n\n--knn\nNumber of nearest neighbors to use for matching.\ninteger, default: 20\n\n\n--batch_size\nThe batch size used in the alignment vector computation. Useful when integrating very large (&gt;100k samples) datasets. Set to large value that runs within available memory.\ninteger, default: 5000\n\n\n--sigma\nCorrection smoothing parameter on Gaussian kernel.\ndouble, default: 15\n\n\n--approx\nUse approximate nearest neighbors with Python annoy; greatly speeds up matching runtime.\nboolean, default: TRUE\n\n\n--alpha\nAlignment score minimum cutoff\ndouble, default: 0.1\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‘–obs_cluster’ suffixed with an underscore and one of the resolutions specified in ‘–leiden_resolution’.\nstring, default: \"scanorama_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \":\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_scanorama_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration/scanorama_leiden.html#authors",
    "href": "components/workflows/multiomics/integration/scanorama_leiden.html#authors",
    "title": "Scanorama leiden",
    "section": "Authors",
    "text": "Authors\n\nMauro Saporita   (author)\nPovilas Gibas   (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration/scanorama_leiden.html#visualisation",
    "href": "components/workflows/multiomics/integration/scanorama_leiden.html#visualisation",
    "title": "Scanorama leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v11(scanorama)\n    v13(join)\n    v21(find_neighbors)\n    v23(join)\n    v31(leiden)\n    v33(join)\n    v41(umap)\n    v43(join)\n    v51(move_obsm_to_obs)\n    v53(join)\n    v60(Output)\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v13\n    v4--&gt;v11\n    v11--&gt;v13\n    v13--&gt;v23\n    v13--&gt;v21\n    v21--&gt;v23\n    v23--&gt;v33\n    v23--&gt;v31\n    v31--&gt;v33\n    v33--&gt;v43\n    v33--&gt;v41\n    v41--&gt;v43\n    v43--&gt;v53\n    v43--&gt;v51\n    v51--&gt;v53\n    v53--&gt;v60"
  },
  {
    "objectID": "components/workflows/multiomics/integration/bbknn_leiden.html",
    "href": "components/workflows/multiomics/integration/bbknn_leiden.html",
    "title": "Bbknn leiden",
    "section": "",
    "text": "ID: bbknn_leiden\nNamespace: multiomics/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration/bbknn_leiden.html#example-commands",
    "href": "components/workflows/multiomics/integration/bbknn_leiden.html#example-commands",
    "title": "Bbknn leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/multiomics/integration/bbknn_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Bbknn\nobsm_input: \"X_pca\"\nobs_batch: \"sample_id\"\nuns_output: \"bbknn_integration_neighbors\"\nobsp_distances: \"bbknn_integration_distances\"\nobsp_connectivities: \"bbknn_integration_connectivities\"\nn_neighbors_within_batch: 3\nn_pcs: 50\n# n_trim: 123\n\n# Clustering options\nobs_cluster: \"bbknn_integration_leiden\"\nleiden_resolution: [1]\n\n# UMAP options\nobsm_umap: \"X_leiden_bbknn_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/integration/bbknn_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration/bbknn_leiden.html#argument-groups",
    "href": "components/workflows/multiomics/integration/bbknn_leiden.html#argument-groups",
    "title": "Bbknn leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nBbknn\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_input\nThe dimensionality reduction in .obsm to use for neighbour detection. Defaults to X_pca.\nstring, default: \"X_pca\"\n\n\n--obs_batch\n.obs column name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--uns_output\nMandatory .uns slot to store various neighbor output objects.\nstring, default: \"bbknn_integration_neighbors\"\n\n\n--obsp_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"bbknn_integration_distances\"\n\n\n--obsp_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"bbknn_integration_connectivities\"\n\n\n--n_neighbors_within_batch\nHow many top neighbours to report for each batch; total number of neighbours in the initial k-nearest-neighbours computation will be this number times the number of batches.\ninteger, default: 3\n\n\n--n_pcs\nHow many dimensions (in case of PCA, principal components) to use in the analysis.\ninteger, default: 50\n\n\n--n_trim\nTrim the neighbours of each cell to these many top connectivities. May help with population independence and improve the tidiness of clustering. The lower the value the more independent the individual populations, at the cost of more conserved batch effect. If None (default), sets the parameter value automatically to 10 times neighbors_within_batch times the number of batches. Set to 0 to skip.\ninteger\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‘–obs_cluster’ suffixed with an underscore and one of the resolutions resolutions specified in ‘–leiden_resolution’.\nstring, default: \"bbknn_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \":\"\n\n\n\n\n\nUMAP options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_bbknn_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration/bbknn_leiden.html#authors",
    "href": "components/workflows/multiomics/integration/bbknn_leiden.html#authors",
    "title": "Bbknn leiden",
    "section": "Authors",
    "text": "Authors\n\nMauro Saporita   (author)\nPovilas Gibas   (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration/bbknn_leiden.html#visualisation",
    "href": "components/workflows/multiomics/integration/bbknn_leiden.html#visualisation",
    "title": "Bbknn leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v10(bbknn)\n    v12(join)\n    v20(leiden)\n    v22(join)\n    v30(umap)\n    v32(join)\n    v40(move_obsm_to_obs)\n    v42(join)\n    v48(Output)\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v12\n    v4--&gt;v10\n    v10--&gt;v12\n    v12--&gt;v22\n    v12--&gt;v20\n    v20--&gt;v22\n    v22--&gt;v32\n    v22--&gt;v30\n    v30--&gt;v32\n    v32--&gt;v42\n    v32--&gt;v40\n    v40--&gt;v42\n    v42--&gt;v48"
  },
  {
    "objectID": "components/workflows/multiomics/integration/totalvi_leiden.html",
    "href": "components/workflows/multiomics/integration/totalvi_leiden.html",
    "title": "Totalvi leiden",
    "section": "",
    "text": "ID: totalvi_leiden\nNamespace: multiomics/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration/totalvi_leiden.html#example-commands",
    "href": "components/workflows/multiomics/integration/totalvi_leiden.html#example-commands",
    "title": "Totalvi leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/multiomics/integration/totalvi_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\nprot_modality: \"prot\"\nreference: # please fill in - example: \"path/to/file\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# reference_model_path: \"$id.$key.reference_model_path.reference_model_path\"\n# query_model_path: \"$id.$key.query_model_path.query_model_path\"\n\n# General TotalVI Options\nobs_batch: \"sample_id\"\nmax_epochs: 400\nmax_query_epochs: 200\nweight_decay: 0.0\nforce_retrain: false\n# var_input: \"foo\"\n\n# TotalVI integration options RNA\nrna_reference_modality: \"rna\"\nrna_obsm_output: \"X_totalvi\"\n\n# TotalVI integration options ADT\nprot_reference_modality: \"prot\"\nprot_obsm_output: \"X_totalvi\"\n\n# Neighbour calculation RNA\nrna_uns_neighbors: \"totalvi_integration_neighbors\"\nrna_obsp_neighbor_distances: \"totalvi_integration_distances\"\nrna_obsp_neighbor_connectivities: \"totalvi_integration_connectivities\"\n\n# Neighbour calculation ADT\nprot_uns_neighbors: \"totalvi_integration_neighbors\"\nprot_obsp_neighbor_distances: \"totalvi_integration_distances\"\nprot_obsp_neighbor_connectivities: \"totalvi_integration_connectivities\"\n\n# Clustering options RNA\nrna_obs_cluster: \"totalvi_integration_leiden\"\nrna_leiden_resolution: [1]\n\n# Clustering options ADT\nprot_obs_cluster: \"totalvi_integration_leiden\"\nprot_leiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_totalvi_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/integration/totalvi_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration/totalvi_leiden.html#argument-groups",
    "href": "components/workflows/multiomics/integration/totalvi_leiden.html#argument-groups",
    "title": "Totalvi leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--prot_modality\nWhich modality to process.\nstring, default: \"prot\"\n\n\n--reference\nInput h5mu file with reference data to train the TOTALVI model.\nfile, required\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n--reference_model_path\nDirectory with the reference model. If not exists, trained model will be saved there\nfile, default: \"totalvi_model_reference\"\n\n\n--query_model_path\nDirectory, where the query model will be saved\nfile, default: \"totalvi_model_query\"\n\n\n\n\n\nGeneral TotalVI Options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\n.Obs column name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--max_epochs\nNumber of passes through the dataset\ninteger, default: 400\n\n\n--max_query_epochs\nNumber of passes through the dataset, when fine-tuning model for query\ninteger, default: 200\n\n\n--weight_decay\nWeight decay, when fine-tuning model for query\ndouble, default: 0\n\n\n--force_retrain\nIf true, retrain the model and save it to reference_model_path\nboolean_true\n\n\n--var_input\nBoolean .var column to subset data with (e.g. containing highly variable genes). By default, do not subset genes.\nstring\n\n\n\n\n\nTotalVI integration options RNA\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_reference_modality\n\nstring, default: \"rna\"\n\n\n--rna_obsm_output\nIn which .obsm slot to store the normalized RNA from TOTALVI.\nstring, default: \"X_totalvi\"\n\n\n\n\n\nTotalVI integration options ADT\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_reference_modality\nName of the modality containing proteins in the reference\nstring, default: \"prot\"\n\n\n--prot_obsm_output\nIn which .obsm slot to store the normalized protein data from TOTALVI.\nstring, default: \"X_totalvi\"\n\n\n\n\n\nNeighbour calculation RNA\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"totalvi_integration_neighbors\"\n\n\n--rna_obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_distances\"\n\n\n--rna_obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_connectivities\"\n\n\n\n\n\nNeighbour calculation ADT\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"totalvi_integration_neighbors\"\n\n\n--prot_obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_distances\"\n\n\n--prot_obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"totalvi_integration_connectivities\"\n\n\n\n\n\nClustering options RNA\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‘–obs_cluster’ suffixed with an underscore and one of the resolutions resolutions specified in ‘–leiden_resolution’.\nstring, default: \"totalvi_integration_leiden\"\n\n\n--rna_leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \":\"\n\n\n\n\n\nClustering options ADT\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‘–obs_cluster’ suffixed with an underscore and one of the resolutions resolutions specified in ‘–leiden_resolution’.\nstring, default: \"totalvi_integration_leiden\"\n\n\n--prot_leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \":\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_totalvi_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration/totalvi_leiden.html#authors",
    "href": "components/workflows/multiomics/integration/totalvi_leiden.html#authors",
    "title": "Totalvi leiden",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration/totalvi_leiden.html#visualisation",
    "href": "components/workflows/multiomics/integration/totalvi_leiden.html#visualisation",
    "title": "Totalvi leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v3(toSortedList)\n    v5(flatMap)\n    v12(totalvi)\n    v14(join)\n    v23(find_neighbors)\n    v25(join)\n    v33(leiden)\n    v35(join)\n    v43(umap)\n    v45(join)\n    v53(move_obsm_to_obs)\n    v55(join)\n    v64(test_wf:run_wf:test_wf:run_wf:neighbors_leiden_umap:find_neighbors:find_neighbors_process1)\n    v66(join)\n    v74(test_wf:run_wf:test_wf:run_wf:neighbors_leiden_umap:leiden:leiden_process1)\n    v76(join)\n    v84(test_wf:run_wf:test_wf:run_wf:neighbors_leiden_umap:umap:umap_process1)\n    v86(join)\n    v94(test_wf:run_wf:test_wf:run_wf:neighbors_leiden_umap:move_obsm_to_obs:move_obsm_to_obs_process1)\n    v96(join)\n    v104(publish)\n    v106(join)\n    v112(Output)\n    v0--&gt;v3\n    v3--&gt;v5\n    v5--&gt;v14\n    v5--&gt;v12\n    v12--&gt;v14\n    v14--&gt;v25\n    v14--&gt;v23\n    v23--&gt;v25\n    v25--&gt;v35\n    v25--&gt;v33\n    v33--&gt;v35\n    v35--&gt;v45\n    v35--&gt;v43\n    v43--&gt;v45\n    v45--&gt;v55\n    v45--&gt;v53\n    v53--&gt;v55\n    v55--&gt;v66\n    v55--&gt;v64\n    v64--&gt;v66\n    v66--&gt;v76\n    v66--&gt;v74\n    v74--&gt;v76\n    v76--&gt;v86\n    v76--&gt;v84\n    v84--&gt;v86\n    v86--&gt;v96\n    v86--&gt;v94\n    v94--&gt;v96\n    v96--&gt;v106\n    v96--&gt;v104\n    v104--&gt;v106\n    v106--&gt;v112"
  },
  {
    "objectID": "components/workflows/multiomics/rna_singlesample.html",
    "href": "components/workflows/multiomics/rna_singlesample.html",
    "title": "Rna singlesample",
    "section": "",
    "text": "ID: rna_singlesample\nNamespace: multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/rna_singlesample.html#example-commands",
    "href": "components/workflows/multiomics/rna_singlesample.html#example-commands",
    "title": "Rna singlesample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/multiomics/rna_singlesample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\n\n# Filtering options\n# min_counts: 200\n# max_counts: 5000000\n# min_genes_per_cell: 200\n# max_genes_per_cell: 1500000\n# min_cells_per_gene: 3\n# min_fraction_mito: 0\n# max_fraction_mito: 0.2\n\n# Mitochondrial gene detection\n# var_name_mitochondrial_genes: \"foo\"\n# var_gene_names: \"gene_symbol\"\nmitochondrial_gene_regex: \"^[mM][tT]-\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/rna_singlesample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/rna_singlesample.html#argument-groups",
    "href": "components/workflows/multiomics/rna_singlesample.html#argument-groups",
    "title": "Rna singlesample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nFiltering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--min_genes_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--max_genes_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--min_cells_per_gene\nMinimum of non-zero values per gene.\ninteger, example: 3\n\n\n--min_fraction_mito\nMinimum fraction of UMIs that are mitochondrial.\ndouble, example: 0\n\n\n--max_fraction_mito\nMaximum fraction of UMIs that are mitochondrial.\ndouble, example: 0.2\n\n\n\n\n\nMitochondrial gene detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_name_mitochondrial_genes\nIn which .var slot to store a boolean array corresponding the mitochondrial genes.\nstring\n\n\n--var_gene_names\n.var column name to be used to detect mitochondrial genes instead of .var_names (default if not set). Gene names matching with the regex value from –mitochondrial_gene_regex will be identified as a mitochondrial gene.\nstring, example: \"gene_symbol\"\n\n\n--mitochondrial_gene_regex\nRegex string that identifies mitochondrial genes from –var_gene_names. By default will detect human and mouse mitochondrial genes from a gene symbol.\nstring, default: \"^[mM][tT]-\""
  },
  {
    "objectID": "components/workflows/multiomics/rna_singlesample.html#authors",
    "href": "components/workflows/multiomics/rna_singlesample.html#authors",
    "title": "Rna singlesample",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (author, maintainer)\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/rna_singlesample.html#visualisation",
    "href": "components/workflows/multiomics/rna_singlesample.html#visualisation",
    "title": "Rna singlesample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v3(toSortedList)\n    v5(flatMap)\n    v12(filter_with_counts)\n    v14(join)\n    v22(do_filter)\n    v24(join)\n    v32(filter_with_scrublet)\n    v34(join)\n    v42(Output)\n    v0--&gt;v3\n    v3--&gt;v5\n    v5--&gt;v14\n    v5--&gt;v12\n    v12--&gt;v14\n    v14--&gt;v24\n    v14--&gt;v22\n    v22--&gt;v24\n    v24--&gt;v34\n    v24--&gt;v32\n    v32--&gt;v34\n    v34--&gt;v42"
  },
  {
    "objectID": "components/workflows/multiomics/prot_singlesample.html",
    "href": "components/workflows/multiomics/prot_singlesample.html",
    "title": "Prot singlesample",
    "section": "",
    "text": "ID: prot_singlesample\nNamespace: multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/prot_singlesample.html#example-commands",
    "href": "components/workflows/multiomics/prot_singlesample.html#example-commands",
    "title": "Prot singlesample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/multiomics/prot_singlesample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\n\n# Filtering options\n# min_counts: 200\n# max_counts: 5000000\n# min_proteins_per_cell: 200\n# max_proteins_per_cell: 1500000\n# min_cells_per_protein: 3\n# min_fraction_mito: 0\n# max_fraction_mito: 0.2\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/prot_singlesample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/prot_singlesample.html#argument-groups",
    "href": "components/workflows/multiomics/prot_singlesample.html#argument-groups",
    "title": "Prot singlesample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nFiltering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--min_proteins_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--max_proteins_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--min_cells_per_protein\nMinimum of non-zero values per gene.\ninteger, example: 3\n\n\n--min_fraction_mito\nMinimum fraction of proteins that are mitochondrial.\ndouble, example: 0\n\n\n--max_fraction_mito\nMaximum fraction of proteins that are mitochondrial.\ndouble, example: 0.2"
  },
  {
    "objectID": "components/workflows/multiomics/prot_singlesample.html#authors",
    "href": "components/workflows/multiomics/prot_singlesample.html#authors",
    "title": "Prot singlesample",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (author, maintainer)\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/prot_singlesample.html#visualisation",
    "href": "components/workflows/multiomics/prot_singlesample.html#visualisation",
    "title": "Prot singlesample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v3(toSortedList)\n    v5(flatMap)\n    v12(filter_with_counts)\n    v14(join)\n    v22(do_filter)\n    v24(join)\n    v30(toSortedList)\n    v32(Output)\n    v0--&gt;v3\n    v3--&gt;v5\n    v5--&gt;v14\n    v5--&gt;v12\n    v12--&gt;v14\n    v14--&gt;v24\n    v14--&gt;v22\n    v22--&gt;v24\n    v24--&gt;v30\n    v30--&gt;v32"
  },
  {
    "objectID": "components/index.html",
    "href": "components/index.html",
    "title": "Components",
    "section": "",
    "text": "Order By\n       Default\n         \n          Name\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nName\n\n\nNamespace\n\n\nDescription\n\n\n\n\n\n\nWorkflows\n\n\n \n\n\n\n\n\n\n\nBD Rhapsody\n\n\nIngestion\n\n\nA generic pipeline for running BD Rhapsody WTA or Targeted mapping, with support for AbSeq, VDJ and/or SMK.\n\n\n\n\nBbknn leiden\n\n\nMultiomics/integration\n\n\nRun bbknn followed by leiden clustering and run umap on the result.\n\n\n\n\nCell Ranger mapping\n\n\nIngestion\n\n\nA pipeline for running Cell Ranger mapping.\n\n\n\n\nCell Ranger multi\n\n\nIngestion\n\n\nA pipeline for running Cell Ranger multi.\n\n\n\n\nCell Ranger post-processing\n\n\nIngestion\n\n\nPost-processing Cell Ranger datasets.\n\n\n\n\nConversion\n\n\nIngestion\n\n\nA pipeline to convert different file formats to .h5mu.\n\n\n\n\nDemux\n\n\nIngestion\n\n\nA generic pipeline for running bcl2fastq, bcl-convert or Cell Ranger mkfastq.\n\n\n\n\nFull pipeline\n\n\nMultiomics\n\n\nA pipeline to analyse multiple multiomics samples.\n\n\n\n\nHarmony leiden\n\n\nIntegration/common\n\n\nRun harmony integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nHarmony leiden\n\n\nMultiomics/integration\n\n\nRun harmony integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nInitialize integration\n\n\nIntegration/initialize integration\n\n\nRun calculations that output information required for most integration methods: PCA, nearest neighbour and UMAP.\n\n\n\n\nInitialize integration\n\n\nMultiomics/integration\n\n\nRun calculations that output information required for most integration methods: PCA, nearest neighbour and UMAP.\n\n\n\n\nIntegration\n\n\nMultiomics\n\n\nA pipeline for demultiplexing multimodal multi-sample RNA transcriptomics data.\n\n\n\n\nLeiden scvi\n\n\nMultiomics/integration\n\n\nRun scvi integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nMake reference\n\n\nIngestion\n\n\nBuild a transcriptomics reference into one of many formats\n\n\n\n\nMultisample\n\n\nMultiomics\n\n\nThis workflow serves as an entrypoint into the ‘full_pipeline’ in order to re-run the multisample processing and the integration setup.\n\n\n\n\nProt multisample\n\n\nMultiomics\n\n\nProcessing unimodal multi-sample ADT data.\n\n\n\n\nProt singlesample\n\n\nMultiomics\n\n\nProcessing unimodal single-sample CITE-seq data.\n\n\n\n\nQc\n\n\nQc\n\n\nA pipeline to add basic qc statistics to a MuData\n\n\n\n\nRna multisample\n\n\nMultiomics\n\n\nProcessing unimodal multi-sample RNA transcriptomics data.\n\n\n\n\nRna singlesample\n\n\nMultiomics\n\n\nProcessing unimodal single-sample RNA transcriptomics data.\n\n\n\n\nScanorama leiden\n\n\nIntegration/scanorama leiden\n\n\nRun scanorama integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScanorama leiden\n\n\nMultiomics/integration\n\n\nRun scanorama integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScvi\n\n\nIntegration/scvi\n\n\nRun scvi integration followed by neighbour calculations and run umap on the result.\n\n\n\n\nScvi leiden\n\n\nMultiomics/integration\n\n\nRun scvi integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nTotalvi leiden\n\n\nMultiomics/integration\n\n\nRun totalVI integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "components/index.html#workflows",
    "href": "components/index.html#workflows",
    "title": "Components",
    "section": "",
    "text": "Order By\n       Default\n         \n          Name\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nName\n\n\nNamespace\n\n\nDescription\n\n\n\n\n\n\nWorkflows\n\n\n \n\n\n\n\n\n\n\nBD Rhapsody\n\n\nIngestion\n\n\nA generic pipeline for running BD Rhapsody WTA or Targeted mapping, with support for AbSeq, VDJ and/or SMK.\n\n\n\n\nBbknn leiden\n\n\nMultiomics/integration\n\n\nRun bbknn followed by leiden clustering and run umap on the result.\n\n\n\n\nCell Ranger mapping\n\n\nIngestion\n\n\nA pipeline for running Cell Ranger mapping.\n\n\n\n\nCell Ranger multi\n\n\nIngestion\n\n\nA pipeline for running Cell Ranger multi.\n\n\n\n\nCell Ranger post-processing\n\n\nIngestion\n\n\nPost-processing Cell Ranger datasets.\n\n\n\n\nConversion\n\n\nIngestion\n\n\nA pipeline to convert different file formats to .h5mu.\n\n\n\n\nDemux\n\n\nIngestion\n\n\nA generic pipeline for running bcl2fastq, bcl-convert or Cell Ranger mkfastq.\n\n\n\n\nFull pipeline\n\n\nMultiomics\n\n\nA pipeline to analyse multiple multiomics samples.\n\n\n\n\nHarmony leiden\n\n\nIntegration/common\n\n\nRun harmony integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nHarmony leiden\n\n\nMultiomics/integration\n\n\nRun harmony integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nInitialize integration\n\n\nIntegration/initialize integration\n\n\nRun calculations that output information required for most integration methods: PCA, nearest neighbour and UMAP.\n\n\n\n\nInitialize integration\n\n\nMultiomics/integration\n\n\nRun calculations that output information required for most integration methods: PCA, nearest neighbour and UMAP.\n\n\n\n\nIntegration\n\n\nMultiomics\n\n\nA pipeline for demultiplexing multimodal multi-sample RNA transcriptomics data.\n\n\n\n\nLeiden scvi\n\n\nMultiomics/integration\n\n\nRun scvi integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nMake reference\n\n\nIngestion\n\n\nBuild a transcriptomics reference into one of many formats\n\n\n\n\nMultisample\n\n\nMultiomics\n\n\nThis workflow serves as an entrypoint into the ‘full_pipeline’ in order to re-run the multisample processing and the integration setup.\n\n\n\n\nProt multisample\n\n\nMultiomics\n\n\nProcessing unimodal multi-sample ADT data.\n\n\n\n\nProt singlesample\n\n\nMultiomics\n\n\nProcessing unimodal single-sample CITE-seq data.\n\n\n\n\nQc\n\n\nQc\n\n\nA pipeline to add basic qc statistics to a MuData\n\n\n\n\nRna multisample\n\n\nMultiomics\n\n\nProcessing unimodal multi-sample RNA transcriptomics data.\n\n\n\n\nRna singlesample\n\n\nMultiomics\n\n\nProcessing unimodal single-sample RNA transcriptomics data.\n\n\n\n\nScanorama leiden\n\n\nIntegration/scanorama leiden\n\n\nRun scanorama integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScanorama leiden\n\n\nMultiomics/integration\n\n\nRun scanorama integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nScvi\n\n\nIntegration/scvi\n\n\nRun scvi integration followed by neighbour calculations and run umap on the result.\n\n\n\n\nScvi leiden\n\n\nMultiomics/integration\n\n\nRun scvi integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\nTotalvi leiden\n\n\nMultiomics/integration\n\n\nRun totalVI integration followed by neighbour calculations, leiden clustering and run umap on the result.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "components/index.html#modules",
    "href": "components/index.html#modules",
    "title": "Components",
    "section": "Modules",
    "text": "Modules\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Name\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nName\n\n\nNamespace\n\n\nDescription\n\n\n\n\n\n\nModules\n\n\n \n\n\n\n\n\n\n\nAdd id\n\n\nMetadata\n\n\nAdd id of .obs.\n\n\n\n\nBD Rhapsody\n\n\nMapping\n\n\nA wrapper for the BD Rhapsody Analysis CWL v1.10.1 pipeline\n\n\n\n\nBbknn\n\n\nNeighbors\n\n\nBBKNN network generation\n\n\n\n\nBcl convert\n\n\nDemux\n\n\nConvert bcl files to fastq files using bcl-convert.\n\n\n\n\nBcl2fastq\n\n\nDemux\n\n\nConvert bcl files to fastq files using bcl2fastq\n\n\n\n\nBuild bdrhap reference\n\n\nReference\n\n\nCompile a reference into a STAR index compatible with the BD Rhapsody pipeline.\n\n\n\n\nBuild cellranger reference\n\n\nReference\n\n\nBuild a Cell Ranger-compatible reference folder from user-supplied genome FASTA and gene GTF files.\n\n\n\n\nCalculate qc metrics\n\n\nQc\n\n\nAdd basic quality control metrics to an .h5mu file.\n\n\n\n\nCellbender remove background\n\n\nCorrection\n\n\nEliminating technical artifacts from high-throughput single-cell RNA sequencing data.\n\n\n\n\nCellbender remove background v0 2\n\n\nCorrection\n\n\nEliminating technical artifacts from high-throughput single-cell RNA sequencing data.\n\n\n\n\nCellranger count\n\n\nMapping\n\n\nAlign fastq files using Cell Ranger count.\n\n\n\n\nCellranger count split\n\n\nMapping\n\n\nSplit 10x Cell Ranger output directory into separate output fields.\n\n\n\n\nCellranger mkfastq\n\n\nDemux\n\n\nDemultiplex raw sequencing data\n\n\n\n\nCellranger multi\n\n\nMapping\n\n\nAlign fastq files using Cell Ranger multi.\n\n\n\n\nCellxgene census\n\n\nQuery\n\n\nQuery CellxGene Census or user-specified TileDBSoma object, and eventually fetch cell and gene metadata or/and expression counts.\n\n\n\n\nClr\n\n\nTransform\n\n\nPerform CLR normalization on CITE-seq data (Stoeckius et al., 2017)\n\n\n\n\nCompress h5mu\n\n\nCompression\n\n\nCompress a MuData file.\n\n\n\n\nConcat\n\n\nDataflow\n\n\nConcatenates several uni-modal samples in .h5mu files into a single file\n\n\n\n\nDelete layer\n\n\nTransform\n\n\nDelete an anndata layer from one or more modalities\n\n\n\n\nDelimit fraction\n\n\nFilter\n\n\nTurns a column containing values between 0 and 1 into a boolean column based on thresholds\n\n\n\n\nDo filter\n\n\nFilter\n\n\nRemove observations and variables based on specified .obs and .var columns\n\n\n\n\nDownload file\n\n\nDownload\n\n\nDownload a file\n\n\n\n\nFastqc\n\n\nQc\n\n\nFastqc component, please see https://www.bioinformatics.babraham.ac.uk/projects/fastqc/.\n\n\n\n\nFilter 10xh5\n\n\nProcess 10xh5\n\n\nFilter a 10x h5 dataset\n\n\n\n\nFilter with counts\n\n\nFilter\n\n\nFilter scRNA-seq data based on the primary QC metrics.\n\n\n\n\nFilter with hvg\n\n\nFilter\n\n\nAnnotate highly variable genes [Satija15] [Zheng17] [Stuart19].\n\n\n\n\nFilter with scrublet\n\n\nFilter\n\n\nDoublet detection using the Scrublet method (Wolock, Lopez and Klein, 2019).\n\n\n\n\nFind neighbors\n\n\nNeighbors\n\n\nCompute a neighborhood graph of observations [McInnes18].\n\n\n\n\nFrom 10xh5 to h5mu\n\n\nConvert\n\n\nConverts a 10x h5 into an h5mu file\n\n\n\n\nFrom 10xmtx to h5mu\n\n\nConvert\n\n\nConverts a 10x mtx into an h5mu file\n\n\n\n\nFrom bd to 10x molecular barcode tags\n\n\nConvert\n\n\nConvert the molecular barcode sequence SAM tag from BD format (MA) to 10X format (UB)\n\n\n\n\nFrom bdrhap to h5mu\n\n\nConvert\n\n\nConvert the output of a BD Rhapsody WTA pipeline to a MuData h5 file\n\n\n\n\nFrom cellranger multi to h5mu\n\n\nConvert\n\n\nConverts the output from cellranger multi to a single .h5mu file.\n\n\n\n\nFrom h5ad to h5mu\n\n\nConvert\n\n\nConverts a single layer h5ad file into a single MuData object\n\n\n\n\nFrom h5mu to h5ad\n\n\nConvert\n\n\nConverts a h5mu file into a h5ad file\n\n\n\n\nGrep annotation column\n\n\nMetadata\n\n\nPerform a regex lookup on a column from the annotation matrices .obs or .var.\n\n\n\n\nHarmonypy\n\n\nIntegrate\n\n\nPerforms Harmony integration based as described in https://github.com/immunogenomics/harmony.\n\n\n\n\nHtseq count\n\n\nMapping\n\n\nQuantify gene expression for subsequent testing for differential expression.\n\n\n\n\nHtseq count to h5mu\n\n\nMapping\n\n\nConvert the htseq table to a h5mu\n\n\n\n\nJoin csv\n\n\nMetadata\n\n\nJoin a csv containing metadata to the .obs or .var field of a mudata file.\n\n\n\n\nJoin uns to obs\n\n\nMetadata\n\n\nJoin a data frame of length 1 (1 row index value) in .uns containing metadata to the .obs of a mudata file.\n\n\n\n\nKnn\n\n\nLabels transfer\n\n\nPerforms label transfer from reference to query using KNN classifier\n\n\n\n\nLeiden\n\n\nCluster\n\n\nCluster cells using the Leiden algorithm [Traag18] implemented in the Scanpy framework [Wolf18].\n\n\n\n\nLianapy\n\n\nInterpret\n\n\nPerforms LIANA integration based as described in https://github.com/saezlab/liana-py\n\n\n\n\nLog1p\n\n\nTransform\n\n\nLogarithmize the data matrix.\n\n\n\n\nMake params\n\n\nFiles\n\n\nLooks for files in a directory and turn it in a params file.\n\n\n\n\nMake reference\n\n\nReference\n\n\nPreprocess and build a transcriptome reference.\n\n\n\n\nMerge\n\n\nDataflow\n\n\nCombine one or more single-modality .h5mu files together into one .h5mu file\n\n\n\n\nMermaid\n\n\nReport\n\n\nGenerates a network from mermaid code\n\n\n\n\nMove obsm to obs\n\n\nMetadata\n\n\nMove a matrix from .obsm to .obs.\n\n\n\n\nMulti star\n\n\nMapping\n\n\nAlign fastq files using STAR.\n\n\n\n\nMulti star to h5mu\n\n\nMapping\n\n\nConvert the output of multi_star to a h5mu\n\n\n\n\nMultiqc\n\n\nQc\n\n\nMultiQC aggregates results from bioinformatics analyses across many samples into a single report.\n\n\n\n\nNormalize total\n\n\nTransform\n\n\nNormalize counts per cell.\n\n\n\n\nPca\n\n\nDimred\n\n\nComputes PCA coordinates, loadings and variance decomposition.\n\n\n\n\nPopv\n\n\nAnnotate\n\n\nPerforms popular major vote cell typing on single cell sequence data using multiple algorithms.\n\n\n\n\nPublish\n\n\nTransfer\n\n\nPublish an artifact and optionally rename with parameters\n\n\n\n\nRegress out\n\n\nTransform\n\n\nRegress out (mostly) unwanted sources of variation.\n\n\n\n\nRemove modality\n\n\nFilter\n\n\nRemove a modality from a .h5mu file\n\n\n\n\nSamtools sort\n\n\nMapping\n\n\nSort and (optionally) index alignments.\n\n\n\n\nScale\n\n\nTransform\n\n\nScale data to unit variance and zero mean\n\n\n\n\nScanorama\n\n\nIntegrate\n\n\nUse Scanorama to integrate different experiments\n\n\n\n\nScarches\n\n\nIntegrate\n\n\nPerforms reference mapping with scArches\n\n\n\n\nScvelo\n\n\nVelocity\n\n\n\n\n\n\n\nScvi\n\n\nIntegrate\n\n\nPerforms scvi integration as done in the human lung cell atlas https://github.com/LungCellAtlas/HLCA\n\n\n\n\nSplit modalities\n\n\nDataflow\n\n\nSplit the modalities from a single .h5mu multimodal sample into seperate .h5mu files.\n\n\n\n\nStar align\n\n\nMapping\n\n\nAlign fastq files using STAR.\n\n\n\n\nStar align v273a\n\n\nMapping\n\n\nAlign fastq files using STAR.\n\n\n\n\nStar build reference\n\n\nMapping\n\n\nCreate a reference for STAR from a set of fasta files.\n\n\n\n\nSubset h5mu\n\n\nFilter\n\n\nCreate a subset of a mudata file by selecting the first number of observations\n\n\n\n\nSync test resources\n\n\nDownload\n\n\nSynchronise the test resources from s3://openpipelines-data to resources_test\n\n\n\n\nTotalvi\n\n\nIntegrate\n\n\nPerforms mapping to the reference by totalvi model: https://docs.scvi-tools.org/en/stable/tutorials/notebooks/scarches_scvi_tools.html#Reference-mapping-with-TOTALVI\n\n\n\n\nUmap\n\n\nDimred\n\n\nUMAP (Uniform Manifold Approximation and Projection) is a manifold learning technique suitable for visualizing high-dimensional data.\n\n\n\n\nVelocyto\n\n\nVelocity\n\n\nRuns the velocity analysis on a BAM file, outputting a loom file.\n\n\n\n\nVelocyto to h5mu\n\n\nConvert\n\n\nConvert a velocyto loom file to a h5mu file.\n\n\n\n\nXgboost\n\n\nLabels transfer\n\n\nPerforms label transfer from reference to query using XGBoost classifier\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "team/index.html",
    "href": "team/index.html",
    "title": "Team",
    "section": "",
    "text": "Angela Oliveira Pisco\n      Contributor\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Director of Computational Biology \n           at \n              \n              Insitro\n              \n        \n      \n      \n        \n          Core Member \n           at \n              \n              Open Problems\n              \n        \n      \n    \n  \n  \n    \n    \n      Dries De Maeyer\n      Core Team Member\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Principal Scientist \n           at \n              \n              Janssen Pharmaceuticals\n              \n        \n      \n    \n  \n  \n    \n    \n      Dries Schaumont\n      Core Team Member\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Data Scientist \n           at \n              \n              Data Intuitive\n              \n        \n      \n    \n  \n  \n    \n    \n      Malte D. Luecken\n      Core Team Member\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Group Leader \n           at \n              \n              Helmholtz Munich\n              \n        \n      \n      \n        \n          Core Member \n           at \n              \n              Open Problems\n              \n        \n      \n    \n  \n  \n    \n    \n      Marijke Van Moerbeke\n      Contributor\n      \n        \n      \n      \n        \n      \n      \n        \n          Statistical Consultant \n           at \n              \n              OpenAnalytics\n              \n        \n      \n    \n  \n  \n    \n    \n      Matthias Beyens\n      Contributor\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Principal Scientist \n           at \n              \n              Janssen Pharmaceuticals\n              \n        \n      \n    \n  \n  \n    \n    \n      Mauro Saporita\n      Contributor\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Lead Nextflow Developer \n           at \n              \n              Ardigen\n              \n        \n      \n    \n  \n  \n    \n    \n      Povilas Gibas\n      Contributor\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Bioinformatician \n           at \n              \n              Ardigen\n              \n        \n      \n    \n  \n  \n    \n    \n      Robrecht Cannoodt\n      Core Team Member\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          Data Science Engineer \n           at \n              \n              Data Intuitive\n              \n        \n      \n      \n        \n          Core Member \n           at \n              \n              Open Problems\n              \n        \n      \n    \n  \n  \n    \n    \n      Samuel D'Souza\n      Contributor\n      \n        \n      \n      \n        \n      \n      \n        \n          Data Engineer \n           at \n              \n              Chan Zuckerberg Biohub\n              \n        \n      \n    \n  \n  \n    \n    \n      Toni Verbeiren\n      Core Team Member\n      \n        \n      \n      \n        \n      \n      \n        \n          Data Scientist and CEO \n           at \n              \n              Data Intuitive\n              \n        \n      \n    \n  \n  \n    \n    \n      Vladimir Shitov\n      Contributor\n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n      \n      \n        \n          PhD Candidate \n           at \n              \n              Helmholtz Munich\n              \n        \n      \n    \n  \n\n\nNo matching items"
  },
  {
    "objectID": "more_information/cheat_sheets.html",
    "href": "more_information/cheat_sheets.html",
    "title": "Cheat sheets",
    "section": "",
    "text": "Figure 1: Cheat sheet for developing modular pipeline components with Viash, including a sample Viash component (left) and common commands used throughout the various stages of a development cycle (right)."
  },
  {
    "objectID": "more_information/cheat_sheets.html#viash",
    "href": "more_information/cheat_sheets.html#viash",
    "title": "Cheat sheets",
    "section": "",
    "text": "Figure 1: Cheat sheet for developing modular pipeline components with Viash, including a sample Viash component (left) and common commands used throughout the various stages of a development cycle (right)."
  },
  {
    "objectID": "more_information/faq.html",
    "href": "more_information/faq.html",
    "title": "FAQ",
    "section": "",
    "text": "It is possible to add additional resources such as a file containing helper functions or other resources. All you need to do is list those files under the functionality.resources section of your component and refer to them in your script using meta[\"resources_dir\"] + \"/myresource.txt\". Please visit the Viash documentation for concrete examples on how to add helper functions and other resources to your component."
  },
  {
    "objectID": "more_information/faq.html#how-can-i-add-an-external-resource-to-my-viash-component",
    "href": "more_information/faq.html#how-can-i-add-an-external-resource-to-my-viash-component",
    "title": "FAQ",
    "section": "",
    "text": "It is possible to add additional resources such as a file containing helper functions or other resources. All you need to do is list those files under the functionality.resources section of your component and refer to them in your script using meta[\"resources_dir\"] + \"/myresource.txt\". Please visit the Viash documentation for concrete examples on how to add helper functions and other resources to your component."
  },
  {
    "objectID": "more_information/faq.html#what-does-__merge__-do",
    "href": "more_information/faq.html#what-does-__merge__-do",
    "title": "FAQ",
    "section": "What does __merge__ do?",
    "text": "What does __merge__ do?\nThe __merge__ field is used to merge another YAML into a Viash config. One of its uses is in making sure that all of the components in a task has the same API.\nEach task in OpenProblems contains strict definitions of the input/output file interface of its components and the file formats of those files. These interfaces are stored as YAML files in the api subdirectory of each task."
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "OpenPipelines.bio next release",
    "section": "",
    "text": "Add descriptions to all pages and add listings to index pages.\nUpdate documentation on creating components for developers.\nUpdate getting started page for developers\nUpdate project structure.\nUpdate information on running tests.\nUpdate “More information” pages\nWrite getting started page for user guide\nDocument how to run workflows\nDocument parameter lists"
  },
  {
    "objectID": "CHANGELOG.html#major-changes",
    "href": "CHANGELOG.html#major-changes",
    "title": "OpenPipelines.bio next release",
    "section": "",
    "text": "Add descriptions to all pages and add listings to index pages.\nUpdate documentation on creating components for developers.\nUpdate getting started page for developers\nUpdate project structure.\nUpdate information on running tests.\nUpdate “More information” pages\nWrite getting started page for user guide\nDocument how to run workflows\nDocument parameter lists"
  },
  {
    "objectID": "CHANGELOG.html#major-changes-1",
    "href": "CHANGELOG.html#major-changes-1",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.12.1 release."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-2",
    "href": "CHANGELOG.html#major-changes-2",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.12.0 release."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-3",
    "href": "CHANGELOG.html#major-changes-3",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.11.0 release."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-4",
    "href": "CHANGELOG.html#major-changes-4",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.10.0 release.\nAdd documentation for OpenPipelines architecture."
  },
  {
    "objectID": "CHANGELOG.html#minor-changes",
    "href": "CHANGELOG.html#minor-changes",
    "title": "OpenPipelines.bio next release",
    "section": "MINOR CHANGES",
    "text": "MINOR CHANGES\n\nAlso generate documentation for the multiple_sep values of component arguments."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-5",
    "href": "CHANGELOG.html#major-changes-5",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.9.0 release."
  },
  {
    "objectID": "CHANGELOG.html#minor-changes-1",
    "href": "CHANGELOG.html#minor-changes-1",
    "title": "OpenPipelines.bio next release",
    "section": "MINOR CHANGES",
    "text": "MINOR CHANGES\n\nUpdate to Viash actions 0.4.0."
  },
  {
    "objectID": "CHANGELOG.html#major-changes-6",
    "href": "CHANGELOG.html#major-changes-6",
    "title": "OpenPipelines.bio next release",
    "section": "MAJOR CHANGES",
    "text": "MAJOR CHANGES\n\nUpdate component documentation to v0.8.0 release.\nUse git submodule to access openpipeline repo.\nPropose new website structure.\nUpdate author page."
  },
  {
    "objectID": "user_guide/bug_reports.html",
    "href": "user_guide/bug_reports.html",
    "title": "Bug reports",
    "section": "",
    "text": "Issues with Openpipelines are being tracked on Github. In order for an issue to be fixed in a timely manner, creating a complete and reproducable is essential."
  },
  {
    "objectID": "user_guide/running_pipelines.html",
    "href": "user_guide/running_pipelines.html",
    "title": "Running pipelines",
    "section": "",
    "text": "Dependening on whether you want to run a workflow locally or on cloud infrastructure, using Nextflow Tower or not, you will need to use different commands."
  },
  {
    "objectID": "user_guide/running_pipelines.html#run-locally-from-the-cli",
    "href": "user_guide/running_pipelines.html#run-locally-from-the-cli",
    "title": "Running pipelines",
    "section": "Run locally from the CLI",
    "text": "Run locally from the CLI\nYou can run a workflow from the command line using the following command:\nnextflow run openpipelines-bio/openpipeline \\\n  -main-script target/nextflow/workflows/integration/multimodal_integration/main.nf \\\n  -revision 0.12.1 \\\n  -latest \\\n  -profile docker \\\n  --publish_dir foo/ \\\n  --input \"bar\" \\\n  --output \"test.txt\"\nDoing so will run the workflow locally using a Docker container."
  },
  {
    "objectID": "user_guide/running_pipelines.html#on-cloud-infrastructure",
    "href": "user_guide/running_pipelines.html#on-cloud-infrastructure",
    "title": "Running pipelines",
    "section": "On cloud infrastructure",
    "text": "On cloud infrastructure\nYou can use a similar command to run the workflow on cloud infrastructure, such as AWS Batch or Google Cloud Platform. However, this requires you to create a separate Nextflow config file for each cloud provider. See the Nextflow documentation for more information.\nnextflow run openpipelines-bio/openpipeline \\\n  -main-script target/nextflow/workflows/integration/multimodal_integration/main.nf \\\n  -revision 0.12.1 \\\n  -latest \\\n  --publish_dir foo/ \\\n  --input \"bar\" \\\n  --output \"test.txt\" \\\n  -c configs/my_hpc.config"
  },
  {
    "objectID": "user_guide/running_pipelines.html#using-the-nextflow-tower-cli",
    "href": "user_guide/running_pipelines.html#using-the-nextflow-tower-cli",
    "title": "Running pipelines",
    "section": "Using the Nextflow Tower CLI",
    "text": "Using the Nextflow Tower CLI\nIf you have access to a Nextflow Tower instance in which a Compute Environment has already been set up, you can run a workflow from the Tower CLI. The command is very similar to the command to run a workflow from the CLI, but you need to: * Use tw launch instead of nextflow run * Specify the workspace ID and compute environment ID * Rename arguments: -revision to --revision, -latest to --pull-latest, -main-script to --main-script, -c to --config * Store workflow arguments in a separate yaml file (if this was not already the case).\nExample:\ntw launch openpipelines-bio/openpipeline \\\n  --revision 0.12.1 \\\n  --pull-latest \\\n  --main-script target/nextflow/workflows/integration/multimodal_integration/main.nf \\\n  --workspace &lt;your workspace id&gt; \\\n  --compute-env &lt;your compute environment id&gt; \\\n  --params-file params.yaml \\\n  --config configs/my_hpc.config"
  },
  {
    "objectID": "user_guide/running_pipelines.html#using-the-nextflow-tower-web-ui",
    "href": "user_guide/running_pipelines.html#using-the-nextflow-tower-web-ui",
    "title": "Running pipelines",
    "section": "Using the Nextflow Tower Web UI",
    "text": "Using the Nextflow Tower Web UI\nIf you have access to a Nextflow Tower instance in which a Compute Environment has already been set up, you can run a workflow from the Tower UI. To do so, go to the “Launchpad” and click on the button “launch a run without configuration”.\n\nNext, fill in the required fields and click on “Launch run”.\n\nCompute environment: Select the compute environment you want to run the workflow on.\nPipeline to launch: Fill in openpipelines-bio/openpipeline.\nRevision number: The release number of the pipeline you want to run, e.g. 0.12.1. You can find the release number on the GitHub releases page.\nWork directory: The bucket path where the scratch data is stored.\nPipeline parameters: The YAML or JSON of the parameters that are passed to the pipeline. See the Components page for more information about the parameters of each pipeline."
  },
  {
    "objectID": "contributing/pull_requests.html",
    "href": "contributing/pull_requests.html",
    "title": "Publishing your changes",
    "section": "",
    "text": "After ensuring that the implemented changes pass all relevant tests and meets the contribution guidelines, you can create a pull request following the steps below."
  },
  {
    "objectID": "contributing/pull_requests.html#step-1-merge-upstream-repository",
    "href": "contributing/pull_requests.html#step-1-merge-upstream-repository",
    "title": "Publishing your changes",
    "section": "Step 1: Merge upstream repository",
    "text": "Step 1: Merge upstream repository\nBefore you contribute your changes need to merge the upstream main branch into your fork. This ensures that your changes are based on the latest version of the code.\nTo do this, enter the following commands adapted from Syncing a Fork in your terminal or command prompt:\n# add the upstream repository to your local repository\ngit remote add upstream https://github.com/openpipelines-bio/openpipeline.git\n# download the changes from the openpipelines repo\ngit fetch upstream\n# change your current branch to the branch of the pull request\ngit checkout &lt;feature_branch&gt;\n# merge the changes from upstream into your branch\ngit merge upstream/main\n# push the updates, your pull request will also be updated\ngit push"
  },
  {
    "objectID": "contributing/pull_requests.html#step-2-edit-changelog",
    "href": "contributing/pull_requests.html#step-2-edit-changelog",
    "title": "Publishing your changes",
    "section": "Step 2: Edit changelog",
    "text": "Step 2: Edit changelog\nAdd an entry to the CHANGELOG.md file describing the proposed changes."
  },
  {
    "objectID": "contributing/pull_requests.html#step-3-create-pull-request",
    "href": "contributing/pull_requests.html#step-3-create-pull-request",
    "title": "Publishing your changes",
    "section": "Step 3: Create pull request",
    "text": "Step 3: Create pull request\nThe following steps were adapted from Creating a pull request from a fork\n\nGo to https://github.com/openpipelines-bio/openpipeline/pulls.\nClick on the New pull request button.\nOn the compare page click on the link compare across forks below the title. \nOn the right side in the head section select your fork repo and the correct branch you want to merge.\nClick on Create pull request.\nConstruct your PR by giving it a title and description.\nMake sure you select the box below the description Allow edits from maintainers.\nIf the PR is ready for review click the button Create Pull Request. Otherwise you can click the arrow next to the button and select Create Draft Pull Request and click the button when it changes."
  },
  {
    "objectID": "contributing/pull_requests.html#next-steps",
    "href": "contributing/pull_requests.html#next-steps",
    "title": "Publishing your changes",
    "section": "Next steps",
    "text": "Next steps\n\nGithub Actions\nWhenever a Pull Request (including draft) is created a github workflow will perform checks. These checks need to be succesful as a minimum requirement before a merge can be done. When there are errors in the checks, try to fix them while waiting on a review. If it is not possible to fix the error, add a comment to the PR to let the reviewers know.\n\n\nReview\nYour PR will be reviewed by maintainers of OpenPipelines. During the review, you can be asked for changes to the code."
  },
  {
    "objectID": "contributing/getting_started.html",
    "href": "contributing/getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "The OpenPipelines code is hosted on GitHub. To start working on OpenPipelines, you should create your own copy of the repository by forking it. Visit the OpenPipelines repository here and use the ‘Fork’ button on the top right hand side of the page. After you are done forking, you can clone the repository to a local directory on your computer using git clone. You can choose between using an SSH key to log in to GitHub or username and password (HTTPS) to connect to github.\n\nHTTPSSSH\n\n\ngit clone https://github.com/&lt;YOUR USERNAME&gt;/openpipeline.git\ncd openpipeline\ngit remote add upstream https://github.com/openpipeline-bio/openpipeline.git\n\n\ngit clone git@github.com:&lt;YOUR USERNAME&gt;/openpipeline.git\ncd openpipeline\ngit remote add upstream https://github.com/openpipeline-bio/openpipeline.git"
  },
  {
    "objectID": "contributing/getting_started.html#forking-the-code-and-cloning-the-repository",
    "href": "contributing/getting_started.html#forking-the-code-and-cloning-the-repository",
    "title": "Getting started",
    "section": "",
    "text": "The OpenPipelines code is hosted on GitHub. To start working on OpenPipelines, you should create your own copy of the repository by forking it. Visit the OpenPipelines repository here and use the ‘Fork’ button on the top right hand side of the page. After you are done forking, you can clone the repository to a local directory on your computer using git clone. You can choose between using an SSH key to log in to GitHub or username and password (HTTPS) to connect to github.\n\nHTTPSSSH\n\n\ngit clone https://github.com/&lt;YOUR USERNAME&gt;/openpipeline.git\ncd openpipeline\ngit remote add upstream https://github.com/openpipeline-bio/openpipeline.git\n\n\ngit clone git@github.com:&lt;YOUR USERNAME&gt;/openpipeline.git\ncd openpipeline\ngit remote add upstream https://github.com/openpipeline-bio/openpipeline.git"
  },
  {
    "objectID": "contributing/getting_started.html#sec-install-viash-nextflow",
    "href": "contributing/getting_started.html#sec-install-viash-nextflow",
    "title": "Getting started",
    "section": "Install viash and nextflow",
    "text": "Install viash and nextflow\nTo start contributing to OpenPipelines, you will need at Java 11 (or higher) and Docker installed on your system.\nOpenPipelines is being developed in Viash and Nextflow. If you are unfamiliar with either one of these platforms, you can check out their respective documentation pages.\nYou can check if is installed correctly by running the following commands.\nnextflow run hello -with-docker\nviash --version"
  },
  {
    "objectID": "contributing/getting_started.html#fetch-test-resources",
    "href": "contributing/getting_started.html#fetch-test-resources",
    "title": "Getting started",
    "section": "Fetch test resources",
    "text": "Fetch test resources\nOpenPipelines uses a number of test resources to test the pipelines. If everything is installed correctly, you should be able to fetch these resources by running the following command.\nviash run src/download/sync_test_resources/config.vsh.yaml"
  },
  {
    "objectID": "contributing/index.html",
    "href": "contributing/index.html",
    "title": "Contributing",
    "section": "",
    "text": "Getting started: Install dependencies and fetch test resources\n  \n  \n    Project structure: The structure of OpenPipelines\n  \n  \n    Creating components: A guide on how to create new components\n  \n  \n    Creating pipelines: A guide on how to create new workflows\n  \n  \n    Running tests: How to run component and integration tests.\n  \n  \n    Publishing your changes: How to create a pull request\n  \n\n\nNo matching items"
  },
  {
    "objectID": "fundamentals/philosophy.html",
    "href": "fundamentals/philosophy.html",
    "title": "Philosophy",
    "section": "",
    "text": "Mission\nOpenPipelines are best-practice living workflows for single-cell uni- and multi-omics data. Building a best-practice pipeline requires knowledge and time that not one single person can provide, but rather requires input from a community. Additionally, a best-pratice pipeline needs constant maintenance to keep up to date with the latest standards, ideally sourcing input from a ‘living’ benchmark. Continuous improvement necessitates a robust system for sourcing and applying community input both from a technical and organisational standpoint.\n\n\n\n\ngraph TB\n  ben[\"🌱📈 Living benchmarks\"]\n  pra[\"🌱📖 Living best practices\"]\n  pip[\"🌱⚙️ Living reproducible pipelines\"]\n  ben --&gt; pra --&gt; pip"
  },
  {
    "objectID": "fundamentals/concepts.html",
    "href": "fundamentals/concepts.html",
    "title": "Concepts",
    "section": "",
    "text": "Goals\nOpenPipelines strives to provide easy ways to interact with the pipeline and/or codebase for three types of users:\n\nPipeline executor: runs the pipeline from a GUI side\nPipeline editor: adapts pipelines with existing components for specific projects\nComponent developer: develops novel components and or pipelines\n\nThis means that openpipelines must be:\n\nUsable by non-experts\nEasy to deploy\nProvide reproducable results\nScalable\nEasy to maintain and adapt\n\n\n\nRequirements\nTo meet these demands, the following concepts have been implemented at the core of Openpipeline:\n\n🌍 A language independent framework\n💾 A versitile storage solution\n🔳 Modularity\n🔀 A best-practice pipeline layout\n⌛ Versioning\n✅ Automatic testing\n💬 Community input\n📺 A graphical interace\n\n\n\nA common file format: AnnData and MuData 💾\nOne of the core principals of OpenPipelines is to use MuData as a common data format throughout the whole pipeline. This means that the input and output for most components and workflows will be a MuData file and converters from and to other common data formats are provided to improve compatibility with up-and downstream applications. Choosing a common data format greatly diminishes the development complexity because it facilitates interfacing between different tools in a pipeline without needing to convert multiple times.\nMuData is a format to store annotated multimodal data. It is derived from the AnnData format. If you are unfamiliar with AnnData or MuData, it is recommended to read up on AnnData first as it is the unimodal counterpart of MuData. MuData can be roughly described as collection of several AnnData objects (stored as a associative array in the .mod attribute). MuData provides a hierarchical way to store the data:\nMuData\n├─ .mod\n│  ├─ modality_1 (AnnData Object)\n│     ├─ .X\n│     ├─ .layers\n│         ├─ layer_1 \n│         ├─ ...\n│     ├─ .var\n│     ├─ .obs\n│     ├─ .obsm\n│     ├─ .varm\n│     ├─ .uns\n│  ├─ modality_2 (AnnData Object)\n├─ .var\n├─ .obs\n├─ .obms\n├─ .varm\n├─ .uns\n\n.mod: an associative array of AnnData objects. Used in OpenPipelines to store the different modalities (CITE-seq, RNA abundance, …)\n.X and .layers: matrices storing the measurements with the columns being the variables measured and the rows being the observations (cells in most cases).\n.var: metadata for the variables (i.e. annotation for the columns of .X or any matrix in .layers). The number of rows in the .var datafame (or the length of each entry in the dictionairy) is equal to the number of columns in the measurement matrices.\n.obs: metadata for the observations (i.e. annotation for the rows of .X or any matrix in .layers). The number of rows in the .obs datafame (or the length of each entry in the dictionairy) is equal to the number of rows in the measurement matrices.\nvarm: the multi-dimensional variable annotation. A key-dataframe mapping where the number of rows in each dataframe is equal to the number of columns in the measurement matrices.\nobsm: the multi-dimensional observation annotation. A key-dataframe mapping where the number of rows in each dataframe is equal to the number of rows in the measurement matrices.\n.uns: A mapping where no restrictions are enforced on the dimensions of the data.\n\n\n\nModularity and a language independent framework 🔳\nTODO\n\n\nA graphical interface 📺\nTODO"
  },
  {
    "objectID": "fundamentals/index.html",
    "href": "fundamentals/index.html",
    "title": "Fundamentals",
    "section": "",
    "text": "Philosophy: Our approach and mission\n  \n  \n    Concepts: The core concepts behind this project\n  \n  \n    Architecture: Structure of the project\n  \n  \n    Roadmap: Development roadmap\n  \n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OpenPipelines",
    "section": "",
    "text": "Fundamentals\n  \n  \n        \n  \n  Philosophy\n  \n    \n        \n  \n  Concepts\n  \n    \n        \n  \n  Architecture\n  \n    \n        \n  \n  Roadmap\n  \n    \n  \n\nNo matching items\n\n\n\n\n\n  \n  User Guide\n  \n  \n        \n  \n  Getting started\n  \n    \n        \n  \n  Running pipelines\n  \n    \n        \n  \n  Passing parameter lists\n  \n    \n        \n  \n  Ingestion\n  \n    \n        \n  \n  Processing\n  \n    \n        \n  \n  Downstream\n  \n    \n        \n  \n  Bug reports\n  \n    \n  \n\nNo matching items\n\n\n\n\n\n  \n  Contributing\n  \n  \n        \n  \n  Getting started\n  \n    \n        \n  \n  Project structure\n  \n    \n        \n  \n  Creating components\n  \n    \n        \n  \n  Creating pipelines\n  \n    \n        \n  \n  Running tests\n  \n    \n        \n  \n  Publishing your changes\n  \n    \n  \n\nNo matching items\n\n\n\n\n\n  \n  More information\n  \n  \n        \n  \n  Cheat sheets\n  \n    \n        \n  \n  Code of conduct\n  \n    \n        \n  \n  FAQ\n  \n    \n  \n\nNo matching items"
  },
  {
    "objectID": "fundamentals/architecture.html",
    "href": "fundamentals/architecture.html",
    "title": "Architecture",
    "section": "",
    "text": "OpenPipeline is a pipeline for the processing of multimodal single-cell data that scales to a great many of samples. Covering the architecture requires us to explain many angles, including: what the expected inputs and outputs are for each workflow are, how do the workflows relate to each other, and what the state of the data is at each step of the pipeline. Here is an overview of the general steps involved in processing sequencing data into a single integrated object. We will discuss each of the steps further below.\nflowchart TD  \n  ingest[\"Ingestion\"] --&gt; split --&gt; unimodalsinglesample[\"Unimodal Single Sample Processing\"] --&gt; concat --&gt; unimodalmultisample[\"Unimodal Multi Sample Processing\"] --&gt; merging --&gt; integation_setup[\"Integration Setup\"] --&gt; integration[\"Integration\"]  --&gt; downstreamprocessing[\"Downstream Processing\"]\n\n\nFigure 1: Overview of the steps included in OpenPipeline for the analysis of single cell multiomics data."
  },
  {
    "objectID": "fundamentals/architecture.html#ingestion-workflows",
    "href": "fundamentals/architecture.html#ingestion-workflows",
    "title": "Architecture",
    "section": "Ingestion workflows",
    "text": "Ingestion workflows\nAll of the following workflows from the ingestion namespace have been discussed in more detail in the ingestion section:\n\ningestion/bd_rhapsody\ningestion/cellranger_mapping\ningestion/cellranger_multi\ningestion/demux\ningestion/make_reference"
  },
  {
    "objectID": "fundamentals/architecture.html#multiomics-workflows",
    "href": "fundamentals/architecture.html#multiomics-workflows",
    "title": "Architecture",
    "section": "Multiomics workflows",
    "text": "Multiomics workflows\nThere exists no singlesample workflow. However, the prot_singlesample and rna_singlesample pipelines do exist and they map identically to the functionality described in the single-sample antibody capture processing and single-sample gene expression processing sections respectively. If you would like to process your samples as described in the unimodal single sample processing section, you can execute both workflows in tandem for the two modalities.\nContrary to the workflows for single sample processing, there exists a multiomics/multisample workflow. However this workflow is not just the multiomics/prot_multisample and multiomics/rna_multisample workflows that have been combined. Instead, it combines the multiomics/prot_multisample, multiomics/rna_multisample and multiomics/integration/initialize_integration workflows. The purpose of this pipeline is to provide an extra ‘entrypoint’ into the full pipeline that skips the singlesample processing, allowing reprocessing samples that have already been processed before. A popular usecase is to manually select one or more celltypes which need to be processed again or the integration of observations from multiple experiments into a single dataset. Keep in mind that concatenation is not included in the multisample pipeline, so when multiple input files are specified they are processed in parallel. If you would like to integrate multiple experiments, you need to first concatenate them in a seperate step:"
  },
  {
    "objectID": "fundamentals/architecture.html#the-full-pipeline",
    "href": "fundamentals/architecture.html#the-full-pipeline",
    "title": "Architecture",
    "section": "The “full” pipeline",
    "text": "The “full” pipeline\nThe name of this pipeline is a bit of a misnomer, because it does not include all the steps from ingestion to integration. As will be discussed in the ingestion section, which ingestion strategy you need is dependant on your technology provider and the chosen platform. For integration, there exist many methods and combination of methods, and you may wish to choose which integration methods are applicable for your usecase. As a consequence, these two stages in the analysis of single-cell need to be executed seperatly and not as part of a single unified pipeline. All other steps outlined below on the other hand are included into the “full” pipeline, which can therefore be summarized in the following figure:\n\n\n\n\n\nflowchart TD  \n  split --&gt; unimodalsinglesample[\"Unimodal Single Sample Processing\"] --&gt; concat --&gt; unimodalmultisample[\"Unimodal Multi Sample Processing\"] --&gt; merging --&gt; integation_setup\n\n\nFigure 2: Overview of the steps included in the full pipelines from OpenPipeline."
  },
  {
    "objectID": "fundamentals/architecture.html#integration-workflows",
    "href": "fundamentals/architecture.html#integration-workflows",
    "title": "Architecture",
    "section": "Integration workflows",
    "text": "Integration workflows\nFor each of the integration methods (and their optional combination with other tools), a seperate pipeline is defined. More information for each of the pipelines is available in the integration methods section.\n\nmultiomics/integration/bbknn_leiden\nmultiomics/integration/harmony_leiden\nmultiomics/integration/scanorama_leiden\nmultiomics/integration/scvi_leiden\nmultiomics/integration/totalvi_leiden\nmultiomics/integration/initialize_integration"
  },
  {
    "objectID": "fundamentals/architecture.html#sec-splitting",
    "href": "fundamentals/architecture.html#sec-splitting",
    "title": "Architecture",
    "section": "Splitting modalities",
    "text": "Splitting modalities\nWe refer to splitting modalities when multimodal MuData file is split into several unimodal MuData files. The number of output files is equal to the number of modalities present in the input file. Splitting the modalities works on MuData files containing data for multiple samples or for single-sample files."
  },
  {
    "objectID": "fundamentals/architecture.html#sec-merging",
    "href": "fundamentals/architecture.html#sec-merging",
    "title": "Architecture",
    "section": "Merging of modalities",
    "text": "Merging of modalities\nMerging refers to combining multiple files with data for one modality into a single output file that contains all input modalities. It is the inverse operation of splitting the modalities."
  },
  {
    "objectID": "fundamentals/architecture.html#concatenation-of-samples",
    "href": "fundamentals/architecture.html#concatenation-of-samples",
    "title": "Architecture",
    "section": "Concatenation of samples",
    "text": "Concatenation of samples\nJoining of observations for different samples, stored in their respective MuData file, into a single MuData file for all samples together is called sample concatenation. In practice, this operation is performed for each modality separately. An extra column (with default name sample_id) is added to the annotation of the observations (.obs) to indicate where each observation originated from.\n\nSpecial care must be taken when considering annotations for observations and features while concatenating the samples. Indeed, the data from different samples can contain conflicting information. Openpipeline’s concat component provides an argument other_axis_mode that allows a user to specify what happens when conflicting information is found. The move option for this argument is the default behavior. In this mode, each annotation column (from .obs and .var) is compared across samples. When no conflicts are found or the column is unique for a sample, the column is added output object. When a conflict does occur, all of the columns are gathered from the samples and stored into a dataframe. This dataframe is then stored into .obsm for annotations for the observations and .varm for feature annotations. This way, a user can have a look at the conflicts and decide what to do with them."
  },
  {
    "objectID": "fundamentals/architecture.html#creating-a-transcriptomics-reference",
    "href": "fundamentals/architecture.html#creating-a-transcriptomics-reference",
    "title": "Architecture",
    "section": "Creating a transcriptomics reference",
    "text": "Creating a transcriptomics reference\nMapping reads from the FASTQ files to features requires a reference that needs to be provided to the mapping component. Depending on the usecase, you might even need to provide references specific for the modalities that you are trying to analyze. For gene expression data, the reference is a reference genome, together with its appropriate gene annotation. A genome reference is often indexed in order to improve the mapping speed. Additionally, some mapping frameworks provided by the single-cell technology providers require extra preprocessing of the reference before they can be used with their worklow. OpenPipelines provides a make_reference that allows you to create references in many formats which can be used to map your reads to."
  },
  {
    "objectID": "fundamentals/architecture.html#sec-single-sample-gex",
    "href": "fundamentals/architecture.html#sec-single-sample-gex",
    "title": "Architecture",
    "section": "Single-sample Gene Expression Processing",
    "text": "Single-sample Gene Expression Processing\nSingle-sample gene expression processing involves two steps: removing cells based on count statistics and flagging observations originating from doublets.\nThe removal of cells based on basic count statistics is split up into two parts: first, cells are flagged for removal by filter_with_counts. It flags observations based on several thresholds:\n\nThe number of genes that have a least a single count. Both a maximum and minimum number of genes for a cell to be removed can be specified.\nThe percentage of read counts that originated from a mitochodrial genes. Cells can be filtered based on both a maximum or minimum fraction of mitochondrial genes.\nThe minimum or maximum total number of counts captured per cell. Cells with 0 total counts are always removed.\n\nFlagging cells for removal involved adding a boolean column to the .obs dataframe. After the cells have been flagged for removal, the cells are actually filtered using do_filter, which reads the values in .obs and removed the cells labeled True. This applies the general phylosophy of “separation of concerns”: one component is responsible for labeling the cells, another for removing them. This keeps the codebase for a single component small and its functionality testable.\nThe next and final step in the single-sample gene expression processing is doublet detection using filter_with_scrublet. Like filter_with_counts, it will not remove cells but add a column to .obs (which have the name filter_with_scrublet by default). The single-sample GEX workflow will not remove not be removed during the processing (hence no do_filter). However, you can choose to remove them yourself before doing your analyses by applying a filter with the column in .obs yourself."
  },
  {
    "objectID": "fundamentals/architecture.html#sec-single-sample-adt",
    "href": "fundamentals/architecture.html#sec-single-sample-adt",
    "title": "Architecture",
    "section": "Single-sample Antibody Capture Processing",
    "text": "Single-sample Antibody Capture Processing\nThe process of filtering antibody capture data is similar to the filtering in the single-sample gene-expression processing, but without doublet detection. In some particular cases you can use your ADT data to perform doublet detection using for example cell-type maskers. More information can be found in the single-cell best practices book."
  },
  {
    "objectID": "fundamentals/architecture.html#multisample-gene-expression-processing",
    "href": "fundamentals/architecture.html#multisample-gene-expression-processing",
    "title": "Architecture",
    "section": "Multisample Gene Expression Processing",
    "text": "Multisample Gene Expression Processing\nProcessing multisample gene expression involved the following steps:\n\nNormalization: Normalization aims to adjust the raw counts in the dataset for variable sampling effects by scaling the observable variance to a specified range. There are different ways to transform the data, but the normalization method is to make sure each observation (cell) has a total count equal to the median of total counts over all genes for observations (cells) before normalization.\nLog transformation: Calculates \\(X = ln(X + 1)\\), which converts multiplicative relative changes to additive differences. This allows for interpreting the gene expression in terms of relative, rather than absolute, abundances of genes.\nHighly variable gene detection: Detects genes that have a large change in expression between samples. By default, OpenPipeline uses the method from Seurat (Satija et al.). As with other “filtering” components, the filter_with_hvg component does not remove features, but rather annotates genes of interest by adding a boolean column to .var.\nQC metric calculations"
  },
  {
    "objectID": "fundamentals/architecture.html#multisample-antibody-capture-processing",
    "href": "fundamentals/architecture.html#multisample-antibody-capture-processing",
    "title": "Architecture",
    "section": "Multisample Antibody Capture Processing",
    "text": "Multisample Antibody Capture Processing\nProcessing the ADT modality for multiple samples"
  },
  {
    "objectID": "fundamentals/architecture.html#sec-dimensionality-reduction",
    "href": "fundamentals/architecture.html#sec-dimensionality-reduction",
    "title": "Architecture",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\nscRNA-seq is a high-throughput sequencing technology that produces datasets with high dimensions in the number of cells and genes. It is true that the data should provide more information, but it also contains more noise and redudant information, making it harder to distill the usefull information. The number of genes and cells can already reduced by gene filtering, but further reduction is a necessity for downstream analysis. Dimensionality reduction projects high-dimensional data into a lower dimensional space (like taking a photo (2D) of some 3D structure). The lower dimensional representation still captures the underlying information of the data, while having fewer dimensions.\nSeveral dimensionality reduction methods have been developed and applied to single-cell data analysis. Two of which are being applied in OpenPipeline:\n\nPrincipal Component Analysis (PCA): PCA reduces the dimension of a dataset by creating a new set of variables (principal components, PCs) from a linear combination of the original features in such a way that they are as uncorrelated as possible. The PCs can be ranked in the order by which they explain the largest variability in the original dataset. By keeping the top n PCs, the PCs with the lowest variance are discarded to effectively reduce the dimensionality of the data without losing information.\nUniform manifold approximation and projection (UMAP): a non-linear dimensionality technique. It constructs a high dimensional graph representation of the dataset and optimizes the low-dimensional graph representation to be structurally as similar as possible to the original graph. In a review by Xiang et al., 2021 it showed the highest stability and separates best the original cell populations.\nt-SNE is another popular non-linear, graph based dimensionality technique which is very similar to UMAP, but it has not yet been implemented in OpenPipeline."
  },
  {
    "objectID": "fundamentals/architecture.html#sec-initializing-integration",
    "href": "fundamentals/architecture.html#sec-initializing-integration",
    "title": "Architecture",
    "section": "Initializing integration",
    "text": "Initializing integration\nAs will be descibed in more details later on, many integration methods exist and therefore there is no single integration which is executed by default. However, there are common tasks which are run before integration either because they provide required input for many downstream integration methods or because they popular steps that would otherwise be done manually. These operations are executed by default when using the “full pipeline” as part of the initialize_integration subworkflow.\nPCA is used to reduce the dimensionality of the dataset as described previously. Find Neighbors and Leiden Clustering are useful for the identification of cell types or states in the data. Here we apply a popular method to accomplish this is to first calculate a neighborhood graph on a low dimensinonal representation of the data and then cluster the data based on similarity between data points. Finally, UMAP allows us to visualise the clusters by reducing the dimensionality of the data while still providing an accurate representation of the underlying cell population structure."
  },
  {
    "objectID": "fundamentals/architecture.html#sec-integration-methods",
    "href": "fundamentals/architecture.html#sec-integration-methods",
    "title": "Architecture",
    "section": "Integration Methods",
    "text": "Integration Methods\nIntegration is the alignment of cell types across samples. There exist three different types of integration methods, based on the degree of integration across modalities:\n\nUnimodal integration across batches. For example: scVI, scanorama, harmony\nMultimodal integration across batches and modalities. Can be used to integrate joint-profiling data where multiple modalities are measured. For example: totalVI\nMosaic integration: data integration across batches and modalities where not all cells are profiled in all modalities and it may be the case that no cells contain profiles in all integrated modalities. Mosaic integration methods have not been made available in OpenPipeline yet. An example of a tool that performs mosaic integration is StabMap.\n\nIn either of the three cases, concatenated samples are required, and merged modalities preferred. A plethora of integration methods exist, which in turn interact with other functionality (like clustering and dimensionality reduction methods) to generate a large number of possible usecases which one pipeline cannot cover in an easy manner. Therefore, there is no single integration step that is part of a global pipeline which is executed by default. Instead, a user can choose from the integration workflows provided, and ‘stack’ integration methods by adding the outputs to different output slots of the MuData object. The following sections will descibe the integration workflows that are available in OpenPipeline.\n\nUnimodal integration\nFor unimodal integration, scVI, scanorama and harmony have been added to the scvi_leiden, scanorama_leiden, and harmony_leiden workflows respectively. After executing the integration methods themselves, Find Neighbors and Leiden Clustering are run the results of the integration as wel as UMAP in order to be able to visualise the results. The functioning of these components has already been described here.\n\n\n\nMultimodal Integration\nA single multimodal integration method is currently avaiable in OpenPipeline: totalVI. It allows using information from both the gene-expression data and the antibody-capture data together to integrate the cell types. As with the other integration workflows, after running totalVI, Find Neighbors, Leiden Clustering and UMAP are run on the result. However in this case the three components are executed on both of the integrated modalities."
  },
  {
    "objectID": "fundamentals/roadmap.html",
    "href": "fundamentals/roadmap.html",
    "title": "Roadmap",
    "section": "",
    "text": "flowchart LR\n  classDef done fill:#a3f6cf,stroke:#000000;\n  classDef wip fill:#f4cb93,stroke:#000000;\n  classDef unprocessed fill:#afadff,stroke:#000000;\n\n  Raw1[Sample 1] --&gt; Split1[/Split\\nmodalities/]:::done --&gt; ProcGEX1 & ProcRNAV1 & ProcADT1 & ProcATAC1 & ProcVDJ1\n  ProcGEX1[/Process GEX\\nprofile/]:::done --&gt; ConcatGEX[/Concatenate\\nprofiles/]:::done --&gt; ProcGEX[/Process GEX\\nprofiles/]:::done\n  ProcRNAV1[/Process RNAV\\nprofile/]:::wip --&gt; ConcatRNAV[/Concatenate\\nprofiles/]:::done --&gt; ProcRNAV[/Process RNAV\\nprofiles/]:::wip\n  ProcADT1[/Process ADT\\nprofile/]:::done --&gt; ConcatADT[/Concatenate\\nprofiles/]:::done --&gt; ProcADT[/Process ADT\\nprofiles/]:::done\n  ProcATAC1[/Process ATAC\\nprofile/]:::unprocessed --&gt; ConcatATAC[/Concatenate\\nprofiles/]:::done --&gt; ProcATAC[/Process ATAC\\nprofiles/]:::unprocessed\n  ProcVDJ1[/Process VDJ\\nprofile/]:::unprocessed --&gt; ConcatVDJ[/Concatenate\\nprofiles/]:::done --&gt; ProcVDJ[/Process VDJ\\nprofiles/]:::unprocessed\n  ProcGEX & ProcRNAV & ProcADT & ProcATAC & ProcVDJ --&gt; Merge[/Merge\\nmodalities/]:::done --&gt; SetupIntegration[/Setup\\nintegration/]:::done --&gt; Integration[/Integration/]:::done\n\n\nFigure 1: Status of implemented components. Green: implemented, orange: work in progress, purple: modality included in output but unprocessed,\nGEX: Gene-expression. RNAV: RNA Velocity. ADT: Antibody-Derived Tags. ATAC: Assay for Transposase-Accessible Chromatin."
  },
  {
    "objectID": "contributing/running_tests.html",
    "href": "contributing/running_tests.html",
    "title": "Running tests",
    "section": "",
    "text": "The input data that is needed to run the tests will need to be downloaded from the openpipelines Amazon AWS s3 bucket first. To do so, the download/sync_test_resource component can be used, which will download the data to the correct location (resources_test) by default.\nviash run src/download/sync_test_resources/config.vsh.yaml"
  },
  {
    "objectID": "contributing/running_tests.html#fetch-the-test-data",
    "href": "contributing/running_tests.html#fetch-the-test-data",
    "title": "Running tests",
    "section": "",
    "text": "The input data that is needed to run the tests will need to be downloaded from the openpipelines Amazon AWS s3 bucket first. To do so, the download/sync_test_resource component can be used, which will download the data to the correct location (resources_test) by default.\nviash run src/download/sync_test_resources/config.vsh.yaml"
  },
  {
    "objectID": "contributing/running_tests.html#run-component-tests",
    "href": "contributing/running_tests.html#run-component-tests",
    "title": "Running tests",
    "section": "Run component tests",
    "text": "Run component tests\nTo build and run tests for individual component that you are working on, use viash test with the config.vsh.yaml of the component you would like to test. For example:\nviash test src/convert/from_10xh5_to_h5mu/config.vsh.yaml\nKeep in mind that when no platform is passed to viash test, it will use the first platform that is specified in the config, which is docker for most of the components in openpipelines. Use -p native for example if you do not want to use docker.\nIt is also possible to execute the tests for all components in each namespace using:\nviash ns test --parallel -q convert"
  },
  {
    "objectID": "contributing/running_tests.html#run-integration-tests",
    "href": "contributing/running_tests.html#run-integration-tests",
    "title": "Running tests",
    "section": "Run integration tests",
    "text": "Run integration tests\nIndividual integration tests can be run by using the integration_test.sh scripts for a pipeline, located next to the main.nf in the src/workflows folder.\nsrc/workflows/ingestion/cellranger_demux/integration_test.sh"
  },
  {
    "objectID": "contributing/project_structure.html",
    "href": "contributing/project_structure.html",
    "title": "Project structure",
    "section": "",
    "text": "The root of the repository contains two main folders:\n\nsrc, which contains the source code for components and workflows.\n(optionally) the target folder\n\nEach subfolder from src contains a Viash namespace, a logical grouping of pipeline components that perform a similar function. Within each namespace, subfolders designate individual pipeline components. For example ./src/convert/from_bdrhap_to_h5ad contains the implementation for a component from_bdrhap_to_h5ad which is grouped together with other components such as from_10xmtx_to_h5mu into a namespace convert. In a similar manner as grouping components into namespaces, pipelines are grouped together into folders. However, these are not component namespaces and as such do not interact with viash ns commands.\nAs will become apparent later on, Viash not only provides commands to perform operations on individual components, but also on groups of components in a namespace and all components in a project. As a rule of thumb, the basic Viash commands (like viash test) are designated for running commands on individual components, while ns commands are (viash ns test) are for namespaces. When cloning a fresh repository, there will be no target folder present. This is because the target folder will only be created after components have been build."
  },
  {
    "objectID": "contributing/project_structure.html#sec-project-structure",
    "href": "contributing/project_structure.html#sec-project-structure",
    "title": "Project structure",
    "section": "",
    "text": "The root of the repository contains two main folders:\n\nsrc, which contains the source code for components and workflows.\n(optionally) the target folder\n\nEach subfolder from src contains a Viash namespace, a logical grouping of pipeline components that perform a similar function. Within each namespace, subfolders designate individual pipeline components. For example ./src/convert/from_bdrhap_to_h5ad contains the implementation for a component from_bdrhap_to_h5ad which is grouped together with other components such as from_10xmtx_to_h5mu into a namespace convert. In a similar manner as grouping components into namespaces, pipelines are grouped together into folders. However, these are not component namespaces and as such do not interact with viash ns commands.\nAs will become apparent later on, Viash not only provides commands to perform operations on individual components, but also on groups of components in a namespace and all components in a project. As a rule of thumb, the basic Viash commands (like viash test) are designated for running commands on individual components, while ns commands are (viash ns test) are for namespaces. When cloning a fresh repository, there will be no target folder present. This is because the target folder will only be created after components have been build."
  },
  {
    "objectID": "contributing/project_structure.html#sec-versioning",
    "href": "contributing/project_structure.html#sec-versioning",
    "title": "Project structure",
    "section": "Versioning and branching strategy",
    "text": "Versioning and branching strategy\nOpenPipeline tries to use of semantic versioning to govern changes between versions. An release of openpipelines uses a version number in the format MAJOR.MINOR.PATCH. Currenly, openpipelines is still at major version 0.x.y, meaning that public-facing breaking changes are possible on MINOR releases. These breaking changes will be documented in a dedicated section of the CHANGELOG that is published with each release. A PATCH release (i.e. a release where the MAJOR and MINOR version number stay the same), is used to resolve bugs with the pipeline but should not introduce breaking changes. Keep in mind that patches might introduce behavioral changes that may look breaking but are actually rectifying changes that were inadvertently introduced previously (and were in fact also ‘breaking changes’). In this case, a bug can also be released without changing the MINOR version, in a PATH release.\nBetween releases, development progress is tracked on Git branches. A git branch represents a snapshot of a codebase in time, to which changes can be added (i.e. committed). Eventually, all new feature or bugfixes must be reconsiled into a single branch so that a new release can be created. This process is called merging and the process of requesting the merging of two branches is called a pull request. Openpipelines follows the convention that the target branch for all pull requests is the main branch. Thus, the main branch contains the latest changes for the code and it can be considered the development branch.\nOnce a pull request has been approved and merged, Github Actions CI will automatically build all components (creating the target directory) and push the result to the main_build branch. In essence, the main_build branch is a copy of the main branch, but also containing the build components. Once it is time to create a openpipelines release, the Github CI release workflow is manually triggered, the components on the main branch will be build and tested. Then, the result will be pushed to the release branch and the integration tests will be run. If all tests succeeded, a new github tag and release can be created manually from the release branch.\n\n\n\n\n%%{init: { 'logLevel': 'debug', 'theme': 'default'} } }%%\ngitGraph\n  commit id: \"initial commit\"\n  branch main_build\n  commit id: \"CI build\"\n  checkout main\n  commit\n  checkout main_build\n  merge main\n  checkout main\n  branch feature_a\n  branch feature_b\n  checkout feature_a\n  commit\n  commit\n  checkout main\n  commit id: \"#release 0.1\" type: HIGHLIGHT\n  checkout main_build\n  merge main\n  checkout main\n  branch release\n  commit tag: \"0.1\"\n  checkout main\n  commit\n  checkout feature_b\n  commit\n  commit\n  checkout feature_a\n  commit\n  checkout main\n  merge feature_a\n  checkout main_build\n  merge main\n  checkout main\n  checkout feature_b\n  commit\n  checkout main\n  merge feature_b\n  checkout main_build\n  merge main\n  checkout release\n  merge main tag: \"0.2\""
  },
  {
    "objectID": "contributing/creating_components.html",
    "href": "contributing/creating_components.html",
    "title": "Creating components",
    "section": "",
    "text": "One of the core principals of OpenPipelines is to use MuData as a common data format troughout the whole pipeline. See the concepts page for more information on openpipelines uses MuData to store single-cell data."
  },
  {
    "objectID": "contributing/creating_components.html#a-common-file-format",
    "href": "contributing/creating_components.html#a-common-file-format",
    "title": "Creating components",
    "section": "",
    "text": "One of the core principals of OpenPipelines is to use MuData as a common data format troughout the whole pipeline. See the concepts page for more information on openpipelines uses MuData to store single-cell data."
  },
  {
    "objectID": "contributing/creating_components.html#component-location",
    "href": "contributing/creating_components.html#component-location",
    "title": "Creating components",
    "section": "Component location",
    "text": "Component location\nAs discussed in the project structure, components in the repository are stored within src. Additionally, components are grouped into namespaces, according to a common functionality. An example of such a namespace is the dimensionality reduction namespace (dimred), of which the components pca and umap are members. This means that within src, the namespace folders can be found that stores the components that belong to these namespaces.\nIn order to create a new component in OpenPipelines, you will need to create a new folder that will contain the different elements of the component:\nmkdir src/my_namespace/my_component\n\n\n\n\n\n\nTip\n\n\n\nTake a look at the components that are already in src/! There might be a component that already does something similar to what you need."
  },
  {
    "objectID": "contributing/creating_components.html#the-elements-of-a-component",
    "href": "contributing/creating_components.html#the-elements-of-a-component",
    "title": "Creating components",
    "section": "The elements of a component",
    "text": "The elements of a component\nA component consists of one or more scripts that provide the functionality of the component together with metadata of the component in a configuration file. The Viash config contains metadata of your dataset, which script is used to run it, and the required dependencies. An in-depth guide on how to create components is available on the viash website, but a few specifics and guidelines will be discussed here."
  },
  {
    "objectID": "contributing/creating_components.html#the-config",
    "href": "contributing/creating_components.html#the-config",
    "title": "Creating components",
    "section": "The config",
    "text": "The config\nfunctionality:\n  name: \"my_component\"\n  namespace: \"my_namespace\"\n  description: \"My new custom component\"\n  authors:\n    - __merge__: ../../authors/my_name.yaml\n      roles: [ author ]\n  arguments:\n    - name: \"--output\"\n      type: file\n      example: \"output_file.h5mu\"\n      description: \"Location were the output file should be written to.\"\n      direction: \"output\"\n  resources:\n    - type: python_script\n      path: script.py\nplatforms:\n  - type: docker\n    image: python:3.11\n    setup:\n      - type: python\n        packages: mudata~=0.2.3\n  - type: nextflow\n    directives:\n      label: [highcpu, midmem]\n\nBasic information\nEach component should have the name, a namespace, a description and author information defined in the config. Because a single author can contribute to multiple components, the author information is often duplicated across components, which was causing issues with the author information being out of date and not easy to maintain. Therefore, it was decided to move author information to ./src/authors. Each author has a yaml file containing the author information, and the viash __merge__ property is used to merge this information into the viash configs.\nBasic information checklist:\n\nGive the component a name\nAdd the component to an appropriate namespace\nAdd a description\nAdd author information\n\n\n\nArguments and argument groups\nIf you component requires arguments, they should be defined in arguments or argument_groups. Try tro group individual arguments into argument_groups when the number of arguments become too larg (10 or more as a rule of thumb).\nArgument checklist:\n\nAdd a description and name\nEach argument should have the appropriate type.\nInput and output files should be of type file instead of string and use the appropriate direction:\nIf possible: add an example\nIf the argument can accept multiple values, add multiple: true\nIf the possible input for an argument is limited to certain set of values, use choices:\n\n\n\n(Test)resources\nResources define files that are required for a component to perform its function. These can be scripts, but also additional files like settings for tools you might require. Defining resources is both a necessity because viash needs to know what code to execute, but defining resources also has the added benefit that these resources are automatically made available, regardless of the build environment. For example: resources are automatically mounted within a running docker container.\nThere is a difference between defining resources and test_resources. While resources are required for a component to function, test_resources only need to be included when testing the component (with for example viash test) in addition to the regular resources. Having a look at the example above, resources are defined using the resources: property. It takes a list of multiple files or folders.\nIn openpipelines, it was decided to not use a service like git lfs to include large resources into the repository. Instead, if large resources are required, there are two possibilities: * Large resources required for testing are to uploaded into an s3 bucket that is synced automatically before running tests (both locally and on github). Please ping a maintainer when you open a PR and ask them to upload the files for you. * Other large resources that are not needed for testing can be considered as input. This means that an argument of type: file needs to be created. The downside of this method is that viash is not able to natively support remote files f\nResources checklist: - Script resources are located next to the config and added to the config with the correct type (python_script, r_script, …) - Small resources (&lt;50MB) that are not scripts can also be checked in into the repo, next to the\n\n\nThe script file\nTODO\n\n\nAuthor information\nTODO"
  },
  {
    "objectID": "contributing/creating_components.html#adding-dependencies",
    "href": "contributing/creating_components.html#adding-dependencies",
    "title": "Creating components",
    "section": "Adding dependencies",
    "text": "Adding dependencies\nTODO"
  },
  {
    "objectID": "contributing/creating_components.html#building-components-from-their-source",
    "href": "contributing/creating_components.html#building-components-from-their-source",
    "title": "Creating components",
    "section": "Building components from their source",
    "text": "Building components from their source\nWhen running or testing individual components, it is not necessary to execute an extra command to run the build step, viash test and viash run will build the component on the fly. However, before integrating components into a pipeline, you will need to build the components. More specifically, openpipelines uses Nextflow to combine components into pipelines, so we need to have at least the components build for nextflow platform as target. The easiest method to build the components is to use:\nviash ns build --parallel --setup cachedbuild\nAfter using viash ns build, the target folder will be populated with three subfolders, corresponding to the build platforms that viash supports: native, docker and nextflow.\nBuilding an individual component can still be useful, for example when debugging a component for which the build fails or if you want to create a standalone executable for a component to execute it without the need to use viash. To build an individual component, viash build can be used. Note that the default build directory of this viash base command is output, which is not the location where build components will be imported from when integrating them in pipelines. Using the --output argument, you can set it to any directory you want, for example:\nviash build src/filter/do_filter/config.vsh.yaml -o target/native/filter/do_filter/ -p native"
  },
  {
    "objectID": "contributing/creating_components.html#containerization",
    "href": "contributing/creating_components.html#containerization",
    "title": "Creating components",
    "section": "Containerization",
    "text": "Containerization\nOne of the key benefits of using Viash is that containers can be created that gather dependencies per component, which avoids building one container that has to encorporate all dependencies for a pipeline together. The containers for a single component can be reduced in size, defining the minimal requirements to run the component. That being said, building containers from scratch can be labour intensive and error prone, with base containers from reputable publishers often benefiting from improved reliability and security. Hence, a balance has to be made between reducing the container’s size and adding many dependencies to a small base container.\nThe preferred containerization setup in OpenPipelines uses the following guidelines:\n\nChoose a base container from a reputable source and use its latest version\nDo not use base containers that have not been updated in a while\nUse package managers to install dependencies as much as possible\nAvoid building depdencies from source.\n\nExamples of base containers that are currently being used are:\n\npython:3.11 for python environments\nubuntu:focal for general linux environments and bash scripts\neddelbuettel/r2u:22.04 for R\nnvcr.io/nvidia/pytorch:22.09-py3 for using GPU accelerated calculations using pytorch in python"
  },
  {
    "objectID": "user_guide/index.html",
    "href": "user_guide/index.html",
    "title": "User Guide",
    "section": "",
    "text": "Getting started: Setting up infrastructure\n  \n  \n    Running pipelines: Run a pipeline from CLI or Nextflow Tower\n  \n  \n    Passing parameter lists: Pass a large number of inputs to a workflow\n  \n  \n    Ingestion: From sequencing to count tables\n  \n  \n    Processing: From count tables to integrated data\n  \n  \n    Downstream: Celltyping and cell-cell communication\n  \n  \n    Bug reports: How to report bugs\n  \n\n\nNo matching items"
  },
  {
    "objectID": "user_guide/getting_started.html",
    "href": "user_guide/getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "Depending on whether you plan to run the OpenPipelines workflows locally or in the cloud"
  },
  {
    "objectID": "user_guide/getting_started.html#starting-workflows-locally",
    "href": "user_guide/getting_started.html#starting-workflows-locally",
    "title": "Getting started",
    "section": "Starting workflows locally",
    "text": "Starting workflows locally\nIf you want to start workflows locally, you will need to install Nextflow.\n\nInstall Docker (optional)\nDocker is a containerization platform that allows you to package your application and all its dependencies into a single image. It is used to run the analysis pipelines.\nIf you are planning on running the workflows locally, you will need to install Docker. You do not need to install Docker if the workflows will be run in the cloud using AWS Batch, Azure Batch, Google Cloud Batch, or other cloud-based compute environments.\nTo install Docker, follow the instructions here.\n\n\nInstall Java\nNextflow requires Java 11 or later. To check if Java is installed on your system, run:\njava -version\nIf Java is not installed, you can download it from here.\n\n\nInstall Nextflow\nNextflow is distributed as a single executable file. To install it, run:\ncurl -s https://get.nextflow.io | bash\nThis command will download the latest version of Nextflow and store it in the current directory.\nTo install Nextflow system-wide, move the downloaded file to a directory in your $PATH, e.g.:\nmv nextflow /usr/local/bin\n\n\nTest the installation\nTo test the installation, run:\nnextflow run hello -with-docker"
  },
  {
    "objectID": "user_guide/getting_started.html#using-nextflow-tower",
    "href": "user_guide/getting_started.html#using-nextflow-tower",
    "title": "Getting started",
    "section": "Using Nextflow Tower",
    "text": "Using Nextflow Tower\nNextflow Tower is a web-based user interface for running and monitoring Nextflow pipelines. If you are planning on using Nextflow Tower, a compute environment will need to be set up."
  },
  {
    "objectID": "user_guide/parameter_lists.html",
    "href": "user_guide/parameter_lists.html",
    "title": "Passing parameter lists",
    "section": "",
    "text": "Using Viash’s VDSL3 nextflow platform, an optional --param_list argument can be used to pass a large number of inputs to a workflow. A param_list can either be a csv file, a json file, a yaml file, a yaml blob, or be passed as a nextflow config file."
  },
  {
    "objectID": "user_guide/parameter_lists.html#csv-file",
    "href": "user_guide/parameter_lists.html#csv-file",
    "title": "Passing parameter lists",
    "section": "CSV file",
    "text": "CSV file\nThe following example shows how to use a csv file as a parameter list. The csv file has two columns, id and input. The id column is used to name the output file, and the input column is used as the input file. The input column is relativized to the location of the csv file.\n$ cat param_list.csv\nid,input\nfoo,foo.txt\nbar,bar.txt\nnextflow run ... --param_list param_list.csv"
  },
  {
    "objectID": "user_guide/parameter_lists.html#yaml-file",
    "href": "user_guide/parameter_lists.html#yaml-file",
    "title": "Passing parameter lists",
    "section": "YAML file",
    "text": "YAML file\nThe following example shows how to use a yaml file as a parameter list.\n$ cat param_list.yaml\n- id: foo\n  input: foo.txt\n- id: bar\n  input: bar.txt\nnextflow run ... --param_list param_list.yaml"
  },
  {
    "objectID": "user_guide/parameter_lists.html#yaml-blob",
    "href": "user_guide/parameter_lists.html#yaml-blob",
    "title": "Passing parameter lists",
    "section": "YAML blob",
    "text": "YAML blob\nThe following example shows how to use a yaml blob as a parameter list.\nnextflow run ... --param_list \"[ {'id': 'foo', 'input': 'foo.txt'}, {'id': 'bar', 'input': 'bar.txt'} ]\""
  },
  {
    "objectID": "user_guide/parameter_lists.html#as-a-nextflow-config",
    "href": "user_guide/parameter_lists.html#as-a-nextflow-config",
    "title": "Passing parameter lists",
    "section": "As a Nextflow config",
    "text": "As a Nextflow config\nThe following example shows how to use a nextflow.config file as a parameter list.\n$ cat params.config\nparams {\n  param_list: [\n    ['id': 'foo', 'input': 'foo.txt'],\n    ['id': 'bar', 'input': 'bar.txt']\n  ]\n}\nnextflow run ... -params-file params.config"
  },
  {
    "objectID": "user_guide/parameter_lists.html#global-parameters",
    "href": "user_guide/parameter_lists.html#global-parameters",
    "title": "Passing parameter lists",
    "section": "Global parameters",
    "text": "Global parameters\nNote that a param_list can be combined with setting parameters that are set for all parameter sets. These ‘global’ parameters will always be overwritten with their counterpart that was specified in a more specific manner for a single parameter set.\nFor example, using --param_list param_list.yaml --ref global.txt with the following param_list.yaml:\n- id: foo\n  input: foo.txt\n- id: bar\n  input: bar.txt\n  ref: custom_bar_ref.txt\nWill result in the following parameter sets being processed:\n\nid: foo, input: foo.txt, ref: global.txt\nid: bar, input: bar.txt, ref: custom_bar_ref.txt"
  },
  {
    "objectID": "user_guide/parameter_lists.html#resolving-paths",
    "href": "user_guide/parameter_lists.html#resolving-paths",
    "title": "Passing parameter lists",
    "section": "Resolving paths",
    "text": "Resolving paths\nIf the --param_list is a file (CSV, YAML, or JSON), all files in the param_list are relativized to the location of the param_list file. If the --param_list is a YAML blob or a Nextflow config, all files in the param_list are relativized to the current working directory.\nFor example, with a param_list.yaml file located in the data directory:\n$ cat /data/param_list.yaml\n- id: foo\n  input: foo.txt\n- id: bar\n  input: /path/to/bar.txt\nThis will result in the following parameter sets being processed:\n\nid: foo, input: /data/foo.txt\nid: bar, input: /path/to/bar.txt\n\nNote that this also works when the param list is located on a remote location, such as an S3 bucket. In that case, the files in the param list are relativized to the location of the param list on the remote location."
  },
  {
    "objectID": "more_information/index.html",
    "href": "more_information/index.html",
    "title": "More information",
    "section": "",
    "text": "Cheat sheets: Cheat sheets for various tools\n  \n  \n    Code of conduct: Our DEI values\n  \n  \n    FAQ: Frequently Asked Questions\n  \n\n\nNo matching items"
  },
  {
    "objectID": "more_information/code_of_conduct.html",
    "href": "more_information/code_of_conduct.html",
    "title": "Code of conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\nOur full Code of Conduct is adapted from the Contributor Covenant, version 2.1."
  },
  {
    "objectID": "components/workflows/multiomics/rna_multisample.html",
    "href": "components/workflows/multiomics/rna_multisample.html",
    "title": "Rna multisample",
    "section": "",
    "text": "ID: rna_multisample\nNamespace: multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/rna_multisample.html#example-commands",
    "href": "components/workflows/multiomics/rna_multisample.html#example-commands",
    "title": "Rna multisample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/multiomics/rna_multisample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"concatenated\"\ninput: # please fill in - example: \"dataset.h5mu\"\n\n# Output\n# output: \"$id.$key.output.h5mu\"\n\n# Filtering highly variable genes\nfilter_with_hvg_var_output: \"filter_with_hvg\"\nfilter_with_hvg_obs_batch_key: \"sample_id\"\nfilter_with_hvg_flavor: \"seurat\"\n# filter_with_hvg_n_top_genes: 123\n\n# QC metrics calculation options\nvar_qc_metrics: [\"filter_with_hvg\"]\ntop_n_vars: [50, 100, 200, 500]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/rna_multisample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/rna_multisample.html#argument-groups",
    "href": "components/workflows/multiomics/rna_multisample.html#argument-groups",
    "title": "Rna multisample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the concatenated file\nstring, required, example: \"concatenated\"\n\n\n--input\nPath to the samples.\nfile, required, example: \"dataset.h5mu\"\n\n\n\n\n\nOutput\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nFiltering highly variable genes\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--filter_with_hvg_var_output\nIn which .var slot to store a boolean array corresponding to the highly variable genes.\nstring, default: \"filter_with_hvg\"\n\n\n--filter_with_hvg_obs_batch_key\nIf specified, highly-variable genes are selected within each batch separately and merged. This simple process avoids the selection of batch-specific genes and acts as a lightweight batch correction method. For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If flavor = ‘seurat_v3’, ties are broken by the median (across batches) rank based on within-batch normalized variance.\nstring, default: \"sample_id\"\n\n\n--filter_with_hvg_flavor\nChoose the flavor for identifying highly variable genes. For the dispersion based methods in their default workflows, Seurat passes the cutoffs whereas Cell Ranger passes n_top_genes.\nstring, default: \"seurat\"\n\n\n--filter_with_hvg_n_top_genes\nNumber of highly-variable genes to keep. Mandatory if filter_with_hvg_flavor is set to ‘seurat_v3’.\ninteger\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‘True’, compared to the total sum of the values for all genes.\nList of string, default: \"filter_with_hvg\", example: \"ercc,highly_variable\", multiple_sep: \",\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\""
  },
  {
    "objectID": "components/workflows/multiomics/rna_multisample.html#authors",
    "href": "components/workflows/multiomics/rna_multisample.html#authors",
    "title": "Rna multisample",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nRobrecht Cannoodt    (author, maintainer)\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/rna_multisample.html#visualisation",
    "href": "components/workflows/multiomics/rna_multisample.html#visualisation",
    "title": "Rna multisample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v3(toSortedList)\n    v5(flatMap)\n    v7(toSortedList)\n    v9(Output)\n    v15(normalize_total)\n    v17(join)\n    v25(log1p)\n    v27(join)\n    v35(delete_layer)\n    v37(join)\n    v45(filter_with_hvg)\n    v47(join)\n    v55(rna_calculate_qc_metrics)\n    v57(join)\n    v64(Output)\n    v0--&gt;v3\n    v3--&gt;v5\n    v5--&gt;v7\n    v7--&gt;v9\n    v5--&gt;v17\n    v5--&gt;v15\n    v15--&gt;v17\n    v17--&gt;v27\n    v17--&gt;v25\n    v25--&gt;v27\n    v27--&gt;v37\n    v27--&gt;v35\n    v35--&gt;v37\n    v37--&gt;v47\n    v37--&gt;v45\n    v45--&gt;v47\n    v47--&gt;v57\n    v47--&gt;v55\n    v55--&gt;v57\n    v57--&gt;v64"
  },
  {
    "objectID": "components/workflows/multiomics/integration/initialize_integration.html",
    "href": "components/workflows/multiomics/integration/initialize_integration.html",
    "title": "Initialize integration",
    "section": "",
    "text": "ID: initialize_integration\nNamespace: multiomics/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration/initialize_integration.html#example-commands",
    "href": "components/workflows/multiomics/integration/initialize_integration.html#example-commands",
    "title": "Initialize integration",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/multiomics/integration/initialize_integration/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# PCA options\nobsm_pca: \"X_pca\"\n# var_pca_feature_selection: \"foo\"\npca_overwrite: false\n\n# Neighbour calculation\nuns_neighbors: \"neighbors\"\nobsp_neighbor_distances: \"distances\"\nobsp_neighbor_connectivities: \"connectivities\"\n\n# Umap options\nobsm_umap: \"X_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/integration/initialize_integration/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration/initialize_integration.html#argument-groups",
    "href": "components/workflows/multiomics/integration/initialize_integration.html#argument-groups",
    "title": "Initialize integration",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_pca\nIn which .obsm slot to store the resulting PCA embedding.\nstring, default: \"X_pca\"\n\n\n--var_pca_feature_selection\nColumn name in .var matrix that will be used to select which genes to run the PCA on.\nstring\n\n\n--pca_overwrite\nAllow overwriting slots for PCA output.\nboolean_true\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"connectivities\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration/initialize_integration.html#authors",
    "href": "components/workflows/multiomics/integration/initialize_integration.html#authors",
    "title": "Initialize integration",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration/initialize_integration.html#visualisation",
    "href": "components/workflows/multiomics/integration/initialize_integration.html#visualisation",
    "title": "Initialize integration",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v11(pca)\n    v13(join)\n    v21(find_neighbors)\n    v23(join)\n    v31(umap)\n    v33(join)\n    v38(toSortedList)\n    v40(Output)\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v13\n    v4--&gt;v11\n    v11--&gt;v13\n    v13--&gt;v23\n    v13--&gt;v21\n    v21--&gt;v23\n    v23--&gt;v33\n    v23--&gt;v31\n    v31--&gt;v33\n    v33--&gt;v38\n    v38--&gt;v40"
  },
  {
    "objectID": "components/workflows/multiomics/integration/scvi_leiden.html",
    "href": "components/workflows/multiomics/integration/scvi_leiden.html",
    "title": "Scvi leiden",
    "section": "",
    "text": "ID: scvi_leiden\nNamespace: multiomics/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration/scvi_leiden.html#example-commands",
    "href": "components/workflows/multiomics/integration/scvi_leiden.html#example-commands",
    "title": "Scvi leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/multiomics/integration/scvi_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_model: \"$id.$key.output_model.output_model\"\n\n# Neighbour calculation\nuns_neighbors: \"scvi_integration_neighbors\"\nobsp_neighbor_distances: \"scvi_integration_distances\"\nobsp_neighbor_connectivities: \"scvi_integration_connectivities\"\n\n# Scvi integration options\nobs_batch: # please fill in - example: \"foo\"\nobsm_output: \"X_scvi_integrated\"\n# var_input: \"foo\"\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n# max_epochs: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30\n\n# Clustering options\nobs_cluster: \"scvi_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_scvi_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/integration/scvi_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration/scvi_leiden.html#argument-groups",
    "href": "components/workflows/multiomics/integration/scvi_leiden.html#argument-groups",
    "title": "Scvi leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n--output_model\nFolder where the state of the trained model will be saved to.\nfile, required, example: \"output_dir\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"scvi_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"scvi_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"scvi_integration_connectivities\"\n\n\n\n\n\nScvi integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, required\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_scvi_integrated\"\n\n\n--var_input\n.var column containing highly variable genes. By default, do not subset genes.\nstring\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‘–obs_cluster’ suffixed with an underscore and one of the resolutions resolutions specified in ‘–leiden_resolution’.\nstring, default: \"scvi_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \":\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_scvi_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration/scvi_leiden.html#authors",
    "href": "components/workflows/multiomics/integration/scvi_leiden.html#authors",
    "title": "Scvi leiden",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration/scvi_leiden.html#visualisation",
    "href": "components/workflows/multiomics/integration/scvi_leiden.html#visualisation",
    "title": "Scvi leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v3(toSortedList)\n    v5(flatMap)\n    v12(scvi)\n    v14(join)\n    v23(find_neighbors)\n    v25(join)\n    v33(leiden)\n    v35(join)\n    v43(umap)\n    v45(join)\n    v53(move_obsm_to_obs)\n    v55(join)\n    v62(Output)\n    v0--&gt;v3\n    v3--&gt;v5\n    v5--&gt;v14\n    v5--&gt;v12\n    v12--&gt;v14\n    v14--&gt;v25\n    v14--&gt;v23\n    v23--&gt;v25\n    v25--&gt;v35\n    v25--&gt;v33\n    v33--&gt;v35\n    v35--&gt;v45\n    v35--&gt;v43\n    v43--&gt;v45\n    v45--&gt;v55\n    v45--&gt;v53\n    v53--&gt;v55\n    v55--&gt;v62"
  },
  {
    "objectID": "components/workflows/multiomics/integration/leiden_scvi.html",
    "href": "components/workflows/multiomics/integration/leiden_scvi.html",
    "title": "Leiden scvi",
    "section": "",
    "text": "ID: leiden_scvi\nNamespace: multiomics/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration/leiden_scvi.html#example-commands",
    "href": "components/workflows/multiomics/integration/leiden_scvi.html#example-commands",
    "title": "Leiden scvi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.10.0 -latest \\\n  -main-script ./workflows/multiomics/integration/scvi_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_model: \"$id.$key.output_model.output_model\"\n\n# Neighbour calculation\nuns_neighbors: \"scvi_integration_neighbors\"\nobsp_neighbor_distances: \"scvi_integration_distances\"\nobsp_neighbor_connectivities: \"scvi_integration_connectivities\"\n\n# Scvi integration options\nobs_batch: # please fill in - example: \"foo\"\nobsm_output: \"X_scvi_integrated\"\n# early_stopping: true\nearly_stopping_monitor: \"elbo_validation\"\nearly_stopping_patience: 45\nearly_stopping_min_delta: 0.0\n# max_epochs: 123\nreduce_lr_on_plateau: true\nlr_factor: 0.6\nlr_patience: 30\n\n# Clustering options\nobs_cluster: \"scvi_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_scvi_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.10.0 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/integration/scvi_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration/leiden_scvi.html#argument-groups",
    "href": "components/workflows/multiomics/integration/leiden_scvi.html#argument-groups",
    "title": "Leiden scvi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n--output_model\nFolder where the state of the trained model will be saved to.\nfile, required, example: \"output_dir\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"scvi_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"scvi_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"scvi_integration_connectivities\"\n\n\n\n\n\nScvi integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, required\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_scvi_integrated\"\n\n\n--early_stopping\nWhether to perform early stopping with respect to the validation set.\nboolean\n\n\n--early_stopping_monitor\nMetric logged during validation set epoch.\nstring, default: \"elbo_validation\"\n\n\n--early_stopping_patience\nNumber of validation epochs with no improvement after which training will be stopped.\ninteger, default: 45\n\n\n--early_stopping_min_delta\nMinimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\ndouble, default: 0\n\n\n--max_epochs\nNumber of passes through the dataset, defaults to (20000 / number of cells) * 400 or 400; whichever is smallest.\ninteger\n\n\n--reduce_lr_on_plateau\nWhether to monitor validation loss and reduce learning rate when validation set lr_scheduler_metric plateaus.\nboolean, default: TRUE\n\n\n--lr_factor\nFactor to reduce learning rate.\ndouble, default: 0.6\n\n\n--lr_patience\nNumber of epochs with no improvement after which learning rate will be reduced.\ndouble, default: 30\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‘–obs_cluster’ suffixed with an underscore and one of the resolutions resolutions specified in ‘–leiden_resolution’.\nstring, default: \"scvi_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \":\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_scvi_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration/leiden_scvi.html#authors",
    "href": "components/workflows/multiomics/integration/leiden_scvi.html#authors",
    "title": "Leiden scvi",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration/leiden_scvi.html#visualisation",
    "href": "components/workflows/multiomics/integration/leiden_scvi.html#visualisation",
    "title": "Leiden scvi",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    p0(Input)\n    p3(toSortedList)\n    p5(flatMap)\n    p12(scvi)\n    p14(join)\n    p23(find_neighbors)\n    p25(join)\n    p33(leiden)\n    p35(join)\n    p43(umap)\n    p45(join)\n    p53(move_obsm_to_obs)\n    p55(join)\n    p62(Output)\n    p0--&gt;p3\n    p3--&gt;p5\n    p5--&gt;p14\n    p5--&gt;p12\n    p12--&gt;p14\n    p14--&gt;p25\n    p14--&gt;p23\n    p23--&gt;p25\n    p25--&gt;p35\n    p25--&gt;p33\n    p33--&gt;p35\n    p35--&gt;p45\n    p35--&gt;p43\n    p43--&gt;p45\n    p45--&gt;p55\n    p45--&gt;p53\n    p53--&gt;p55\n    p55--&gt;p62"
  },
  {
    "objectID": "components/workflows/multiomics/integration/harmony_leiden.html",
    "href": "components/workflows/multiomics/integration/harmony_leiden.html",
    "title": "Harmony leiden",
    "section": "",
    "text": "ID: harmony_leiden\nNamespace: multiomics/integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/integration/harmony_leiden.html#example-commands",
    "href": "components/workflows/multiomics/integration/harmony_leiden.html#example-commands",
    "title": "Harmony leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/multiomics/integration/harmony_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Neighbour calculation\nuns_neighbors: \"harmonypy_integration_neighbors\"\nobsp_neighbor_distances: \"harmonypy_integration_distances\"\nobsp_neighbor_connectivities: \"harmonypy_integration_connectivities\"\n\n# Harmony integration options\nembedding: \"X_pca\"\nobsm_integrated: \"X_pca_integrated\"\nobs_covariates: # please fill in - example: [\"batch\", \"sample\"]\ntheta: [2]\n\n# Clustering options\nobs_cluster: \"harmony_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_leiden_harmony_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/integration/harmony_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/integration/harmony_leiden.html#argument-groups",
    "href": "components/workflows/multiomics/integration/harmony_leiden.html#argument-groups",
    "title": "Harmony leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"harmonypy_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"harmonypy_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"harmonypy_integration_connectivities\"\n\n\n\n\n\nHarmony integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--embedding\nEmbedding to use as input\nstring, default: \"X_pca\"\n\n\n--obsm_integrated\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_pca_integrated\"\n\n\n--obs_covariates\nThe .obs field(s) that define the covariate(s) to regress out.\nList of string, required, example: \"batch\", \"sample\", multiple_sep: \":\"\n\n\n--theta\nDiversity clustering penalty parameter. Specify for each variable in group.by.vars. theta=0 does not encourage any diversity. Larger values of theta result in more diverse clusters.”\nList of double, default: 2, multiple_sep: \":\"\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nPrefix for the .obs keys under which to add the cluster labels. Newly created columns in .obs will be created from the specified value for ‘–obs_cluster’ suffixed with an underscore and one of the resolutions resolutions specified in ‘–leiden_resolution’.\nstring, default: \"harmony_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\nList of double, default: 1, multiple_sep: \":\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_harmony_umap\""
  },
  {
    "objectID": "components/workflows/multiomics/integration/harmony_leiden.html#authors",
    "href": "components/workflows/multiomics/integration/harmony_leiden.html#authors",
    "title": "Harmony leiden",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/multiomics/integration/harmony_leiden.html#visualisation",
    "href": "components/workflows/multiomics/integration/harmony_leiden.html#visualisation",
    "title": "Harmony leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v10(harmonypy)\n    v12(join)\n    v20(find_neighbors)\n    v22(join)\n    v30(leiden)\n    v32(join)\n    v40(umap)\n    v42(join)\n    v50(move_obsm_to_obs)\n    v52(join)\n    v58(Output)\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v12\n    v4--&gt;v10\n    v10--&gt;v12\n    v12--&gt;v22\n    v12--&gt;v20\n    v20--&gt;v22\n    v22--&gt;v32\n    v22--&gt;v30\n    v30--&gt;v32\n    v32--&gt;v42\n    v32--&gt;v40\n    v40--&gt;v42\n    v42--&gt;v52\n    v42--&gt;v50\n    v50--&gt;v52\n    v52--&gt;v58"
  },
  {
    "objectID": "components/workflows/multiomics/full_pipeline.html",
    "href": "components/workflows/multiomics/full_pipeline.html",
    "title": "Full pipeline",
    "section": "",
    "text": "ID: full_pipeline\nNamespace: multiomics\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/multiomics/full_pipeline.html#example-commands",
    "href": "components/workflows/multiomics/full_pipeline.html#example-commands",
    "title": "Full pipeline",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/multiomics/full_pipeline/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Sample ID options\nadd_id_to_obs: true\nadd_id_obs_output: \"sample_id\"\nadd_id_make_observation_keys_unique: true\n\n# RNA filtering options\n# rna_min_counts: 200\n# rna_max_counts: 5000000\n# rna_min_genes_per_cell: 200\n# rna_max_genes_per_cell: 1500000\n# rna_min_cells_per_gene: 3\n# rna_min_fraction_mito: 0\n# rna_max_fraction_mito: 0.2\n\n# CITE-seq filtering options\n# prot_min_counts: 3\n# prot_max_counts: 5000000\n# prot_min_proteins_per_cell: 200\n# prot_max_proteins_per_cell: 100000000\n# prot_min_cells_per_protein: 3\n\n# Highly variable gene detection\nfilter_with_hvg_var_output: \"filter_with_hvg\"\nfilter_with_hvg_obs_batch_key: \"sample_id\"\n\n# Mitochondrial Gene Detection\n# var_name_mitochondrial_genes: \"foo\"\n# var_gene_names: \"gene_symbol\"\nmitochondrial_gene_regex: \"^[mM][tT]-\"\n\n# QC metrics calculation options\n# var_qc_metrics: [\"ercc\", \"highly_variable\"]\ntop_n_vars: [50, 100, 200, 500]\n\n# PCA options\npca_overwrite: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/full_pipeline/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/full_pipeline.html#argument-groups",
    "href": "components/workflows/multiomics/full_pipeline.html#argument-groups",
    "title": "Full pipeline",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"input.h5mu\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nSample ID options\nOptions for adding the id to .obs on the MuData object. Having a sample id present in a requirement of several components for this pipeline.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--add_id_to_obs\nAdd the value passed with –id to .obs.\nboolean, default: TRUE\n\n\n--add_id_obs_output\n.Obs column to add the sample IDs to. Required and only used when –add_id_to_obs is set to ‘true’\nstring, default: \"sample_id\"\n\n\n--add_id_make_observation_keys_unique\nJoin the id to the .obs index (.obs_names). Only used when –add_id_to_obs is set to ‘true’.\nboolean, default: TRUE\n\n\n\n\n\nRNA filtering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--rna_min_counts\nMinimum number of counts captured per cell.\ninteger, example: 200\n\n\n--rna_max_counts\nMaximum number of counts captured per cell.\ninteger, example: 5000000\n\n\n--rna_min_genes_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--rna_max_genes_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 1500000\n\n\n--rna_min_cells_per_gene\nMinimum of non-zero values per gene.\ninteger, example: 3\n\n\n--rna_min_fraction_mito\nMinimum fraction of UMIs that are mitochondrial.\ndouble, example: 0\n\n\n--rna_max_fraction_mito\nMaximum fraction of UMIs that are mitochondrial.\ndouble, example: 0.2\n\n\n\n\n\nCITE-seq filtering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--prot_min_counts\nMinimum number of counts per cell.\ninteger, example: 3\n\n\n--prot_max_counts\nMinimum number of counts per cell.\ninteger, example: 5000000\n\n\n--prot_min_proteins_per_cell\nMinimum of non-zero values per cell.\ninteger, example: 200\n\n\n--prot_max_proteins_per_cell\nMaximum of non-zero values per cell.\ninteger, example: 100000000\n\n\n--prot_min_cells_per_protein\nMinimum of non-zero values per protein.\ninteger, example: 3\n\n\n\n\n\nHighly variable gene detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--filter_with_hvg_var_output\nIn which .var slot to store a boolean array corresponding to the highly variable genes.\nstring, default: \"filter_with_hvg\"\n\n\n--filter_with_hvg_obs_batch_key\nIf specified, highly-variable genes are selected within each batch separately and merged. This simple process avoids the selection of batch-specific genes and acts as a lightweight batch correction method.\nstring, default: \"sample_id\"\n\n\n\n\n\nMitochondrial Gene Detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_name_mitochondrial_genes\nIn which .var slot to store a boolean array corresponding the mitochondrial genes.\nstring\n\n\n--var_gene_names\n.var column name to be used to detect mitochondrial genes instead of .var_names (default if not set). Gene names matching with the regex value from –mitochondrial_gene_regex will be identified as a mitochondrial gene.\nstring, example: \"gene_symbol\"\n\n\n--mitochondrial_gene_regex\nRegex string that identifies mitochondrial genes from –var_gene_names. By default will detect human and mouse mitochondrial genes from a gene symbol.\nstring, default: \"^[mM][tT]-\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‘True’, compared to the total sum of the values for all genes. Defaults to the combined values specified for –var_name_mitochondrial_genes and –filter_with_hvg_var_output.\nList of string, example: \"ercc,highly_variable\", multiple_sep: \",\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pca_overwrite\nAllow overwriting slots for PCA output.\nboolean_true"
  },
  {
    "objectID": "components/workflows/multiomics/full_pipeline.html#authors",
    "href": "components/workflows/multiomics/full_pipeline.html#authors",
    "title": "Full pipeline",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/multiomics/full_pipeline.html#visualisation",
    "href": "components/workflows/multiomics/full_pipeline.html#visualisation",
    "title": "Full pipeline",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v7(toSortedList)\n    v9(Output)\n    v11(filter)\n    v17(add_id)\n    v19(join)\n    v23(mix)\n    v22(filter)\n    v25(filter)\n    v30(split_modalities)\n    v32(join)\n    v39(concat)\n    v35(filter)\n    v37(test_wf:run_wf:split_modalities_workflow:splitStub)\n    v40(flatMap)\n    v41(filter)\n    v44(toSortedList)\n    v46(flatMap)\n    v53(filter_with_counts)\n    v55(join)\n    v63(do_filter)\n    v65(join)\n    v73(filter_with_scrublet)\n    v75(join)\n    v110(concat)\n    v79(filter)\n    v82(toSortedList)\n    v84(flatMap)\n    v91(test_wf:run_wf:singlesample_processing_workflow:prot_singlesample:filter_with_counts:filter_with_counts_process1)\n    v93(join)\n    v101(test_wf:run_wf:singlesample_processing_workflow:prot_singlesample:do_filter:do_filter_process1)\n    v103(join)\n    v108(filter)\n    v112(groupTuple)\n    v118(concat)\n    v120(join)\n    v125(filter)\n    v128(toSortedList)\n    v130(flatMap)\n    v132(toSortedList)\n    v134(Output)\n    v140(normalize_total)\n    v142(join)\n    v150(log1p)\n    v152(join)\n    v160(delete_layer)\n    v162(join)\n    v170(filter_with_hvg)\n    v172(join)\n    v180(rna_calculate_qc_metrics)\n    v182(join)\n    v223(concat)\n    v188(filter)\n    v191(toSortedList)\n    v193(flatMap)\n    v195(toSortedList)\n    v197(Output)\n    v203(clr)\n    v205(join)\n    v213(prot_calculate_qc_metrics)\n    v215(join)\n    v221(filter)\n    v224(toSortedList)\n    v230(merge)\n    v232(join)\n    v235(filter)\n    v239(toSortedList)\n    v241(flatMap)\n    v248(pca)\n    v250(join)\n    v258(find_neighbors)\n    v260(join)\n    v268(umap)\n    v270(join)\n    v275(concat)\n    v274(filter)\n    v276(filter)\n    v280(toSortedList)\n    v282(flatMap)\n    v289(pca)\n    v291(join)\n    v299(find_neighbors)\n    v301(join)\n    v309(test_wf:run_wf:integration_setup_workflow:initialize_integration_prot:umap:umap_process1)\n    v311(join)\n    v316(concat)\n    v315(filter)\n    v322(publish)\n    v324(join)\n    v329(toSortedList)\n    v331(Output)\n    v22--&gt;v23\n    v39--&gt;v40\n    v40--&gt;v41\n    v40--&gt;v79\n    v40--&gt;v108\n    v223--&gt;v224\n    v274--&gt;v275\n    v275--&gt;v276\n    v275--&gt;v315\n    v315--&gt;v316\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v7\n    v7--&gt;v9\n    v4--&gt;v11\n    v4--&gt;v22\n    v11--&gt;v19\n    v11--&gt;v17\n    v17--&gt;v19\n    v19--&gt;v23\n    v23--&gt;v25\n    v23--&gt;v35\n    v25--&gt;v32\n    v25--&gt;v30\n    v30--&gt;v32\n    v32--&gt;v39\n    v35--&gt;v37\n    v37--&gt;v39\n    v41--&gt;v44\n    v44--&gt;v46\n    v46--&gt;v55\n    v46--&gt;v53\n    v53--&gt;v55\n    v55--&gt;v65\n    v55--&gt;v63\n    v63--&gt;v65\n    v65--&gt;v75\n    v65--&gt;v73\n    v73--&gt;v75\n    v75--&gt;v110\n    v79--&gt;v82\n    v82--&gt;v84\n    v84--&gt;v93\n    v84--&gt;v91\n    v91--&gt;v93\n    v93--&gt;v103\n    v93--&gt;v101\n    v101--&gt;v103\n    v103--&gt;v110\n    v108--&gt;v110\n    v110--&gt;v112\n    v112--&gt;v120\n    v112--&gt;v118\n    v118--&gt;v120\n    v120--&gt;v125\n    v120--&gt;v188\n    v120--&gt;v221\n    v125--&gt;v128\n    v128--&gt;v130\n    v130--&gt;v132\n    v132--&gt;v134\n    v130--&gt;v142\n    v130--&gt;v140\n    v140--&gt;v142\n    v142--&gt;v152\n    v142--&gt;v150\n    v150--&gt;v152\n    v152--&gt;v162\n    v152--&gt;v160\n    v160--&gt;v162\n    v162--&gt;v172\n    v162--&gt;v170\n    v170--&gt;v172\n    v172--&gt;v182\n    v172--&gt;v180\n    v180--&gt;v182\n    v182--&gt;v223\n    v188--&gt;v191\n    v191--&gt;v193\n    v193--&gt;v195\n    v195--&gt;v197\n    v193--&gt;v205\n    v193--&gt;v203\n    v203--&gt;v205\n    v205--&gt;v215\n    v205--&gt;v213\n    v213--&gt;v215\n    v215--&gt;v223\n    v221--&gt;v223\n    v224--&gt;v232\n    v224--&gt;v230\n    v230--&gt;v232\n    v232--&gt;v235\n    v232--&gt;v274\n    v235--&gt;v239\n    v239--&gt;v241\n    v241--&gt;v250\n    v241--&gt;v248\n    v248--&gt;v250\n    v250--&gt;v260\n    v250--&gt;v258\n    v258--&gt;v260\n    v260--&gt;v270\n    v260--&gt;v268\n    v268--&gt;v270\n    v270--&gt;v275\n    v276--&gt;v280\n    v280--&gt;v282\n    v282--&gt;v291\n    v282--&gt;v289\n    v289--&gt;v291\n    v291--&gt;v301\n    v291--&gt;v299\n    v299--&gt;v301\n    v301--&gt;v311\n    v301--&gt;v309\n    v309--&gt;v311\n    v311--&gt;v316\n    v316--&gt;v324\n    v316--&gt;v322\n    v322--&gt;v324\n    v324--&gt;v329\n    v329--&gt;v331"
  },
  {
    "objectID": "components/workflows/multiomics/multisample.html",
    "href": "components/workflows/multiomics/multisample.html",
    "title": "Multisample",
    "section": "",
    "text": "ID: multisample\nNamespace: multiomics\n\n\n\nSource\nAn input .h5mu file will first be split in order to run the multisample processing per modality. Next, the modalities are merged again and the integration setup pipeline is executed. Please note that this workflow assumes that samples from multiple pipelines are already concatenated."
  },
  {
    "objectID": "components/workflows/multiomics/multisample.html#example-commands",
    "href": "components/workflows/multiomics/multisample.html#example-commands",
    "title": "Multisample",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/multiomics/multisample/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"input.h5mu\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Highly variable gene detection\nfilter_with_hvg_var_output: \"filter_with_hvg\"\nfilter_with_hvg_obs_batch_key: \"sample_id\"\n\n# QC metrics calculation options\nvar_qc_metrics: [\"filter_with_hvg\"]\ntop_n_vars: [50, 100, 200, 500]\n\n# PCA options\npca_overwrite: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/multiomics/multisample/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/multiomics/multisample.html#argument-groups",
    "href": "components/workflows/multiomics/multisample.html#argument-groups",
    "title": "Multisample",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"input.h5mu\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nHighly variable gene detection\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--filter_with_hvg_var_output\nIn which .var slot to store a boolean array corresponding to the highly variable genes.\nstring, default: \"filter_with_hvg\"\n\n\n--filter_with_hvg_obs_batch_key\nIf specified, highly-variable genes are selected within each batch separately and merged. This simple process avoids the selection of batch-specific genes and acts as a lightweight batch correction method.\nstring, default: \"sample_id\"\n\n\n\n\n\nQC metrics calculation options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‘True’, compared to the total sum of the values for all genes.\nList of string, default: \"filter_with_hvg\", example: \"ercc,highly_variable\", multiple_sep: \",\"\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, default: 50, 100, 200, 500, multiple_sep: \",\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--pca_overwrite\nAllow overwriting slots for PCA output.\nboolean_true"
  },
  {
    "objectID": "components/workflows/multiomics/multisample.html#authors",
    "href": "components/workflows/multiomics/multisample.html#authors",
    "title": "Multisample",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)"
  },
  {
    "objectID": "components/workflows/multiomics/multisample.html#visualisation",
    "href": "components/workflows/multiomics/multisample.html#visualisation",
    "title": "Multisample",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v7(filter)\n    v12(split_modalities)\n    v14(join)\n    v21(concat)\n    v17(filter)\n    v19(test_wf:run_wf:split_modalities_workflow:splitStub)\n    v22(flatMap)\n    v23(filter)\n    v26(toSortedList)\n    v28(flatMap)\n    v30(toSortedList)\n    v32(Output)\n    v38(normalize_total)\n    v40(join)\n    v48(log1p)\n    v50(join)\n    v58(delete_layer)\n    v60(join)\n    v68(filter_with_hvg)\n    v70(join)\n    v78(rna_calculate_qc_metrics)\n    v80(join)\n    v121(concat)\n    v86(filter)\n    v89(toSortedList)\n    v91(flatMap)\n    v93(toSortedList)\n    v95(Output)\n    v101(clr)\n    v103(join)\n    v111(prot_calculate_qc_metrics)\n    v113(join)\n    v119(filter)\n    v122(groupTuple)\n    v128(merge)\n    v130(join)\n    v133(filter)\n    v137(toSortedList)\n    v139(flatMap)\n    v146(pca)\n    v148(join)\n    v156(find_neighbors)\n    v158(join)\n    v166(umap)\n    v168(join)\n    v173(concat)\n    v172(filter)\n    v174(filter)\n    v178(toSortedList)\n    v180(flatMap)\n    v187(pca)\n    v189(join)\n    v197(find_neighbors)\n    v199(join)\n    v207(test_wf:run_wf:integration_setup_workflow:initialize_integration_prot:umap:umap_process1)\n    v209(join)\n    v214(concat)\n    v213(filter)\n    v220(publish)\n    v222(join)\n    v227(toSortedList)\n    v229(Output)\n    v21--&gt;v22\n    v22--&gt;v23\n    v22--&gt;v86\n    v22--&gt;v119\n    v121--&gt;v122\n    v172--&gt;v173\n    v173--&gt;v174\n    v173--&gt;v213\n    v213--&gt;v214\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v7\n    v4--&gt;v17\n    v7--&gt;v14\n    v7--&gt;v12\n    v12--&gt;v14\n    v14--&gt;v21\n    v17--&gt;v19\n    v19--&gt;v21\n    v23--&gt;v26\n    v26--&gt;v28\n    v28--&gt;v30\n    v30--&gt;v32\n    v28--&gt;v40\n    v28--&gt;v38\n    v38--&gt;v40\n    v40--&gt;v50\n    v40--&gt;v48\n    v48--&gt;v50\n    v50--&gt;v60\n    v50--&gt;v58\n    v58--&gt;v60\n    v60--&gt;v70\n    v60--&gt;v68\n    v68--&gt;v70\n    v70--&gt;v80\n    v70--&gt;v78\n    v78--&gt;v80\n    v80--&gt;v121\n    v86--&gt;v89\n    v89--&gt;v91\n    v91--&gt;v93\n    v93--&gt;v95\n    v91--&gt;v103\n    v91--&gt;v101\n    v101--&gt;v103\n    v103--&gt;v113\n    v103--&gt;v111\n    v111--&gt;v113\n    v113--&gt;v121\n    v119--&gt;v121\n    v122--&gt;v130\n    v122--&gt;v128\n    v128--&gt;v130\n    v130--&gt;v133\n    v130--&gt;v172\n    v133--&gt;v137\n    v137--&gt;v139\n    v139--&gt;v148\n    v139--&gt;v146\n    v146--&gt;v148\n    v148--&gt;v158\n    v148--&gt;v156\n    v156--&gt;v158\n    v158--&gt;v168\n    v158--&gt;v166\n    v166--&gt;v168\n    v168--&gt;v173\n    v174--&gt;v178\n    v178--&gt;v180\n    v180--&gt;v189\n    v180--&gt;v187\n    v187--&gt;v189\n    v189--&gt;v199\n    v189--&gt;v197\n    v197--&gt;v199\n    v199--&gt;v209\n    v199--&gt;v207\n    v207--&gt;v209\n    v209--&gt;v214\n    v214--&gt;v222\n    v214--&gt;v220\n    v220--&gt;v222\n    v222--&gt;v227\n    v227--&gt;v229"
  },
  {
    "objectID": "components/workflows/ingestion/demux.html",
    "href": "components/workflows/ingestion/demux.html",
    "title": "Demux",
    "section": "",
    "text": "ID: demux\nNamespace: ingestion\n\n\n\nSource\nConvert .bcl files to .fastq files using bcl2fastq, bcl-convert or Cell Ranger mkfastq."
  },
  {
    "objectID": "components/workflows/ingestion/demux.html#example-commands",
    "href": "components/workflows/ingestion/demux.html#example-commands",
    "title": "Demux",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/ingestion/demux/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"bcl_dir\"\nsample_sheet: # please fill in - example: \"bcl_dir\"\ndemultiplexer: \"bcl2fastq\"\n# ignore_missing: true\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/ingestion/demux/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/ingestion/demux.html#argument-group",
    "href": "components/workflows/ingestion/demux.html#argument-group",
    "title": "Demux",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nInput run directory\nfile, required, example: \"bcl_dir\"\n\n\n--sample_sheet\nPointer to the sample sheet\nfile, required, example: \"bcl_dir\"\n\n\n--demultiplexer\nThe multiplexer to use, one of bclconvert or mkfastq\nstring, default: \"bcl2fastq\"\n\n\n--ignore_missing\nShould the demultiplexer ignore missing entities (filter, …)\nboolean"
  },
  {
    "objectID": "components/workflows/ingestion/demux.html#authors",
    "href": "components/workflows/ingestion/demux.html#authors",
    "title": "Demux",
    "section": "Authors",
    "text": "Authors\n\nToni Verbeiren   (author, maintainer)\nMarijke Van Moerbeke    (author)\nAngela Oliveira Pisco    (author)\nSamuel D’Souza   (author)\nRobrecht Cannoodt    (author)"
  },
  {
    "objectID": "components/workflows/ingestion/demux.html#visualisation",
    "href": "components/workflows/ingestion/demux.html#visualisation",
    "title": "Demux",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v5(filter)\n    v10(cellranger_mkfastq)\n    v12(join)\n    v35(mix)\n    v15(filter)\n    v20(bcl_convert)\n    v22(join)\n    v25(filter)\n    v30(bcl2fastq)\n    v32(join)\n    v41(fastqc)\n    v43(join)\n    v46(Output)\n    v48(toSortedList)\n    v54(multiqc)\n    v56(join)\n    v59(Output)\n    v63(Output)\n    v4--&gt;v5\n    v4--&gt;v15\n    v4--&gt;v25\n    v0--&gt;v2\n    v2--&gt;v4\n    v5--&gt;v12\n    v5--&gt;v10\n    v10--&gt;v12\n    v12--&gt;v35\n    v15--&gt;v22\n    v15--&gt;v20\n    v20--&gt;v22\n    v22--&gt;v35\n    v25--&gt;v32\n    v25--&gt;v30\n    v30--&gt;v32\n    v32--&gt;v35\n    v35--&gt;v43\n    v35--&gt;v41\n    v41--&gt;v43\n    v43--&gt;v46\n    v35--&gt;v48\n    v48--&gt;v56\n    v48--&gt;v54\n    v54--&gt;v56\n    v56--&gt;v59\n    v35--&gt;v63"
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html",
    "href": "components/workflows/ingestion/conversion.html",
    "title": "Conversion",
    "section": "",
    "text": "ID: conversion\nNamespace: ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html#example-commands",
    "href": "components/workflows/ingestion/conversion.html#example-commands",
    "title": "Conversion",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/ingestion/conversion/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: [\"input.h5mu\"]\ninput_type: # please fill in - example: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Conversion from h5ad\n# modality: [\"foo\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/ingestion/conversion/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html#argument-groups",
    "href": "components/workflows/ingestion/conversion.html#argument-groups",
    "title": "Conversion",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nList of file, required, example: \"input.h5mu\", multiple_sep: \";\"\n\n\n--input_type\nType of the input file\nstring, required\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nName or template for the output files.\nfile, example: \"output.h5mu\"\n\n\n\n\n\nConversion from h5ad\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--modality\nName of the modality where the h5ad is stored in the h5mu object.\nList of string, multiple_sep: \":\""
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html#authors",
    "href": "components/workflows/ingestion/conversion.html#authors",
    "title": "Conversion",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author, maintainer)\nDries De Maeyer   (author)"
  },
  {
    "objectID": "components/workflows/ingestion/conversion.html#visualisation",
    "href": "components/workflows/ingestion/conversion.html#visualisation",
    "title": "Conversion",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v5(filter)\n    v10(from_10xh5_to_h5mu)\n    v12(join)\n    v35(mix)\n    v15(filter)\n    v20(from_10xmtx_to_h5mu)\n    v22(join)\n    v25(filter)\n    v30(from_h5ad_to_h5mu)\n    v32(join)\n    v37(toSortedList)\n    v39(Output)\n    v4--&gt;v5\n    v4--&gt;v15\n    v4--&gt;v25\n    v0--&gt;v2\n    v2--&gt;v4\n    v5--&gt;v12\n    v5--&gt;v10\n    v10--&gt;v12\n    v12--&gt;v35\n    v15--&gt;v22\n    v15--&gt;v20\n    v20--&gt;v22\n    v22--&gt;v35\n    v25--&gt;v32\n    v25--&gt;v30\n    v30--&gt;v32\n    v32--&gt;v35\n    v35--&gt;v37\n    v37--&gt;v39"
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html",
    "href": "components/workflows/ingestion/bd_rhapsody.html",
    "title": "BD Rhapsody",
    "section": "",
    "text": "ID: bd_rhapsody\nNamespace: ingestion\n\n\n\nSource\nA wrapper for the BD Rhapsody Analysis CWL v1.10.1 pipeline.\nThis pipeline can be used for a targeted analysis (with --mode targeted) or for a whole transcriptome analysis (with --mode wta).\nThe reference_genome and transcriptome_annotation files can be generated with the make_reference pipeline. Alternatively, BD also provides standard references which can be downloaded from these locations:"
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html#example-commands",
    "href": "components/workflows/ingestion/bd_rhapsody.html#example-commands",
    "title": "BD Rhapsody",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/ingestion/bd_rhapsody/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nmode: # please fill in - example: \"wta\"\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: [\"input.fastq.gz\"]\nreference: # please fill in - example: [\"reference_genome.tar.gz|reference.fasta\"]\n# transcriptome_annotation: \"transcriptome.gtf\"\n# abseq_reference: [\"abseq_reference.fasta\"]\n# supplemental_reference: [\"supplemental_reference.fasta\"]\nsample_prefix: \"sample\"\n\n# Outputs\n# output_raw: \"$id.$key.output_raw.output_raw\"\n# output_h5mu: \"$id.$key.output_h5mu.h5mu\"\n\n# Putative cell calling settings\n# putative_cell_call: \"mRNA\"\n# exact_cell_count: 10000\ndisable_putative_calling: false\n\n# Subsample arguments\n# subsample: 0.01\n# subsample_seed: 3445\n\n# Multiplex arguments\n# sample_tags_version: \"human\"\n# tag_names: [\"4-mySample\", \"9-myOtherSample\", \"6-alsoThisSample\"]\n\n# VDJ arguments\n# vdj_version: \"human\"\n\n# CWL-runner arguments\nparallel: true\ntimestamps: false\ndryrun: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/ingestion/bd_rhapsody/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html#argument-groups",
    "href": "components/workflows/ingestion/bd_rhapsody.html#argument-groups",
    "title": "BD Rhapsody",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--mode\nWhether to run a whole transcriptome analysis (WTA) or a targeted analysis.\nstring, required, example: \"wta\"\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to your read files in the FASTQ.GZ format. You may specify as many R1/R2 read pairs as you want.\nList of file, required, example: \"input.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nRefence to map to. For --mode wta, this is the path to STAR index as a tar.gz file. For --mode targeted, this is the path to mRNA reference file for pre-designed, supplemental, or custom panel, in FASTA format\nList of file, required, example: \"reference_genome.tar.gz&#124;reference.fasta\", multiple_sep: \";\"\n\n\n--transcriptome_annotation\nPath to GTF annotation file (only for --mode wta).\nfile, example: \"transcriptome.gtf\"\n\n\n--abseq_reference\nPath to the AbSeq reference file in FASTA format. Only needed if BD AbSeq Ab-Oligos are used.\nList of file, example: \"abseq_reference.fasta\", multiple_sep: \";\"\n\n\n--supplemental_reference\nPath to the supplemental reference file in FASTA format. Only needed if there are additional transgene sequences used in the experiment (only for --mode wta).\nList of file, example: \"supplemental_reference.fasta\", multiple_sep: \";\"\n\n\n--sample_prefix\nSpecify a run name to use as the output file base name. Use only letters, numbers, or hyphens. Do not use special characters or spaces.\nstring, default: \"sample\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_raw\nThe BD Rhapsody output folder as it comes out of the BD Rhapsody pipeline\nfile, required, example: \"output_dir\"\n\n\n--output_h5mu\nThe converted h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nPutative cell calling settings\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--putative_cell_call\nSpecify the dataset to be used for putative cell calling. For putative cell calling using an AbSeq dataset, please provide an AbSeq_Reference fasta file above.\nstring, example: \"mRNA\"\n\n\n--exact_cell_count\nExact cell count - Set a specific number (&gt;=1) of cells as putative, based on those with the highest error-corrected read count\ninteger, example: 10000\n\n\n--disable_putative_calling\nDisable Refined Putative Cell Calling - Determine putative cells using only the basic algorithm (minimum second derivative along the cumulative reads curve). The refined algorithm attempts to remove false positives and recover false negatives, but may not be ideal for certain complex mixtures of cell types. Does not apply if Exact Cell Count is set.\nboolean_true\n\n\n\n\n\nSubsample arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--subsample\nA number &gt;1 or fraction (0 &lt; n &lt; 1) to indicate the number or percentage of reads to subsample.\ndouble, example: 0.01\n\n\n--subsample_seed\nA seed for replicating a previous subsampled run.\ninteger, example: 3445\n\n\n\n\n\nMultiplex arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sample_tags_version\nSpecify if multiplexed run.\nstring, example: \"human\"\n\n\n--tag_names\nTag_Names (optional) - Specify the tag number followed by ‘-’ and the desired sample name to appear in Sample_Tag_Metrics.csv. Do not use the special characters: &, (), [], {}, &lt;&gt;, ?, |\nList of string, example: \"4-mySample\", \"9-myOtherSample\", \"6-alsoThisSample\", multiple_sep: \":\"\n\n\n\n\n\nVDJ arguments\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--vdj_version\nSpecify if VDJ run.\nstring, example: \"human\"\n\n\n\n\n\nCWL-runner arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--parallel\nRun jobs in parallel.\nboolean, default: TRUE\n\n\n--timestamps\nAdd timestamps to the errors, warnings, and notifications.\nboolean_true\n\n\n--dryrun\nIf true, the output directory will only contain the CWL input files, but the pipeline itself will not be executed.\nboolean_true"
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html#authors",
    "href": "components/workflows/ingestion/bd_rhapsody.html#authors",
    "title": "BD Rhapsody",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/workflows/ingestion/bd_rhapsody.html#visualisation",
    "href": "components/workflows/ingestion/bd_rhapsody.html#visualisation",
    "title": "BD Rhapsody",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v10(bd_rhapsody)\n    v12(join)\n    v20(from_bdrhap_to_h5mu)\n    v22(join)\n    v28(Output)\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v12\n    v4--&gt;v10\n    v10--&gt;v12\n    v12--&gt;v22\n    v12--&gt;v20\n    v20--&gt;v22\n    v22--&gt;v28"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html",
    "href": "components/workflows/ingestion/cellranger_mapping.html",
    "title": "Cell Ranger mapping",
    "section": "",
    "text": "ID: cellranger_mapping\nNamespace: ingestion\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html#example-commands",
    "href": "components/workflows/ingestion/cellranger_mapping.html#example-commands",
    "title": "Cell Ranger mapping",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script ./workflows/ingestion/cellranger_mapping/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: [\"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\"]\nreference: # please fill in - example: \"reference.tar.gz\"\n\n# Outputs\n# output_raw: \"$id.$key.output_raw.output_raw\"\n# output_h5mu: \"$id.$key.output_h5mu.h5mu\"\nobsm_metrics: \"metrics_summary\"\noutput_type: \"raw\"\n\n# Cell Ranger arguments\n# expect_cells: 3000\nchemistry: \"auto\"\nsecondary_analysis: false\ngenerate_bam: true\ninclude_introns: true\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script ./workflows/ingestion/cellranger_mapping/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html#argument-groups",
    "href": "components/workflows/ingestion/cellranger_mapping.html#argument-groups",
    "title": "Cell Ranger mapping",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nThe fastq.gz files to align. Can also be a single directory containing fastq.gz files.\nList of file, required, example: \"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nThe path to Cell Ranger reference tar.gz file.\nfile, required, example: \"reference.tar.gz\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output_raw\nLocation where the output folder from Cell Ranger will be stored.\nfile, required, example: \"output_dir\"\n\n\n--output_h5mu\nThe output from Cell Ranger, converted to h5mu.\nfile, required, example: \"output.h5mu\"\n\n\n--obsm_metrics\nName of the .obsm slot under which to QC metrics (if any).\nstring, default: \"metrics_summary\"\n\n\n--output_type\nWhich Cell Ranger output to use for converting to h5mu.\nstring, default: \"raw\"\n\n\n\n\n\nCell Ranger arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\ninteger, example: 3000\n\n\n--chemistry\nAssay configuration. - auto: autodetect mode - threeprime: Single Cell 3’ - fiveprime: Single Cell 5’ - SC3Pv1: Single Cell 3’ v1 - SC3Pv2: Single Cell 3’ v2 - SC3Pv3: Single Cell 3’ v3 - SC3Pv3LT: Single Cell 3’ v3 LT - SC3Pv3HT: Single Cell 3’ v3 HT - SC5P-PE: Single Cell 5’ paired-end - SC5P-R2: Single Cell 5’ R2-only - SC-FB: Single Cell Antibody-only 3’ v2 or 5’ See https://kb.10xgenomics.com/hc/en-us/articles/115003764132-How-does-Cell-Ranger-auto-detect-chemistry- for more information.\nstring, default: \"auto\"\n\n\n--secondary_analysis\nWhether or not to run the secondary analysis e.g. clustering.\nboolean, default: FALSE\n\n\n--generate_bam\nWhether to generate a BAM file.\nboolean, default: TRUE\n\n\n--include_introns\nInclude intronic reads in count (default=true unless –target-panel is specified in which case default=false)\nboolean, default: TRUE"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html#authors",
    "href": "components/workflows/ingestion/cellranger_mapping.html#authors",
    "title": "Cell Ranger mapping",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)\nDries De Maeyer   (author)"
  },
  {
    "objectID": "components/workflows/ingestion/cellranger_mapping.html#visualisation",
    "href": "components/workflows/ingestion/cellranger_mapping.html#visualisation",
    "title": "Cell Ranger mapping",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    v0(Input)\n    v2(toSortedList)\n    v4(flatMap)\n    v11(cellranger_count)\n    v13(join)\n    v20(cellranger_count_split)\n    v22(join)\n    v30(from_10xh5_to_h5mu)\n    v32(join)\n    v39(Output)\n    v0--&gt;v2\n    v2--&gt;v4\n    v4--&gt;v13\n    v4--&gt;v11\n    v11--&gt;v13\n    v13--&gt;v22\n    v13--&gt;v20\n    v20--&gt;v22\n    v22--&gt;v32\n    v22--&gt;v30\n    v30--&gt;v32\n    v32--&gt;v39"
  },
  {
    "objectID": "components/workflows/integration/initialize_integration/initialize_integration.html",
    "href": "components/workflows/integration/initialize_integration/initialize_integration.html",
    "title": "Initialize integration",
    "section": "",
    "text": "ID: initialize_integration\nNamespace: integration/initialize_integration\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/integration/initialize_integration/initialize_integration.html#example-commands",
    "href": "components/workflows/integration/initialize_integration/initialize_integration.html#example-commands",
    "title": "Initialize integration",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -main-script workflows/multiomics/integration/initialize_integration/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# PCA options\nobsm_pca: \"X_pca\"\n# var_pca_feature_selection: \"foo\"\n\n# Neighbour calculation\nuns_neighbors: \"neighbors\"\nobsp_neighbor_distances: \"distances\"\nobsp_neighbor_connectivities: \"connectivities\"\n\n# Umap options\nobsm_umap: \"X_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -profile docker \\\n  -main-script workflows/multiomics/integration/initialize_integration/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/integration/initialize_integration/initialize_integration.html#argument-groups",
    "href": "components/workflows/integration/initialize_integration/initialize_integration.html#argument-groups",
    "title": "Initialize integration",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nPCA options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_pca\nIn which .obsm slot to store the resulting PCA embedding.\nstring, default: \"X_pca\"\n\n\n--var_pca_feature_selection\nColumn name in .var matrix that will be used to select which genes to run the PCA on.\nstring\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"connectivities\"\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_umap\""
  },
  {
    "objectID": "components/workflows/integration/initialize_integration/initialize_integration.html#authors",
    "href": "components/workflows/integration/initialize_integration/initialize_integration.html#authors",
    "title": "Initialize integration",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/workflows/integration/initialize_integration/initialize_integration.html#visualisation",
    "href": "components/workflows/integration/initialize_integration/initialize_integration.html#visualisation",
    "title": "Initialize integration",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    p0(Input)\n    p2(toSortedList)\n    p4(flatMap)\n    p12(pca)\n    p22(find_neighbors)\n    p32(umap)\n    p40(Output)\n    p0--&gt;p2\n    p2--&gt;p4\n    p4--&gt;p12\n    p12--&gt;p22\n    p22--&gt;p32\n    p32--&gt;p40"
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html",
    "href": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html",
    "title": "Scanorama leiden",
    "section": "",
    "text": "ID: scanorama_leiden\nNamespace: integration/scanorama_leiden\n\n\n\nSource"
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#example-commands",
    "href": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#example-commands",
    "title": "Scanorama leiden",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -main-script workflows/multiomics/integration/scanorama_leiden/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"foo\"\ninput: # please fill in - example: \"dataset.h5mu\"\nlayer: \"log_normalized\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n\n# Neighbour calculation\nuns_neighbors: \"scanorama_integration_neighbors\"\nobsp_neighbor_distances: \"scanorama_integration_distances\"\nobsp_neighbor_connectivities: \"scanorama_integration_connectivities\"\n\n# Scanorama integration options\nobs_batch: \"sample_id\"\nobsm_input: \"X_pca\"\nobsm_output: \"X_scanorama\"\nknn: 20\nbatch_size: 5000\nsigma: 15\napprox: true\nalpha: 0.1\n\n# Clustering options\nobs_cluster: \"scanorama_integration_leiden\"\nleiden_resolution: [1]\n\n# Umap options\nobsm_umap: \"X_leiden_scanorama_umap\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.9.0 -latest \\\n  -profile docker \\\n  -main-script workflows/multiomics/integration/scanorama_leiden/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#argument-groups",
    "href": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#argument-groups",
    "title": "Scanorama leiden",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nID of the sample.\nstring, required, example: \"foo\"\n\n\n--input\nPath to the sample.\nfile, required, example: \"dataset.h5mu\"\n\n\n--layer\nuse specified layer for expression values instead of the .X object from the modality.\nstring, default: \"log_normalized\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nDestination path to the output.\nfile, required, example: \"output.h5mu\"\n\n\n\n\n\nNeighbour calculation\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--uns_neighbors\nIn which .uns slot to store various neighbor output objects.\nstring, default: \"scanorama_integration_neighbors\"\n\n\n--obsp_neighbor_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"scanorama_integration_distances\"\n\n\n--obsp_neighbor_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"scanorama_integration_connectivities\"\n\n\n\n\n\nScanorama integration options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--obsm_input\n.osbm slot that points to embedding to run scanorama on.\nstring, default: \"X_pca\"\n\n\n--obsm_output\nThe name of the field in adata.obsm where the integrated embeddings will be stored after running this function. Defaults to X_scanorama.\nstring, default: \"X_scanorama\"\n\n\n--knn\nNumber of nearest neighbors to use for matching.\ninteger, default: 20\n\n\n--batch_size\nThe batch size used in the alignment vector computation. Useful when integrating very large (&gt;100k samples) datasets. Set to large value that runs within available memory.\ninteger, default: 5000\n\n\n--sigma\nCorrection smoothing parameter on Gaussian kernel.\ndouble, default: 15\n\n\n--approx\nUse approximate nearest neighbors with Python annoy; greatly speeds up matching runtime.\nboolean, default: TRUE\n\n\n--alpha\nAlignment score minimum cutoff\ndouble, default: 0.1\n\n\n\n\n\nClustering options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obs_cluster\nName of the .obs key under which to add the cluster labels.\nstring, default: \"scanorama_integration_leiden\"\n\n\n--leiden_resolution\nControl the coarseness of the clustering. Higher values lead to more clusters.\ndouble, default: 1\n\n\n\n\n\nUmap options\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--obsm_umap\nIn which .obsm slot to store the resulting UMAP embedding.\nstring, default: \"X_leiden_scanorama_umap\""
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#authors",
    "href": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#authors",
    "title": "Scanorama leiden",
    "section": "Authors",
    "text": "Authors\n\nMauro Saporita   (author)\nPovilas Gibas   (author)"
  },
  {
    "objectID": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#visualisation",
    "href": "components/workflows/integration/scanorama_leiden/scanorama_leiden.html#visualisation",
    "title": "Scanorama leiden",
    "section": "Visualisation",
    "text": "Visualisation\n\n\n\n\nflowchart LR\n    p0(Input)\n    p2(toSortedList)\n    p4(flatMap)\n    p12(scanorama)\n    p22(find_neighbors)\n    p32(leiden)\n    p42(umap)\n    p52(move_obsm_to_obs)\n    p60(Output)\n    p0--&gt;p2\n    p2--&gt;p4\n    p4--&gt;p12\n    p12--&gt;p22\n    p22--&gt;p32\n    p32--&gt;p42\n    p42--&gt;p52\n    p52--&gt;p60"
  },
  {
    "objectID": "components/modules/dimred/pca.html",
    "href": "components/modules/dimred/pca.html",
    "title": "Pca",
    "section": "",
    "text": "ID: pca\nNamespace: dimred\n\n\n\nSource\nUses the implementation of scikit-learn [Pedregosa11]"
  },
  {
    "objectID": "components/modules/dimred/pca.html#example-commands",
    "href": "components/modules/dimred/pca.html#example-commands",
    "title": "Pca",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/dimred/pca/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"foo\"\n# var_input: \"filter_with_hvg\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobsm_output: \"X_pca\"\nvarm_output: \"pca_loadings\"\nuns_output: \"pca_variance\"\n# num_components: 25\noverwrite: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dimred/pca/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/dimred/pca.html#argument-group",
    "href": "components/modules/dimred/pca.html#argument-group",
    "title": "Pca",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\nUse specified layer for expression values instead of the .X object from the modality.\nstring\n\n\n--var_input\nColumn name in .var matrix that will be used to select which genes to run the PCA on.\nstring, example: \"filter_with_hvg\"\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obsm_output\nIn which .obsm slot to store the resulting embedding.\nstring, default: \"X_pca\"\n\n\n--varm_output\nIn which .varm slot to store the resulting loadings matrix.\nstring, default: \"pca_loadings\"\n\n\n--uns_output\nIn which .uns slot to store the resulting variance objects.\nstring, default: \"pca_variance\"\n\n\n--num_components\nNumber of principal components to compute. Defaults to 50, or 1 - minimum dimension size of selected representation.\ninteger, example: 25\n\n\n--overwrite\nAllow overwriting .obsm, .varm and .uns slots.\nboolean_true"
  },
  {
    "objectID": "components/modules/dimred/pca.html#authors",
    "href": "components/modules/dimred/pca.html#authors",
    "title": "Pca",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)"
  },
  {
    "objectID": "components/modules/metadata/join_csv.html",
    "href": "components/modules/metadata/join_csv.html",
    "title": "Join csv",
    "section": "",
    "text": "ID: join_csv\nNamespace: metadata\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/metadata/join_csv.html#example-commands",
    "href": "components/modules/metadata/join_csv.html#example-commands",
    "title": "Join csv",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/metadata/join_csv/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# MuData Input\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# obs_key: \"foo\"\n# var_key: \"foo\"\n\n# MuData Output\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Metadata Input\ninput_csv: # please fill in - example: \"metadata.csv\"\ncsv_key: \"id\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/join_csv/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/metadata/join_csv.html#argument-groups",
    "href": "components/modules/metadata/join_csv.html#argument-groups",
    "title": "Join csv",
    "section": "Argument groups",
    "text": "Argument groups\n\nMuData Input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obs_key\nObs column name where the sample id can be found for each observation to join on. Useful when adding metadata to concatenated samples. Mutually exclusive with --var_key.”\nstring\n\n\n--var_key\nVar column name where the sample id can be found for each variable to join on. Mutually exclusive with --obs_key.”\nstring\n\n\n\n\n\nMuData Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n\n\n\nMetadata Input\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_csv\n.csv file containing metadata\nfile, required, example: \"metadata.csv\"\n\n\n--csv_key\ncolumn of the the csv that corresponds to the sample id.\nstring, default: \"id\""
  },
  {
    "objectID": "components/modules/metadata/join_csv.html#authors",
    "href": "components/modules/metadata/join_csv.html#authors",
    "title": "Join csv",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/modules/metadata/add_id.html",
    "href": "components/modules/metadata/add_id.html",
    "title": "Add id",
    "section": "",
    "text": "ID: add_id\nNamespace: metadata\n\n\n\nSource\nAlso allows to make .obs_names (the .obs index) unique by prefixing the values with an unique id per .h5mu file"
  },
  {
    "objectID": "components/modules/metadata/add_id.html#example-commands",
    "href": "components/modules/metadata/add_id.html#example-commands",
    "title": "Add id",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/metadata/add_id/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"sample_path\"\ninput_id: # please fill in - example: \"foo\"\nobs_output: \"sample_id\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nmake_observation_keys_unique: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/add_id/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/metadata/add_id.html#argument-group",
    "href": "components/modules/metadata/add_id.html#argument-group",
    "title": "Add id",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the input .h5mu.\nfile, required, example: \"sample_path\"\n\n\n--input_id\nThe input id.\nstring, required\n\n\n--obs_output\nName of the .obs column where to store the id.\nstring, default: \"sample_id\"\n\n\n--output\n\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--make_observation_keys_unique\nJoin the id to the .obs index (.obs_names).\nboolean_true"
  },
  {
    "objectID": "components/modules/metadata/add_id.html#authors",
    "href": "components/modules/metadata/add_id.html#authors",
    "title": "Add id",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/metadata/join_uns_to_obs.html",
    "href": "components/modules/metadata/join_uns_to_obs.html",
    "title": "Join uns to obs",
    "section": "",
    "text": "ID: join_uns_to_obs\nNamespace: metadata\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/metadata/join_uns_to_obs.html#example-commands",
    "href": "components/modules/metadata/join_uns_to_obs.html#example-commands",
    "title": "Join uns to obs",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/metadata/join_uns_to_obs/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nuns_key: # please fill in - example: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/metadata/join_uns_to_obs/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/metadata/join_uns_to_obs.html#argument-group",
    "href": "components/modules/metadata/join_uns_to_obs.html#argument-group",
    "title": "Join uns to obs",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--uns_key\n\nstring, required\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/files/make_params.html",
    "href": "components/modules/files/make_params.html",
    "title": "Make params",
    "section": "",
    "text": "ID: make_params\nNamespace: files\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/files/make_params.html#example-commands",
    "href": "components/modules/files/make_params.html#example-commands",
    "title": "Make params",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/files/make_params/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nbase_dir: # please fill in - example: \"/path/to/dir\"\npattern: # please fill in - example: \"*.fastq.gz\"\nn_dirname_drop: 0\nn_basename_id: 0\nid_name: \"id\"\npath_name: \"path\"\n# group_name: \"param_list\"\n# output: \"$id.$key.output.yaml\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/files/make_params/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/files/make_params.html#argument-group",
    "href": "components/modules/files/make_params.html#argument-group",
    "title": "Make params",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--base_dir\nBase directory to search recursively\nfile, required, example: \"/path/to/dir\"\n\n\n--pattern\nAn optional regular expression. Only file names which match the regular expression will be matched.\nstring, required, example: \"*.fastq.gz\"\n\n\n--n_dirname_drop\nFor every matched file, the parent directory will be traversed N times.\ninteger, default: 0\n\n\n--n_basename_id\nThe unique identifiers will consist of at least N dirnames.\ninteger, default: 0\n\n\n--id_name\nThe name for storing the identifier field in the yaml.\nstring, default: \"id\"\n\n\n--path_name\nThe name for storing the path field in the yaml.\nstring, default: \"path\"\n\n\n--group_name\nTop level name for the group of entries.\nstring, example: \"param_list\"\n\n\n--output\nOutput YAML file.\nfile, required, example: \"params.yaml\""
  },
  {
    "objectID": "components/modules/files/make_params.html#authors",
    "href": "components/modules/files/make_params.html#authors",
    "title": "Make params",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (maintainer, author)"
  },
  {
    "objectID": "components/modules/velocity/scvelo.html",
    "href": "components/modules/velocity/scvelo.html",
    "title": "Scvelo",
    "section": "",
    "text": "ID: scvelo\nNamespace: velocity\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/velocity/scvelo.html#example-commands",
    "href": "components/modules/velocity/scvelo.html#example-commands",
    "title": "Scvelo",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/velocity/scvelo/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"path/to/file\"\n\n# Outputs\n# output: \"$id.$key.output.output\"\n# output_compression: \"gzip\"\n\n# Filtering and normalization\n# min_counts: 123\n# min_counts_u: 123\n# min_cells: 123\n# min_cells_u: 123\n# min_shared_counts: 123\n# min_shared_cells: 123\n# n_top_genes: 123\nlog_transform: true\n\n# Fitting parameters\n# n_principal_components: 123\nn_neighbors: 30\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/velocity/scvelo/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/velocity/scvelo.html#argument-groups",
    "href": "components/modules/velocity/scvelo.html#argument-groups",
    "title": "Scvelo",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nVelocyto loom file.\nfile, required\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput directory. If it does not exist, will be created.\nfile, required\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n\n\n\nFiltering and normalization\nArguments for filtering, normalization an log transform (see scvelo.pp.filter_and_normalize function)\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--min_counts\nMinimum number of counts required for a gene to pass filtering (spliced).\ninteger\n\n\n--min_counts_u\nMinimum number of counts required for a gene to pass filtering (unspliced).\ninteger\n\n\n--min_cells\nMinimum number of cells expressed required to pass filtering (spliced).\ninteger\n\n\n--min_cells_u\nMinimum number of cells expressed required to pass filtering (unspliced).\ninteger\n\n\n--min_shared_counts\nMinimum number of counts (both unspliced and spliced) required for a gene.\ninteger\n\n\n--min_shared_cells\nMinimum number of cells required to be expressed (both unspliced and spliced).\ninteger\n\n\n--n_top_genes\nNumber of genes to keep.\ninteger\n\n\n--log_transform\nDo not log transform counts.\nboolean, default: TRUE\n\n\n\n\n\nFitting parameters\nArguments for fitting the data\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--n_principal_components\nNumber of principal components to use for calculating moments.\ninteger\n\n\n--n_neighbors\nNumber of neighbors to use. First/second-order moments are computed for each cell across its nearest neighbors, where the neighbor graph is obtained from euclidean distances in PCA space.\ninteger, default: 30"
  },
  {
    "objectID": "components/modules/velocity/scvelo.html#authors",
    "href": "components/modules/velocity/scvelo.html#authors",
    "title": "Scvelo",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/download/sync_test_resources.html",
    "href": "components/modules/download/sync_test_resources.html",
    "title": "Sync test resources",
    "section": "",
    "text": "ID: sync_test_resources\nNamespace: download\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/download/sync_test_resources.html#example-commands",
    "href": "components/modules/download/sync_test_resources.html#example-commands",
    "title": "Sync test resources",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/download/sync_test_resources/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: \"s3://openpipelines-data\"\n# output: \"$id.$key.output.output\"\nquiet: false\ndryrun: false\ndelete: false\n# exclude: [\"foo\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/download/sync_test_resources/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/download/sync_test_resources.html#argument-group",
    "href": "components/modules/download/sync_test_resources.html#argument-group",
    "title": "Sync test resources",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the S3 bucket to sync from.\nstring, default: \"s3://openpipelines-data\"\n\n\n--output\nPath to the test resource directory.\nfile, default: \"resources_test\"\n\n\n--quiet\nDisplays the operations that would be performed using the specified command without actually running them.\nboolean_true\n\n\n--dryrun\nDoes not display the operations performed from the specified command.\nboolean_true\n\n\n--delete\nFiles that exist in the destination but not in the source are deleted during sync.\nboolean_true\n\n\n--exclude\nExclude all files or objects from the command that matches the specified pattern.\nList of string, multiple_sep: \":\""
  },
  {
    "objectID": "components/modules/download/sync_test_resources.html#authors",
    "href": "components/modules/download/sync_test_resources.html#authors",
    "title": "Sync test resources",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/mapping/cellranger_multi.html",
    "href": "components/modules/mapping/cellranger_multi.html",
    "title": "Cellranger multi",
    "section": "",
    "text": "ID: cellranger_multi\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/cellranger_multi.html#example-commands",
    "href": "components/modules/mapping/cellranger_multi.html#example-commands",
    "title": "Cellranger multi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/mapping/cellranger_multi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Outputs\n# output: \"$id.$key.output.output\"\n\n# Input files\ninput: # please fill in - example: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\ngex_reference: # please fill in - example: \"reference_genome.tar.gz\"\n# vdj_reference: \"reference_vdj.tar.gz\"\n# vdj_inner_enrichment_primers: \"enrichment_primers.txt\"\n# feature_reference: \"feature_reference.csv\"\n\n# Library arguments\nlibrary_id: # please fill in - example: [\"mysample1\"]\nlibrary_type: # please fill in - example: [\"Gene Expression\"]\n# library_subsample: [\"0.5\"]\n# library_lanes: [\"1-4\"]\n\n# Gene expression arguments\n# gex_expect_cells: 3000\ngex_chemistry: \"auto\"\ngex_secondary_analysis: false\ngex_generate_bam: false\ngex_include_introns: true\n\n# Cell multiplexing parameters\n# cell_multiplex_sample_id: \"foo\"\n# cell_multiplex_oligo_ids: \"foo\"\n# cell_multiplex_description: \"foo\"\n\n# Executor arguments\ndryrun: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/cellranger_multi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/cellranger_multi.html#argument-groups",
    "href": "components/modules/mapping/cellranger_multi.html#argument-groups",
    "title": "Cellranger multi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput files\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe FASTQ files to be analyzed. FASTQ files should conform to the naming conventions of bcl2fastq and mkfastq: [Sample Name]_S[Sample Index]_L00[Lane Number]_[Read Type]_001.fastq.gz\nList of file, required, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--gex_reference\nGenome refence index built by Cell Ranger mkref.\nfile, required, example: \"reference_genome.tar.gz\"\n\n\n--vdj_reference\nVDJ refence index built by Cell Ranger mkref.\nfile, example: \"reference_vdj.tar.gz\"\n\n\n--vdj_inner_enrichment_primers\nV(D)J Immune Profiling libraries: if inner enrichment primers other than those provided in the 10x Genomics kits are used, they need to be specified here as a text file with one primer per line.\nfile, example: \"enrichment_primers.txt\"\n\n\n--feature_reference\nPath to the Feature reference CSV file, declaring Feature Barcode constructs and associated barcodes. Required only for Antibody Capture or CRISPR Guide Capture libraries. See https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/using/feature-bc-analysis#feature-ref for more information.\nfile, example: \"feature_reference.csv\"\n\n\n\n\n\nLibrary arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--library_id\nThe Illumina sample name to analyze. This must exactly match the ‘Sample Name’ part of the FASTQ files specified in the --input argument.\nList of string, required, example: \"mysample1\", multiple_sep: \";\"\n\n\n--library_type\nThe underlying feature type of the library. Possible values: “Gene Expression”, “VDJ”, “VDJ-T”, “VDJ-B”, “Antibody Capture”, “CRISPR Guide Capture”, “Multiplexing Capture”\nList of string, required, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--library_subsample\nOptional. The rate at which reads from the provided FASTQ files are sampled. Must be strictly greater than 0 and less than or equal to 1.\nList of string, example: \"0.5\", multiple_sep: \";\"\n\n\n--library_lanes\nLanes associated with this sample. Defaults to using all lanes.\nList of string, example: \"1-4\", multiple_sep: \";\"\n\n\n\n\n\nGene expression arguments\nArguments relevant to the analysis of gene expression data.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--gex_expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\ninteger, example: 3000\n\n\n--gex_chemistry\nAssay configuration. - auto: autodetect mode - threeprime: Single Cell 3’ - fiveprime: Single Cell 5’ - SC3Pv1: Single Cell 3’ v1 - SC3Pv2: Single Cell 3’ v2 - SC3Pv3: Single Cell 3’ v3 - SC3Pv3LT: Single Cell 3’ v3 LT - SC3Pv3HT: Single Cell 3’ v3 HT - SC5P-PE: Single Cell 5’ paired-end - SC5P-R2: Single Cell 5’ R2-only - SC-FB: Single Cell Antibody-only 3’ v2 or 5’ See https://kb.10xgenomics.com/hc/en-us/articles/115003764132-How-does-Cell-Ranger-auto-detect-chemistry- for more information.\nstring, default: \"auto\"\n\n\n--gex_secondary_analysis\nWhether or not to run the secondary analysis e.g. clustering.\nboolean, default: FALSE\n\n\n--gex_generate_bam\nWhether to generate a BAM file.\nboolean, default: FALSE\n\n\n--gex_include_introns\nInclude intronic reads in count (default=true unless –target-panel is specified in which case default=false)\nboolean, default: TRUE\n\n\n\n\n\nCell multiplexing parameters\nArguments related to cell multiplexing.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--cell_multiplex_sample_id\nA name to identify a multiplexed sample. Must be alphanumeric with hyphens and/or underscores, and less than 64 characters. Required for Cell Multiplexing libraries.\nstring\n\n\n--cell_multiplex_oligo_ids\nThe Cell Multiplexing oligo IDs used to multiplex this sample. If multiple CMOs were used for a sample, separate IDs with a pipe (e.g., CMO301|CMO302). Required for Cell Multiplexing libraries.\nstring\n\n\n--cell_multiplex_description\nA description for the sample.\nstring\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe folder to store the alignment results.\nfile, required, example: \"/path/to/output\"\n\n\n\n\n\nExecutor arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--dryrun\nIf true, the output directory will only contain the CWL input files, but the pipeline itself will not be executed.\nboolean_true"
  },
  {
    "objectID": "components/modules/mapping/cellranger_multi.html#authors",
    "href": "components/modules/mapping/cellranger_multi.html#authors",
    "title": "Cellranger multi",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)\nDries De Maeyer   (author)"
  },
  {
    "objectID": "components/modules/mapping/bd_rhapsody.html",
    "href": "components/modules/mapping/bd_rhapsody.html",
    "title": "BD Rhapsody",
    "section": "",
    "text": "ID: bd_rhapsody\nNamespace: mapping\n\n\n\nSource\nA wrapper for the BD Rhapsody Analysis CWL v1.10.1 pipeline.\nThe CWL pipeline file is obtained by cloning ‘https://bitbucket.org/CRSwDev/cwl/src/master/’ and removing all objects with class ‘DockerRequirement’ from the YML.\nThis pipeline can be used for a targeted analysis (with --mode targeted) or for a whole transcriptome analysis (with --mode wta).\nThe reference_genome and transcriptome_annotation files can be generated with the make_reference pipeline. Alternatively, BD also provides standard references which can be downloaded from these locations:"
  },
  {
    "objectID": "components/modules/mapping/bd_rhapsody.html#example-commands",
    "href": "components/modules/mapping/bd_rhapsody.html#example-commands",
    "title": "BD Rhapsody",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/mapping/bd_rhapsody/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nmode: # please fill in - example: \"wta\"\ninput: # please fill in - example: [\"input.fastq.gz\"]\nreference: # please fill in - example: [\"reference_genome.tar.gz|reference.fasta\"]\n# transcriptome_annotation: \"transcriptome.gtf\"\n# abseq_reference: [\"abseq_reference.fasta\"]\n# supplemental_reference: [\"supplemental_reference.fasta\"]\nsample_prefix: \"sample\"\n\n# Outputs\n# output: \"$id.$key.output.output\"\n\n# Putative cell calling settings\n# putative_cell_call: \"mRNA\"\n# exact_cell_count: 10000\ndisable_putative_calling: false\n\n# Subsample arguments\n# subsample: 0.01\n# subsample_seed: 3445\n\n# Multiplex arguments\n# sample_tags_version: \"human\"\n# tag_names: [\"4-mySample\", \"9-myOtherSample\", \"6-alsoThisSample\"]\n\n# VDJ arguments\n# vdj_version: \"human\"\n\n# CWL-runner arguments\nparallel: true\ntimestamps: false\ndryrun: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/bd_rhapsody/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/bd_rhapsody.html#argument-groups",
    "href": "components/modules/mapping/bd_rhapsody.html#argument-groups",
    "title": "BD Rhapsody",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--mode\nWhether to run a whole transcriptome analysis (WTA) or a targeted analysis.\nstring, required, example: \"wta\"\n\n\n--input\nPath to your read files in the FASTQ.GZ format. You may specify as many R1/R2 read pairs as you want.\nList of file, required, example: \"input.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nRefence to map to. For --mode wta, this is the path to STAR index as a tar.gz file. For --mode targeted, this is the path to mRNA reference file for pre-designed, supplemental, or custom panel, in FASTA format\nList of file, required, example: \"reference_genome.tar.gz&#124;reference.fasta\", multiple_sep: \";\"\n\n\n--transcriptome_annotation\nPath to GTF annotation file (only for --mode wta).\nfile, example: \"transcriptome.gtf\"\n\n\n--abseq_reference\nPath to the AbSeq reference file in FASTA format. Only needed if BD AbSeq Ab-Oligos are used.\nList of file, example: \"abseq_reference.fasta\", multiple_sep: \";\"\n\n\n--supplemental_reference\nPath to the supplemental reference file in FASTA format. Only needed if there are additional transgene sequences used in the experiment (only for --mode wta).\nList of file, example: \"supplemental_reference.fasta\", multiple_sep: \";\"\n\n\n--sample_prefix\nSpecify a run name to use as the output file base name. Use only letters, numbers, or hyphens. Do not use special characters or spaces.\nstring, default: \"sample\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput folder. Output still needs to be processed further.\nfile, required, example: \"output_dir\"\n\n\n\n\n\nPutative cell calling settings\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--putative_cell_call\nSpecify the dataset to be used for putative cell calling. For putative cell calling using an AbSeq dataset, please provide an AbSeq_Reference fasta file above.\nstring, example: \"mRNA\"\n\n\n--exact_cell_count\nExact cell count - Set a specific number (&gt;=1) of cells as putative, based on those with the highest error-corrected read count\ninteger, example: 10000\n\n\n--disable_putative_calling\nDisable Refined Putative Cell Calling - Determine putative cells using only the basic algorithm (minimum second derivative along the cumulative reads curve). The refined algorithm attempts to remove false positives and recover false negatives, but may not be ideal for certain complex mixtures of cell types. Does not apply if Exact Cell Count is set.\nboolean_true\n\n\n\n\n\nSubsample arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--subsample\nA number &gt;1 or fraction (0 &lt; n &lt; 1) to indicate the number or percentage of reads to subsample.\ndouble, example: 0.01\n\n\n--subsample_seed\nA seed for replicating a previous subsampled run.\ninteger, example: 3445\n\n\n\n\n\nMultiplex arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sample_tags_version\nSpecify if multiplexed run.\nstring, example: \"human\"\n\n\n--tag_names\nTag_Names (optional) - Specify the tag number followed by ‘-’ and the desired sample name to appear in Sample_Tag_Metrics.csv. Do not use the special characters: &, (), [], {}, &lt;&gt;, ?, |\nList of string, example: \"4-mySample\", \"9-myOtherSample\", \"6-alsoThisSample\", multiple_sep: \":\"\n\n\n\n\n\nVDJ arguments\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--vdj_version\nSpecify if VDJ run.\nstring, example: \"human\"\n\n\n\n\n\nCWL-runner arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--parallel\nRun jobs in parallel.\nboolean, default: TRUE\n\n\n--timestamps\nAdd timestamps to the errors, warnings, and notifications.\nboolean_true\n\n\n--dryrun\nIf true, the output directory will only contain the CWL input files, but the pipeline itself will not be executed.\nboolean_true"
  },
  {
    "objectID": "components/modules/mapping/bd_rhapsody.html#authors",
    "href": "components/modules/mapping/bd_rhapsody.html#authors",
    "title": "BD Rhapsody",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/mapping/star_align_v273a.html",
    "href": "components/modules/mapping/star_align_v273a.html",
    "title": "Star align v273a",
    "section": "",
    "text": "ID: star_align_v273a\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/star_align_v273a.html#example-commands",
    "href": "components/modules/mapping/star_align_v273a.html#example-commands",
    "title": "Star align v273a",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/mapping/star_align_v273a/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input/Output\ninput: # please fill in - example: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\nreference: # please fill in - example: \"/path/to/reference\"\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/star_align_v273a/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/star_align_v273a.html#argument-groups",
    "href": "components/modules/mapping/star_align_v273a.html#argument-groups",
    "title": "Star align v273a",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput/Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe FASTQ files to be analyzed. Corresponds to the –readFilesIn in the STAR command.\nList of file, required, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nPath to the reference built by star_build_reference. Corresponds to the –genomeDir in the STAR command.\nfile, required, example: \"/path/to/reference\"\n\n\n--output\nPath to output directory. Corresponds to the –outFileNamePrefix in the STAR command.\nfile, required, example: \"/path/to/foo\"\n\n\n\n\n\nRun Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--runRNGseed\nrandom number generator seed.\ninteger, example: 777\n\n\n\n\n\nGenome Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genomeLoad\nmode of shared memory usage for the genome files. Only used with –runMode alignReads. - LoadAndKeep … load genome into shared and keep it in memory after run - LoadAndRemove … load genome into shared but remove it after run - LoadAndExit … load genome into shared memory and exit, keeping the genome in memory for future runs - Remove … do not map anything, just remove loaded genome from memory - NoSharedMemory … do not use shared memory, each job will have its own private copy of the genome\nstring, example: \"NoSharedMemory\"\n\n\n--genomeFastaFiles\npath(s) to the fasta files with the genome sequences, separated by spaces. These files should be plain text FASTA files, they cannot be zipped. Required for the genome generation (–runMode genomeGenerate). Can also be used in the mapping (–runMode alignReads) to add extra (new) sequences to the genome (e.g. spike-ins).\nList of file, multiple_sep: \";\"\n\n\n--genomeFileSizes\ngenome files exact sizes in bytes. Typically, this should not be defined by the user.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--genomeTransformOutput\nwhich output to transform back to original genome - SAM … SAM/BAM alignments - SJ … splice junctions (SJ.out.tab) - None … no transformation of the output\nList of string, multiple_sep: \";\"\n\n\n--genomeChrSetMitochondrial\nnames of the mitochondrial chromosomes. Presently only used for STARsolo statistics output/\nList of string, example: \"chrM\", \"M\", \"MT\", multiple_sep: \";\"\n\n\n\n\n\nSplice Junctions Database\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sjdbFileChrStartEnd\npath to the files with genomic coordinates (chr  start  end  strand) for the splice junction introns. Multiple files can be supplied and will be concatenated.\nList of string, multiple_sep: \";\"\n\n\n--sjdbGTFfile\npath to the GTF file with annotations\nfile\n\n\n--sjdbGTFchrPrefix\nprefix for chromosome names in a GTF file (e.g. ‘chr’ for using ENSMEBL annotations with UCSC genomes)\nstring\n\n\n--sjdbGTFfeatureExon\nfeature type in GTF file to be used as exons for building transcripts\nstring, example: \"exon\"\n\n\n--sjdbGTFtagExonParentTranscript\nGTF attribute name for parent transcript ID (default “transcript_id” works for GTF files)\nstring, example: \"transcript_id\"\n\n\n--sjdbGTFtagExonParentGene\nGTF attribute name for parent gene ID (default “gene_id” works for GTF files)\nstring, example: \"gene_id\"\n\n\n--sjdbGTFtagExonParentGeneName\nGTF attribute name for parent gene name\nList of string, example: \"gene_name\", multiple_sep: \";\"\n\n\n--sjdbGTFtagExonParentGeneType\nGTF attribute name for parent gene type\nList of string, example: \"gene_type\", \"gene_biotype\", multiple_sep: \";\"\n\n\n--sjdbOverhang\nlength of the donor/acceptor sequence on each side of the junctions, ideally = (mate_length - 1)\ninteger, example: 100\n\n\n--sjdbScore\nextra alignment score for alignments that cross database junctions\ninteger, example: 2\n\n\n--sjdbInsertSave\nwhich files to save when sjdb junctions are inserted on the fly at the mapping step - Basic … only small junction / transcript files - All … all files including big Genome, SA and SAindex - this will create a complete genome directory\nstring, example: \"Basic\"\n\n\n\n\n\nVariation parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--varVCFfile\npath to the VCF file that contains variation data. The 10th column should contain the genotype information, e.g. 0/1\nstring\n\n\n\n\n\nRead Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--readFilesType\nformat of input read files - Fastx … FASTA or FASTQ - SAM SE … SAM or BAM single-end reads; for BAM use –readFilesCommand samtools view - SAM PE … SAM or BAM paired-end reads; for BAM use –readFilesCommand samtools view\nstring, example: \"Fastx\"\n\n\n--readFilesSAMattrKeep\nfor –readFilesType SAM SE/PE, which SAM tags to keep in the output BAM, e.g.: –readFilesSAMtagsKeep RG PL - All … keep all tags - None … do not keep any tags\nList of string, example: \"All\", multiple_sep: \";\"\n\n\n--readFilesManifest\npath to the “manifest” file with the names of read files. The manifest file should contain 3 tab-separated columns: paired-end reads: read1_file_name \\(tab\\) read2_file_name \\(tab\\) read_group_line. single-end reads: read1_file_name \\(tab\\) - \\(tab\\) read_group_line. Spaces, but not tabs are allowed in file names. If read_group_line does not start with ID:, it can only contain one ID field, and ID: will be added to it. If read_group_line starts with ID:, it can contain several fields separated by \\(tab\\), and all fields will be be copied verbatim into SAM @RG header line.\nfile\n\n\n--readFilesPrefix\nprefix for the read files names, i.e. it will be added in front of the strings in –readFilesIn\nstring\n\n\n--readFilesCommand\ncommand line to execute for each of the input file. This command should generate FASTA or FASTQ text and send it to stdout For example: zcat - to uncompress .gz files, bzcat - to uncompress .bz2 files, etc.\nList of string, multiple_sep: \";\"\n\n\n--readMapNumber\nnumber of reads to map from the beginning of the file -1: map all reads\ninteger, example: -1\n\n\n--readMatesLengthsIn\nEqual/NotEqual - lengths of names,sequences,qualities for both mates are the same / not the same. NotEqual is safe in all situations.\nstring, example: \"NotEqual\"\n\n\n--readNameSeparator\ncharacter(s) separating the part of the read names that will be trimmed in output (read name after space is always trimmed)\nList of string, example: \"/\", multiple_sep: \";\"\n\n\n--readQualityScoreBase\nnumber to be subtracted from the ASCII code to get Phred quality score\ninteger, example: 33\n\n\n\n\n\nRead Clipping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--clipAdapterType\nadapter clipping type - Hamming … adapter clipping based on Hamming distance, with the number of mismatches controlled by –clip5pAdapterMMp - CellRanger4 … 5p and 3p adapter clipping similar to CellRanger4. Utilizes Opal package by Martin Sosic: https://github.com/Martinsos/opal - None … no adapter clipping, all other clip* parameters are disregarded\nstring, example: \"Hamming\"\n\n\n--clip3pNbases\nnumber(s) of bases to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip3pAdapterSeq\nadapter sequences to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates. - polyA … polyA sequence with the length equal to read length\nList of string, multiple_sep: \";\"\n\n\n--clip3pAdapterMMp\nmax proportion of mismatches for 3p adapter clipping for each mate. If one value is given, it will be assumed the same for both mates.\nList of double, example: 0.1, multiple_sep: \";\"\n\n\n--clip3pAfterAdapterNbases\nnumber of bases to clip from 3p of each mate after the adapter clipping. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip5pNbases\nnumber(s) of bases to clip from 5p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n\n\n\nLimits\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--limitGenomeGenerateRAM\nmaximum available RAM (bytes) for genome generation\nlong, example: NA\n\n\n--limitIObufferSize\nmax available buffers size (bytes) for input/output, per thread\nList of long, example: 30000000, 50000000, multiple_sep: \";\"\n\n\n--limitOutSAMoneReadBytes\nmax size of the SAM record (bytes) for one read. Recommended value: &gt;(2(LengthMate1+LengthMate2+100)outFilterMultimapNmax\nlong, example: 100000\n\n\n--limitOutSJoneRead\nmax number of junctions for one read (including all multi-mappers)\ninteger, example: 1000\n\n\n--limitOutSJcollapsed\nmax number of collapsed junctions\ninteger, example: 1000000\n\n\n--limitBAMsortRAM\nmaximum available RAM (bytes) for sorting BAM. If =0, it will be set to the genome index size. 0 value can only be used with –genomeLoad NoSharedMemory option.\nlong, example: 0\n\n\n--limitSjdbInsertNsj\nmaximum number of junctions to be inserted to the genome on the fly at the mapping stage, including those from annotations and those detected in the 1st step of the 2-pass run\ninteger, example: 1000000\n\n\n--limitNreadsSoft\nsoft limit on the number of reads\ninteger, example: -1\n\n\n\n\n\nOutput: general\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outTmpKeep\nwhether to keep the temporary files after STAR runs is finished - None … remove all temporary files - All … keep all files\nstring\n\n\n--outStd\nwhich output will be directed to stdout (standard out) - Log … log messages - SAM … alignments in SAM format (which normally are output to Aligned.out.sam file), normal standard output will go into Log.std.out - BAM_Unsorted … alignments in BAM format, unsorted. Requires –outSAMtype BAM Unsorted - BAM_SortedByCoordinate … alignments in BAM format, sorted by coordinate. Requires –outSAMtype BAM SortedByCoordinate - BAM_Quant … alignments to transcriptome in BAM format, unsorted. Requires –quantMode TranscriptomeSAM\nstring, example: \"Log\"\n\n\n--outReadsUnmapped\noutput of unmapped and partially mapped (i.e. mapped only one mate of a paired end read) reads in separate file(s). - None … no output - Fastx … output in separate fasta/fastq files, Unmapped.out.mate1/2\nstring\n\n\n--outQSconversionAdd\nadd this number to the quality score (e.g. to convert from Illumina to Sanger, use -31)\ninteger, example: 0\n\n\n--outMultimapperOrder\norder of multimapping alignments in the output files - Old_2.4 … quasi-random order used before 2.5.0 - Random … random order of alignments for each multi-mapper. Read mates (pairs) are always adjacent, all alignment for each read stay together. This option will become default in the future releases.\nstring, example: \"Old_2.4\"\n\n\n\n\n\nOutput: SAM and BAM\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSAMtype\ntype of SAM/BAM output 1st word: - BAM … output BAM without sorting - SAM … output SAM without sorting - None … no SAM/BAM output 2nd, 3rd: - Unsorted … standard unsorted - SortedByCoordinate … sorted by coordinate. This option will allocate extra memory for sorting which can be specified by –limitBAMsortRAM.\nList of string, example: \"SAM\", multiple_sep: \";\"\n\n\n--outSAMmode\nmode of SAM output - None … no SAM output - Full … full SAM output - NoQS … full SAM but without quality scores\nstring, example: \"Full\"\n\n\n--outSAMstrandField\nCufflinks-like strand field flag - None … not used - intronMotif … strand derived from the intron motif. This option changes the output alignments: reads with inconsistent and/or non-canonical introns are filtered out.\nstring\n\n\n--outSAMattributes\na string of desired SAM attributes, in the order desired for the output SAM. Tags can be listed in any combination/order. Presets: - None … no attributes - Standard … NH HI AS nM - All … NH HI AS nM NM MD jM jI MC ch Alignment: - NH … number of loci the reads maps to: =1 for unique mappers, &gt;1 for multimappers. Standard SAM tag. - HI … multiple alignment index, starts with –outSAMattrIHstart (=1 by default). Standard SAM tag. - AS … local alignment score, +1/-1 for matches/mismateches, score* penalties for indels and gaps. For PE reads, total score for two mates. Stadnard SAM tag. - nM … number of mismatches. For PE reads, sum over two mates. - NM … edit distance to the reference (number of mismatched + inserted + deleted bases) for each mate. Standard SAM tag. - MD … string encoding mismatched and deleted reference bases (see standard SAM specifications). Standard SAM tag. - jM … intron motifs for all junctions (i.e. N in CIGAR): 0: non-canonical; 1: GT/AG, 2: CT/AC, 3: GC/AG, 4: CT/GC, 5: AT/AC, 6: GT/AT. If splice junctions database is used, and a junction is annotated, 20 is added to its motif value. - jI … start and end of introns for all junctions (1-based). - XS … alignment strand according to –outSAMstrandField. - MC … mate’s CIGAR string. Standard SAM tag. - ch … marks all segment of all chimeric alingments for –chimOutType WithinBAM output. - cN … number of bases clipped from the read ends: 5’ and 3’ Variation: - vA … variant allele - vG … genomic coordinate of the variant overlapped by the read. - vW … 1 - alignment passes WASP filtering; 2,3,4,5,6,7 - alignment does not pass WASP filtering. Requires –waspOutputMode SAMtag. STARsolo: - CR CY UR UY … sequences and quality scores of cell barcodes and UMIs for the solo* demultiplexing. - GX GN … gene ID and gene name for unique-gene reads. - gx gn … gene IDs and gene names for unique- and multi-gene reads. - CB UB … error-corrected cell barcodes and UMIs for solo* demultiplexing. Requires –outSAMtype BAM SortedByCoordinate. - sM … assessment of CB and UMI. - sS … sequence of the entire barcode (CB,UMI,adapter). - sQ … quality of the entire barcode. ***Unsupported/undocumented: - ha … haplotype (1/2) when mapping to the diploid genome. Requires genome generated with –genomeTransformType Diploid . - rB … alignment block read/genomic coordinates. - vR … read coordinate of the variant.\nList of string, example: \"Standard\", multiple_sep: \";\"\n\n\n--outSAMattrIHstart\nstart value for the IH attribute. 0 may be required by some downstream software, such as Cufflinks or StringTie.\ninteger, example: 1\n\n\n--outSAMunmapped\noutput of unmapped reads in the SAM format 1st word: - None … no output - Within … output unmapped reads within the main SAM file (i.e. Aligned.out.sam) 2nd word: - KeepPairs … record unmapped mate for each alignment, and, in case of unsorted output, keep it adjacent to its mapped mate. Only affects multi-mapping reads.\nList of string, multiple_sep: \";\"\n\n\n--outSAMorder\ntype of sorting for the SAM output Paired: one mate after the other for all paired alignments PairedKeepInputOrder: one mate after the other for all paired alignments, the order is kept the same as in the input FASTQ files\nstring, example: \"Paired\"\n\n\n--outSAMprimaryFlag\nwhich alignments are considered primary - all others will be marked with 0x100 bit in the FLAG - OneBestScore … only one alignment with the best score is primary - AllBestScore … all alignments with the best score are primary\nstring, example: \"OneBestScore\"\n\n\n--outSAMreadID\nread ID record type - Standard … first word (until space) from the FASTx read ID line, removing /1,/2 from the end - Number … read number (index) in the FASTx file\nstring, example: \"Standard\"\n\n\n--outSAMmapqUnique\n0 to 255: the MAPQ value for unique mappers\ninteger, example: 255\n\n\n--outSAMflagOR\n0 to 65535: sam FLAG will be bitwise OR’d with this value, i.e. FLAG=FLAG | outSAMflagOR. This is applied after all flags have been set by STAR, and after outSAMflagAND. Can be used to set specific bits that are not set otherwise.\ninteger, example: 0\n\n\n--outSAMflagAND\n0 to 65535: sam FLAG will be bitwise AND’d with this value, i.e. FLAG=FLAG & outSAMflagOR. This is applied after all flags have been set by STAR, but before outSAMflagOR. Can be used to unset specific bits that are not set otherwise.\ninteger, example: 65535\n\n\n--outSAMattrRGline\nSAM/BAM read group line. The first word contains the read group identifier and must start with “ID:”, e.g. –outSAMattrRGline ID:xxx CN:yy “DS:z z z”. xxx will be added as RG tag to each output alignment. Any spaces in the tag values have to be double quoted. Comma separated RG lines correspons to different (comma separated) input files in –readFilesIn. Commas have to be surrounded by spaces, e.g. –outSAMattrRGline ID:xxx , ID:zzz “DS:z z” , ID:yyy DS:yyyy\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderHD\n@HD (header) line of the SAM header\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderPG\nextra @PG (software) line of the SAM header (in addition to STAR)\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderCommentFile\npath to the file with @CO (comment) lines of the SAM header\nstring\n\n\n--outSAMfilter\nfilter the output into main SAM/BAM files - KeepOnlyAddedReferences … only keep the reads for which all alignments are to the extra reference sequences added with –genomeFastaFiles at the mapping stage. - KeepAllAddedReferences … keep all alignments to the extra reference sequences added with –genomeFastaFiles at the mapping stage.\nList of string, multiple_sep: \";\"\n\n\n--outSAMmultNmax\nmax number of multiple alignments for a read that will be output to the SAM/BAM files. Note that if this value is not equal to -1, the top scoring alignment will be output first - -1 … all alignments (up to –outFilterMultimapNmax) will be output\ninteger, example: -1\n\n\n--outSAMtlen\ncalculation method for the TLEN field in the SAM/BAM files - 1 … leftmost base of the (+)strand mate to rightmost base of the (-)mate. (+)sign for the (+)strand mate - 2 … leftmost base of any mate to rightmost base of any mate. (+)sign for the mate with the leftmost base. This is different from 1 for overlapping mates with protruding ends\ninteger, example: 1\n\n\n--outBAMcompression\n-1 to 10 BAM compression level, -1=default compression (6?), 0=no compression, 10=maximum compression\ninteger, example: 1\n\n\n--outBAMsortingThreadN\n&gt;=0: number of threads for BAM sorting. 0 will default to min(6,–runThreadN).\ninteger, example: 0\n\n\n--outBAMsortingBinsN\n&gt;0: number of genome bins for coordinate-sorting\ninteger, example: 50\n\n\n\n\n\nBAM processing\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--bamRemoveDuplicatesType\nmark duplicates in the BAM file, for now only works with (i) sorted BAM fed with inputBAMfile, and (ii) for paired-end alignments only - - … no duplicate removal/marking - UniqueIdentical … mark all multimappers, and duplicate unique mappers. The coordinates, FLAG, CIGAR must be identical - UniqueIdenticalNotMulti … mark duplicate unique mappers but not multimappers.\nstring\n\n\n--bamRemoveDuplicatesMate2basesN\nnumber of bases from the 5’ of mate 2 to use in collapsing (e.g. for RAMPAGE)\ninteger, example: 0\n\n\n\n\n\nOutput Wiggle\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outWigType\ntype of signal output, e.g. “bedGraph” OR “bedGraph read1_5p”. Requires sorted BAM: –outSAMtype BAM SortedByCoordinate . 1st word: - None … no signal output - bedGraph … bedGraph format - wiggle … wiggle format 2nd word: - read1_5p … signal from only 5’ of the 1st read, useful for CAGE/RAMPAGE etc - read2 … signal from only 2nd read\nList of string, multiple_sep: \";\"\n\n\n--outWigStrand\nstrandedness of wiggle/bedGraph output - Stranded … separate strands, str1 and str2 - Unstranded … collapsed strands\nstring, example: \"Stranded\"\n\n\n--outWigReferencesPrefix\nprefix matching reference names to include in the output wiggle file, e.g. “chr”, default “-” - include all references\nstring\n\n\n--outWigNorm\ntype of normalization for the signal - RPM … reads per million of mapped reads - None … no normalization, “raw” counts\nstring, example: \"RPM\"\n\n\n\n\n\nOutput Filtering\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outFilterType\ntype of filtering - Normal … standard filtering using only current alignment - BySJout … keep only those reads that contain junctions that passed filtering into SJ.out.tab\nstring, example: \"Normal\"\n\n\n--outFilterMultimapScoreRange\nthe score range below the maximum score for multimapping alignments\ninteger, example: 1\n\n\n--outFilterMultimapNmax\nmaximum number of loci the read is allowed to map to. Alignments (all of them) will be output only if the read maps to no more loci than this value. Otherwise no alignments will be output, and the read will be counted as “mapped to too many loci” in the Log.final.out .\ninteger, example: 10\n\n\n--outFilterMismatchNmax\nalignment will be output only if it has no more mismatches than this value.\ninteger, example: 10\n\n\n--outFilterMismatchNoverLmax\nalignment will be output only if its ratio of mismatches to mapped length is less than or equal to this value.\ndouble, example: 0.3\n\n\n--outFilterMismatchNoverReadLmax\nalignment will be output only if its ratio of mismatches to read length is less than or equal to this value.\ndouble, example: 1\n\n\n--outFilterScoreMin\nalignment will be output only if its score is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterScoreMinOverLread\nsame as outFilterScoreMin, but normalized to read length (sum of mates’ lengths for paired-end reads)\ndouble, example: 0.66\n\n\n--outFilterMatchNmin\nalignment will be output only if the number of matched bases is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterMatchNminOverLread\nsam as outFilterMatchNmin, but normalized to the read length (sum of mates’ lengths for paired-end reads).\ndouble, example: 0.66\n\n\n--outFilterIntronMotifs\nfilter alignment using their motifs - None … no filtering - RemoveNoncanonical … filter out alignments that contain non-canonical junctions - RemoveNoncanonicalUnannotated … filter out alignments that contain non-canonical unannotated junctions when using annotated splice junctions database. The annotated non-canonical junctions will be kept.\nstring\n\n\n--outFilterIntronStrands\nfilter alignments - RemoveInconsistentStrands … remove alignments that have junctions with inconsistent strands - None … no filtering\nstring, example: \"RemoveInconsistentStrands\"\n\n\n\n\n\nOutput splice junctions (SJ.out.tab)\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJtype\ntype of splice junction output - Standard … standard SJ.out.tab output - None … no splice junction output\nstring, example: \"Standard\"\n\n\n\n\n\nOutput Filtering: Splice Junctions\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJfilterReads\nwhich reads to consider for collapsed splice junctions output - All … all reads, unique- and multi-mappers - Unique … uniquely mapping reads only\nstring, example: \"All\"\n\n\n--outSJfilterOverhangMin\nminimum overhang length for splice junctions on both sides for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif does not apply to annotated junctions\nList of integer, example: 30, 12, 12, 12, multiple_sep: \";\"\n\n\n--outSJfilterCountUniqueMin\nminimum uniquely mapping read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterCountTotalMin\nminimum total (multi-mapping+unique) read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterDistToOtherSJmin\nminimum allowed distance to other junctions’ donor/acceptor does not apply to annotated junctions\nList of integer, example: 10, 0, 5, 10, multiple_sep: \";\"\n\n\n--outSJfilterIntronMaxVsReadN\nmaximum gap allowed for junctions supported by 1,2,3,,,N reads i.e. by default junctions supported by 1 read can have gaps &lt;=50000b, by 2 reads: &lt;=100000b, by 3 reads: &lt;=200000. by &gt;=4 reads any gap &lt;=alignIntronMax does not apply to annotated junctions\nList of integer, example: 50000, 100000, 200000, multiple_sep: \";\"\n\n\n\n\n\nScoring\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--scoreGap\nsplice junction penalty (independent on intron motif)\ninteger, example: 0\n\n\n--scoreGapNoncan\nnon-canonical junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGapGCAG\nGC/AG and CT/GC junction penalty (in addition to scoreGap)\ninteger, example: -4\n\n\n--scoreGapATAC\nAT/AC and GT/AT junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGenomicLengthLog2scale\nextra score logarithmically scaled with genomic length of the alignment: scoreGenomicLengthLog2scale*log2(genomicLength)\ninteger, example: 0\n\n\n--scoreDelOpen\ndeletion open penalty\ninteger, example: -2\n\n\n--scoreDelBase\ndeletion extension penalty per base (in addition to scoreDelOpen)\ninteger, example: -2\n\n\n--scoreInsOpen\ninsertion open penalty\ninteger, example: -2\n\n\n--scoreInsBase\ninsertion extension penalty per base (in addition to scoreInsOpen)\ninteger, example: -2\n\n\n--scoreStitchSJshift\nmaximum score reduction while searching for SJ boundaries in the stitching step\ninteger, example: 1\n\n\n\n\n\nAlignments and Seeding\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--seedSearchStartLmax\ndefines the search start point through the read - the read is split into pieces no longer than this value\ninteger, example: 50\n\n\n--seedSearchStartLmaxOverLread\nseedSearchStartLmax normalized to read length (sum of mates’ lengths for paired-end reads)\ndouble, example: 1\n\n\n--seedSearchLmax\ndefines the maximum length of the seeds, if =0 seed length is not limited\ninteger, example: 0\n\n\n--seedMultimapNmax\nonly pieces that map fewer than this value are utilized in the stitching procedure\ninteger, example: 10000\n\n\n--seedPerReadNmax\nmax number of seeds per read\ninteger, example: 1000\n\n\n--seedPerWindowNmax\nmax number of seeds per window\ninteger, example: 50\n\n\n--seedNoneLociPerWindow\nmax number of one seed loci per window\ninteger, example: 10\n\n\n--seedSplitMin\nmin length of the seed sequences split by Ns or mate gap\ninteger, example: 12\n\n\n--seedMapMin\nmin length of seeds to be mapped\ninteger, example: 5\n\n\n--alignIntronMin\nminimum intron size, genomic gap is considered intron if its length&gt;=alignIntronMin, otherwise it is considered Deletion\ninteger, example: 21\n\n\n--alignIntronMax\nmaximum intron size, if 0, max intron size will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignMatesGapMax\nmaximum gap between two mates, if 0, max intron gap will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignSJoverhangMin\nminimum overhang (i.e. block size) for spliced alignments\ninteger, example: 5\n\n\n--alignSJstitchMismatchNmax\nmaximum number of mismatches for stitching of the splice junctions (-1: no limit). (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif.\nList of integer, example: 0, -1, 0, 0, multiple_sep: \";\"\n\n\n--alignSJDBoverhangMin\nminimum overhang (i.e. block size) for annotated (sjdb) spliced alignments\ninteger, example: 3\n\n\n--alignSplicedMateMapLmin\nminimum mapped length for a read mate that is spliced\ninteger, example: 0\n\n\n--alignSplicedMateMapLminOverLmate\nalignSplicedMateMapLmin normalized to mate length\ndouble, example: 0.66\n\n\n--alignWindowsPerReadNmax\nmax number of windows per read\ninteger, example: 10000\n\n\n--alignTranscriptsPerWindowNmax\nmax number of transcripts per window\ninteger, example: 100\n\n\n--alignTranscriptsPerReadNmax\nmax number of different alignments per read to consider\ninteger, example: 10000\n\n\n--alignEndsType\ntype of read ends alignment - Local … standard local alignment with soft-clipping allowed - EndToEnd … force end-to-end read alignment, do not soft-clip - Extend5pOfRead1 … fully extend only the 5p of the read1, all other ends: local alignment - Extend5pOfReads12 … fully extend only the 5p of the both read1 and read2, all other ends: local alignment\nstring, example: \"Local\"\n\n\n--alignEndsProtrude\nallow protrusion of alignment ends, i.e. start (end) of the +strand mate downstream of the start (end) of the -strand mate 1st word: int: maximum number of protrusion bases allowed 2nd word: string: - ConcordantPair … report alignments with non-zero protrusion as concordant pairs - DiscordantPair … report alignments with non-zero protrusion as discordant pairs\nstring, example: \"0    ConcordantPair\"\n\n\n--alignSoftClipAtReferenceEnds\nallow the soft-clipping of the alignments past the end of the chromosomes - Yes … allow - No … prohibit, useful for compatibility with Cufflinks\nstring, example: \"Yes\"\n\n\n--alignInsertionFlush\nhow to flush ambiguous insertion positions - None … insertions are not flushed - Right … insertions are flushed to the right\nstring\n\n\n\n\n\nPaired-End reads\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--peOverlapNbasesMin\nminimum number of overlapping bases to trigger mates merging and realignment. Specify &gt;0 value to switch on the “merginf of overlapping mates” algorithm.\ninteger, example: 0\n\n\n--peOverlapMMp\nmaximum proportion of mismatched bases in the overlap area\ndouble, example: 0.01\n\n\n\n\n\nWindows, Anchors, Binning\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--winAnchorMultimapNmax\nmax number of loci anchors are allowed to map to\ninteger, example: 50\n\n\n--winBinNbits\n=log2(winBin), where winBin is the size of the bin for the windows/clustering, each window will occupy an integer number of bins.\ninteger, example: 16\n\n\n--winAnchorDistNbins\nmax number of bins between two anchors that allows aggregation of anchors into one window\ninteger, example: 9\n\n\n--winFlankNbins\nlog2(winFlank), where win Flank is the size of the left and right flanking regions for each window\ninteger, example: 4\n\n\n--winReadCoverageRelativeMin\nminimum relative coverage of the read sequence by the seeds in a window, for STARlong algorithm only.\ndouble, example: 0.5\n\n\n--winReadCoverageBasesMin\nminimum number of bases covered by the seeds in a window , for STARlong algorithm only.\ninteger, example: 0\n\n\n\n\n\nChimeric Alignments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--chimOutType\ntype of chimeric output - Junctions … Chimeric.out.junction - SeparateSAMold … output old SAM into separate Chimeric.out.sam file - WithinBAM … output into main aligned BAM files (Aligned.*.bam) - WithinBAM HardClip … (default) hard-clipping in the CIGAR for supplemental chimeric alignments (default if no 2nd word is present) - WithinBAM SoftClip … soft-clipping in the CIGAR for supplemental chimeric alignments\nList of string, example: \"Junctions\", multiple_sep: \";\"\n\n\n--chimSegmentMin\nminimum length of chimeric segment length, if ==0, no chimeric output\ninteger, example: 0\n\n\n--chimScoreMin\nminimum total (summed) score of the chimeric segments\ninteger, example: 0\n\n\n--chimScoreDropMax\nmax drop (difference) of chimeric score (the sum of scores of all chimeric segments) from the read length\ninteger, example: 20\n\n\n--chimScoreSeparation\nminimum difference (separation) between the best chimeric score and the next one\ninteger, example: 10\n\n\n--chimScoreJunctionNonGTAG\npenalty for a non-GT/AG chimeric junction\ninteger, example: -1\n\n\n--chimJunctionOverhangMin\nminimum overhang for a chimeric junction\ninteger, example: 20\n\n\n--chimSegmentReadGapMax\nmaximum gap in the read sequence between chimeric segments\ninteger, example: 0\n\n\n--chimFilter\ndifferent filters for chimeric alignments - None … no filtering - banGenomicN … Ns are not allowed in the genome sequence around the chimeric junction\nList of string, example: \"banGenomicN\", multiple_sep: \";\"\n\n\n--chimMainSegmentMultNmax\nmaximum number of multi-alignments for the main chimeric segment. =1 will prohibit multimapping main segments.\ninteger, example: 10\n\n\n--chimMultimapNmax\nmaximum number of chimeric multi-alignments - 0 … use the old scheme for chimeric detection which only considered unique alignments\ninteger, example: 0\n\n\n--chimMultimapScoreRange\nthe score range for multi-mapping chimeras below the best chimeric score. Only works with –chimMultimapNmax &gt; 1\ninteger, example: 1\n\n\n--chimNonchimScoreDropMin\nto trigger chimeric detection, the drop in the best non-chimeric alignment score with respect to the read length has to be greater than this value\ninteger, example: 20\n\n\n--chimOutJunctionFormat\nformatting type for the Chimeric.out.junction file - 0 … no comment lines/headers - 1 … comment lines at the end of the file: command line and Nreads: total, unique/multi-mapping\ninteger, example: 0\n\n\n\n\n\nQuantification of Annotations\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--quantMode\ntypes of quantification requested - - … none - TranscriptomeSAM … output SAM/BAM alignments to transcriptome into a separate file - GeneCounts … count reads per gene\nList of string, multiple_sep: \";\"\n\n\n--quantTranscriptomeBAMcompression\n-2 to 10 transcriptome BAM compression level - -2 … no BAM output - -1 … default compression (6?) - 0 … no compression - 10 … maximum compression\ninteger, example: 1\n\n\n--quantTranscriptomeBan\nprohibit various alignment type - IndelSoftclipSingleend … prohibit indels, soft clipping and single-end alignments - compatible with RSEM - Singleend … prohibit single-end alignments\nstring, example: \"IndelSoftclipSingleend\"\n\n\n\n\n\n2-pass Mapping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--twopassMode\n2-pass mapping mode. - None … 1-pass mapping - Basic … basic 2-pass mapping, with all 1st pass junctions inserted into the genome indices on the fly\nstring\n\n\n--twopass1readsN\nnumber of reads to process for the 1st step. Use very large number (or default -1) to map all reads in the first step.\ninteger, example: -1\n\n\n\n\n\nWASP parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--waspOutputMode\nWASP allele-specific output type. This is re-implementation of the original WASP mappability filtering by Bryce van de Geijn, Graham McVicker, Yoav Gilad & Jonathan K Pritchard. Please cite the original WASP paper: Nature Methods 12, 1061-1063 (2015), https://www.nature.com/articles/nmeth.3582 . - SAMtag … add WASP tags to the alignments that pass WASP filtering\nstring\n\n\n\n\n\nSTARsolo (single cell RNA-seq) parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--soloType\ntype of single-cell RNA-seq - CB_UMI_Simple … (a.k.a. Droplet) one UMI and one Cell Barcode of fixed length in read2, e.g. Drop-seq and 10X Chromium. - CB_UMI_Complex … multiple Cell Barcodes of varying length, one UMI of fixed length and one adapter sequence of fixed length are allowed in read2 only (e.g. inDrop, ddSeq). - CB_samTagOut … output Cell Barcode as CR and/or CB SAm tag. No UMI counting. –readFilesIn cDNA_read1 [cDNA_read2 if paired-end] CellBarcode_read . Requires –outSAMtype BAM Unsorted [and/or SortedByCoordinate] - SmartSeq … Smart-seq: each cell in a separate FASTQ (paired- or single-end), barcodes are corresponding read-groups, no UMI sequences, alignments deduplicated according to alignment start and end (after extending soft-clipped bases)\nList of string, multiple_sep: \";\"\n\n\n--soloCBwhitelist\nfile(s) with whitelist(s) of cell barcodes. Only –soloType CB_UMI_Complex allows more than one whitelist file. - None … no whitelist: all cell barcodes are allowed\nList of string, multiple_sep: \";\"\n\n\n--soloCBstart\ncell barcode start base\ninteger, example: 1\n\n\n--soloCBlen\ncell barcode length\ninteger, example: 16\n\n\n--soloUMIstart\nUMI start base\ninteger, example: 17\n\n\n--soloUMIlen\nUMI length\ninteger, example: 10\n\n\n--soloBarcodeReadLength\nlength of the barcode read - 1 … equal to sum of soloCBlen+soloUMIlen - 0 … not defined, do not check\ninteger, example: 1\n\n\n--soloBarcodeMate\nidentifies which read mate contains the barcode (CB+UMI) sequence - 0 … barcode sequence is on separate read, which should always be the last file in the –readFilesIn listed - 1 … barcode sequence is a part of mate 1 - 2 … barcode sequence is a part of mate 2\ninteger, example: 0\n\n\n--soloCBposition\nposition of Cell Barcode(s) on the barcode read. Presently only works with –soloType CB_UMI_Complex, and barcodes are assumed to be on Read2. Format for each barcode: startAnchor_startPosition_endAnchor_endPosition start(end)Anchor defines the Anchor Base for the CB: 0: read start; 1: read end; 2: adapter start; 3: adapter end start(end)Position is the 0-based position with of the CB start(end) with respect to the Anchor Base String for different barcodes are separated by space. Example: inDrop (Zilionis et al, Nat. Protocols, 2017): –soloCBposition 0_0_2_-1 3_1_3_8\nList of string, multiple_sep: \";\"\n\n\n--soloUMIposition\nposition of the UMI on the barcode read, same as soloCBposition Example: inDrop (Zilionis et al, Nat. Protocols, 2017): –soloCBposition 3_9_3_14\nstring\n\n\n--soloAdapterSequence\nadapter sequence to anchor barcodes. Only one adapter sequence is allowed.\nstring\n\n\n--soloAdapterMismatchesNmax\nmaximum number of mismatches allowed in adapter sequence.\ninteger, example: 1\n\n\n--soloCBmatchWLtype\nmatching the Cell Barcodes to the WhiteList - Exact … only exact matches allowed - 1MM … only one match in whitelist with 1 mismatched base allowed. Allowed CBs have to have at least one read with exact match. - 1MM_multi … multiple matches in whitelist with 1 mismatched base allowed, posterior probability calculation is used choose one of the matches. Allowed CBs have to have at least one read with exact match. This option matches best with CellRanger 2.2.0 - 1MM_multi_pseudocounts … same as 1MM_Multi, but pseudocounts of 1 are added to all whitelist barcodes. - 1MM_multi_Nbase_pseudocounts … same as 1MM_multi_pseudocounts, multimatching to WL is allowed for CBs with N-bases. This option matches best with CellRanger &gt;= 3.0.0 - EditDist_2 … allow up to edit distance of 3 fpr each of the barcodes. May include one deletion + one insertion. Only works with –soloType CB_UMI_Complex. Matches to multiple passlist barcdoes are not allowed. Similar to ParseBio Split-seq pipeline.\nstring, example: \"1MM_multi\"\n\n\n--soloInputSAMattrBarcodeSeq\nwhen inputting reads from a SAM file (–readsFileType SAM SE/PE), these SAM attributes mark the barcode sequence (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use –soloInputSAMattrBarcodeSeq CR UR . This parameter is required when running STARsolo with input from SAM.\nList of string, multiple_sep: \";\"\n\n\n--soloInputSAMattrBarcodeQual\nwhen inputting reads from a SAM file (–readsFileType SAM SE/PE), these SAM attributes mark the barcode qualities (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use –soloInputSAMattrBarcodeQual CY UY . If this parameter is ‘-’ (default), the quality ‘H’ will be assigned to all bases.\nList of string, multiple_sep: \";\"\n\n\n--soloStrand\nstrandedness of the solo libraries: - Unstranded … no strand information - Forward … read strand same as the original RNA molecule - Reverse … read strand opposite to the original RNA molecule\nstring, example: \"Forward\"\n\n\n--soloFeatures\ngenomic features for which the UMI counts per Cell Barcode are collected - Gene … genes: reads match the gene transcript - SJ … splice junctions: reported in SJ.out.tab - GeneFull … full gene (pre-mRNA): count all reads overlapping genes’ exons and introns - GeneFull_ExonOverIntron … full gene (pre-mRNA): count all reads overlapping genes’ exons and introns: prioritize 100% overlap with exons - GeneFull_Ex50pAS … full gene (pre-RNA): count all reads overlapping genes’ exons and introns: prioritize &gt;50% overlap with exons. Do not count reads with 100% exonic overlap in the antisense direction.\nList of string, example: \"Gene\", multiple_sep: \";\"\n\n\n--soloMultiMappers\ncounting method for reads mapping to multiple genes - Unique … count only reads that map to unique genes - Uniform … uniformly distribute multi-genic UMIs to all genes - Rescue … distribute UMIs proportionally to unique+uniform counts (~ first iteration of EM) - PropUnique … distribute UMIs proportionally to unique mappers, if present, and uniformly if not. - EM … multi-gene UMIs are distributed using Expectation Maximization algorithm\nList of string, example: \"Unique\", multiple_sep: \";\"\n\n\n--soloUMIdedup\ntype of UMI deduplication (collapsing) algorithm - 1MM_All … all UMIs with 1 mismatch distance to each other are collapsed (i.e. counted once). - 1MM_Directional_UMItools … follows the “directional” method from the UMI-tools by Smith, Heger and Sudbery (Genome Research 2017). - 1MM_Directional … same as 1MM_Directional_UMItools, but with more stringent criteria for duplicate UMIs - Exact … only exactly matching UMIs are collapsed. - NoDedup … no deduplication of UMIs, count all reads. - 1MM_CR … CellRanger2-4 algorithm for 1MM UMI collapsing.\nList of string, example: \"1MM_All\", multiple_sep: \";\"\n\n\n--soloUMIfiltering\ntype of UMI filtering (for reads uniquely mapping to genes) - - … basic filtering: remove UMIs with N and homopolymers (similar to CellRanger 2.2.0). - MultiGeneUMI … basic + remove lower-count UMIs that map to more than one gene. - MultiGeneUMI_All … basic + remove all UMIs that map to more than one gene. - MultiGeneUMI_CR … basic + remove lower-count UMIs that map to more than one gene, matching CellRanger &gt; 3.0.0 . Only works with –soloUMIdedup 1MM_CR\nList of string, multiple_sep: \";\"\n\n\n--soloOutFileNames\nfile names for STARsolo output: file_name_prefix gene_names barcode_sequences cell_feature_count_matrix\nList of string, example: \"Solo.out/\", \"features.tsv\", \"barcodes.tsv\", \"matrix.mtx\", multiple_sep: \";\"\n\n\n--soloCellFilter\ncell filtering type and parameters - None … do not output filtered cells - TopCells … only report top cells by UMI count, followed by the exact number of cells - CellRanger2.2 … simple filtering of CellRanger 2.2. Can be followed by numbers: number of expected cells, robust maximum percentile for UMI count, maximum to minimum ratio for UMI count The harcoded values are from CellRanger: nExpectedCells=3000; maxPercentile=0.99; maxMinRatio=10 - EmptyDrops_CR … EmptyDrops filtering in CellRanger flavor. Please cite the original EmptyDrops paper: A.T.L Lun et al, Genome Biology, 20, 63 (2019): https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1662-y Can be followed by 10 numeric parameters: nExpectedCells maxPercentile maxMinRatio indMin indMax umiMin umiMinFracMedian candMaxN FDR simN The harcoded values are from CellRanger: 3000 0.99 10 45000 90000 500 0.01 20000 0.01 10000\nList of string, example: \"CellRanger2.2\", \"3000\", \"0.99\", \"10\", multiple_sep: \";\"\n\n\n--soloOutFormatFeaturesGeneField3\nfield 3 in the Gene features.tsv file. If “-”, then no 3rd field is output.\nList of string, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--soloCellReadStats\nOutput reads statistics for each CB - Standard … standard output\nstring"
  },
  {
    "objectID": "components/modules/mapping/star_align_v273a.html#authors",
    "href": "components/modules/mapping/star_align_v273a.html#authors",
    "title": "Star align v273a",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/mapping/cellranger_count.html",
    "href": "components/modules/mapping/cellranger_count.html",
    "title": "Cellranger count",
    "section": "",
    "text": "ID: cellranger_count\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/cellranger_count.html#example-commands",
    "href": "components/modules/mapping/cellranger_count.html#example-commands",
    "title": "Cellranger count",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/mapping/cellranger_count/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: [\"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\"]\nreference: # please fill in - example: \"reference.tar.gz\"\n\n# Outputs\n# output: \"$id.$key.output.output\"\n\n# Arguments\n# expect_cells: 3000\nchemistry: \"auto\"\nsecondary_analysis: false\ngenerate_bam: true\ninclude_introns: true\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/cellranger_count/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/cellranger_count.html#argument-groups",
    "href": "components/modules/mapping/cellranger_count.html#argument-groups",
    "title": "Cellranger count",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe fastq.gz files to align. Can also be a single directory containing fastq.gz files.\nList of file, required, example: \"sample_S1_L001_R1_001.fastq.gz\", \"sample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nThe path to Cell Ranger reference tar.gz file. Can also be a directory.\nfile, required, example: \"reference.tar.gz\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe folder to store the alignment results.\nfile, required, example: \"/path/to/output\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--expect_cells\nExpected number of recovered cells, used as input to cell calling algorithm.\ninteger, example: 3000\n\n\n--chemistry\nAssay configuration. - auto: autodetect mode - threeprime: Single Cell 3’ - fiveprime: Single Cell 5’ - SC3Pv1: Single Cell 3’ v1 - SC3Pv2: Single Cell 3’ v2 - SC3Pv3: Single Cell 3’ v3 - SC3Pv3LT: Single Cell 3’ v3 LT - SC3Pv3HT: Single Cell 3’ v3 HT - SC5P-PE: Single Cell 5’ paired-end - SC5P-R2: Single Cell 5’ R2-only - SC-FB: Single Cell Antibody-only 3’ v2 or 5’ See https://kb.10xgenomics.com/hc/en-us/articles/115003764132-How-does-Cell-Ranger-auto-detect-chemistry- for more information.\nstring, default: \"auto\"\n\n\n--secondary_analysis\nWhether or not to run the secondary analysis e.g. clustering.\nboolean, default: FALSE\n\n\n--generate_bam\nWhether to generate a BAM file.\nboolean, default: TRUE\n\n\n--include_introns\nInclude intronic reads in count (default=true unless –target-panel is specified in which case default=false)\nboolean, default: TRUE"
  },
  {
    "objectID": "components/modules/mapping/cellranger_count.html#authors",
    "href": "components/modules/mapping/cellranger_count.html#authors",
    "title": "Cellranger count",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nSamuel D’Souza   (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/mapping/star_build_reference.html",
    "href": "components/modules/mapping/star_build_reference.html",
    "title": "Star build reference",
    "section": "",
    "text": "ID: star_build_reference\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/star_build_reference.html#example-commands",
    "href": "components/modules/mapping/star_build_reference.html#example-commands",
    "title": "Star build reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/mapping/star_build_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input/Output\ngenome_fasta: # please fill in - example: [\"chr1.fasta\", \"chr2.fasta\"]\n# transcriptome_gtf: \"path/to/file\"\n# output: \"$id.$key.output.output\"\n\n# Genome indexing arguments\ngenomeSAindexNbases: 14\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/star_build_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/star_build_reference.html#argument-groups",
    "href": "components/modules/mapping/star_build_reference.html#argument-groups",
    "title": "Star build reference",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput/Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genome_fasta\nThe fasta files to be included in the reference. Corresponds to the –genomeFastaFiles argument in the STAR command.\nList of file, required, example: \"chr1.fasta\", \"chr2.fasta\", multiple_sep: \" \"\n\n\n--transcriptome_gtf\nSpecifies the path to the file with annotated transcripts in the standard GTF format. STAR will extract splice junctions from this file and use them to greatly improve accuracy of the mapping. Corresponds to the –sjdbGTFfile argument in the STAR command.\nfile\n\n\n--output\nPath to output directory. Corresponds to the –genomeDir argument in the STAR command.\nfile, required, example: \"/path/to/foo\"\n\n\n\n\n\nGenome indexing arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genomeSAindexNbases\nLength (bases) of the SA pre-indexing string. Typically between 10 and 15. Longer strings will use much more memory, but allow faster searches. For small genomes, the parameter {genomeSAindexNbases must be scaled down to min(14, log2(GenomeLength)/2 - 1).\ninteger, default: 14"
  },
  {
    "objectID": "components/modules/mapping/star_build_reference.html#authors",
    "href": "components/modules/mapping/star_build_reference.html#authors",
    "title": "Star build reference",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/modules/mapping/star_align.html",
    "href": "components/modules/mapping/star_align.html",
    "title": "Star align",
    "section": "",
    "text": "ID: star_align\nNamespace: mapping\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/mapping/star_align.html#example-commands",
    "href": "components/modules/mapping/star_align.html#example-commands",
    "title": "Star align",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/mapping/star_align/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Input/Output\ninput: # please fill in - example: [\"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\"]\nreference: # please fill in - example: \"/path/to/reference\"\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/mapping/star_align/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/mapping/star_align.html#argument-groups",
    "href": "components/modules/mapping/star_align.html#argument-groups",
    "title": "Star align",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput/Output\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe FASTQ files to be analyzed. Corresponds to the –readFilesIn argument in the STAR command.\nList of file, required, example: \"mysample_S1_L001_R1_001.fastq.gz\", \"mysample_S1_L001_R2_001.fastq.gz\", multiple_sep: \";\"\n\n\n--reference\nPath to the reference built by star_build_reference. Corresponds to the –genomeDir argument in the STAR command.\nfile, required, example: \"/path/to/reference\"\n\n\n--output\nPath to output directory. Corresponds to the –outFileNamePrefix argument in the STAR command.\nfile, required, example: \"/path/to/foo\"\n\n\n\n\n\nRun Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--runRNGseed\nrandom number generator seed.\ninteger, example: 777\n\n\n\n\n\nGenome Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genomeLoad\nmode of shared memory usage for the genome files. Only used with –runMode alignReads. - LoadAndKeep … load genome into shared and keep it in memory after run - LoadAndRemove … load genome into shared but remove it after run - LoadAndExit … load genome into shared memory and exit, keeping the genome in memory for future runs - Remove … do not map anything, just remove loaded genome from memory - NoSharedMemory … do not use shared memory, each job will have its own private copy of the genome\nstring, example: \"NoSharedMemory\"\n\n\n--genomeFastaFiles\npath(s) to the fasta files with the genome sequences, separated by spaces. These files should be plain text FASTA files, they cannot be zipped. Required for the genome generation (–runMode genomeGenerate). Can also be used in the mapping (–runMode alignReads) to add extra (new) sequences to the genome (e.g. spike-ins).\nList of file, multiple_sep: \";\"\n\n\n--genomeFileSizes\ngenome files exact sizes in bytes. Typically, this should not be defined by the user.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--genomeTransformOutput\nwhich output to transform back to original genome - SAM … SAM/BAM alignments - SJ … splice junctions (SJ.out.tab) - None … no transformation of the output\nList of string, multiple_sep: \";\"\n\n\n--genomeChrSetMitochondrial\nnames of the mitochondrial chromosomes. Presently only used for STARsolo statistics output/\nList of string, example: \"chrM\", \"M\", \"MT\", multiple_sep: \";\"\n\n\n\n\n\nSplice Junctions Database\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--sjdbFileChrStartEnd\npath to the files with genomic coordinates (chr  start  end  strand) for the splice junction introns. Multiple files can be supplied and will be concatenated.\nList of string, multiple_sep: \";\"\n\n\n--sjdbGTFfile\npath to the GTF file with annotations\nfile\n\n\n--sjdbGTFchrPrefix\nprefix for chromosome names in a GTF file (e.g. ‘chr’ for using ENSMEBL annotations with UCSC genomes)\nstring\n\n\n--sjdbGTFfeatureExon\nfeature type in GTF file to be used as exons for building transcripts\nstring, example: \"exon\"\n\n\n--sjdbGTFtagExonParentTranscript\nGTF attribute name for parent transcript ID (default “transcript_id” works for GTF files)\nstring, example: \"transcript_id\"\n\n\n--sjdbGTFtagExonParentGene\nGTF attribute name for parent gene ID (default “gene_id” works for GTF files)\nstring, example: \"gene_id\"\n\n\n--sjdbGTFtagExonParentGeneName\nGTF attribute name for parent gene name\nList of string, example: \"gene_name\", multiple_sep: \";\"\n\n\n--sjdbGTFtagExonParentGeneType\nGTF attribute name for parent gene type\nList of string, example: \"gene_type\", \"gene_biotype\", multiple_sep: \";\"\n\n\n--sjdbOverhang\nlength of the donor/acceptor sequence on each side of the junctions, ideally = (mate_length - 1)\ninteger, example: 100\n\n\n--sjdbScore\nextra alignment score for alignments that cross database junctions\ninteger, example: 2\n\n\n--sjdbInsertSave\nwhich files to save when sjdb junctions are inserted on the fly at the mapping step - Basic … only small junction / transcript files - All … all files including big Genome, SA and SAindex - this will create a complete genome directory\nstring, example: \"Basic\"\n\n\n\n\n\nVariation parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--varVCFfile\npath to the VCF file that contains variation data. The 10th column should contain the genotype information, e.g. 0/1\nstring\n\n\n\n\n\nRead Parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--readFilesType\nformat of input read files - Fastx … FASTA or FASTQ - SAM SE … SAM or BAM single-end reads; for BAM use –readFilesCommand samtools view - SAM PE … SAM or BAM paired-end reads; for BAM use –readFilesCommand samtools view\nstring, example: \"Fastx\"\n\n\n--readFilesSAMattrKeep\nfor –readFilesType SAM SE/PE, which SAM tags to keep in the output BAM, e.g.: –readFilesSAMtagsKeep RG PL - All … keep all tags - None … do not keep any tags\nList of string, example: \"All\", multiple_sep: \";\"\n\n\n--readFilesManifest\npath to the “manifest” file with the names of read files. The manifest file should contain 3 tab-separated columns: paired-end reads: read1_file_name \\(tab\\) read2_file_name \\(tab\\) read_group_line. single-end reads: read1_file_name \\(tab\\) - \\(tab\\) read_group_line. Spaces, but not tabs are allowed in file names. If read_group_line does not start with ID:, it can only contain one ID field, and ID: will be added to it. If read_group_line starts with ID:, it can contain several fields separated by \\(tab\\), and all fields will be be copied verbatim into SAM @RG header line.\nfile\n\n\n--readFilesPrefix\nprefix for the read files names, i.e. it will be added in front of the strings in –readFilesIn\nstring\n\n\n--readFilesCommand\ncommand line to execute for each of the input file. This command should generate FASTA or FASTQ text and send it to stdout For example: zcat - to uncompress .gz files, bzcat - to uncompress .bz2 files, etc.\nList of string, multiple_sep: \";\"\n\n\n--readMapNumber\nnumber of reads to map from the beginning of the file -1: map all reads\ninteger, example: -1\n\n\n--readMatesLengthsIn\nEqual/NotEqual - lengths of names,sequences,qualities for both mates are the same / not the same. NotEqual is safe in all situations.\nstring, example: \"NotEqual\"\n\n\n--readNameSeparator\ncharacter(s) separating the part of the read names that will be trimmed in output (read name after space is always trimmed)\nList of string, example: \"/\", multiple_sep: \";\"\n\n\n--readQualityScoreBase\nnumber to be subtracted from the ASCII code to get Phred quality score\ninteger, example: 33\n\n\n\n\n\nRead Clipping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--clipAdapterType\nadapter clipping type - Hamming … adapter clipping based on Hamming distance, with the number of mismatches controlled by –clip5pAdapterMMp - CellRanger4 … 5p and 3p adapter clipping similar to CellRanger4. Utilizes Opal package by Martin Sosic: https://github.com/Martinsos/opal - None … no adapter clipping, all other clip* parameters are disregarded\nstring, example: \"Hamming\"\n\n\n--clip3pNbases\nnumber(s) of bases to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip3pAdapterSeq\nadapter sequences to clip from 3p of each mate. If one value is given, it will be assumed the same for both mates. - polyA … polyA sequence with the length equal to read length\nList of string, multiple_sep: \";\"\n\n\n--clip3pAdapterMMp\nmax proportion of mismatches for 3p adapter clipping for each mate. If one value is given, it will be assumed the same for both mates.\nList of double, example: 0.1, multiple_sep: \";\"\n\n\n--clip3pAfterAdapterNbases\nnumber of bases to clip from 3p of each mate after the adapter clipping. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n--clip5pNbases\nnumber(s) of bases to clip from 5p of each mate. If one value is given, it will be assumed the same for both mates.\nList of integer, example: 0, multiple_sep: \";\"\n\n\n\n\n\nLimits\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--limitGenomeGenerateRAM\nmaximum available RAM (bytes) for genome generation\nlong, example: NA\n\n\n--limitIObufferSize\nmax available buffers size (bytes) for input/output, per thread\nList of long, example: 30000000, 50000000, multiple_sep: \";\"\n\n\n--limitOutSAMoneReadBytes\nmax size of the SAM record (bytes) for one read. Recommended value: &gt;(2(LengthMate1+LengthMate2+100)outFilterMultimapNmax\nlong, example: 100000\n\n\n--limitOutSJoneRead\nmax number of junctions for one read (including all multi-mappers)\ninteger, example: 1000\n\n\n--limitOutSJcollapsed\nmax number of collapsed junctions\ninteger, example: 1000000\n\n\n--limitBAMsortRAM\nmaximum available RAM (bytes) for sorting BAM. If =0, it will be set to the genome index size. 0 value can only be used with –genomeLoad NoSharedMemory option.\nlong, example: 0\n\n\n--limitSjdbInsertNsj\nmaximum number of junctions to be inserted to the genome on the fly at the mapping stage, including those from annotations and those detected in the 1st step of the 2-pass run\ninteger, example: 1000000\n\n\n--limitNreadsSoft\nsoft limit on the number of reads\ninteger, example: -1\n\n\n\n\n\nOutput: general\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outTmpKeep\nwhether to keep the temporary files after STAR runs is finished - None … remove all temporary files - All … keep all files\nstring\n\n\n--outStd\nwhich output will be directed to stdout (standard out) - Log … log messages - SAM … alignments in SAM format (which normally are output to Aligned.out.sam file), normal standard output will go into Log.std.out - BAM_Unsorted … alignments in BAM format, unsorted. Requires –outSAMtype BAM Unsorted - BAM_SortedByCoordinate … alignments in BAM format, sorted by coordinate. Requires –outSAMtype BAM SortedByCoordinate - BAM_Quant … alignments to transcriptome in BAM format, unsorted. Requires –quantMode TranscriptomeSAM\nstring, example: \"Log\"\n\n\n--outReadsUnmapped\noutput of unmapped and partially mapped (i.e. mapped only one mate of a paired end read) reads in separate file(s). - None … no output - Fastx … output in separate fasta/fastq files, Unmapped.out.mate1/2\nstring\n\n\n--outQSconversionAdd\nadd this number to the quality score (e.g. to convert from Illumina to Sanger, use -31)\ninteger, example: 0\n\n\n--outMultimapperOrder\norder of multimapping alignments in the output files - Old_2.4 … quasi-random order used before 2.5.0 - Random … random order of alignments for each multi-mapper. Read mates (pairs) are always adjacent, all alignment for each read stay together. This option will become default in the future releases.\nstring, example: \"Old_2.4\"\n\n\n\n\n\nOutput: SAM and BAM\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSAMtype\ntype of SAM/BAM output 1st word: - BAM … output BAM without sorting - SAM … output SAM without sorting - None … no SAM/BAM output 2nd, 3rd: - Unsorted … standard unsorted - SortedByCoordinate … sorted by coordinate. This option will allocate extra memory for sorting which can be specified by –limitBAMsortRAM.\nList of string, example: \"SAM\", multiple_sep: \";\"\n\n\n--outSAMmode\nmode of SAM output - None … no SAM output - Full … full SAM output - NoQS … full SAM but without quality scores\nstring, example: \"Full\"\n\n\n--outSAMstrandField\nCufflinks-like strand field flag - None … not used - intronMotif … strand derived from the intron motif. This option changes the output alignments: reads with inconsistent and/or non-canonical introns are filtered out.\nstring\n\n\n--outSAMattributes\na string of desired SAM attributes, in the order desired for the output SAM. Tags can be listed in any combination/order. Presets: - None … no attributes - Standard … NH HI AS nM - All … NH HI AS nM NM MD jM jI MC ch Alignment: - NH … number of loci the reads maps to: =1 for unique mappers, &gt;1 for multimappers. Standard SAM tag. - HI … multiple alignment index, starts with –outSAMattrIHstart (=1 by default). Standard SAM tag. - AS … local alignment score, +1/-1 for matches/mismateches, score* penalties for indels and gaps. For PE reads, total score for two mates. Stadnard SAM tag. - nM … number of mismatches. For PE reads, sum over two mates. - NM … edit distance to the reference (number of mismatched + inserted + deleted bases) for each mate. Standard SAM tag. - MD … string encoding mismatched and deleted reference bases (see standard SAM specifications). Standard SAM tag. - jM … intron motifs for all junctions (i.e. N in CIGAR): 0: non-canonical; 1: GT/AG, 2: CT/AC, 3: GC/AG, 4: CT/GC, 5: AT/AC, 6: GT/AT. If splice junctions database is used, and a junction is annotated, 20 is added to its motif value. - jI … start and end of introns for all junctions (1-based). - XS … alignment strand according to –outSAMstrandField. - MC … mate’s CIGAR string. Standard SAM tag. - ch … marks all segment of all chimeric alingments for –chimOutType WithinBAM output. - cN … number of bases clipped from the read ends: 5’ and 3’ Variation: - vA … variant allele - vG … genomic coordinate of the variant overlapped by the read. - vW … 1 - alignment passes WASP filtering; 2,3,4,5,6,7 - alignment does not pass WASP filtering. Requires –waspOutputMode SAMtag. STARsolo: - CR CY UR UY … sequences and quality scores of cell barcodes and UMIs for the solo* demultiplexing. - GX GN … gene ID and gene name for unique-gene reads. - gx gn … gene IDs and gene names for unique- and multi-gene reads. - CB UB … error-corrected cell barcodes and UMIs for solo* demultiplexing. Requires –outSAMtype BAM SortedByCoordinate. - sM … assessment of CB and UMI. - sS … sequence of the entire barcode (CB,UMI,adapter). - sQ … quality of the entire barcode. ***Unsupported/undocumented: - ha … haplotype (1/2) when mapping to the diploid genome. Requires genome generated with –genomeTransformType Diploid . - rB … alignment block read/genomic coordinates. - vR … read coordinate of the variant.\nList of string, example: \"Standard\", multiple_sep: \";\"\n\n\n--outSAMattrIHstart\nstart value for the IH attribute. 0 may be required by some downstream software, such as Cufflinks or StringTie.\ninteger, example: 1\n\n\n--outSAMunmapped\noutput of unmapped reads in the SAM format 1st word: - None … no output - Within … output unmapped reads within the main SAM file (i.e. Aligned.out.sam) 2nd word: - KeepPairs … record unmapped mate for each alignment, and, in case of unsorted output, keep it adjacent to its mapped mate. Only affects multi-mapping reads.\nList of string, multiple_sep: \";\"\n\n\n--outSAMorder\ntype of sorting for the SAM output Paired: one mate after the other for all paired alignments PairedKeepInputOrder: one mate after the other for all paired alignments, the order is kept the same as in the input FASTQ files\nstring, example: \"Paired\"\n\n\n--outSAMprimaryFlag\nwhich alignments are considered primary - all others will be marked with 0x100 bit in the FLAG - OneBestScore … only one alignment with the best score is primary - AllBestScore … all alignments with the best score are primary\nstring, example: \"OneBestScore\"\n\n\n--outSAMreadID\nread ID record type - Standard … first word (until space) from the FASTx read ID line, removing /1,/2 from the end - Number … read number (index) in the FASTx file\nstring, example: \"Standard\"\n\n\n--outSAMmapqUnique\n0 to 255: the MAPQ value for unique mappers\ninteger, example: 255\n\n\n--outSAMflagOR\n0 to 65535: sam FLAG will be bitwise OR’d with this value, i.e. FLAG=FLAG | outSAMflagOR. This is applied after all flags have been set by STAR, and after outSAMflagAND. Can be used to set specific bits that are not set otherwise.\ninteger, example: 0\n\n\n--outSAMflagAND\n0 to 65535: sam FLAG will be bitwise AND’d with this value, i.e. FLAG=FLAG & outSAMflagOR. This is applied after all flags have been set by STAR, but before outSAMflagOR. Can be used to unset specific bits that are not set otherwise.\ninteger, example: 65535\n\n\n--outSAMattrRGline\nSAM/BAM read group line. The first word contains the read group identifier and must start with “ID:”, e.g. –outSAMattrRGline ID:xxx CN:yy “DS:z z z”. xxx will be added as RG tag to each output alignment. Any spaces in the tag values have to be double quoted. Comma separated RG lines correspons to different (comma separated) input files in –readFilesIn. Commas have to be surrounded by spaces, e.g. –outSAMattrRGline ID:xxx , ID:zzz “DS:z z” , ID:yyy DS:yyyy\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderHD\n@HD (header) line of the SAM header\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderPG\nextra @PG (software) line of the SAM header (in addition to STAR)\nList of string, multiple_sep: \";\"\n\n\n--outSAMheaderCommentFile\npath to the file with @CO (comment) lines of the SAM header\nstring\n\n\n--outSAMfilter\nfilter the output into main SAM/BAM files - KeepOnlyAddedReferences … only keep the reads for which all alignments are to the extra reference sequences added with –genomeFastaFiles at the mapping stage. - KeepAllAddedReferences … keep all alignments to the extra reference sequences added with –genomeFastaFiles at the mapping stage.\nList of string, multiple_sep: \";\"\n\n\n--outSAMmultNmax\nmax number of multiple alignments for a read that will be output to the SAM/BAM files. Note that if this value is not equal to -1, the top scoring alignment will be output first - -1 … all alignments (up to –outFilterMultimapNmax) will be output\ninteger, example: -1\n\n\n--outSAMtlen\ncalculation method for the TLEN field in the SAM/BAM files - 1 … leftmost base of the (+)strand mate to rightmost base of the (-)mate. (+)sign for the (+)strand mate - 2 … leftmost base of any mate to rightmost base of any mate. (+)sign for the mate with the leftmost base. This is different from 1 for overlapping mates with protruding ends\ninteger, example: 1\n\n\n--outBAMcompression\n-1 to 10 BAM compression level, -1=default compression (6?), 0=no compression, 10=maximum compression\ninteger, example: 1\n\n\n--outBAMsortingThreadN\n&gt;=0: number of threads for BAM sorting. 0 will default to min(6,–runThreadN).\ninteger, example: 0\n\n\n--outBAMsortingBinsN\n&gt;0: number of genome bins for coordinate-sorting\ninteger, example: 50\n\n\n\n\n\nBAM processing\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--bamRemoveDuplicatesType\nmark duplicates in the BAM file, for now only works with (i) sorted BAM fed with inputBAMfile, and (ii) for paired-end alignments only - - … no duplicate removal/marking - UniqueIdentical … mark all multimappers, and duplicate unique mappers. The coordinates, FLAG, CIGAR must be identical - UniqueIdenticalNotMulti … mark duplicate unique mappers but not multimappers.\nstring\n\n\n--bamRemoveDuplicatesMate2basesN\nnumber of bases from the 5’ of mate 2 to use in collapsing (e.g. for RAMPAGE)\ninteger, example: 0\n\n\n\n\n\nOutput Wiggle\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outWigType\ntype of signal output, e.g. “bedGraph” OR “bedGraph read1_5p”. Requires sorted BAM: –outSAMtype BAM SortedByCoordinate . 1st word: - None … no signal output - bedGraph … bedGraph format - wiggle … wiggle format 2nd word: - read1_5p … signal from only 5’ of the 1st read, useful for CAGE/RAMPAGE etc - read2 … signal from only 2nd read\nList of string, multiple_sep: \";\"\n\n\n--outWigStrand\nstrandedness of wiggle/bedGraph output - Stranded … separate strands, str1 and str2 - Unstranded … collapsed strands\nstring, example: \"Stranded\"\n\n\n--outWigReferencesPrefix\nprefix matching reference names to include in the output wiggle file, e.g. “chr”, default “-” - include all references\nstring\n\n\n--outWigNorm\ntype of normalization for the signal - RPM … reads per million of mapped reads - None … no normalization, “raw” counts\nstring, example: \"RPM\"\n\n\n\n\n\nOutput Filtering\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outFilterType\ntype of filtering - Normal … standard filtering using only current alignment - BySJout … keep only those reads that contain junctions that passed filtering into SJ.out.tab\nstring, example: \"Normal\"\n\n\n--outFilterMultimapScoreRange\nthe score range below the maximum score for multimapping alignments\ninteger, example: 1\n\n\n--outFilterMultimapNmax\nmaximum number of loci the read is allowed to map to. Alignments (all of them) will be output only if the read maps to no more loci than this value. Otherwise no alignments will be output, and the read will be counted as “mapped to too many loci” in the Log.final.out .\ninteger, example: 10\n\n\n--outFilterMismatchNmax\nalignment will be output only if it has no more mismatches than this value.\ninteger, example: 10\n\n\n--outFilterMismatchNoverLmax\nalignment will be output only if its ratio of mismatches to mapped length is less than or equal to this value.\ndouble, example: 0.3\n\n\n--outFilterMismatchNoverReadLmax\nalignment will be output only if its ratio of mismatches to read length is less than or equal to this value.\ndouble, example: 1\n\n\n--outFilterScoreMin\nalignment will be output only if its score is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterScoreMinOverLread\nsame as outFilterScoreMin, but normalized to read length (sum of mates’ lengths for paired-end reads)\ndouble, example: 0.66\n\n\n--outFilterMatchNmin\nalignment will be output only if the number of matched bases is higher than or equal to this value.\ninteger, example: 0\n\n\n--outFilterMatchNminOverLread\nsam as outFilterMatchNmin, but normalized to the read length (sum of mates’ lengths for paired-end reads).\ndouble, example: 0.66\n\n\n--outFilterIntronMotifs\nfilter alignment using their motifs - None … no filtering - RemoveNoncanonical … filter out alignments that contain non-canonical junctions - RemoveNoncanonicalUnannotated … filter out alignments that contain non-canonical unannotated junctions when using annotated splice junctions database. The annotated non-canonical junctions will be kept.\nstring\n\n\n--outFilterIntronStrands\nfilter alignments - RemoveInconsistentStrands … remove alignments that have junctions with inconsistent strands - None … no filtering\nstring, example: \"RemoveInconsistentStrands\"\n\n\n\n\n\nOutput splice junctions (SJ.out.tab)\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJtype\ntype of splice junction output - Standard … standard SJ.out.tab output - None … no splice junction output\nstring, example: \"Standard\"\n\n\n\n\n\nOutput Filtering: Splice Junctions\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--outSJfilterReads\nwhich reads to consider for collapsed splice junctions output - All … all reads, unique- and multi-mappers - Unique … uniquely mapping reads only\nstring, example: \"All\"\n\n\n--outSJfilterOverhangMin\nminimum overhang length for splice junctions on both sides for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif does not apply to annotated junctions\nList of integer, example: 30, 12, 12, 12, multiple_sep: \";\"\n\n\n--outSJfilterCountUniqueMin\nminimum uniquely mapping read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterCountTotalMin\nminimum total (multi-mapping+unique) read count per junction for: (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif. -1 means no output for that motif Junctions are output if one of outSJfilterCountUniqueMin OR outSJfilterCountTotalMin conditions are satisfied does not apply to annotated junctions\nList of integer, example: 3, 1, 1, 1, multiple_sep: \";\"\n\n\n--outSJfilterDistToOtherSJmin\nminimum allowed distance to other junctions’ donor/acceptor does not apply to annotated junctions\nList of integer, example: 10, 0, 5, 10, multiple_sep: \";\"\n\n\n--outSJfilterIntronMaxVsReadN\nmaximum gap allowed for junctions supported by 1,2,3,,,N reads i.e. by default junctions supported by 1 read can have gaps &lt;=50000b, by 2 reads: &lt;=100000b, by 3 reads: &lt;=200000. by &gt;=4 reads any gap &lt;=alignIntronMax does not apply to annotated junctions\nList of integer, example: 50000, 100000, 200000, multiple_sep: \";\"\n\n\n\n\n\nScoring\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--scoreGap\nsplice junction penalty (independent on intron motif)\ninteger, example: 0\n\n\n--scoreGapNoncan\nnon-canonical junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGapGCAG\nGC/AG and CT/GC junction penalty (in addition to scoreGap)\ninteger, example: -4\n\n\n--scoreGapATAC\nAT/AC and GT/AT junction penalty (in addition to scoreGap)\ninteger, example: -8\n\n\n--scoreGenomicLengthLog2scale\nextra score logarithmically scaled with genomic length of the alignment: scoreGenomicLengthLog2scale*log2(genomicLength)\ninteger, example: 0\n\n\n--scoreDelOpen\ndeletion open penalty\ninteger, example: -2\n\n\n--scoreDelBase\ndeletion extension penalty per base (in addition to scoreDelOpen)\ninteger, example: -2\n\n\n--scoreInsOpen\ninsertion open penalty\ninteger, example: -2\n\n\n--scoreInsBase\ninsertion extension penalty per base (in addition to scoreInsOpen)\ninteger, example: -2\n\n\n--scoreStitchSJshift\nmaximum score reduction while searching for SJ boundaries in the stitching step\ninteger, example: 1\n\n\n\n\n\nAlignments and Seeding\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--seedSearchStartLmax\ndefines the search start point through the read - the read is split into pieces no longer than this value\ninteger, example: 50\n\n\n--seedSearchStartLmaxOverLread\nseedSearchStartLmax normalized to read length (sum of mates’ lengths for paired-end reads)\ndouble, example: 1\n\n\n--seedSearchLmax\ndefines the maximum length of the seeds, if =0 seed length is not limited\ninteger, example: 0\n\n\n--seedMultimapNmax\nonly pieces that map fewer than this value are utilized in the stitching procedure\ninteger, example: 10000\n\n\n--seedPerReadNmax\nmax number of seeds per read\ninteger, example: 1000\n\n\n--seedPerWindowNmax\nmax number of seeds per window\ninteger, example: 50\n\n\n--seedNoneLociPerWindow\nmax number of one seed loci per window\ninteger, example: 10\n\n\n--seedSplitMin\nmin length of the seed sequences split by Ns or mate gap\ninteger, example: 12\n\n\n--seedMapMin\nmin length of seeds to be mapped\ninteger, example: 5\n\n\n--alignIntronMin\nminimum intron size, genomic gap is considered intron if its length&gt;=alignIntronMin, otherwise it is considered Deletion\ninteger, example: 21\n\n\n--alignIntronMax\nmaximum intron size, if 0, max intron size will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignMatesGapMax\nmaximum gap between two mates, if 0, max intron gap will be determined by (2^winBinNbits)*winAnchorDistNbins\ninteger, example: 0\n\n\n--alignSJoverhangMin\nminimum overhang (i.e. block size) for spliced alignments\ninteger, example: 5\n\n\n--alignSJstitchMismatchNmax\nmaximum number of mismatches for stitching of the splice junctions (-1: no limit). (1) non-canonical motifs, (2) GT/AG and CT/AC motif, (3) GC/AG and CT/GC motif, (4) AT/AC and GT/AT motif.\nList of integer, example: 0, -1, 0, 0, multiple_sep: \";\"\n\n\n--alignSJDBoverhangMin\nminimum overhang (i.e. block size) for annotated (sjdb) spliced alignments\ninteger, example: 3\n\n\n--alignSplicedMateMapLmin\nminimum mapped length for a read mate that is spliced\ninteger, example: 0\n\n\n--alignSplicedMateMapLminOverLmate\nalignSplicedMateMapLmin normalized to mate length\ndouble, example: 0.66\n\n\n--alignWindowsPerReadNmax\nmax number of windows per read\ninteger, example: 10000\n\n\n--alignTranscriptsPerWindowNmax\nmax number of transcripts per window\ninteger, example: 100\n\n\n--alignTranscriptsPerReadNmax\nmax number of different alignments per read to consider\ninteger, example: 10000\n\n\n--alignEndsType\ntype of read ends alignment - Local … standard local alignment with soft-clipping allowed - EndToEnd … force end-to-end read alignment, do not soft-clip - Extend5pOfRead1 … fully extend only the 5p of the read1, all other ends: local alignment - Extend5pOfReads12 … fully extend only the 5p of the both read1 and read2, all other ends: local alignment\nstring, example: \"Local\"\n\n\n--alignEndsProtrude\nallow protrusion of alignment ends, i.e. start (end) of the +strand mate downstream of the start (end) of the -strand mate 1st word: int: maximum number of protrusion bases allowed 2nd word: string: - ConcordantPair … report alignments with non-zero protrusion as concordant pairs - DiscordantPair … report alignments with non-zero protrusion as discordant pairs\nstring, example: \"0    ConcordantPair\"\n\n\n--alignSoftClipAtReferenceEnds\nallow the soft-clipping of the alignments past the end of the chromosomes - Yes … allow - No … prohibit, useful for compatibility with Cufflinks\nstring, example: \"Yes\"\n\n\n--alignInsertionFlush\nhow to flush ambiguous insertion positions - None … insertions are not flushed - Right … insertions are flushed to the right\nstring\n\n\n\n\n\nPaired-End reads\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--peOverlapNbasesMin\nminimum number of overlapping bases to trigger mates merging and realignment. Specify &gt;0 value to switch on the “merginf of overlapping mates” algorithm.\ninteger, example: 0\n\n\n--peOverlapMMp\nmaximum proportion of mismatched bases in the overlap area\ndouble, example: 0.01\n\n\n\n\n\nWindows, Anchors, Binning\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--winAnchorMultimapNmax\nmax number of loci anchors are allowed to map to\ninteger, example: 50\n\n\n--winBinNbits\n=log2(winBin), where winBin is the size of the bin for the windows/clustering, each window will occupy an integer number of bins.\ninteger, example: 16\n\n\n--winAnchorDistNbins\nmax number of bins between two anchors that allows aggregation of anchors into one window\ninteger, example: 9\n\n\n--winFlankNbins\nlog2(winFlank), where win Flank is the size of the left and right flanking regions for each window\ninteger, example: 4\n\n\n--winReadCoverageRelativeMin\nminimum relative coverage of the read sequence by the seeds in a window, for STARlong algorithm only.\ndouble, example: 0.5\n\n\n--winReadCoverageBasesMin\nminimum number of bases covered by the seeds in a window , for STARlong algorithm only.\ninteger, example: 0\n\n\n\n\n\nChimeric Alignments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--chimOutType\ntype of chimeric output - Junctions … Chimeric.out.junction - SeparateSAMold … output old SAM into separate Chimeric.out.sam file - WithinBAM … output into main aligned BAM files (Aligned.*.bam) - WithinBAM HardClip … (default) hard-clipping in the CIGAR for supplemental chimeric alignments (default if no 2nd word is present) - WithinBAM SoftClip … soft-clipping in the CIGAR for supplemental chimeric alignments\nList of string, example: \"Junctions\", multiple_sep: \";\"\n\n\n--chimSegmentMin\nminimum length of chimeric segment length, if ==0, no chimeric output\ninteger, example: 0\n\n\n--chimScoreMin\nminimum total (summed) score of the chimeric segments\ninteger, example: 0\n\n\n--chimScoreDropMax\nmax drop (difference) of chimeric score (the sum of scores of all chimeric segments) from the read length\ninteger, example: 20\n\n\n--chimScoreSeparation\nminimum difference (separation) between the best chimeric score and the next one\ninteger, example: 10\n\n\n--chimScoreJunctionNonGTAG\npenalty for a non-GT/AG chimeric junction\ninteger, example: -1\n\n\n--chimJunctionOverhangMin\nminimum overhang for a chimeric junction\ninteger, example: 20\n\n\n--chimSegmentReadGapMax\nmaximum gap in the read sequence between chimeric segments\ninteger, example: 0\n\n\n--chimFilter\ndifferent filters for chimeric alignments - None … no filtering - banGenomicN … Ns are not allowed in the genome sequence around the chimeric junction\nList of string, example: \"banGenomicN\", multiple_sep: \";\"\n\n\n--chimMainSegmentMultNmax\nmaximum number of multi-alignments for the main chimeric segment. =1 will prohibit multimapping main segments.\ninteger, example: 10\n\n\n--chimMultimapNmax\nmaximum number of chimeric multi-alignments - 0 … use the old scheme for chimeric detection which only considered unique alignments\ninteger, example: 0\n\n\n--chimMultimapScoreRange\nthe score range for multi-mapping chimeras below the best chimeric score. Only works with –chimMultimapNmax &gt; 1\ninteger, example: 1\n\n\n--chimNonchimScoreDropMin\nto trigger chimeric detection, the drop in the best non-chimeric alignment score with respect to the read length has to be greater than this value\ninteger, example: 20\n\n\n--chimOutJunctionFormat\nformatting type for the Chimeric.out.junction file - 0 … no comment lines/headers - 1 … comment lines at the end of the file: command line and Nreads: total, unique/multi-mapping\ninteger, example: 0\n\n\n\n\n\nQuantification of Annotations\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--quantMode\ntypes of quantification requested - - … none - TranscriptomeSAM … output SAM/BAM alignments to transcriptome into a separate file - GeneCounts … count reads per gene\nList of string, multiple_sep: \";\"\n\n\n--quantTranscriptomeBAMcompression\n-2 to 10 transcriptome BAM compression level - -2 … no BAM output - -1 … default compression (6?) - 0 … no compression - 10 … maximum compression\ninteger, example: 1\n\n\n--quantTranscriptomeBan\nprohibit various alignment type - IndelSoftclipSingleend … prohibit indels, soft clipping and single-end alignments - compatible with RSEM - Singleend … prohibit single-end alignments\nstring, example: \"IndelSoftclipSingleend\"\n\n\n\n\n\n2-pass Mapping\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--twopassMode\n2-pass mapping mode. - None … 1-pass mapping - Basic … basic 2-pass mapping, with all 1st pass junctions inserted into the genome indices on the fly\nstring\n\n\n--twopass1readsN\nnumber of reads to process for the 1st step. Use very large number (or default -1) to map all reads in the first step.\ninteger, example: -1\n\n\n\n\n\nWASP parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--waspOutputMode\nWASP allele-specific output type. This is re-implementation of the original WASP mappability filtering by Bryce van de Geijn, Graham McVicker, Yoav Gilad & Jonathan K Pritchard. Please cite the original WASP paper: Nature Methods 12, 1061-1063 (2015), https://www.nature.com/articles/nmeth.3582 . - SAMtag … add WASP tags to the alignments that pass WASP filtering\nstring\n\n\n\n\n\nSTARsolo (single cell RNA-seq) parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--soloType\ntype of single-cell RNA-seq - CB_UMI_Simple … (a.k.a. Droplet) one UMI and one Cell Barcode of fixed length in read2, e.g. Drop-seq and 10X Chromium. - CB_UMI_Complex … multiple Cell Barcodes of varying length, one UMI of fixed length and one adapter sequence of fixed length are allowed in read2 only (e.g. inDrop, ddSeq). - CB_samTagOut … output Cell Barcode as CR and/or CB SAm tag. No UMI counting. –readFilesIn cDNA_read1 [cDNA_read2 if paired-end] CellBarcode_read . Requires –outSAMtype BAM Unsorted [and/or SortedByCoordinate] - SmartSeq … Smart-seq: each cell in a separate FASTQ (paired- or single-end), barcodes are corresponding read-groups, no UMI sequences, alignments deduplicated according to alignment start and end (after extending soft-clipped bases)\nList of string, multiple_sep: \";\"\n\n\n--soloCBwhitelist\nfile(s) with whitelist(s) of cell barcodes. Only –soloType CB_UMI_Complex allows more than one whitelist file. - None … no whitelist: all cell barcodes are allowed\nList of string, multiple_sep: \";\"\n\n\n--soloCBstart\ncell barcode start base\ninteger, example: 1\n\n\n--soloCBlen\ncell barcode length\ninteger, example: 16\n\n\n--soloUMIstart\nUMI start base\ninteger, example: 17\n\n\n--soloUMIlen\nUMI length\ninteger, example: 10\n\n\n--soloBarcodeReadLength\nlength of the barcode read - 1 … equal to sum of soloCBlen+soloUMIlen - 0 … not defined, do not check\ninteger, example: 1\n\n\n--soloBarcodeMate\nidentifies which read mate contains the barcode (CB+UMI) sequence - 0 … barcode sequence is on separate read, which should always be the last file in the –readFilesIn listed - 1 … barcode sequence is a part of mate 1 - 2 … barcode sequence is a part of mate 2\ninteger, example: 0\n\n\n--soloCBposition\nposition of Cell Barcode(s) on the barcode read. Presently only works with –soloType CB_UMI_Complex, and barcodes are assumed to be on Read2. Format for each barcode: startAnchor_startPosition_endAnchor_endPosition start(end)Anchor defines the Anchor Base for the CB: 0: read start; 1: read end; 2: adapter start; 3: adapter end start(end)Position is the 0-based position with of the CB start(end) with respect to the Anchor Base String for different barcodes are separated by space. Example: inDrop (Zilionis et al, Nat. Protocols, 2017): –soloCBposition 0_0_2_-1 3_1_3_8\nList of string, multiple_sep: \";\"\n\n\n--soloUMIposition\nposition of the UMI on the barcode read, same as soloCBposition Example: inDrop (Zilionis et al, Nat. Protocols, 2017): –soloCBposition 3_9_3_14\nstring\n\n\n--soloAdapterSequence\nadapter sequence to anchor barcodes. Only one adapter sequence is allowed.\nstring\n\n\n--soloAdapterMismatchesNmax\nmaximum number of mismatches allowed in adapter sequence.\ninteger, example: 1\n\n\n--soloCBmatchWLtype\nmatching the Cell Barcodes to the WhiteList - Exact … only exact matches allowed - 1MM … only one match in whitelist with 1 mismatched base allowed. Allowed CBs have to have at least one read with exact match. - 1MM_multi … multiple matches in whitelist with 1 mismatched base allowed, posterior probability calculation is used choose one of the matches. Allowed CBs have to have at least one read with exact match. This option matches best with CellRanger 2.2.0 - 1MM_multi_pseudocounts … same as 1MM_Multi, but pseudocounts of 1 are added to all whitelist barcodes. - 1MM_multi_Nbase_pseudocounts … same as 1MM_multi_pseudocounts, multimatching to WL is allowed for CBs with N-bases. This option matches best with CellRanger &gt;= 3.0.0 - EditDist_2 … allow up to edit distance of 3 fpr each of the barcodes. May include one deletion + one insertion. Only works with –soloType CB_UMI_Complex. Matches to multiple passlist barcdoes are not allowed. Similar to ParseBio Split-seq pipeline.\nstring, example: \"1MM_multi\"\n\n\n--soloInputSAMattrBarcodeSeq\nwhen inputting reads from a SAM file (–readsFileType SAM SE/PE), these SAM attributes mark the barcode sequence (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use –soloInputSAMattrBarcodeSeq CR UR . This parameter is required when running STARsolo with input from SAM.\nList of string, multiple_sep: \";\"\n\n\n--soloInputSAMattrBarcodeQual\nwhen inputting reads from a SAM file (–readsFileType SAM SE/PE), these SAM attributes mark the barcode qualities (in proper order). For instance, for 10X CellRanger or STARsolo BAMs, use –soloInputSAMattrBarcodeQual CY UY . If this parameter is ‘-’ (default), the quality ‘H’ will be assigned to all bases.\nList of string, multiple_sep: \";\"\n\n\n--soloStrand\nstrandedness of the solo libraries: - Unstranded … no strand information - Forward … read strand same as the original RNA molecule - Reverse … read strand opposite to the original RNA molecule\nstring, example: \"Forward\"\n\n\n--soloFeatures\ngenomic features for which the UMI counts per Cell Barcode are collected - Gene … genes: reads match the gene transcript - SJ … splice junctions: reported in SJ.out.tab - GeneFull … full gene (pre-mRNA): count all reads overlapping genes’ exons and introns - GeneFull_ExonOverIntron … full gene (pre-mRNA): count all reads overlapping genes’ exons and introns: prioritize 100% overlap with exons - GeneFull_Ex50pAS … full gene (pre-RNA): count all reads overlapping genes’ exons and introns: prioritize &gt;50% overlap with exons. Do not count reads with 100% exonic overlap in the antisense direction.\nList of string, example: \"Gene\", multiple_sep: \";\"\n\n\n--soloMultiMappers\ncounting method for reads mapping to multiple genes - Unique … count only reads that map to unique genes - Uniform … uniformly distribute multi-genic UMIs to all genes - Rescue … distribute UMIs proportionally to unique+uniform counts (~ first iteration of EM) - PropUnique … distribute UMIs proportionally to unique mappers, if present, and uniformly if not. - EM … multi-gene UMIs are distributed using Expectation Maximization algorithm\nList of string, example: \"Unique\", multiple_sep: \";\"\n\n\n--soloUMIdedup\ntype of UMI deduplication (collapsing) algorithm - 1MM_All … all UMIs with 1 mismatch distance to each other are collapsed (i.e. counted once). - 1MM_Directional_UMItools … follows the “directional” method from the UMI-tools by Smith, Heger and Sudbery (Genome Research 2017). - 1MM_Directional … same as 1MM_Directional_UMItools, but with more stringent criteria for duplicate UMIs - Exact … only exactly matching UMIs are collapsed. - NoDedup … no deduplication of UMIs, count all reads. - 1MM_CR … CellRanger2-4 algorithm for 1MM UMI collapsing.\nList of string, example: \"1MM_All\", multiple_sep: \";\"\n\n\n--soloUMIfiltering\ntype of UMI filtering (for reads uniquely mapping to genes) - - … basic filtering: remove UMIs with N and homopolymers (similar to CellRanger 2.2.0). - MultiGeneUMI … basic + remove lower-count UMIs that map to more than one gene. - MultiGeneUMI_All … basic + remove all UMIs that map to more than one gene. - MultiGeneUMI_CR … basic + remove lower-count UMIs that map to more than one gene, matching CellRanger &gt; 3.0.0 . Only works with –soloUMIdedup 1MM_CR\nList of string, multiple_sep: \";\"\n\n\n--soloOutFileNames\nfile names for STARsolo output: file_name_prefix gene_names barcode_sequences cell_feature_count_matrix\nList of string, example: \"Solo.out/\", \"features.tsv\", \"barcodes.tsv\", \"matrix.mtx\", multiple_sep: \";\"\n\n\n--soloCellFilter\ncell filtering type and parameters - None … do not output filtered cells - TopCells … only report top cells by UMI count, followed by the exact number of cells - CellRanger2.2 … simple filtering of CellRanger 2.2. Can be followed by numbers: number of expected cells, robust maximum percentile for UMI count, maximum to minimum ratio for UMI count The harcoded values are from CellRanger: nExpectedCells=3000; maxPercentile=0.99; maxMinRatio=10 - EmptyDrops_CR … EmptyDrops filtering in CellRanger flavor. Please cite the original EmptyDrops paper: A.T.L Lun et al, Genome Biology, 20, 63 (2019): https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1662-y Can be followed by 10 numeric parameters: nExpectedCells maxPercentile maxMinRatio indMin indMax umiMin umiMinFracMedian candMaxN FDR simN The harcoded values are from CellRanger: 3000 0.99 10 45000 90000 500 0.01 20000 0.01 10000\nList of string, example: \"CellRanger2.2\", \"3000\", \"0.99\", \"10\", multiple_sep: \";\"\n\n\n--soloOutFormatFeaturesGeneField3\nfield 3 in the Gene features.tsv file. If “-”, then no 3rd field is output.\nList of string, example: \"Gene Expression\", multiple_sep: \";\"\n\n\n--soloCellReadStats\nOutput reads statistics for each CB - Standard … standard output\nstring"
  },
  {
    "objectID": "components/modules/mapping/star_align.html#authors",
    "href": "components/modules/mapping/star_align.html#authors",
    "title": "Star align",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/convert/from_bdrhap_to_h5mu.html",
    "href": "components/modules/convert/from_bdrhap_to_h5mu.html",
    "title": "From bdrhap to h5mu",
    "section": "",
    "text": "ID: from_bdrhap_to_h5mu\nNamespace: convert\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/convert/from_bdrhap_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_bdrhap_to_h5mu.html#example-commands",
    "title": "From bdrhap to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/convert/from_bdrhap_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\nid: # please fill in - example: \"my_id\"\ninput: # please fill in - example: \"input_dir/\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_bdrhap_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_bdrhap_to_h5mu.html#argument-groups",
    "href": "components/modules/convert/from_bdrhap_to_h5mu.html#argument-groups",
    "title": "From bdrhap to h5mu",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--id\nA sample ID.\nstring, required, example: \"my_id\"\n\n\n--input\nThe output of a BD Rhapsody workflow.\nfile, required, example: \"input_dir\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/convert/from_bdrhap_to_h5mu.html#authors",
    "href": "components/modules/convert/from_bdrhap_to_h5mu.html#authors",
    "title": "From bdrhap to h5mu",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/convert/from_10xmtx_to_h5mu.html",
    "href": "components/modules/convert/from_10xmtx_to_h5mu.html",
    "title": "From 10xmtx to h5mu",
    "section": "",
    "text": "ID: from_10xmtx_to_h5mu\nNamespace: convert\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/convert/from_10xmtx_to_h5mu.html#example-commands",
    "href": "components/modules/convert/from_10xmtx_to_h5mu.html#example-commands",
    "title": "From 10xmtx to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/convert/from_10xmtx_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input_dir_containing_gz_files\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_10xmtx_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_10xmtx_to_h5mu.html#argument-group",
    "href": "components/modules/convert/from_10xmtx_to_h5mu.html#argument-group",
    "title": "From 10xmtx to h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput mtx folder\nfile, required, example: \"input_dir_containing_gz_files\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/convert/from_10xmtx_to_h5mu.html#authors",
    "href": "components/modules/convert/from_10xmtx_to_h5mu.html#authors",
    "title": "From 10xmtx to h5mu",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/convert/velocyto_to_h5mu.html",
    "href": "components/modules/convert/velocyto_to_h5mu.html",
    "title": "Velocyto to h5mu",
    "section": "",
    "text": "ID: velocyto_to_h5mu\nNamespace: convert\n\n\n\nSource\nIf an input h5mu file is also provided, the velocity h5ad object will get added to that h5mu instead."
  },
  {
    "objectID": "components/modules/convert/velocyto_to_h5mu.html#example-commands",
    "href": "components/modules/convert/velocyto_to_h5mu.html#example-commands",
    "title": "Velocyto to h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/convert/velocyto_to_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput_loom: # please fill in - example: \"input.loom\"\n# input_h5mu: \"input.h5mu\"\nmodality: \"rna_velocity\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nlayer_spliced: \"velo_spliced\"\nlayer_unspliced: \"velo_unspliced\"\nlayer_ambiguous: \"velo_ambiguous\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/velocyto_to_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/velocyto_to_h5mu.html#argument-groups",
    "href": "components/modules/convert/velocyto_to_h5mu.html#argument-groups",
    "title": "Velocyto to h5mu",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_loom\nPath to the input loom file.\nfile, required, example: \"input.loom\"\n\n\n--input_h5mu\nIf a MuData file is provided,\nfile, example: \"input.h5mu\"\n\n\n--modality\nThe name of the modality to operate on.\nstring, default: \"rna_velocity\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nPath to the output MuData file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--layer_spliced\nOutput layer for the spliced reads.\nstring, default: \"velo_spliced\"\n\n\n--layer_unspliced\nOutput layer for the unspliced reads.\nstring, default: \"velo_unspliced\"\n\n\n--layer_ambiguous\nOutput layer for the ambiguous reads.\nstring, default: \"velo_ambiguous\""
  },
  {
    "objectID": "components/modules/convert/velocyto_to_h5mu.html#authors",
    "href": "components/modules/convert/velocyto_to_h5mu.html#authors",
    "title": "Velocyto to h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer, author)\nRobrecht Cannoodt    (author)\nAngela Oliveira Pisco    (contributor)"
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_h5ad.html",
    "href": "components/modules/convert/from_h5mu_to_h5ad.html",
    "title": "From h5mu to h5ad",
    "section": "",
    "text": "ID: from_h5mu_to_h5ad\nNamespace: convert\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_h5ad.html#example-commands",
    "href": "components/modules/convert/from_h5mu_to_h5ad.html#example-commands",
    "title": "From h5mu to h5ad",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/convert/from_h5mu_to_h5ad/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# output: \"$id.$key.output.h5ad\"\noutput_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/convert/from_h5mu_to_h5ad/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_h5ad.html#argument-group",
    "href": "components/modules/convert/from_h5mu_to_h5ad.html#argument-group",
    "title": "From h5mu to h5ad",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput MuData file\nfile, required, default: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--output\nOutput AnnData file.\nfile, default: \"output.h5ad\"\n\n\n--output_compression\nThe compression format to be used on the final h5ad object.\nstring, default: \"gzip\""
  },
  {
    "objectID": "components/modules/convert/from_h5mu_to_h5ad.html#authors",
    "href": "components/modules/convert/from_h5mu_to_h5ad.html#authors",
    "title": "From h5mu to h5ad",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer)"
  },
  {
    "objectID": "components/modules/transfer/publish.html",
    "href": "components/modules/transfer/publish.html",
    "title": "Publish",
    "section": "",
    "text": "ID: publish\nNamespace: transfer\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/transfer/publish.html#example-commands",
    "href": "components/modules/transfer/publish.html#example-commands",
    "title": "Publish",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/transfer/publish/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\n# output: \"$id.$key.output.output\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transfer/publish/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transfer/publish.html#argument-group",
    "href": "components/modules/transfer/publish.html#argument-group",
    "title": "Publish",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput filename\nfile, required\n\n\n--output\nOutput filename\nfile, required"
  },
  {
    "objectID": "components/modules/transfer/publish.html#authors",
    "href": "components/modules/transfer/publish.html#authors",
    "title": "Publish",
    "section": "Authors",
    "text": "Authors\n\nToni Verbeiren   (maintainer)"
  },
  {
    "objectID": "components/modules/integrate/totalvi.html",
    "href": "components/modules/integrate/totalvi.html",
    "title": "Totalvi",
    "section": "",
    "text": "ID: totalvi\nNamespace: integrate\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/integrate/totalvi.html#example-commands",
    "href": "components/modules/integrate/totalvi.html#example-commands",
    "title": "Totalvi",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/integrate/totalvi/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"path/to/file\"\nreference: # please fill in - example: \"path/to/file\"\nforce_retrain: false\nquery_modality: \"rna\"\n# query_proteins_modality: \"foo\"\nreference_modality: \"rna\"\nreference_proteins_modality: \"prot\"\n# input_layer: \"foo\"\nobs_batch: \"sample_id\"\n# var_input: \"foo\"\n\n# Outputs\n# output: \"$id.$key.output.output\"\nobsm_output: \"X_integrated_totalvi\"\nobsm_normalized_rna_output: \"X_totalvi_normalized_rna\"\nobsm_normalized_protein_output: \"X_totalvi_normalized_protein\"\n# reference_model_path: \"$id.$key.reference_model_path.reference_model_path\"\n# query_model_path: \"$id.$key.query_model_path.query_model_path\"\n\n# Learning parameters\nmax_epochs: 400\nmax_query_epochs: 200\nweight_decay: 0.0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/totalvi/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/integrate/totalvi.html#argument-groups",
    "href": "components/modules/integrate/totalvi.html#argument-groups",
    "title": "Totalvi",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file with query data to integrate with reference.\nfile, required\n\n\n--reference\nInput h5mu file with reference data to train the TOTALVI model.\nfile, required\n\n\n--force_retrain\nIf true, retrain the model and save it to reference_model_path\nboolean_true\n\n\n--query_modality\n\nstring, default: \"rna\"\n\n\n--query_proteins_modality\nName of the modality in the input (query) h5mu file containing protein data\nstring\n\n\n--reference_modality\n\nstring, default: \"rna\"\n\n\n--reference_proteins_modality\nName of the modality containing proteins in the reference\nstring, default: \"prot\"\n\n\n--input_layer\nInput layer to use. If None, X is used\nstring\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"sample_id\"\n\n\n--var_input\n.var column containing highly variable genes. By default, do not subset genes.\nstring\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required\n\n\n--obsm_output\nIn which .obsm slot to store the resulting integrated embedding.\nstring, default: \"X_integrated_totalvi\"\n\n\n--obsm_normalized_rna_output\nIn which .obsm slot to store the normalized RNA from TOTALVI.\nstring, default: \"X_totalvi_normalized_rna\"\n\n\n--obsm_normalized_protein_output\nIn which .obsm slot to store the normalized protein data from TOTALVI.\nstring, default: \"X_totalvi_normalized_protein\"\n\n\n--reference_model_path\nDirectory with the reference model. If not exists, trained model will be saved there\nfile, default: \"totalvi_model_reference\"\n\n\n--query_model_path\nDirectory, where the query model will be saved\nfile, default: \"totalvi_model_query\"\n\n\n\n\n\nLearning parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--max_epochs\nNumber of passes through the dataset\ninteger, default: 400\n\n\n--max_query_epochs\nNumber of passes through the dataset, when fine-tuning model for query\ninteger, default: 200\n\n\n--weight_decay\nWeight decay, when fine-tuning model for query\ndouble, default: 0"
  },
  {
    "objectID": "components/modules/integrate/totalvi.html#authors",
    "href": "components/modules/integrate/totalvi.html#authors",
    "title": "Totalvi",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov"
  },
  {
    "objectID": "components/modules/integrate/scanorama.html",
    "href": "components/modules/integrate/scanorama.html",
    "title": "Scanorama",
    "section": "",
    "text": "ID: scanorama\nNamespace: integrate\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/integrate/scanorama.html#example-commands",
    "href": "components/modules/integrate/scanorama.html#example-commands",
    "title": "Scanorama",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/integrate/scanorama/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"path/to/file\"\nmodality: \"rna\"\n# output: \"$id.$key.output.h5ad\"\n# output_compression: \"gzip\"\nobs_batch: \"batch\"\nobsm_input: \"X_pca\"\nobsm_output: \"X_scanorama\"\nknn: 20\nbatch_size: 5000\nsigma: 15\napprox: true\nalpha: 0.1\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/integrate/scanorama/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/integrate/scanorama.html#argument-group",
    "href": "components/modules/integrate/scanorama.html#argument-group",
    "title": "Scanorama",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--output\nOutput .h5mu file\nfile, required, default: \"output.h5ad\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obs_batch\nColumn name discriminating between your batches.\nstring, default: \"batch\"\n\n\n--obsm_input\nBasis obsm slot to run scanorama on.\nstring, default: \"X_pca\"\n\n\n--obsm_output\nThe name of the field in adata.obsm where the integrated embeddings will be stored after running this function. Defaults to X_scanorama.\nstring, default: \"X_scanorama\"\n\n\n--knn\nNumber of nearest neighbors to use for matching.\ninteger, default: 20\n\n\n--batch_size\nThe batch size used in the alignment vector computation. Useful when integrating very large (&gt;100k samples) datasets. Set to large value that runs within available memory.\ninteger, default: 5000\n\n\n--sigma\nCorrection smoothing parameter on Gaussian kernel.\ndouble, default: 15\n\n\n--approx\nUse approximate nearest neighbors with Python annoy; greatly speeds up matching runtime.\nboolean, default: TRUE\n\n\n--alpha\nAlignment score minimum cutoff\ndouble, default: 0.1"
  },
  {
    "objectID": "components/modules/integrate/scanorama.html#authors",
    "href": "components/modules/integrate/scanorama.html#authors",
    "title": "Scanorama",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (author)\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/qc/fastqc.html",
    "href": "components/modules/qc/fastqc.html",
    "title": "Fastqc",
    "section": "",
    "text": "ID: fastqc\nNamespace: qc\n\n\n\nSource\nThis component can take one or more files (by means of shell globbing) or a complete directory"
  },
  {
    "objectID": "components/modules/qc/fastqc.html#example-commands",
    "href": "components/modules/qc/fastqc.html#example-commands",
    "title": "Fastqc",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/qc/fastqc/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\nmode: \"files\"\ninput: # please fill in - example: \"fastq_dir/\"\n# output: \"$id.$key.output.output\"\n# threads: 123\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/qc/fastqc/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/qc/fastqc.html#argument-group",
    "href": "components/modules/qc/fastqc.html#argument-group",
    "title": "Fastqc",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--mode\nThe mode in which the component works. Can be either files or dir.\nstring, default: \"files\"\n\n\n--input\nDirectory containing input fastq files.\nfile, required, example: \"fastq_dir\"\n\n\n--output\nOutput directory to write reports to.\nfile, required, example: \"qc\"\n\n\n--threads\nSpecifies the number of files which can be processed simultaneously. Each thread will be allocated 250MB of memory.\ninteger"
  },
  {
    "objectID": "components/modules/qc/calculate_qc_metrics.html",
    "href": "components/modules/qc/calculate_qc_metrics.html",
    "title": "Calculate qc metrics",
    "section": "",
    "text": "ID: calculate_qc_metrics\nNamespace: qc\n\n\n\nSource\nThe metrics are comparable to what scanpy.pp.calculate_qc_metrics output, although they have slightly different names:\nVar metrics (name in this component -&gt; name in scanpy): - pct_dropout -&gt; pct_dropout_by_{expr_type} - num_nonzero_obs -&gt; n_cells_by_{expr_type} - obs_mean -&gt; mean_{expr_type} - total_counts -&gt; total_{expr_type}\nObs metrics: - num_nonzero_vars -&gt; n_genes_by_{expr_type} - pct_{var_qc_metrics]} -&gt; pct_{expr_type}{qc_var} - total_counts{var_qc_metrics} -&gt; total_{expr_type}{qc_var} - pct_of_counts_in_top{top_n_vars}vars -&gt; pct{expr_type}in_top{n}{var_type} - total_counts -&gt; total{expr_type}"
  },
  {
    "objectID": "components/modules/qc/calculate_qc_metrics.html#example-commands",
    "href": "components/modules/qc/calculate_qc_metrics.html#example-commands",
    "title": "Calculate qc metrics",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/qc/calculate_qc_metrics/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# layer: \"raw_counts\"\n# var_qc_metrics: [\"ercc\", \"highly_variable\", \"mitochondrial\"]\n# var_qc_metrics_fill_na_value: true\n# top_n_vars: [123]\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/qc/calculate_qc_metrics/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/qc/calculate_qc_metrics.html#argument-groups",
    "href": "components/modules/qc/calculate_qc_metrics.html#argument-groups",
    "title": "Calculate qc metrics",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--layer\n\nstring, example: \"raw_counts\"\n\n\n--var_qc_metrics\nKeys to select a boolean (containing only True or False) column from .var. For each cell, calculate the proportion of total values for genes which are labeled ‘True’, compared to the total sum of the values for all genes.\nList of string, example: \"ercc,highly_variable,mitochondrial\", multiple_sep: \",\"\n\n\n--var_qc_metrics_fill_na_value\nFill any ‘NA’ values found in the columns specified with –var_qc_metrics to ‘True’ or ‘False’. as False.\nboolean\n\n\n--top_n_vars\nNumber of top vars to be used to calculate cumulative proportions. If not specified, proportions are not calculated. --top_n_vars 20,50 finds cumulative proportion to the 20th and 50th most expressed vars.\nList of integer, multiple_sep: \",\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/qc/calculate_qc_metrics.html#authors",
    "href": "components/modules/qc/calculate_qc_metrics.html#authors",
    "title": "Calculate qc metrics",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (author)"
  },
  {
    "objectID": "components/modules/demux/bcl2fastq.html",
    "href": "components/modules/demux/bcl2fastq.html",
    "title": "Bcl2fastq",
    "section": "",
    "text": "ID: bcl2fastq\nNamespace: demux\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/demux/bcl2fastq.html#example-commands",
    "href": "components/modules/demux/bcl2fastq.html#example-commands",
    "title": "Bcl2fastq",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/demux/bcl2fastq/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"bcl_dir\"\nsample_sheet: # please fill in - example: \"SampleSheet.csv\"\n# output: \"$id.$key.output.output\"\n# reports: \"$id.$key.reports.reports\"\nignore_missing: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/demux/bcl2fastq/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/demux/bcl2fastq.html#argument-group",
    "href": "components/modules/demux/bcl2fastq.html#argument-group",
    "title": "Bcl2fastq",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput run directory\nfile, required, example: \"bcl_dir\"\n\n\n--sample_sheet\nPointer to the sample sheet\nfile, required, example: \"SampleSheet.csv\"\n\n\n--output\nOutput directory containig fastq files\nfile, required, example: \"fastq_dir\"\n\n\n--reports\nReports directory\nfile, example: \"reports_dir\"\n\n\n--ignore_missing\n\nboolean_true"
  },
  {
    "objectID": "components/modules/demux/bcl2fastq.html#authors",
    "href": "components/modules/demux/bcl2fastq.html#authors",
    "title": "Bcl2fastq",
    "section": "Authors",
    "text": "Authors\n\nToni Verbeiren   (author, maintainer)"
  },
  {
    "objectID": "components/modules/compression/compress_h5mu.html",
    "href": "components/modules/compression/compress_h5mu.html",
    "title": "Compress h5mu",
    "section": "",
    "text": "ID: compress_h5mu\nNamespace: compression\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/compression/compress_h5mu.html#example-commands",
    "href": "components/modules/compression/compress_h5mu.html#example-commands",
    "title": "Compress h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/compression/compress_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"sample_path\"\n# output: \"$id.$key.output.output\"\ncompression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/compression/compress_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/compression/compress_h5mu.html#argument-group",
    "href": "components/modules/compression/compress_h5mu.html#argument-group",
    "title": "Compress h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPath to the input .h5mu.\nfile, required, example: \"sample_path\"\n\n\n--output\nlocation of output file.\nfile, required\n\n\n--compression\nCompression type.\nstring, default: \"gzip\""
  },
  {
    "objectID": "components/modules/compression/compress_h5mu.html#authors",
    "href": "components/modules/compression/compress_h5mu.html#authors",
    "title": "Compress h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/neighbors/find_neighbors.html",
    "href": "components/modules/neighbors/find_neighbors.html",
    "title": "Find neighbors",
    "section": "",
    "text": "ID: find_neighbors\nNamespace: neighbors\n\n\n\nSource\nThe neighbor search efficiency of this heavily relies on UMAP [McInnes18], which also provides a method for estimating connectivities of data points - the connectivity of the manifold (method==‘umap’). If method==‘gauss’, connectivities are computed according to [Coifman05], in the adaption of [Haghverdi16]."
  },
  {
    "objectID": "components/modules/neighbors/find_neighbors.html#example-commands",
    "href": "components/modules/neighbors/find_neighbors.html#example-commands",
    "title": "Find neighbors",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/neighbors/find_neighbors/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\nobsm_input: \"X_pca\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nuns_output: \"neighbors\"\nobsp_distances: \"distances\"\nobsp_connectivities: \"connectivities\"\nmetric: \"euclidean\"\nnum_neighbors: 15\nseed: 0\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/neighbors/find_neighbors/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/neighbors/find_neighbors.html#argument-group",
    "href": "components/modules/neighbors/find_neighbors.html#argument-group",
    "title": "Find neighbors",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obsm_input\nWhich .obsm slot to use as a starting PCA embedding.\nstring, default: \"X_pca\"\n\n\n--output\nOutput h5mu file containing the found neighbors.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--uns_output\nMandatory .uns slot to store various neighbor output objects.\nstring, default: \"neighbors\"\n\n\n--obsp_distances\nIn which .obsp slot to store the distance matrix between the resulting neighbors.\nstring, default: \"distances\"\n\n\n--obsp_connectivities\nIn which .obsp slot to store the connectivities matrix between the resulting neighbors.\nstring, default: \"connectivities\"\n\n\n--metric\nThe distance metric to be used in the generation of the nearest neighborhood network.\nstring, default: \"euclidean\"\n\n\n--num_neighbors\nThe size of local neighborhood (in terms of number of neighboring data points) used for manifold approximation. Larger values result in more global views of the manifold, while smaller values result in more local data being preserved. In general values should be in the range 2 to 100. If knn is True, number of nearest neighbors to be searched. If knn is False, a Gaussian kernel width is set to the distance of the n_neighbors neighbor.\ninteger, default: 15\n\n\n--seed\nA random seed.\ninteger, default: 0"
  },
  {
    "objectID": "components/modules/neighbors/find_neighbors.html#authors",
    "href": "components/modules/neighbors/find_neighbors.html#authors",
    "title": "Find neighbors",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)\nRobrecht Cannoodt    (contributor)"
  },
  {
    "objectID": "components/modules/labels_transfer/xgboost.html",
    "href": "components/modules/labels_transfer/xgboost.html",
    "title": "Xgboost",
    "section": "",
    "text": "ID: xgboost\nNamespace: labels_transfer\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/labels_transfer/xgboost.html#example-commands",
    "href": "components/modules/labels_transfer/xgboost.html#example-commands",
    "title": "Xgboost",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/labels_transfer/xgboost/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Execution arguments\nforce_retrain: false\nuse_gpu: false\nverbosity: 1\n# model_output: \"$id.$key.model_output.model_output\"\n\n# Learning parameters\nlearning_rate: 0.3\nmin_split_loss: 0\nmax_depth: 6\nmin_child_weight: 1\nmax_delta_step: 0\nsubsample: 1\nsampling_method: \"uniform\"\ncolsample_bytree: 1\ncolsample_bylevel: 1\ncolsample_bynode: 1\nreg_lambda: 1\nreg_alpha: 0\nscale_pos_weight: 1\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/labels_transfer/xgboost/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/labels_transfer/xgboost.html#argument-groups",
    "href": "components/modules/labels_transfer/xgboost.html#argument-groups",
    "title": "Xgboost",
    "section": "Argument groups",
    "text": "Argument groups\n\nInput dataset (query) arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nThe query data to transfer the labels to. Should be a .h5mu file.\nfile, required\n\n\n--modality\nWhich modality to use.\nstring, default: \"rna\"\n\n\n--input_obsm_features\nThe .obsm key of the embedding to use for the classifier’s inference. If not provided, the .X slot will be used instead. Make sure that embedding was obtained in the same way as the reference embedding (e.g. by the same model or preprocessing).\nstring, example: \"X_integrated_scanvi\"\n\n\n\n\n\nReference dataset arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nThe reference data to train classifiers on.\nfile, example: \"https:/zenodo.org/record/6337966/files/HLCA_emb_and_metadata.h5ad\"\n\n\n--reference_obsm_features\nThe .obsm key of the embedding to use for the classifier’s training. Make sure that embedding was obtained in the same way as the query embedding (e.g. by the same model or preprocessing).\nstring, required, default: \"X_integrated_scanvi\"\n\n\n--reference_obs_targets\nThe .obs key of the target labels to tranfer.\nList of string, default: \"ann_level_1\", \"ann_level_2\", \"ann_level_3\", \"ann_level_4\", \"ann_level_5\", \"ann_finest_level\", multiple_sep: \",\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nThe query data in .h5mu format with predicted labels transfered from the reference.\nfile, required\n\n\n--output_obs_predictions\nIn which .obs slots to store the predicted information. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_pred\" suffix.\nList of string, multiple_sep: \":\"\n\n\n--output_obs_uncertainty\nIn which .obs slots to store the uncertainty of the predictions. If provided, must have the same length as --reference_obs_targets. If empty, will default to the reference_obs_targets combined with the \"_uncertainty\" suffix.\nList of string, multiple_sep: \":\"\n\n\n--output_uns_parameters\nThe .uns key to store additional information about the parameters used for the label transfer.\nstring, default: \"labels_transfer\"\n\n\n\n\n\nExecution arguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--force_retrain\nRetrain models on the reference even if model_output directory already has trained classifiers. WARNING! It will rewrite existing classifiers for targets in the model_output directory!\nboolean_true\n\n\n--use_gpu\nUse GPU during models training and inference (recommended).\nboolean, default: FALSE\n\n\n--verbosity\nThe verbosity level for evaluation of the classifier from the range [0,2]\ninteger, default: 1\n\n\n--model_output\nOutput directory for model\nfile, default: \"model\"\n\n\n\n\n\nLearning parameters\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--learning_rate\nStep size shrinkage used in update to prevents overfitting. Range: [0,1]. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 0.3\n\n\n--min_split_loss\nMinimum loss reduction required to make a further partition on a leaf node of the tree. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 0\n\n\n--max_depth\nMaximum depth of a tree. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ninteger, default: 6\n\n\n--min_child_weight\nMinimum sum of instance weight (hessian) needed in a child. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ninteger, default: 1\n\n\n--max_delta_step\nMaximum delta step we allow each leaf output to be. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 0\n\n\n--subsample\nSubsample ratio of the training instances. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--sampling_method\nThe method to use to sample the training instances. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\nstring, default: \"uniform\"\n\n\n--colsample_bytree\nFraction of columns to be subsampled. Range (0, 1]. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--colsample_bylevel\nSubsample ratio of columns for each level. Range (0, 1]. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--colsample_bynode\nSubsample ratio of columns for each node (split). Range (0, 1]. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--reg_lambda\nL2 regularization term on weights. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1\n\n\n--reg_alpha\nL1 regularization term on weights. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 0\n\n\n--scale_pos_weight\nControl the balance of positive and negative weights, useful for unbalanced classes. See https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster for the reference\ndouble, default: 1"
  },
  {
    "objectID": "components/modules/labels_transfer/xgboost.html#authors",
    "href": "components/modules/labels_transfer/xgboost.html#authors",
    "title": "Xgboost",
    "section": "Authors",
    "text": "Authors\n\nVladimir Shitov    (author)"
  },
  {
    "objectID": "components/modules/filter/filter_with_scrublet.html",
    "href": "components/modules/filter/filter_with_scrublet.html",
    "title": "Filter with scrublet",
    "section": "",
    "text": "ID: filter_with_scrublet\nNamespace: filter\n\n\n\nSource\nThe method tests for potential doublets by using the expression profiles of cells to generate synthetic potential doubles which are tested against cells. The method returns a “doublet score” on which it calls for potential doublets.\nFor the source code please visit https://github.com/AllonKleinLab/scrublet.\nFor 10x we expect the doublet rates to be: Multiplet Rate (%) - # of Cells Loaded - # of Cells Recovered ~0.4% ~800 ~500 ~0.8% ~1,600 ~1,000 ~1.6% ~3,200 ~2,000 ~2.3% ~4,800 ~3,000 ~3.1% ~6,400 ~4,000 ~3.9% ~8,000 ~5,000 ~4.6% ~9,600 ~6,000 ~5.4% ~11,200 ~7,000 ~6.1% ~12,800 ~8,000 ~6.9% ~14,400 ~9,000 ~7.6% ~16,000 ~10,000"
  },
  {
    "objectID": "components/modules/filter/filter_with_scrublet.html#example-commands",
    "href": "components/modules/filter/filter_with_scrublet.html#example-commands",
    "title": "Filter with scrublet",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/filter/filter_with_scrublet/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobs_name_filter: \"filter_with_scrublet\"\ndo_subset: false\nobs_name_doublet_score: \"scrublet_doublet_score\"\nmin_counts: 2\nmin_cells: 3\nmin_gene_variablity_percent: 85\nnum_pca_components: 30\ndistance_metric: \"euclidean\"\nallow_automatic_threshold_detection_fail: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/filter_with_scrublet/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/filter_with_scrublet.html#argument-group",
    "href": "components/modules/filter/filter_with_scrublet.html#argument-group",
    "title": "Filter with scrublet",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obs_name_filter\nIn which .obs slot to store a boolean array corresponding to which observations should be filtered out.\nstring, default: \"filter_with_scrublet\"\n\n\n--do_subset\nWhether to subset before storing the output.\nboolean_true\n\n\n--obs_name_doublet_score\nName of the doublet scores column in the obs slot of the returned object.\nstring, default: \"scrublet_doublet_score\"\n\n\n--min_counts\nThe number of minimal UMI counts per cell that have to be present for initial cell detection.\ninteger, default: 2\n\n\n--min_cells\nThe number of cells in which UMIs for a gene were detected.\ninteger, default: 3\n\n\n--min_gene_variablity_percent\nUsed for gene filtering prior to PCA. Keep the most highly variable genes (in the top min_gene_variability_pctl percentile), as measured by the v-statistic [Klein et al., Cell 2015].\ndouble, default: 85\n\n\n--num_pca_components\nNumber of principal components to use during PCA dimensionality reduction.\ninteger, default: 30\n\n\n--distance_metric\nThe distance metric used for computing similarities.\nstring, default: \"euclidean\"\n\n\n--allow_automatic_threshold_detection_fail\nWhen scrublet fails to automatically determine the double score threshold, allow the component to continue and set the output columns to NA.\nboolean_true"
  },
  {
    "objectID": "components/modules/filter/filter_with_scrublet.html#authors",
    "href": "components/modules/filter/filter_with_scrublet.html#authors",
    "title": "Filter with scrublet",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (contributor)\nRobrecht Cannoodt    (maintainer, contributor)"
  },
  {
    "objectID": "components/modules/filter/subset_h5mu.html",
    "href": "components/modules/filter/subset_h5mu.html",
    "title": "Subset h5mu",
    "section": "",
    "text": "ID: subset_h5mu\nNamespace: filter\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/filter/subset_h5mu.html#example-commands",
    "href": "components/modules/filter/subset_h5mu.html#example-commands",
    "title": "Subset h5mu",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/filter/subset_h5mu/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n# number_of_observations: 5\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/subset_h5mu/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/subset_h5mu.html#argument-group",
    "href": "components/modules/filter/subset_h5mu.html#argument-group",
    "title": "Subset h5mu",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--number_of_observations\nNumber of observations to be selected from the h5mu file.\ninteger, example: 5"
  },
  {
    "objectID": "components/modules/filter/subset_h5mu.html#authors",
    "href": "components/modules/filter/subset_h5mu.html#authors",
    "title": "Subset h5mu",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/filter/do_filter.html",
    "href": "components/modules/filter/do_filter.html",
    "title": "Do filter",
    "section": "",
    "text": "ID: do_filter\nNamespace: filter\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/filter/do_filter.html#example-commands",
    "href": "components/modules/filter/do_filter.html#example-commands",
    "title": "Do filter",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/filter/do_filter/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# obs_filter: [\"filter_with_x\"]\n# var_filter: [\"filter_with_x\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/filter/do_filter/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/filter/do_filter.html#argument-group",
    "href": "components/modules/filter/do_filter.html#argument-group",
    "title": "Do filter",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--obs_filter\nWhich .obs columns to use to filter the observations by.\nList of string, example: \"filter_with_x\", multiple_sep: \":\"\n\n\n--var_filter\nWhich .var columns to use to filter the observations by.\nList of string, example: \"filter_with_x\", multiple_sep: \":\"\n\n\n--output\nOutput h5mu file.\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/filter/do_filter.html#authors",
    "href": "components/modules/filter/do_filter.html#authors",
    "title": "Do filter",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer, contributor)"
  },
  {
    "objectID": "components/modules/dataflow/merge.html",
    "href": "components/modules/dataflow/merge.html",
    "title": "Merge",
    "section": "",
    "text": "ID: merge\nNamespace: dataflow\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/dataflow/merge.html#example-commands",
    "href": "components/modules/dataflow/merge.html#example-commands",
    "title": "Merge",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/dataflow/merge/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: [\"sample_paths\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dataflow/merge/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/dataflow/merge.html#argument-group",
    "href": "components/modules/dataflow/merge.html#argument-group",
    "title": "Merge",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPaths to the single-modality .h5mu files that need to be combined\nList of file, required, default: \"sample_paths\", multiple_sep: \",\"\n\n\n--output\nPath to the output file.\nfile, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/dataflow/merge.html#authors",
    "href": "components/modules/dataflow/merge.html#authors",
    "title": "Merge",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/dataflow/concat.html",
    "href": "components/modules/dataflow/concat.html",
    "title": "Concat",
    "section": "",
    "text": "ID: concat\nNamespace: dataflow\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/dataflow/concat.html#example-commands",
    "href": "components/modules/dataflow/concat.html#example-commands",
    "title": "Concat",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/dataflow/concat/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: [\"sample_paths\"]\n# input_id: [\"foo\"]\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nobs_sample_name: \"sample_id\"\nother_axis_mode: \"move\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/dataflow/concat/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/dataflow/concat.html#argument-group",
    "href": "components/modules/dataflow/concat.html#argument-group",
    "title": "Concat",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nPaths to the different samples to be concatenated.\nList of file, required, example: \"sample_paths\", multiple_sep: \",\"\n\n\n--input_id\nNames of the different samples that have to be concatenated. Must be specified when using ‘–mode move’. In this case, the ids will be used for the columns names of the dataframes registring the conflicts. If specified, must be of same length as --input.\nList of string, multiple_sep: \",\"\n\n\n--output\n\nfile, example: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--obs_sample_name\nName of the .obs key under which to add the sample names.\nstring, default: \"sample_id\"\n\n\n--other_axis_mode\nHow to handle the merging of other axis (var, obs, …). - None: keep no data - same: only keep elements of the matrices which are the same in each of the samples - unique: only keep elements for which there is only 1 possible value (1 value that can occur in multiple samples) - first: keep the annotation from the first sample - only: keep elements that show up in only one of the objects (1 unique element in only 1 sample) - move: identical to ‘same’, but moving the conflicting values to .varm or .obsm\nstring, default: \"move\""
  },
  {
    "objectID": "components/modules/dataflow/concat.html#authors",
    "href": "components/modules/dataflow/concat.html#authors",
    "title": "Concat",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/annotate/popv.html",
    "href": "components/modules/annotate/popv.html",
    "title": "Popv",
    "section": "",
    "text": "ID: popv\nNamespace: annotate\n\n\n\nSource\nNote that this is a one-shot version of PopV."
  },
  {
    "objectID": "components/modules/annotate/popv.html#example-commands",
    "href": "components/modules/annotate/popv.html#example-commands",
    "title": "Popv",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/annotate/popv/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# input_obs_batch: \"foo\"\n# input_var_subset: \"foo\"\n# input_obs_label: \"foo\"\nunknown_celltype_label: \"unknown\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Arguments\nmethods: # please fill in - example: [\"knn_on_scvi\", \"scanvi\"]\n\n# Reference\nreference: # please fill in - example: \"TS_Bladder_filtered.h5ad\"\n# reference_layer: \"foo\"\nreference_obs_label: \"cell_ontology_class\"\nreference_obs_batch: \"donor_assay\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/annotate/popv/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/annotate/popv.html#argument-groups",
    "href": "components/modules/annotate/popv.html#argument-groups",
    "title": "Popv",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\nArguments related to the input (aka query) dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nWhich modality to process.\nstring, default: \"rna\"\n\n\n--input_layer\nWhich layer to use. If no value is provided, the counts are assumed to be in the .X slot. Otherwise, count data is expected to be in .layers[input_layer].\nstring\n\n\n--input_obs_batch\nKey in obs field of input adata for batch information. If no value is provided, batch label is assumed to be unknown.\nstring\n\n\n--input_var_subset\nSubset the input object with this column.\nstring\n\n\n--input_obs_label\nKey in obs field of input adata for label information. This is only used for training scANVI. Unlabelled cells should be set to \"unknown_celltype_label\".\nstring\n\n\n--unknown_celltype_label\nIf input_obs_label is specified, cells with this value will be treated as unknown and will be predicted by the model.\nstring, default: \"unknown\"\n\n\n\n\n\nReference\nArguments related to the reference dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--reference\nUser-provided reference tissue. The data that will be used as reference to call cell types.\nfile, required, example: \"TS_Bladder_filtered.h5ad\"\n\n\n--reference_layer\nWhich layer to use. If no value is provided, the counts are assumed to be in the .X slot. Otherwise, count data is expected to be in .layers[reference_layer].\nstring\n\n\n--reference_obs_label\nKey in obs field of reference AnnData with cell-type information.\nstring, default: \"cell_ontology_class\"\n\n\n--reference_obs_batch\nKey in obs field of input adata for batch information.\nstring, default: \"donor_assay\"\n\n\n\n\n\nOutputs\nOutput arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n\n\n\nArguments\nOther arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--methods\nMethods to call cell types. By default, runs to knn_on_scvi and scanvi.\nList of string, required, example: \"knn_on_scvi\", \"scanvi\", multiple_sep: \":\""
  },
  {
    "objectID": "components/modules/annotate/popv.html#authors",
    "href": "components/modules/annotate/popv.html#authors",
    "title": "Popv",
    "section": "Authors",
    "text": "Authors\n\nMatthias Beyens    (author)\nRobrecht Cannoodt    (author)"
  },
  {
    "objectID": "components/modules/transform/clr.html",
    "href": "components/modules/transform/clr.html",
    "title": "Clr",
    "section": "",
    "text": "ID: clr\nNamespace: transform\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/transform/clr.html#example-commands",
    "href": "components/modules/transform/clr.html#example-commands",
    "title": "Clr",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/transform/clr/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"prot\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n# output_layer: \"foo\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/clr/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transform/clr.html#argument-group",
    "href": "components/modules/transform/clr.html#argument-group",
    "title": "Clr",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"prot\"\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--output_layer\nOutput layer to use. By default, use X.\nstring"
  },
  {
    "objectID": "components/modules/transform/clr.html#authors",
    "href": "components/modules/transform/clr.html#authors",
    "title": "Clr",
    "section": "Authors",
    "text": "Authors\n\nDries Schaumont    (maintainer)"
  },
  {
    "objectID": "components/modules/transform/regress_out.html",
    "href": "components/modules/transform/regress_out.html",
    "title": "Regress out",
    "section": "",
    "text": "ID: regress_out\nNamespace: transform\n\n\n\nSource\nUses simple linear regression. This is inspired by Seurat’s regressOut function in R [Satija15]. Note that this function tends to overcorrect in certain circumstances as described in issue theislab/scanpy#526. See https://github.com/theislab/scanpy/issues/526"
  },
  {
    "objectID": "components/modules/transform/regress_out.html#example-commands",
    "href": "components/modules/transform/regress_out.html#example-commands",
    "title": "Regress out",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/transform/regress_out/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nmodality: \"rna\"\n# obs_keys: [\"foo\"]\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/regress_out/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transform/regress_out.html#argument-group",
    "href": "components/modules/transform/regress_out.html#argument-group",
    "title": "Regress out",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--modality\nWhich modality (one or more) to run this component on.\nstring, default: \"rna\"\n\n\n--obs_keys\nWhich .obs keys to regress on.\nList of string, multiple_sep: \":\""
  },
  {
    "objectID": "components/modules/transform/regress_out.html#authors",
    "href": "components/modules/transform/regress_out.html#authors",
    "title": "Regress out",
    "section": "Authors",
    "text": "Authors\n\nRobrecht Cannoodt    (maintainer, contributor)"
  },
  {
    "objectID": "components/modules/transform/normalize_total.html",
    "href": "components/modules/transform/normalize_total.html",
    "title": "Normalize total",
    "section": "",
    "text": "ID: normalize_total\nNamespace: transform\n\n\n\nSource\nNormalize each cell by total counts over all genes, so that every cell has the same total count after normalization. If choosing target_sum=1e6, this is CPM normalization.\nIf exclude_highly_expressed=True, very highly expressed genes are excluded from the computation of the normalization factor (size factor) for each cell. This is meaningful as these can strongly influence the resulting normalized values for all other genes [Weinreb17]."
  },
  {
    "objectID": "components/modules/transform/normalize_total.html#example-commands",
    "href": "components/modules/transform/normalize_total.html#example-commands",
    "title": "Normalize total",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/transform/normalize_total/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n# input_layer: \"foo\"\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n# output_layer: \"foo\"\ntarget_sum: 10000\nexclude_highly_expressed: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/transform/normalize_total/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/transform/normalize_total.html#argument-group",
    "href": "components/modules/transform/normalize_total.html#argument-group",
    "title": "Normalize total",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file\nfile, required, example: \"input.h5mu\"\n\n\n--modality\n\nstring, default: \"rna\"\n\n\n--input_layer\nInput layer to use. By default, X is normalized\nstring\n\n\n--output\nOutput h5mu file.\nfile, required, default: \"output.h5mu\"\n\n\n--output_compression\nThe compression format to be used on the output h5mu object.\nstring, example: \"gzip\"\n\n\n--output_layer\nOutput layer to use. By default, use X.\nstring\n\n\n--target_sum\nIf None, after normalization, each observation (cell) has a total count equal to the median of total counts for observations (cells) before normalization.\ninteger, default: 10000\n\n\n--exclude_highly_expressed\nExclude (very) highly expressed genes for the computation of the normalization factor (size factor) for each cell. A gene is considered highly expressed, if it has more than max_fraction of the total counts in at least one cell. The not-excluded genes will sum up to target_sum.\nboolean_true"
  },
  {
    "objectID": "components/modules/transform/normalize_total.html#authors",
    "href": "components/modules/transform/normalize_total.html#authors",
    "title": "Normalize total",
    "section": "Authors",
    "text": "Authors\n\nDries De Maeyer   (maintainer)\nRobrecht Cannoodt    (contributor)"
  },
  {
    "objectID": "components/modules/reference/build_bdrhap_reference.html",
    "href": "components/modules/reference/build_bdrhap_reference.html",
    "title": "Build bdrhap reference",
    "section": "",
    "text": "ID: build_bdrhap_reference\nNamespace: reference\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/reference/build_bdrhap_reference.html#example-commands",
    "href": "components/modules/reference/build_bdrhap_reference.html#example-commands",
    "title": "Build bdrhap reference",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/reference/build_bdrhap_reference/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Arguments\ngenome_fasta: # please fill in - example: \"genome_sequence.fa.gz\"\ntranscriptome_gtf: # please fill in - example: \"transcriptome_annotation.gtf.gz\"\n# output: \"$id.$key.output.gz\"\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/reference/build_bdrhap_reference/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/reference/build_bdrhap_reference.html#argument-group",
    "href": "components/modules/reference/build_bdrhap_reference.html#argument-group",
    "title": "Build bdrhap reference",
    "section": "Argument group",
    "text": "Argument group\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--genome_fasta\nReference genome fasta.\nfile, required, example: \"genome_sequence.fa.gz\"\n\n\n--transcriptome_gtf\nReference transcriptome annotation.\nfile, required, example: \"transcriptome_annotation.gtf.gz\"\n\n\n--output\nStar index\nfile, required, example: \"star_index.tar.gz\""
  },
  {
    "objectID": "components/modules/reference/build_bdrhap_reference.html#authors",
    "href": "components/modules/reference/build_bdrhap_reference.html#authors",
    "title": "Build bdrhap reference",
    "section": "Authors",
    "text": "Authors\n\nAngela Oliveira Pisco    (author)\nRobrecht Cannoodt    (author, maintainer)"
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background.html",
    "href": "components/modules/correction/cellbender_remove_background.html",
    "title": "Cellbender remove background",
    "section": "",
    "text": "ID: cellbender_remove_background\nNamespace: correction\n\n\n\nSource\nThis module removes counts due to ambient RNA molecules and random barcode swapping from (raw) UMI-based scRNA-seq count matrices. At the moment, only the count matrices produced by the CellRanger count pipeline is supported. Support for additional tools and protocols will be added in the future. A quick start tutorial can be found here.\nFleming et al. 2022, bioRxiv."
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background.html#example-commands",
    "href": "components/modules/correction/cellbender_remove_background.html#example-commands",
    "title": "Cellbender remove background",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/correction/cellbender_remove_background/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput: # please fill in - example: \"input.h5mu\"\nmodality: \"rna\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\nlayer_output: \"cellbender_corrected\"\nobs_background_fraction: \"cellbender_background_fraction\"\nobs_cell_probability: \"cellbender_cell_probability\"\nobs_cell_size: \"cellbender_cell_size\"\nobs_droplet_efficiency: \"cellbender_droplet_efficiency\"\nobs_latent_scale: \"cellbender_latent_scale\"\nvar_ambient_expression: \"cellbender_ambient_expression\"\nobsm_gene_expression_encoding: \"cellbender_gene_expression_encoding\"\n\n# Arguments\nexpected_cells_from_qc: false\n# expected_cells: 1000\n# total_droplets_included: 25000\n# force_cell_umi_prior: 123\n# force_empty_umi_prior: 123\nmodel: \"full\"\nepochs: 150\nlow_count_threshold: 5\nz_dim: 64\nz_layers: [512]\ntraining_fraction: 0.9\nempty_drop_training_fraction: 0.2\n# ignore_features: [123]\nfpr: [0.01]\n# exclude_feature_types: [\"foo\"]\nprojected_ambient_count_threshold: 0.1\nlearning_rate: 1.0E-4\n# final_elbo_fail_fraction: 123.0\n# epoch_elbo_fail_fraction: 123.0\nnum_training_tries: 1\nlearning_rate_retry_mult: 0.2\nposterior_batch_size: 128\n# posterior_regulation: \"foo\"\n# alpha: 123.0\n# q: 123.0\nestimator: \"mckp\"\nestimator_multiple_cpu: false\n# constant_learning_rate: true\ndebug: false\ncuda: false\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/correction/cellbender_remove_background/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/correction/cellbender_remove_background.html#argument-groups",
    "href": "components/modules/correction/cellbender_remove_background.html#argument-groups",
    "title": "Cellbender remove background",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input\nInput h5mu file. Data file on which to run tool. Data must be un-filtered: it should include empty droplets.\nfile, required, example: \"input.h5mu\"\n\n\n--modality\nList of modalities to process.\nstring, default: \"rna\"\n\n\n\n\n\nOutputs\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nFull count matrix as an h5mu file, with background RNA removed. This file contains all the original droplet barcodes.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\"\n\n\n--layer_output\nOutput layer\nstring, default: \"cellbender_corrected\"\n\n\n--obs_background_fraction\n\nstring, default: \"cellbender_background_fraction\"\n\n\n--obs_cell_probability\n\nstring, default: \"cellbender_cell_probability\"\n\n\n--obs_cell_size\n\nstring, default: \"cellbender_cell_size\"\n\n\n--obs_droplet_efficiency\n\nstring, default: \"cellbender_droplet_efficiency\"\n\n\n--obs_latent_scale\n\nstring, default: \"cellbender_latent_scale\"\n\n\n--var_ambient_expression\n\nstring, default: \"cellbender_ambient_expression\"\n\n\n--obsm_gene_expression_encoding\n\nstring, default: \"cellbender_gene_expression_encoding\"\n\n\n\n\n\nArguments\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--expected_cells_from_qc\nWill use the Cell Ranger QC to determine the estimated number of cells\nboolean, default: FALSE\n\n\n--expected_cells\nNumber of cells expected in the dataset (a rough estimate within a factor of 2 is sufficient).\ninteger, example: 1000\n\n\n--total_droplets_included\nThe number of droplets from the rank-ordered UMI plot that will have their cell probabilities inferred as an output. Include the droplets which might contain cells. Droplets beyond TOTAL_DROPLETS_INCLUDED should be ‘surely empty’ droplets.\ninteger, example: 25000\n\n\n--force_cell_umi_prior\nIgnore CellBender’s heuristic prior estimation, and use this prior for UMI counts in cells.\ninteger\n\n\n--force_empty_umi_prior\nIgnore CellBender’s heuristic prior estimation, and use this prior for UMI counts in empty droplets.\ninteger\n\n\n--model\nWhich model is being used for count data. * ‘naive’ subtracts the estimated ambient profile. * ‘simple’ does not model either ambient RNA or random barcode swapping (for debugging purposes – not recommended). * ‘ambient’ assumes background RNA is incorporated into droplets. * ‘swapping’ assumes background RNA comes from random barcode swapping (via PCR chimeras). * ‘full’ uses a combined ambient and swapping model.\nstring, default: \"full\"\n\n\n--epochs\nNumber of epochs to train.\ninteger, default: 150\n\n\n--low_count_threshold\nDroplets with UMI counts below this number are completely excluded from the analysis. This can help identify the correct prior for empty droplet counts in the rare case where empty counts are extremely high (over 200).\ninteger, default: 5\n\n\n--z_dim\nDimension of latent variable z.\ninteger, default: 64\n\n\n--z_layers\nDimension of hidden layers in the encoder for z.\nList of integer, default: 512, multiple_sep: \":\"\n\n\n--training_fraction\nTraining detail: the fraction of the data used for training. The rest is never seen by the inference algorithm. Speeds up learning.\ndouble, default: 0.9\n\n\n--empty_drop_training_fraction\nTraining detail: the fraction of the training data each epoch that is drawn (randomly sampled) from surely empty droplets.\ndouble, default: 0.2\n\n\n--ignore_features\nInteger indices of features to ignore entirely. In the output count matrix, the counts for these features will be unchanged.\nList of integer, multiple_sep: \":\"\n\n\n--fpr\nTarget ‘delta’ false positive rate in [0, 1). Use 0 for a cohort of samples which will be jointly analyzed for differential expression. A false positive is a true signal count that is erroneously removed. More background removal is accompanied by more signal removal at high values of FPR. You can specify multiple values, which will create multiple output files.\nList of double, default: 0.01, multiple_sep: \":\"\n\n\n--exclude_feature_types\nFeature types to ignore during the analysis. These features will be left unchanged in the output file.\nList of string, multiple_sep: \":\"\n\n\n--projected_ambient_count_threshold\nControls how many features are included in the analysis, which can lead to a large speedup. If a feature is expected to have less than PROJECTED_AMBIENT_COUNT_THRESHOLD counts total in all cells (summed), then that gene is excluded, and it will be unchanged in the output count matrix. For example, PROJECTED_AMBIENT_COUNT_THRESHOLD = 0 will include all features which have even a single count in any empty droplet.\ndouble, default: 0.1\n\n\n--learning_rate\nTraining detail: lower learning rate for inference. A OneCycle learning rate schedule is used, where the upper learning rate is ten times this value. (For this value, probably do not exceed 1e-3).\ndouble, default: 1e-04\n\n\n--final_elbo_fail_fraction\nTraining is considered to have failed if (best_test_ELBO - final_test_ELBO)/(best_test_ELBO - initial_test_ELBO) &gt; FINAL_ELBO_FAIL_FRACTION. Training will automatically re-run if –num-training-tries &gt; 1. By default, will not fail training based on final_training_ELBO.\ndouble\n\n\n--epoch_elbo_fail_fraction\nTraining is considered to have failed if (previous_epoch_test_ELBO - current_epoch_test_ELBO)/(previous_epoch_test_ELBO - initial_train_ELBO) &gt; EPOCH_ELBO_FAIL_FRACTION. Training will automatically re-run if –num-training-tries &gt; 1. By default, will not fail training based on epoch_training_ELBO.\ndouble\n\n\n--num_training_tries\nNumber of times to attempt to train the model. At each subsequent attempt, the learning rate is multiplied by LEARNING_RATE_RETRY_MULT.\ninteger, default: 1\n\n\n--learning_rate_retry_mult\nLearning rate is multiplied by this amount each time a new training attempt is made. (This parameter is only used if training fails based on EPOCH_ELBO_FAIL_FRACTION or FINAL_ELBO_FAIL_FRACTION and NUM_TRAINING_TRIES is &gt; 1.)\ndouble, default: 0.2\n\n\n--posterior_batch_size\nTraining detail: size of batches when creating the posterior. Reduce this to avoid running out of GPU memory creating the posterior (will be slower).\ninteger, default: 128\n\n\n--posterior_regulation\nPosterior regularization method. (For experts: not required for normal usage, see documentation). * PRq is approximate quantile-targeting. * PRmu is approximate mean-targeting aggregated over genes (behavior of v0.2.0). * PRmu_gene is approximate mean-targeting per gene.\nstring\n\n\n--alpha\nTunable parameter alpha for the PRq posterior regularization method (not normally used: see documentation).\ndouble\n\n\n--q\nTunable parameter q for the CDF threshold estimation method (not normally used: see documentation).\ndouble\n\n\n--estimator\nOutput denoised count estimation method. (For experts: not required for normal usage, see documentation).\nstring, default: \"mckp\"\n\n\n--estimator_multiple_cpu\nIncluding the flag –estimator-multiple-cpu will use more than one CPU to compute the MCKP output count estimator in parallel (does nothing for other estimators).\nboolean_true\n\n\n--constant_learning_rate\nIncluding the flag –constant-learning-rate will use the ClippedAdam optimizer instead of the OneCycleLR learning rate schedule, which is the default. Learning is faster with the OneCycleLR schedule. However, training can easily be continued from a checkpoint for more epochs than the initial command specified when using ClippedAdam. On the other hand, if using the OneCycleLR schedule with 150 epochs specified, it is not possible to pick up from that final checkpoint and continue training until 250 epochs.\nboolean\n\n\n--debug\nIncluding the flag –debug will log extra messages useful for debugging.\nboolean_true\n\n\n--cuda\nIncluding the flag –cuda will run the inference on a GPU.\nboolean_true"
  },
  {
    "objectID": "components/modules/query/cellxgene_census.html",
    "href": "components/modules/query/cellxgene_census.html",
    "title": "Cellxgene census",
    "section": "",
    "text": "ID: cellxgene_census\nNamespace: query\n\n\n\nSource"
  },
  {
    "objectID": "components/modules/query/cellxgene_census.html#example-commands",
    "href": "components/modules/query/cellxgene_census.html#example-commands",
    "title": "Cellxgene census",
    "section": "Example commands",
    "text": "Example commands\nYou can run the pipeline using nextflow run.\n\nView help\nYou can use --help as a parameter to get an overview of the possible parameters.\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -main-script target/nextflow/query/cellxgene_census/main.nf \\\n  --help\n\n\nRun command\n\n\nExample of params.yaml\n\n# Inputs\ninput_database: \"CellxGene\"\nmodality: \"rna\"\ncellxgene_release: \"2023-05-15\"\n\n# Outputs\n# output: \"$id.$key.output.h5mu\"\n# output_compression: \"gzip\"\n\n# Query\nspecies: \"homo_sapiens\"\n# cell_query: \"is_primary_data == True and cell_type_ontology_term_id in ['CL:0000136', 'CL:1000311', 'CL:0002616'] and suspension_type == 'cell'\"\n# cells_filter_columns: [\"dataset_id\", \"tissue\", \"assay\", \"disease\", \"cell_type\"]\n# min_cells_filter_columns: 100\n\n# Nextflow input-output arguments\npublish_dir: # please fill in - example: \"output/\"\n# param_list: \"my_params.yaml\"\n\nnextflow run openpipelines-bio/openpipeline \\\n  -r 0.11.3 -latest \\\n  -profile docker \\\n  -main-script target/nextflow/query/cellxgene_census/main.nf \\\n  -params-file params.yaml\n\n\n\n\n\n\nNote\n\n\n\nReplace -profile docker with -profile podman or -profile singularity depending on the desired backend."
  },
  {
    "objectID": "components/modules/query/cellxgene_census.html#argument-groups",
    "href": "components/modules/query/cellxgene_census.html#argument-groups",
    "title": "Cellxgene census",
    "section": "Argument groups",
    "text": "Argument groups\n\nInputs\nArguments related to the input (aka query) dataset.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--input_database\nFull input database S3 prefix URL. Default: CellxGene Census\nstring, default: \"CellxGene\", example: \"s3://\"\n\n\n--modality\nWhich modality to store the output in.\nstring, default: \"rna\"\n\n\n--cellxgene_release\nCellxGene Census release date. More information: https://chanzuckerberg.github.io/cellxgene-census/cellxgene_census_docsite_data_release_info.html\nstring, default: \"2023-05-15\"\n\n\n\n\n\nQuery\nArguments related to the query.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--species\nSpecie(s) of interest. If not specified, Homo Sapiens will be queried.\nstring, default: \"homo_sapiens\", example: \"homo_sapiens\"\n\n\n--cell_query\nThe query for selecting the cells as defined by the cellxgene census schema.\nstring, example: \"is_primary_data == True and cell_type_ontology_term_id in ['CL:0000136', 'CL:1000311', 'CL:0002616'] and suspension_type == 'cell'\"\n\n\n--cells_filter_columns\nThe query for selecting the cells as defined by the cellxgene census schema.\nList of string, example: \"dataset_id\", \"tissue\", \"assay\", \"disease\", \"cell_type\", multiple_sep: \":\"\n\n\n--min_cells_filter_columns\nMinimum of amount of summed cells_filter_columns cells\ndouble, example: 100\n\n\n\n\n\nOutputs\nOutput arguments.\n\n\n\n\n\n\n\n\nName\nDescription\nAttributes\n\n\n\n\n--output\nOutput h5mu file.\nfile, required, example: \"output.h5mu\"\n\n\n--output_compression\n\nstring, example: \"gzip\""
  },
  {
    "objectID": "components/modules/query/cellxgene_census.html#authors",
    "href": "components/modules/query/cellxgene_census.html#authors",
    "title": "Cellxgene census",
    "section": "Authors",
    "text": "Authors\n\nMatthias Beyens   \nDries De Maeyer   (author)"
  }
]